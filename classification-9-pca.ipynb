{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b9c264d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: plotly in ./python-env/lib/python3.6/site-packages (5.8.2)\r\n",
      "Requirement already satisfied: tenacity>=6.2.0 in ./python-env/lib/python3.6/site-packages (from plotly) (8.0.1)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install plotly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c32e90fa",
   "metadata": {
    "id": "c32e90fa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import random\n",
    "import math\n",
    "\n",
    "from numpy import mean, std\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,  cross_val_score, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import get_scorer, make_scorer, confusion_matrix, classification_report, recall_score, precision_score, accuracy_score, fbeta_score, roc_curve, roc_auc_score, f1_score, confusion_matrix, mean_squared_error, log_loss\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "from warnings import simplefilter\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "simplefilter(\"ignore\", category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e97763",
   "metadata": {
    "id": "b4e97763"
   },
   "outputs": [],
   "source": [
    "path = \"/Users/yaeerk/Documents/NAYA/classification/\"\n",
    "jobs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be32050a",
   "metadata": {
    "id": "be32050a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'PROTECT_and_RISK_shared_DEGs_NOT NORM.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40272eb6",
   "metadata": {
    "id": "40272eb6"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Diagnosis', axis = 1)\n",
    "y = df.Diagnosis\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "numerical_cols = X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa04d5bd",
   "metadata": {
    "id": "aa04d5bd"
   },
   "outputs": [],
   "source": [
    "tab = \"  \"\n",
    "testsizes = [0.08, 0.1, 0.15, 0.2]\n",
    "#randomstates = [132, 400, 1440, 1600, 2500, 3333, 4567]\n",
    "randomstates = [250, 650, 850, 1050, 1250, 1850, 2050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b49851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score, test score, train score, test variance, train variance, test rmse, train rmse, test log_loss, train log_loss, test size, random state, estimator, estimator params]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pca params\n",
    "ncomponentss = [2, 3, 5, 10, 15, 25, 50, 100]\n",
    "\n",
    "#cross validation\n",
    "cv = 5\n",
    "\n",
    "#scores we want\n",
    "scores = ['f1', 'accuracy']\n",
    "\n",
    "results = pd.DataFrame(columns = [\"score\", \"test score\", \"train score\", \"test variance\", \"train variance\", \"test rmse\", \"train rmse\", \"test log_loss\", \"train log_loss\", \"test size\", \"random state\", \"estimator\", \"estimator params\"])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b845754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9447023000880703 using:10,10\n",
      "            train score: 0.958075887687827 with variance: 1.2175329337044011e-05\n",
      "            test  score: 0.9447023000880703 with variance: 0.0007971853957678977\n",
      "          Refitted train score: 0.956140350877193,  RMSE: 0.20896918976428644, Log-Loss:1.5082592233080474\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9453655040611562 using:10,10\n",
      "            train score: 0.958513125176814 with variance: 1.0283989006437225e-05\n",
      "            test  score: 0.9453655040611562 with variance: 0.0007246392030039381\n",
      "          Refitted train score: 0.9563318777292577,  RMSE: 0.20896918976428644, Log-Loss:1.5082592233080474\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9496337979137831 using:10,10\n",
      "            train score: 0.9642380464735159 with variance: 7.898952778523776e-06\n",
      "            test  score: 0.9496337979137831 with variance: 0.0007353713129902083\n",
      "          Refitted train score: 0.9626373626373625,  RMSE: 0.19266007352363126, Log-Loss:1.2820192050119938\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9497372193024367 using:10,10\n",
      "            train score: 0.9645166093417311 with variance: 6.169299092664981e-06\n",
      "            test  score: 0.9497372193024367 with variance: 0.000701753324678603\n",
      "          Refitted train score: 0.962882096069869,  RMSE: 0.19266007352363126, Log-Loss:1.2820192050119938\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.963945335307827 using:10,3\n",
      "            train score: 0.9795247897622978 with variance: 1.4801936002112944e-05\n",
      "            test  score: 0.963945335307827 with variance: 0.0010442769069140749\n",
      "          Refitted train score: 0.9778761061946903,  RMSE: 0.1477635311413854, Log-Loss:0.7541252470392306\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9649546106067846 using:10,3\n",
      "            train score: 0.9797992882774229 with variance: 1.3856773177556378e-05\n",
      "            test  score: 0.9649546106067846 with variance: 0.00093659409827174\n",
      "          Refitted train score: 0.9781659388646288,  RMSE: 0.1477635311413854, Log-Loss:0.7541252470392306\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9638834429602519 using:10,3\n",
      "            train score: 0.9839791787160209 with variance: 1.0590886732646808e-05\n",
      "            test  score: 0.9638834429602519 with variance: 0.000827920949839695\n",
      "          Refitted train score: 0.9845474613686535,  RMSE: 0.12362783988552022, Log-Loss:0.5278869745890946\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9650023889154324 using:10,3\n",
      "            train score: 0.984167895058144 with variance: 1.0201760476641433e-05\n",
      "            test  score: 0.9650023889154324 with variance: 0.0007404610595370678\n",
      "          Refitted train score: 0.9847161572052402,  RMSE: 0.12362783988552022, Log-Loss:0.5278869745890946\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.973066838209267 using:20,3\n",
      "            train score: 0.9884418028368545 with variance: 1.028505923249889e-05\n",
      "            test  score: 0.973066838209267 with variance: 0.00044072333283696276\n",
      "          Refitted train score: 0.989010989010989,  RMSE: 0.10448459488214322, Log-Loss:0.3770626235196157\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9737458193979933 using:20,3\n",
      "            train score: 0.9885379907982312 with variance: 1.009432465690856e-05\n",
      "            test  score: 0.9737458193979933 with variance: 0.000412817826764938\n",
      "          Refitted train score: 0.9890829694323144,  RMSE: 0.10448459488214322, Log-Loss:0.3770626235196157\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.973066838209267 using:20,3\n",
      "            train score: 0.9889988215756915 with variance: 9.057534709765602e-06\n",
      "            test  score: 0.973066838209267 with variance: 0.00044072333283696276\n",
      "          Refitted train score: 0.989010989010989,  RMSE: 0.10448459488214322, Log-Loss:0.3770626235196157\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9737458193979933 using:20,3\n",
      "            train score: 0.9890844388856628 with variance: 8.885257105913937e-06\n",
      "            test  score: 0.9737458193979933 with variance: 0.000412817826764938\n",
      "          Refitted train score: 0.9890829694323144,  RMSE: 0.10448459488214322, Log-Loss:0.3770626235196157\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9731687667171538 using:10,3\n",
      "            train score: 0.9939635128904876 with variance: 1.3185369716272439e-05\n",
      "            test  score: 0.9731687667171538 with variance: 0.000545410989529827\n",
      "          Refitted train score: 0.9934065934065934,  RMSE: 0.08093341918275387, Log-Loss:0.22623652660421945\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9737219302436694 using:10,3\n",
      "            train score: 0.9939950268757165 with variance: 1.3080202419486644e-05\n",
      "            test  score: 0.9737219302436694 with variance: 0.0005118248460445013\n",
      "          Refitted train score: 0.9934497816593887,  RMSE: 0.08093341918275387, Log-Loss:0.22623652660421945\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9755142948147659 using:20,3\n",
      "            train score: 0.9989070956664552 with variance: 1.791682115067413e-06\n",
      "            test  score: 0.9755142948147659 with variance: 0.0005866922507527936\n",
      "          Refitted train score: 0.9978118161925601,  RMSE: 0.046726931351599776, Log-Loss:0.07541217553474047\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9759197324414716 using:20,3\n",
      "            train score: 0.9989085927845028 with variance: 1.7867601075586788e-06\n",
      "            test  score: 0.9759197324414716 with variance: 0.0005500474929628006\n",
      "          Refitted train score: 0.9978165938864629,  RMSE: 0.046726931351599776, Log-Loss:0.07541217553474047\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9582734236310675 using:10,3\n",
      "            train score: 0.9725873901464075 with variance: 6.011456218805758e-06\n",
      "            test  score: 0.9582734236310675 with variance: 0.00036629896662901954\n",
      "          Refitted train score: 0.9781659388646288,  RMSE: 0.14712247158412492, Log-Loss:0.7475977548515105\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.19611613513818404, Log-Loss:1.3284144767273351\n",
      "        accuracy\n",
      "          CV score: 0.9589294062646097 using:10,3\n",
      "            train score: 0.972946605141727 with variance: 5.7021955955988316e-06\n",
      "            test  score: 0.9589294062646097 with variance: 0.00033965704264247315\n",
      "          Refitted train score: 0.9783549783549783,  RMSE: 0.14712247158412492, Log-Loss:0.7475977548515105\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284144767273351\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9604783958143832 using:10,3\n",
      "            train score: 0.9776235528219204 with variance: 2.8391311108950945e-05\n",
      "            test  score: 0.9604783958143832 with variance: 0.0004160947611459068\n",
      "          Refitted train score: 0.971677559912854,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "        accuracy\n",
      "          CV score: 0.9611033193080878 using:10,10\n",
      "            train score: 0.9664542591371859 with variance: 1.3214000748233175e-05\n",
      "            test  score: 0.9611033193080878 with variance: 0.0005793331222006071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466399721067772\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9610996888416243 using:10,10\n",
      "            train score: 0.9743468044222814 with variance: 5.260489343829373e-06\n",
      "            test  score: 0.9610996888416243 with variance: 0.0008989648943024748\n",
      "          Refitted train score: 0.975929978118162,  RMSE: 0.1543033499620919, Log-Loss:0.8223570111175509\n",
      "          Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "        accuracy\n",
      "          CV score: 0.9611500701262272 using:10,10\n",
      "            train score: 0.9745696916428622 with variance: 4.558690454580273e-06\n",
      "            test  score: 0.9611500701262272 with variance: 0.0009026612558987665\n",
      "          Refitted train score: 0.9761904761904762,  RMSE: 0.1543033499620919, Log-Loss:0.8223570111175509\n",
      "          Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9716166349838875 using:10,3\n",
      "            train score: 0.9885258006456328 with variance: 4.2925484391131696e-06\n",
      "            test  score: 0.9716166349838875 with variance: 0.0006111765517400982\n",
      "          Refitted train score: 0.9846827133479211,  RMSE: 0.12309149097933274, Log-Loss:0.5233165245926524\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "        accuracy\n",
      "          CV score: 0.9719495091164095 using:10,3\n",
      "            train score: 0.9886354647330255 with variance: 4.116181608129155e-06\n",
      "            test  score: 0.9719495091164095 with variance: 0.0005805221098148089\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.5233165245926524\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9758179409243238 using:10,3\n",
      "            train score: 0.9912835833166636 with variance: 4.1776238004152236e-06\n",
      "            test  score: 0.9758179409243238 with variance: 0.00046711063055587923\n",
      "          Refitted train score: 0.991304347826087,  RMSE: 0.09304842103984709, Log-Loss:0.29903875579453104\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "        accuracy\n",
      "          CV score: 0.9762739597942962 using:10,3\n",
      "            train score: 0.9913425620742693 with variance: 4.081191019467839e-06\n",
      "            test  score: 0.9762739597942962 with variance: 0.0004329259083679595\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903875579453104\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.971853985291364 using:10,3\n",
      "            train score: 0.9956491961258909 with variance: 4.764599366564427e-06\n",
      "            test  score: 0.971853985291364 with variance: 0.0004054220772986385\n",
      "          Refitted train score: 0.9978308026030369,  RMSE: 0.046524210519923545, Log-Loss:0.07475925626604144\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "        accuracy\n",
      "          CV score: 0.9719261337073398 using:10,3\n",
      "            train score: 0.9956727459166483 with variance: 4.665456169548025e-06\n",
      "            test  score: 0.9719261337073398 with variance: 0.0003967448404166617\n",
      "          Refitted train score: 0.9978354978354979,  RMSE: 0.046524210519923545, Log-Loss:0.07475925626604144\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.985274183929318\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9758179409243238 using:10,3\n",
      "            train score: 0.9951071668863086 with variance: 4.1770068984359274e-06\n",
      "            test  score: 0.9758179409243238 with variance: 0.00046711063055587923\n",
      "          Refitted train score: 0.991304347826087,  RMSE: 0.09304842103984709, Log-Loss:0.2990387557945311\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9762739597942962 using:10,3\n",
      "            train score: 0.9951307404965941 with variance: 4.087444090445349e-06\n",
      "            test  score: 0.9762739597942962 with variance: 0.0004329259083679595\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.2990387557945311\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9800653751925189 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9800653751925189 with variance: 0.00032845984623732644\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9805750350631135 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9805750350631135 with variance: 0.0002947847812208137\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9383546387410278 using:20,3\n",
      "            train score: 0.9693748358363077 with variance: 7.352333659544868e-05\n",
      "            test  score: 0.9383546387410278 with variance: 0.0005915360481674686\n",
      "          Refitted train score: 0.975929978118162,  RMSE: 0.1543033499620919, Log-Loss:0.8223570111175509\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9393875642823749 using:20,3\n",
      "            train score: 0.9697033618984838 with variance: 7.104382600735592e-05\n",
      "            test  score: 0.9393875642823749 with variance: 0.0004993288995460653\n",
      "          Refitted train score: 0.9761904761904762,  RMSE: 0.1543033499620919, Log-Loss:0.8223570111175509\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9578195482195095 using:10,3\n",
      "            train score: 0.9764349077917371 with variance: 1.3923907470840406e-05\n",
      "            test  score: 0.9578195482195095 with variance: 0.00041363579883932626\n",
      "          Refitted train score: 0.9803063457330415,  RMSE: 0.13957263155977062, Log-Loss:0.6728367678551015\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9588592800374005 using:10,3\n",
      "            train score: 0.976733318684538 with variance: 1.3365276140008046e-05\n",
      "            test  score: 0.9588592800374005 with variance: 0.00035057103097247175\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728367678551015\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.956148628152983 using:10,3\n",
      "            train score: 0.9818936483424163 with variance: 3.206115036489712e-05\n",
      "            test  score: 0.956148628152983 with variance: 0.00038752719884375275\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9567788686302009 using:10,3\n",
      "            train score: 0.9821445836079983 with variance: 3.093082202792733e-05\n",
      "            test  score: 0.9567788686302009 with variance: 0.00036953363490780164\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9649623868417697 using:10,3\n",
      "            train score: 0.9840792586273743 with variance: 2.2534443099724773e-05\n",
      "            test  score: 0.9649623868417697 with variance: 0.0002594041719415763\n",
      "          Refitted train score: 0.9868421052631579,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9654277699859748 using:10,3\n",
      "            train score: 0.9843052808906467 with variance: 2.1698186334208362e-05\n",
      "            test  score: 0.9654277699859748 with variance: 0.00024906667750743507\n",
      "          Refitted train score: 0.987012987012987,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9669033385137927 using:10,3\n",
      "            train score: 0.9929213817748661 with variance: 4.755748497449862e-06\n",
      "            test  score: 0.9669033385137927 with variance: 0.0002623621367875672\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.2990370250641627\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9675549322113136 using:10,3\n",
      "            train score: 0.9929656485754048 with variance: 4.675031050365412e-06\n",
      "            test  score: 0.9675549322113136 with variance: 0.0002343037789042558\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.2990370250641627\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9692146563114307 using:10,3\n",
      "            train score: 0.9923704911516367 with variance: 7.128151995530895e-06\n",
      "            test  score: 0.9692146563114307 with variance: 0.0003082280547167391\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9697522206638615 using:10,3\n",
      "            train score: 0.9924265729143779 with variance: 7.002988861706585e-06\n",
      "            test  score: 0.9697522206638615 with variance: 0.0002966207179780378\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.97992007992008 using:10,3\n",
      "            train score: 0.9956491799415499 with variance: 1.794918619337425e-06\n",
      "            test  score: 0.97992007992008 with variance: 0.0002756883476164205\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9805282842449742 using:10,3\n",
      "            train score: 0.9956712810371346 with variance: 1.754722443287246e-06\n",
      "            test  score: 0.9805282842449742 with variance: 0.00025379421465728793\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9755085059384523 using:10,3\n",
      "            train score: 0.9994579945799458 with variance: 1.1750795014725341e-06\n",
      "            test  score: 0.9755085059384523 with variance: 0.0003875421404210215\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9762038335670875 using:10,3\n",
      "            train score: 0.9994594594594595 with variance: 1.1687363038714152e-06\n",
      "            test  score: 0.9762038335670875 with variance: 0.00034872198038126713\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9472799961499326 using:10,3\n",
      "            train score: 0.9711813777285385 with variance: 3.9900147256376534e-05\n",
      "            test  score: 0.9472799961499326 with variance: 0.0006803674636230203\n",
      "          Refitted train score: 0.971677559912854,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9481299672744272 using:10,3\n",
      "            train score: 0.9713220537610783 with variance: 3.978602458915008e-05\n",
      "            test  score: 0.9481299672744272 with variance: 0.0006219257621487115\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9542722412097915 using:10,3\n",
      "            train score: 0.973773322865745 with variance: 4.6120164472532265e-06\n",
      "            test  score: 0.9542722412097915 with variance: 0.00025030930074081863\n",
      "          Refitted train score: 0.9780701754385964,  RMSE: 0.14712247158412492, Log-Loss:0.7475960241211421\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9546049555867228 using:10,3\n",
      "            train score: 0.9740276862228082 with variance: 4.590470818745505e-06\n",
      "            test  score: 0.9546049555867228 with variance: 0.0002477782433188844\n",
      "          Refitted train score: 0.9783549783549783,  RMSE: 0.14712247158412492, Log-Loss:0.7475960241211421\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9500399529114374 using:10,10\n",
      "            train score: 0.964386252394912 with variance: 2.0895982118343766e-05\n",
      "            test  score: 0.9500399529114374 with variance: 0.00019974931074826587\n",
      "          Refitted train score: 0.9671772428884026,  RMSE: 0.1801874925391118, Log-Loss:1.1213974976424492\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9502805049088359 using:10,3\n",
      "            train score: 0.9756507727239434 with variance: 5.781270978413268e-06\n",
      "            test  score: 0.9502805049088359 with variance: 0.00030247932330868216\n",
      "          Refitted train score: 0.9783549783549783,  RMSE: 0.14712247158412492, Log-Loss:0.7475960241211421\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9585555353601667 using:10,10\n",
      "            train score: 0.9666500923052823 with variance: 4.077800622681907e-06\n",
      "            test  score: 0.9585555353601667 with variance: 0.00021103044178586144\n",
      "          Refitted train score: 0.9671772428884026,  RMSE: 0.1801874925391118, Log-Loss:1.1213974976424494\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9589294062646095 using:10,10\n",
      "            train score: 0.9669933347982129 with variance: 3.968760202447685e-06\n",
      "            test  score: 0.9589294062646095 with variance: 0.00020091267913224055\n",
      "          Refitted train score: 0.9675324675324676,  RMSE: 0.1801874925391118, Log-Loss:1.1213974976424494\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9690096284718329 using:20,3\n",
      "            train score: 0.9918166548467771 with variance: 3.209996996180569e-10\n",
      "            test  score: 0.9690096284718329 with variance: 0.00042110893619795863\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812228\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.969728845254792 using:20,3\n",
      "            train score: 0.9918831026148099 with variance: 1.1587708743537016e-10\n",
      "            test  score: 0.969728845254792 with variance: 0.00039225116663945444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812228\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9693091854382179 using:10,3\n",
      "            train score: 0.994011356875723 with variance: 1.1945012842545907e-06\n",
      "            test  score: 0.9693091854382179 with variance: 0.0003058184469281193\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9697522206638615 using:10,3\n",
      "            train score: 0.9940481945359995 with variance: 1.1624531906860996e-06\n",
      "            test  score: 0.9697522206638615 with variance: 0.0002966207179780378\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9672915185500998 using:10,3\n",
      "            train score: 0.995104228839865 with variance: 1.1945015718548066e-06\n",
      "            test  score: 0.9672915185500998 with variance: 0.0003237701808910526\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9676016830294529 using:10,3\n",
      "            train score: 0.9951292756170804 with variance: 1.1751224189123256e-06\n",
      "            test  score: 0.9676016830294529 with variance: 0.0003237663543169961\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9713662214363478 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9713662214363478 with variance: 0.000227821589583976\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9719027582982701 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9719027582982701 with variance: 0.00021397733623498656\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9555790771440321 using:10,10\n",
      "            train score: 0.9604852992232061 with variance: 7.797432686405483e-06\n",
      "            test  score: 0.9555790771440321 with variance: 0.0002456363133388757\n",
      "          Refitted train score: 0.9576837416481068,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.955995115995116 using:10,10\n",
      "            train score: 0.960905760905761 with variance: 7.047642387509042e-06\n",
      "            test  score: 0.955995115995116 with variance: 0.00023937945110106255\n",
      "          Refitted train score: 0.9581497797356828,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9555675632091246 using:10,3\n",
      "            train score: 0.9734006700901048 with variance: 1.980207451147629e-05\n",
      "            test  score: 0.9555675632091246 with variance: 4.66772639444971e-05\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767609\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.955970695970696 using:10,3\n",
      "            train score: 0.9735718826627917 with variance: 1.9796200475025704e-05\n",
      "            test  score: 0.955970695970696 with variance: 4.671470165975676e-05\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767609\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9602704656556454 using:10,3\n",
      "            train score: 0.9750287076156429 with variance: 2.386510617730647e-05\n",
      "            test  score: 0.9602704656556454 with variance: 0.00011915002346220361\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767609\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9603907203907204 using:10,3\n",
      "            train score: 0.9752247752247752 with variance: 2.3986016836141897e-05\n",
      "            test  score: 0.9603907203907204 with variance: 0.00012388078615184822\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767609\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9579733370663821 using:10,3\n",
      "            train score: 0.9810860150192315 with variance: 4.458176975597441e-06\n",
      "            test  score: 0.9579733370663821 with variance: 5.982412809083316e-05\n",
      "          Refitted train score: 0.9821428571428572,  RMSE: 0.1327446623199944, Log-Loss:0.608614561138141\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9581684981684981 using:10,3\n",
      "            train score: 0.9812793267338721 with variance: 4.17038783630882e-06\n",
      "            test  score: 0.9581684981684981 with variance: 6.635806196245767e-05\n",
      "          Refitted train score: 0.9823788546255506,  RMSE: 0.1327446623199944, Log-Loss:0.608614561138141\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9602666958814801 using:10,3\n",
      "            train score: 0.9894672309470657 with variance: 2.318375128934403e-05\n",
      "            test  score: 0.9602666958814801 with variance: 2.160909031734301e-05\n",
      "          Refitted train score: 0.9911504424778761,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9603663003663003 using:10,3\n",
      "            train score: 0.9895377349922805 with variance: 2.2457028591390152e-05\n",
      "            test  score: 0.9603663003663003 with variance: 2.803740825718828e-05\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9623167714098164 using:10,3\n",
      "            train score: 0.992249702549002 with variance: 4.393626513744618e-06\n",
      "            test  score: 0.9623167714098164 with variance: 0.0001142828651756445\n",
      "          Refitted train score: 0.9911504424778761,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:10,3\n",
      "            train score: 0.9922910422910423 with variance: 4.244940218058094e-06\n",
      "            test  score: 0.9625885225885226 with variance: 0.00012409546768521118\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9666797002280875 using:20,3\n",
      "            train score: 0.9922466165262792 with variance: 4.4306597759467635e-06\n",
      "            test  score: 0.9666797002280875 with variance: 9.460919541328134e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.2282297999663711\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.966984126984127 using:20,3\n",
      "            train score: 0.9922910422910423 with variance: 4.244940218058094e-06\n",
      "            test  score: 0.966984126984127 with variance: 9.554282374795128e-05\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.2282297999663711\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9689112755324103 using:20,3\n",
      "            train score: 0.9983440634369817 with variance: 4.88050153304447e-06\n",
      "            test  score: 0.9689112755324103 with variance: 0.0001570750113068241\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9692063492063493 using:20,3\n",
      "            train score: 0.9983471074380166 with variance: 4.856984571484873e-06\n",
      "            test  score: 0.9692063492063493 with variance: 0.0001632676914728194\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9511922859748948 using:10,3\n",
      "            train score: 0.9706564613598634 with variance: 4.341143689691669e-05\n",
      "            test  score: 0.9511922859748948 with variance: 0.0003226833937050001\n",
      "          Refitted train score: 0.9777777777777777,  RMSE: 0.14841304429888122, Log-Loss:0.7607712835713607\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9515750915750916 using:10,3\n",
      "            train score: 0.9708216026397845 with variance: 4.377163243090684e-05\n",
      "            test  score: 0.9515750915750916 with variance: 0.00031656938909686123\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607712835713607\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9557864657414882 using:10,3\n",
      "            train score: 0.9777770181023433 with variance: 3.0863428405916995e-06\n",
      "            test  score: 0.9557864657414882 with variance: 0.0007121308235566229\n",
      "          Refitted train score: 0.9777777777777777,  RMSE: 0.14841304429888122, Log-Loss:0.7607712835713608\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9560439560439562 using:10,3\n",
      "            train score: 0.9779750552477825 with variance: 2.961301249789676e-06\n",
      "            test  score: 0.9560439560439562 with variance: 0.0007245501750996249\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607712835713608\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9557408109132247 using:10,3\n",
      "            train score: 0.9832989176091902 with variance: 1.5439647106562493e-05\n",
      "            test  score: 0.9557408109132247 with variance: 0.0006699518876283844\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.956043956043956 using:10,3\n",
      "            train score: 0.983481669845306 with variance: 1.5120148623009417e-05\n",
      "            test  score: 0.956043956043956 with variance: 0.0006762468300929835\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9575939889461781 using:10,3\n",
      "            train score: 0.986069181770447 with variance: 9.416999326353455e-06\n",
      "            test  score: 0.9575939889461781 with variance: 0.0006492694661019198\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9582417582417584 using:10,3\n",
      "            train score: 0.986234977144068 with variance: 9.05713837410246e-06\n",
      "            test  score: 0.9582417582417584 with variance: 0.0006472648230889984\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9665257514245941 using:10,3\n",
      "            train score: 0.9905415591039406 with variance: 1.4339462366487292e-05\n",
      "            test  score: 0.9665257514245941 with variance: 0.0003237475936123226\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9670085470085471 using:10,3\n",
      "            train score: 0.9906396633669361 with variance: 1.3943962227084026e-05\n",
      "            test  score: 0.9670085470085471 with variance: 0.0003370523927300484\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9689164166694757 using:10,3\n",
      "            train score: 0.9916743443371441 with variance: 1.2397023691769937e-05\n",
      "            test  score: 0.9689164166694757 with variance: 0.0003480920038978932\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:10,3\n",
      "            train score: 0.9917415917415917 with variance: 1.210924964856979e-05\n",
      "            test  score: 0.9692307692307693 with variance: 0.00035744475304914854\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9690629025663122 using:10,3\n",
      "            train score: 0.9972390741970193 with variance: 5.590408957329665e-11\n",
      "            test  score: 0.9690629025663122 with variance: 0.0004427920868952537\n",
      "          Refitted train score: 0.9977924944812362,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879106\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:10,3\n",
      "            train score: 0.997246692701238 with variance: 9.164398494168121e-12\n",
      "            test  score: 0.9692307692307693 with variance: 0.0004540514430624317\n",
      "          Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879106\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.969142789052045 using:20,3\n",
      "            train score: 0.9994459833795013 with variance: 1.2277376631549004e-06\n",
      "            test  score: 0.969142789052045 with variance: 0.00033802879494959463\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:10,3\n",
      "            train score: 0.9994490358126722 with variance: 1.2142461428712613e-06\n",
      "            test  score: 0.9692307692307693 with variance: 0.00035744475304914854\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9447957040578379 using:10,3\n",
      "            train score: 0.97103849438742 with variance: 4.13488179183772e-05\n",
      "            test  score: 0.9447957040578379 with variance: 0.0004566943696712687\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.14841304429888122, Log-Loss:0.760769522343541\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.944957264957265 using:10,3\n",
      "            train score: 0.971371053189235 with variance: 3.7830233750016476e-05\n",
      "            test  score: 0.944957264957265 with variance: 0.00043262145533207684\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.760769522343541\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.94925560771338 using:10,3\n",
      "            train score: 0.9760404142190096 with variance: 5.119747417580426e-06\n",
      "            test  score: 0.94925560771338 with variance: 0.00012173533207345032\n",
      "          Refitted train score: 0.9753914988814317,  RMSE: 0.15565691404453527, Log-Loss:0.836846122332331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9493772893772894 using:10,3\n",
      "            train score: 0.9763236763236763 with variance: 4.7411465745198444e-06\n",
      "            test  score: 0.9493772893772894 with variance: 0.0001230339867702507\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.836846122332331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9533801774170426 using:10,3\n",
      "            train score: 0.9759753158746143 with variance: 2.4205789288080196e-05\n",
      "            test  score: 0.9533801774170426 with variance: 0.00027620339590314765\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.14841304429888122, Log-Loss:0.760769522343541\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9537728937728938 using:10,3\n",
      "            train score: 0.9763251899615536 with variance: 2.2851620097349657e-05\n",
      "            test  score: 0.9537728937728938 with variance: 0.0002589273973889354\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.760769522343541\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9574640442790283 using:10,3\n",
      "            train score: 0.9821569675017544 with variance: 3.010904780299558e-05\n",
      "            test  score: 0.9574640442790283 with variance: 0.0001371383109610123\n",
      "          Refitted train score: 0.9821428571428572,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9581684981684981 using:10,3\n",
      "            train score: 0.9823842823842824 with variance: 2.8842598174093028e-05\n",
      "            test  score: 0.9581684981684981 with variance: 0.00011466140696909962\n",
      "          Refitted train score: 0.9823788546255506,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9663589903587173 using:10,3\n",
      "            train score: 0.986130877489569 with variance: 6.246279515924463e-06\n",
      "            test  score: 0.9663589903587173 with variance: 6.402971520137893e-05\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9669597069597069 using:10,3\n",
      "            train score: 0.986234977144068 with variance: 6.0215230169243056e-06\n",
      "            test  score: 0.9669597069597069 with variance: 4.8324813159977646e-05\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9707561031978343 using:10,3\n",
      "            train score: 0.991111059953805 with variance: 1.0544998687483552e-05\n",
      "            test  score: 0.9707561031978343 with variance: 0.0002407545321494808\n",
      "          Refitted train score: 0.9866666666666667,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:10,3\n",
      "            train score: 0.9911906275542639 with variance: 1.029455211636657e-05\n",
      "            test  score: 0.9714285714285715 with variance: 0.00022219538703055155\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9686045708651674 using:20,3\n",
      "            train score: 0.994465904651741 with variance: 9.174362066687958e-06\n",
      "            test  score: 0.9686045708651674 with variance: 8.72271802081674e-05\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9691819291819291 using:20,3\n",
      "            train score: 0.994496412678231 with variance: 9.040275880873152e-06\n",
      "            test  score: 0.9691819291819291 with variance: 6.67754982773293e-05\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9708038815064821 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9708038815064821 with variance: 0.00014485127562319624\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714041514041515 with variance: 0.0001247323562341876\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9454349609752709 using:10,10\n",
      "            train score: 0.9545152548671242 with variance: 4.646716678228811e-05\n",
      "            test  score: 0.9454349609752709 with variance: 0.0008369744206551639\n",
      "          Refitted train score: 0.952808988764045,  RMSE: 0.21650635094610965, Log-Loss:1.6190212068526706\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9463420724094881 using:10,10\n",
      "            train score: 0.9547937318124523 with variance: 4.2144546886943766e-05\n",
      "            test  score: 0.9463420724094881 with variance: 0.0006811236266776394\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190212068526706\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.947541898762433 using:10,10\n",
      "            train score: 0.9608102938017584 with variance: 4.325322044504275e-05\n",
      "            test  score: 0.947541898762433 with variance: 0.0008075862562495944\n",
      "          Refitted train score: 0.9574944071588367,  RMSE: 0.2059386177619785, Log-Loss:1.4648302408039624\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9485892634207241 using:10,3\n",
      "            train score: 0.9720950498747296 with variance: 5.3058415542294726e-05\n",
      "            test  score: 0.9485892634207241 with variance: 0.0007404876239282674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9709821428571429,  RMSE: 0.17034628596731172, Log-Loss:1.002248418579375\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9512559849638501 using:10,3\n",
      "            train score: 0.9779794760521604 with variance: 3.4010685216745785e-05\n",
      "            test  score: 0.9512559849638501 with variance: 0.0011657093730850468\n",
      "          Refitted train score: 0.9751693002257336,  RMSE: 0.15669579263200217, Log-Loss:0.8480556677149743\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9530337078651685 using:10,3\n",
      "            train score: 0.9782325205023266 with variance: 3.256688162357824e-05\n",
      "            test  score: 0.9530337078651685 with variance: 0.0009308052824107208\n",
      "          Refitted train score: 0.9754464285714286,  RMSE: 0.15669579263200217, Log-Loss:0.8480556677149743\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9626090169992609 using:10,3\n",
      "            train score: 0.9853456931521203 with variance: 4.401835740972288e-06\n",
      "            test  score: 0.9626090169992609 with variance: 0.001102676128241718\n",
      "          Refitted train score: 0.9887640449438202,  RMSE: 0.10564428184106457, Log-Loss:0.3854791999374643\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.964194756554307 using:10,3\n",
      "            train score: 0.9854919780271082 with variance: 4.336811613687999e-06\n",
      "            test  score: 0.964194756554307 with variance: 0.0009287666322215825\n",
      "          Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.3854791999374643\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.963055940043892 using:10,3\n",
      "            train score: 0.9887512422603777 with variance: 3.1403545066467312e-06\n",
      "            test  score: 0.963055940043892 with variance: 0.0006789787527628495\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.0944911182523068, Log-Loss:0.3083837169131102\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.964219725343321 using:10,3\n",
      "            train score: 0.98883926487294 with variance: 3.103870714936173e-06\n",
      "            test  score: 0.964219725343321 with variance: 0.000576505335870735\n",
      "          Refitted train score: 0.9910714285714286,  RMSE: 0.0944911182523068, Log-Loss:0.3083837169131102\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9652537422416941 using:10,3\n",
      "            train score: 0.9949453497079395 with variance: 7.600061842678893e-06\n",
      "            test  score: 0.9652537422416941 with variance: 0.0008123882180934055\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0668153104781061, Log-Loss:0.15419096604870944\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9664419475655432 using:10,3\n",
      "            train score: 0.9949751793467266 with variance: 7.48696422840991e-06\n",
      "            test  score: 0.9664419475655432 with variance: 0.000705899149159679\n",
      "          Refitted train score: 0.9955357142857143,  RMSE: 0.0668153104781061, Log-Loss:0.15419096604870944\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9648556209700029 using:10,3\n",
      "            train score: 0.9955150423737382 with variance: 1.8903364335488897e-06\n",
      "            test  score: 0.9648556209700029 with variance: 0.0011887521452994879\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0668153104781061, Log-Loss:0.15419096604870944\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.966441947565543 using:10,3\n",
      "            train score: 0.995535394718414 with variance: 1.8709007568081977e-06\n",
      "            test  score: 0.966441947565543 with variance: 0.00100889119561846\n",
      "          Refitted train score: 0.9955357142857143,  RMSE: 0.0668153104781061, Log-Loss:0.15419096604870944\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9702303797272045 using:10,3\n",
      "            train score: 0.9994428969359331 with variance: 1.2414552959706642e-06\n",
      "            test  score: 0.9702303797272045 with variance: 0.0006490068960909177\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9709612983770288 using:10,3\n",
      "            train score: 0.9994428969359331 with variance: 1.2414552959706642e-06\n",
      "            test  score: 0.9709612983770288 with variance: 0.0005842484659469054\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9502098786728768 using:10,10\n",
      "            train score: 0.9598973804073211 with variance: 2.1362428342844684e-05\n",
      "            test  score: 0.9502098786728768 with variance: 0.00023736784708320362\n",
      "          Refitted train score: 0.9571106094808127,  RMSE: 0.20548046676563256, Log-Loss:1.4583145535286322\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "        accuracy\n",
      "          CV score: 0.9511111111111111 using:10,3\n",
      "            train score: 0.9722222222222221 with variance: 1.543209876543199e-05\n",
      "            test  score: 0.9511111111111111 with variance: 0.00022716049382716028\n",
      "          Refitted train score: 0.9755555555555555,  RMSE: 0.15634719199411432, Log-Loss:0.8442883082971971\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9506932692999772 using:10,3\n",
      "            train score: 0.9775110030210132 with variance: 2.2637515485819923e-05\n",
      "            test  score: 0.9506932692999772 with variance: 0.00041106651046271607\n",
      "          Refitted train score: 0.9798657718120806,  RMSE: 0.1414213562373095, Log-Loss:0.6907808585477493\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9511111111111111 using:10,3\n",
      "            train score: 0.9777777777777779 with variance: 2.1604938271605158e-05\n",
      "            test  score: 0.9511111111111111 with variance: 0.0004246913580246904\n",
      "          Refitted train score: 0.98,  RMSE: 0.1414213562373095, Log-Loss:0.6907808585477493\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9575491799087306 using:10,3\n",
      "            train score: 0.9826200856547542 with variance: 2.285196098248881e-05\n",
      "            test  score: 0.9575491799087306 with variance: 0.0004682524612685267\n",
      "          Refitted train score: 0.9842696629213483,  RMSE: 0.12472191289246472, Log-Loss:0.5372716319151231\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9577777777777777 using:10,3\n",
      "            train score: 0.982777777777778 with variance: 2.2839506172839763e-05\n",
      "            test  score: 0.9577777777777777 with variance: 0.0004641975308641964\n",
      "          Refitted train score: 0.9844444444444445,  RMSE: 0.12472191289246472, Log-Loss:0.5372716319151231\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9639876852236403 using:10,3\n",
      "            train score: 0.9859564882887947 with variance: 9.665521050689096e-06\n",
      "            test  score: 0.9639876852236403 with variance: 0.0003874682128935041\n",
      "          Refitted train score: 0.9887640449438202,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9644444444444445 using:10,3\n",
      "            train score: 0.986111111111111 with variance: 9.25925925925944e-06\n",
      "            test  score: 0.9644444444444445 with variance: 0.000365432098765432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9888888888888889,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9683339008058109 using:10,3\n",
      "            train score: 0.9921724152713886 with variance: 7.58611417798542e-06\n",
      "            test  score: 0.9683339008058109 with variance: 0.0004894974749439088\n",
      "          Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.968888888888889 using:10,3\n",
      "            train score: 0.9922222222222222 with variance: 7.407407407407356e-06\n",
      "            test  score: 0.968888888888889 with variance: 0.0004641975308641976\n",
      "          Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9728804902962207 using:10,3\n",
      "            train score: 0.9944164766844061 with variance: 3.1562272564919637e-06\n",
      "            test  score: 0.9728804902962207 with variance: 0.0004972763060010977\n",
      "          Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9733333333333334 using:10,3\n",
      "            train score: 0.9944444444444445 with variance: 3.086419753086398e-06\n",
      "            test  score: 0.9733333333333334 with variance: 0.00047407407407407457\n",
      "          Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9683270494196492 using:10,3\n",
      "            train score: 0.994416493975004 with variance: 6.259769600185947e-06\n",
      "            test  score: 0.9683270494196492 with variance: 0.0003385003145772892\n",
      "          Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.968888888888889 using:10,3\n",
      "            train score: 0.9944444444444445 with variance: 6.172839506172796e-06\n",
      "            test  score: 0.968888888888889 with variance: 0.00031604938271605004\n",
      "          Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.972720146328717 using:10,3\n",
      "            train score: 0.9994428969359331 with variance: 1.2414552959706642e-06\n",
      "            test  score: 0.972720146328717 with variance: 0.00019346263388276573\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9733333333333334 using:10,3\n",
      "            train score: 0.9994444444444444 with variance: 1.234567901234559e-06\n",
      "            test  score: 0.9733333333333334 with variance: 0.00017777777777777792\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9506251204566866 using:10,3\n",
      "            train score: 0.9710635791014006 with variance: 4.428401398014855e-05\n",
      "            test  score: 0.9506251204566866 with variance: 0.0006301222051091198\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767605\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9516239316239317 using:10,3\n",
      "            train score: 0.9713695395513577 with variance: 4.403965442926505e-05\n",
      "            test  score: 0.9516239316239317 with variance: 0.0005584963943938302\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767605\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9568915442178353 using:10,3\n",
      "            train score: 0.9716303857787603 with variance: 2.848607613981804e-05\n",
      "            test  score: 0.9568915442178353 with variance: 0.0006489472113626319\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767605\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9581929181929182 using:10,3\n",
      "            train score: 0.9719189901008083 with variance: 2.8355968614057633e-05\n",
      "            test  score: 0.9581929181929182 with variance: 0.0005487355406769322\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129262447767605\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9646190004237098 using:10,3\n",
      "            train score: 0.9788112449505098 with variance: 2.0788682639407747e-05\n",
      "            test  score: 0.9646190004237098 with variance: 0.0010086129718351344\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.14841304429888122, Log-Loss:0.7607695223435409\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107448 using:10,3\n",
      "            train score: 0.9790769836224381 with variance: 1.993072468052044e-05\n",
      "            test  score: 0.9648107448107448 with variance: 0.0010325132200590084\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607695223435409\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.966711352972586 using:10,3\n",
      "            train score: 0.9861678735090805 with variance: 1.526318510412094e-05\n",
      "            test  score: 0.966711352972586 with variance: 0.0005785150817578337\n",
      "          Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9670085470085471 using:10,3\n",
      "            train score: 0.986234977144068 with variance: 1.5128369088458643e-05\n",
      "            test  score: 0.9670085470085471 with variance: 0.0005785691177632567\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9661209999376001 using:20,3\n",
      "            train score: 0.9917172058657776 with variance: 2.138472522837364e-05\n",
      "            test  score: 0.9661209999376001 with variance: 0.0006933374223979716\n",
      "          Refitted train score: 0.988962472406181,  RMSE: 0.10494387004027837, Log-Loss:0.3803865223995908\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.967008547008547 using:20,3\n",
      "            train score: 0.9917385644658372 with variance: 2.1266023363099987e-05\n",
      "            test  score: 0.967008547008547 with variance: 0.000626872462769899\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803865223995908\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9638302098487737 using:10,3\n",
      "            train score: 0.992800743330579 with variance: 4.989687530181822e-06\n",
      "            test  score: 0.9638302098487737 with variance: 0.0008054304591252213\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107448 using:10,3\n",
      "            train score: 0.9928404928404928 with variance: 4.867028752234531e-06\n",
      "            test  score: 0.9648107448107448 with variance: 0.0007426931500191575\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9660757903552236 using:10,3\n",
      "            train score: 0.9972360301959842 with variance: 3.0524425141624483e-06\n",
      "            test  score: 0.9660757903552236 with variance: 0.0006509491677442547\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9670085470085471 using:10,3\n",
      "            train score: 0.997245179063361 with variance: 3.035615357178031e-06\n",
      "            test  score: 0.9670085470085471 with variance: 0.0005785691177632567\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9617574724224343 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9617574724224343 with variance: 0.0005785797461983707\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9625885225885226 with variance: 0.0005588255727449864\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9552793799626942 using:10,10\n",
      "            train score: 0.9618978676528445 with variance: 1.965805057558601e-05\n",
      "            test  score: 0.9552793799626942 with variance: 0.0002352983430755306\n",
      "          Refitted train score: 0.9594594594594594,  RMSE: 0.1991169934799916, Log-Loss:1.3693858447095009\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.955970695970696 using:10,10\n",
      "            train score: 0.9625586534677444 with variance: 1.9717166702412756e-05\n",
      "            test  score: 0.955970695970696 with variance: 0.00023992808168632316\n",
      "          Refitted train score: 0.960352422907489,  RMSE: 0.1991169934799916, Log-Loss:1.3693858447095009\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9624663792516964 using:10,3\n",
      "            train score: 0.974967450449469 with variance: 1.8209796589639813e-05\n",
      "            test  score: 0.9624663792516964 with variance: 0.0003815546803605701\n",
      "          Refitted train score: 0.9755011135857461,  RMSE: 0.15565691404453527, Log-Loss:0.8368478835601508\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:10,3\n",
      "            train score: 0.9752217479490206 with variance: 1.813121255662193e-05\n",
      "            test  score: 0.9625885225885226 with variance: 0.00041391553772506033\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368478835601508\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9649591015142056 using:10,3\n",
      "            train score: 0.9761893158644417 with variance: 2.9085890493060577e-05\n",
      "            test  score: 0.9649591015142056 with variance: 0.00032796568423068854\n",
      "          Refitted train score: 0.9756097560975608,  RMSE: 0.15565691404453527, Log-Loss:0.8368496447879706\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9647619047619047 using:10,3\n",
      "            train score: 0.9763236763236763 with variance: 2.902606943194429e-05\n",
      "            test  score: 0.9647619047619047 with variance: 0.0003571441989024405\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368496447879706\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9626080043355222 using:10,3\n",
      "            train score: 0.9850076946752846 with variance: 4.955607715459722e-06\n",
      "            test  score: 0.9626080043355222 with variance: 0.00029217525444469333\n",
      "          Refitted train score: 0.9844789356984479,  RMSE: 0.12417126158110488, Log-Loss:0.532539722377171\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9625641025641025 using:10,3\n",
      "            train score: 0.9851330487694124 with variance: 4.827291920364086e-06\n",
      "            test  score: 0.9625641025641025 with variance: 0.00031817950059708324\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532539722377171\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.964847645992857 using:10,10\n",
      "            train score: 0.9800303522933882 with variance: 2.2693653361151553e-05\n",
      "            test  score: 0.964847645992857 with variance: 0.00019381687480350462\n",
      "          Refitted train score: 0.9777777777777777,  RMSE: 0.14841304429888122, Log-Loss:0.7607712835713608\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647619047619047 using:10,10\n",
      "            train score: 0.9801773983592165 with variance: 2.2410766707792087e-05\n",
      "            test  score: 0.9647619047619047 with variance: 0.00021223416388251596\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607712835713608\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9648551953467581 using:10,3\n",
      "            train score: 0.99170197714894 with variance: 6.071082776721431e-06\n",
      "            test  score: 0.9648551953467581 with variance: 0.0004299299628975924\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.2282297999663711\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647619047619047 using:10,3\n",
      "            train score: 0.9917415917415917 with variance: 6.038018934213728e-06\n",
      "            test  score: 0.9647619047619047 with variance: 0.00045375088891572374\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.2282297999663711\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9647553201907032 using:10,10\n",
      "            train score: 0.9862257442317712 with variance: 1.801381356403351e-05\n",
      "            test  score: 0.9647553201907032 with variance: 0.0002803314458061924\n",
      "          Refitted train score: 0.9845474613686535,  RMSE: 0.12417126158110488, Log-Loss:0.5325414836049907\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647619047619047 using:10,10\n",
      "            train score: 0.986234977144068 with variance: 1.81639844456368e-05\n",
      "            test  score: 0.9647619047619047 with variance: 0.0003088408538957992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.5325414836049907\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9693903192995752 using:20,3\n",
      "            train score: 0.9994490358126722 with variance: 1.2142461428712613e-06\n",
      "            test  score: 0.9693903192995752 with variance: 0.0002896063013949805\n",
      "          Refitted train score: 0.9977924944812362,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879103\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9691575091575091 using:20,3\n",
      "            train score: 0.9994490358126722 with variance: 1.2142461428712613e-06\n",
      "            test  score: 0.9691575091575091 with variance: 0.0003094848984958877\n",
      "          Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879103\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9527785952158851 using:10,3\n",
      "            train score: 0.9724248691122312 with variance: 3.476786163674242e-05\n",
      "            test  score: 0.9527785952158851 with variance: 0.000377054234264287\n",
      "          Refitted train score: 0.9751693002257336,  RMSE: 0.15704673549630008, Log-Loss:0.851860400748293\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9529338327091136 using:10,3\n",
      "            train score: 0.9725395776288043 with variance: 3.557836837698885e-05\n",
      "            test  score: 0.9529338327091136 with variance: 0.000371508149145653\n",
      "          Refitted train score: 0.9753363228699552,  RMSE: 0.15704673549630008, Log-Loss:0.851860400748293\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9527240004499381 using:10,3\n",
      "            train score: 0.9767759455197143 with variance: 4.2377796574291455e-06\n",
      "            test  score: 0.9527240004499381 with variance: 0.00032191687232942376\n",
      "          Refitted train score: 0.9750566893424037,  RMSE: 0.15704673549630008, Log-Loss:0.8518586079289426\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9529338327091136 using:10,3\n",
      "            train score: 0.977019796682718 with variance: 4.320345068450637e-06\n",
      "            test  score: 0.9529338327091136 with variance: 0.00032100947473585607\n",
      "          Refitted train score: 0.9753363228699552,  RMSE: 0.15704673549630008, Log-Loss:0.8518586079289426\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9532292423344904 using:10,3\n",
      "            train score: 0.9773935696101488 with variance: 8.637750170635975e-06\n",
      "            test  score: 0.9532292423344904 with variance: 0.0003126358001569853\n",
      "          Refitted train score: 0.9818181818181819,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9529338327091136 using:10,3\n",
      "            train score: 0.9775800207723538 with variance: 9.354304014443618e-06\n",
      "            test  score: 0.9529338327091136 with variance: 0.00032100947473585607\n",
      "          Refitted train score: 0.9820627802690582,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9527750320166073 using:10,3\n",
      "            train score: 0.9847119162081626 with variance: 8.02764214756041e-06\n",
      "            test  score: 0.9527750320166073 with variance: 0.00016111630634675807\n",
      "          Refitted train score: 0.9886621315192743,  RMSE: 0.10588088747190667, Log-Loss:0.38720601339586064\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9529338327091136 using:10,3\n",
      "            train score: 0.9848660812639662 with variance: 8.142742357023563e-06\n",
      "            test  score: 0.9529338327091136 with variance: 0.00016951345150646559\n",
      "          Refitted train score: 0.9887892376681614,  RMSE: 0.10588088747190667, Log-Loss:0.38720601339586064\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9620220938789347 using:10,3\n",
      "            train score: 0.9915524429507279 with variance: 3.1206198447028898e-06\n",
      "            test  score: 0.9620220938789347 with variance: 0.00011165794799739561\n",
      "          Refitted train score: 0.9932279909706546,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751675\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9619225967540574 using:10,3\n",
      "            train score: 0.991593491329116 with variance: 3.1209178483644236e-06\n",
      "            test  score: 0.9619225967540574 with variance: 0.00012687012644930408\n",
      "          Refitted train score: 0.9932735426008968,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751675\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9661214847121894 using:10,3\n",
      "            train score: 0.993796433140837 with variance: 1.2625576996378552e-06\n",
      "            test  score: 0.9661214847121894 with variance: 0.0001455890026992244\n",
      "          Refitted train score: 0.9954954954954954,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834483\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9663920099875156 using:10,3\n",
      "            train score: 0.9938343876876594 with variance: 1.2519173290115399e-06\n",
      "            test  score: 0.9663920099875156 with variance: 0.00014929153788725345\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834483\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9657110331528937 using:10,3\n",
      "            train score: 0.9966196648150785 with variance: 4.479567539426673e-06\n",
      "            test  score: 0.9657110331528937 with variance: 0.00010385440475091303\n",
      "          Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9663670411985018 using:10,3\n",
      "            train score: 0.9966355081358387 with variance: 4.408059715466027e-06\n",
      "            test  score: 0.9663670411985018 with variance: 0.00010101979267488621\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9683655239828767 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9683655239828767 with variance: 0.00012264743954464296\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9686142322097379 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9686142322097379 with variance: 0.00012088260460940648\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9434499978475183 using:10,3\n",
      "            train score: 0.9741218809509687 with variance: 8.0012232399359e-06\n",
      "            test  score: 0.9434499978475183 with variance: 0.0006636978040743625\n",
      "          Refitted train score: 0.9774774774774775,  RMSE: 0.14973818705886996, Log-Loss:0.7744191980691211\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9439950062421973 using:10,3\n",
      "            train score: 0.9742155289081925 with variance: 7.517358220979067e-06\n",
      "            test  score: 0.9439950062421973 with variance: 0.0006487496122979848\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9775784753363229,  RMSE: 0.14973818705886996, Log-Loss:0.7744191980691211\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9548434669284358 using:10,3\n",
      "            train score: 0.9768472173287158 with variance: 1.7314881907534245e-05\n",
      "            test  score: 0.9548434669284358 with variance: 0.0005634929820670547\n",
      "          Refitted train score: 0.9774774774774775,  RMSE: 0.14973818705886996, Log-Loss:0.7744191980691211\n",
      "          Refitted test  score: 0.9600000000000001,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9552059925093633 using:10,3\n",
      "            train score: 0.9770213703458911 with variance: 1.683194052627168e-05\n",
      "            test  score: 0.9552059925093633 with variance: 0.0005488420373409629\n",
      "          Refitted train score: 0.9775784753363229,  RMSE: 0.14973818705886996, Log-Loss:0.7744191980691211\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9612295750226785 using:10,3\n",
      "            train score: 0.9807840333633677 with variance: 2.3988963736950305e-05\n",
      "            test  score: 0.9612295750226785 with variance: 0.0004524650448465034\n",
      "          Refitted train score: 0.9819819819819819,  RMSE: 0.133929906036485, Log-Loss:0.6195349998914269\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9619475655430711 using:10,3\n",
      "            train score: 0.9809460862996884 with variance: 2.312639510554684e-05\n",
      "            test  score: 0.9619475655430711 with variance: 0.0004256252717810596\n",
      "          Refitted train score: 0.9820627802690582,  RMSE: 0.133929906036485, Log-Loss:0.6195349998914269\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9656684491978609 using:10,3\n",
      "            train score: 0.9858515992703012 with variance: 9.632380170325608e-06\n",
      "            test  score: 0.9656684491978609 with variance: 0.0005167605593525686\n",
      "          Refitted train score: 0.9864253393665159,  RMSE: 0.11598670095405886, Log-Loss:0.46464900889438276\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9664419475655432 using:10,3\n",
      "            train score: 0.9859896767695842 with variance: 9.362723828104253e-06\n",
      "            test  score: 0.9664419475655432 with variance: 0.0004949767846371807\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.46464900889438276\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9704181938352461 using:10,3\n",
      "            train score: 0.9892797791031718 with variance: 1.724881455669587e-05\n",
      "            test  score: 0.9704181938352461 with variance: 0.00033583494221832146\n",
      "          Refitted train score: 0.9887640449438202,  RMSE: 0.10588088747190667, Log-Loss:0.3872095990345611\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9709113607990012 using:10,3\n",
      "            train score: 0.9893541686337457 with variance: 1.6923280645992747e-05\n",
      "            test  score: 0.9709113607990012 with variance: 0.00032662043855916686\n",
      "          Refitted train score: 0.9887892376681614,  RMSE: 0.10588088747190667, Log-Loss:0.3872095990345611\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9657742832030787 using:10,3\n",
      "            train score: 0.9898686143394999 with variance: 2.0820683995516768e-05\n",
      "            test  score: 0.9657742832030787 with variance: 0.0005215685019320981\n",
      "          Refitted train score: 0.990990990990991,  RMSE: 0.09470274476207567, Log-Loss:0.30976660353603896\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.966441947565543 using:10,3\n",
      "            train score: 0.9899143927233816 with variance: 2.069125622133e-05\n",
      "            test  score: 0.966441947565543 with variance: 0.0004949767846371806\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.30976660353603896\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9773214516337336 using:20,3\n",
      "            train score: 0.9943756214290425 with variance: 3.174431113902276e-06\n",
      "            test  score: 0.9773214516337336 with variance: 0.0004064019095691088\n",
      "          Refitted train score: 0.9932279909706546,  RMSE: 0.08201498277207123, Log-Loss:0.2323236080375168\n",
      "          Refitted test  score: 0.9600000000000001,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9776529338327091 using:20,3\n",
      "            train score: 0.9943961854404684 with variance: 3.1297041715607416e-06\n",
      "            test  score: 0.9776529338327091 with variance: 0.00039563529358588903\n",
      "          Refitted train score: 0.9932735426008968,  RMSE: 0.08201498277207123, Log-Loss:0.2323236080375168\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9668214529613515 using:10,3\n",
      "            train score: 0.9988826728462973 with variance: 1.8726543046035592e-06\n",
      "            test  score: 0.9668214529613515 with variance: 0.000939948993125568\n",
      "          Refitted train score: 0.9977628635346756,  RMSE: 0.047351372381037836, Log-Loss:0.07744299549852314\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9664918851435704 using:10,3\n",
      "            train score: 0.9988795518207283 with variance: 1.883106183649917e-06\n",
      "            test  score: 0.9664918851435704 with variance: 0.0009876892336514438\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744299549852314\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9447482568103851 using:10,10\n",
      "            train score: 0.9556552782294435 with variance: 1.98716179367942e-05\n",
      "            test  score: 0.9447482568103851 with variance: 0.0004802329134591084\n",
      "          Refitted train score: 0.9541284403669724,  RMSE: 0.21320071635561044, Log-Loss:1.5699589197219443\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9454545454545455 using:10,10\n",
      "            train score: 0.95625 with variance: 1.8078512396694233e-05\n",
      "            test  score: 0.9454545454545455 with variance: 0.0004855371900826454\n",
      "          Refitted train score: 0.9545454545454546,  RMSE: 0.21320071635561044, Log-Loss:1.5699589197219443\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9519634771358911 using:10,10\n",
      "            train score: 0.9621765247498131 with variance: 1.9353390754951748e-05\n",
      "            test  score: 0.9519634771358911 with variance: 0.0005350794142760017\n",
      "          Refitted train score: 0.963302752293578,  RMSE: 0.19069251784911845, Log-Loss:1.255966408870801\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9522727272727274 using:10,3\n",
      "            train score: 0.9704545454545455 with variance: 1.4850206611570233e-05\n",
      "            test  score: 0.9522727272727274 with variance: 0.0005888429752066125\n",
      "          Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419720807527707\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9565089316813455 using:10,3\n",
      "            train score: 0.9758152853390326 with variance: 2.929760752256606e-05\n",
      "            test  score: 0.9565089316813455 with variance: 0.00022797342378443088\n",
      "          Refitted train score: 0.9745958429561201,  RMSE: 0.15811388300841897, Log-Loss:0.8634730444065415\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9568181818181818 using:10,3\n",
      "            train score: 0.9761363636363637 with variance: 2.776342975206605e-05\n",
      "            test  score: 0.9568181818181818 with variance: 0.00022727272727272795\n",
      "          Refitted train score: 0.975,  RMSE: 0.15811388300841897, Log-Loss:0.8634730444065415\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9611102300847101 using:10,3\n",
      "            train score: 0.9816185462744004 with variance: 1.5551423809756302e-05\n",
      "            test  score: 0.9611102300847101 with variance: 0.00034292773861397736\n",
      "          Refitted train score: 0.9815668202764977,  RMSE: 0.13483997249264842, Log-Loss:0.6279795699016275\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9613636363636363 using:10,3\n",
      "            train score: 0.9818181818181818 with variance: 1.4850206611570233e-05\n",
      "            test  score: 0.9613636363636363 with variance: 0.00034090909090909164\n",
      "          Refitted train score: 0.9818181818181818,  RMSE: 0.13483997249264842, Log-Loss:0.6279795699016275\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9654977297809506 using:10,3\n",
      "            train score: 0.9902970917970917 with variance: 5.2878019354875695e-06\n",
      "            test  score: 0.9654977297809506 with variance: 0.000487404667527702\n",
      "          Refitted train score: 0.9931350114416476,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802834\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:10,3\n",
      "            train score: 0.990340909090909 with variance: 5.1652892561982365e-06\n",
      "            test  score: 0.965909090909091 with variance: 0.00046487603305785195\n",
      "          Refitted train score: 0.9931818181818182,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802834\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.963198879206238 using:10,3\n",
      "            train score: 0.9897207512322126 with variance: 1.5080090335819525e-05\n",
      "            test  score: 0.963198879206238 with variance: 0.0003499123959432239\n",
      "          Refitted train score: 0.9931350114416476,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802834\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:10,3\n",
      "            train score: 0.9897727272727274 with variance: 1.4850206611570233e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.00033057851239669505\n",
      "          Refitted train score: 0.9931818181818182,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802834\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9653876616959781 using:10,10\n",
      "            train score: 0.9839735112279641 with variance: 5.535171189514442e-06\n",
      "            test  score: 0.9653876616959781 with variance: 0.0002247632584888971\n",
      "          Refitted train score: 0.9839816933638444,  RMSE: 0.12613124477737825, Log-Loss:0.5494841680891719\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:10,10\n",
      "            train score: 0.9840909090909091 with variance: 5.1652892561984635e-06\n",
      "            test  score: 0.965909090909091 with variance: 0.00020661157024793355\n",
      "          Refitted train score: 0.9840909090909091,  RMSE: 0.12613124477737825, Log-Loss:0.5494841680891719\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9679017015604124 using:10,3\n",
      "            train score: 0.9994334277620396 with variance: 1.2840164033095977e-06\n",
      "            test  score: 0.9679017015604124 with variance: 0.00013192700964480102\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9681818181818181 using:10,3\n",
      "            train score: 0.9994318181818181 with variance: 1.2913223140495591e-06\n",
      "            test  score: 0.9681818181818181 with variance: 0.0001239669421487601\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.942079297466581 using:10,10\n",
      "            train score: 0.9548264774105094 with variance: 2.9331164645044042e-05\n",
      "            test  score: 0.942079297466581 with variance: 0.0008002151071800396\n",
      "          Refitted train score: 0.9548693586698338,  RMSE: 0.21168684596525353, Log-Loss:1.5477432742517567\n",
      "          Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9434173669467786 using:10,10\n",
      "            train score: 0.955190005205622 with variance: 2.5628871152618727e-05\n",
      "            test  score: 0.9434173669467786 with variance: 0.0006290830057513188\n",
      "          Refitted train score: 0.9551886792452831,  RMSE: 0.21168684596525353, Log-Loss:1.5477432742517567\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9519803944031502 using:10,10\n",
      "            train score: 0.9626849423053523 with variance: 2.0729678793337525e-05\n",
      "            test  score: 0.9519803944031502 with variance: 0.0007271095457570933\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.19425717247145283, Log-Loss:1.3033651393821057\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.952829131652661 using:10,3\n",
      "            train score: 0.9775967378101683 with variance: 4.720885287558294e-05\n",
      "            test  score: 0.952829131652661 with variance: 0.0003875934687600534\n",
      "          Refitted train score: 0.9787735849056604,  RMSE: 0.14569287935358963, Log-Loss:0.7331381762949457\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9588782489740082 using:10,3\n",
      "            train score: 0.9796404513208348 with variance: 3.787202593631231e-05\n",
      "            test  score: 0.9588782489740082 with variance: 0.0009431197261776198\n",
      "          Refitted train score: 0.9784172661870504,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519497\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9599159663865546 using:10,3\n",
      "            train score: 0.9799531494013534 with variance: 3.618503808046989e-05\n",
      "            test  score: 0.9599159663865546 with variance: 0.0008075418402655185\n",
      "          Refitted train score: 0.9787735849056604,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519497\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9685828284802293 using:10,3\n",
      "            train score: 0.9857107004190577 with variance: 1.2114357257512186e-05\n",
      "            test  score: 0.9685828284802293 with variance: 0.000711687985515631\n",
      "          Refitted train score: 0.9857142857142858,  RMSE: 0.11895773785772162, Log-Loss:0.4887581555822988\n",
      "          Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9692997198879553 using:10,3\n",
      "            train score: 0.9858511192087454 with variance: 1.176094220163702e-05\n",
      "            test  score: 0.9692997198879553 with variance: 0.0006459556371568238\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9858490566037735,  RMSE: 0.11895773785772162, Log-Loss:0.4887581555822988\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9708256555634301 using:10,3\n",
      "            train score: 0.9899214724254669 with variance: 5.640352049095875e-06\n",
      "            test  score: 0.9708256555634301 with variance: 0.0006073876864024239\n",
      "          Refitted train score: 0.9929078014184397,  RMSE: 0.08411582311380664, Log-Loss:0.2443800207126478\n",
      "          Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9716806722689076 using:10,3\n",
      "            train score: 0.9899774423043552 with variance: 5.544666474508274e-06\n",
      "            test  score: 0.9716806722689076 with variance: 0.000532702492761811\n",
      "          Refitted train score: 0.9929245283018868,  RMSE: 0.08411582311380664, Log-Loss:0.2443800207126478\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9731908899213412 using:10,3\n",
      "            train score: 0.9899214724254669 with variance: 5.640352049095875e-06\n",
      "            test  score: 0.9731908899213412 with variance: 0.0008883732629128919\n",
      "          Refitted train score: 0.9928741092636578,  RMSE: 0.08411582311380664, Log-Loss:0.24437813486965204\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9740896358543416 using:10,3\n",
      "            train score: 0.9899774423043552 with variance: 5.544666474508274e-06\n",
      "            test  score: 0.9740896358543416 with variance: 0.0007964440678232095\n",
      "          Refitted train score: 0.9929245283018868,  RMSE: 0.08411582311380664, Log-Loss:0.24437813486965204\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9731225743309372 using:10,3\n",
      "            train score: 0.9934646924106836 with variance: 1.2030308639594688e-05\n",
      "            test  score: 0.9731225743309372 with variance: 0.0006003777858204099\n",
      "          Refitted train score: 0.9952606635071091,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976837\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9740896358543418 using:10,3\n",
      "            train score: 0.9935137948984905 with variance: 1.1838359608491738e-05\n",
      "            test  score: 0.9740896358543418 with variance: 0.0005196274588266681\n",
      "          Refitted train score: 0.9952830188679245,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976837\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9708243527167101 using:10,3\n",
      "            train score: 0.9988200589970502 with variance: 2.0883911556635148e-06\n",
      "            test  score: 0.9708243527167101 with variance: 0.0005520403176456646\n",
      "          Refitted train score: 0.9976359338061466,  RMSE: 0.04856429311786321, Log-Loss:0.0814593782898847\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9717366946778713 using:10,3\n",
      "            train score: 0.9988200589970502 with variance: 2.0883911556635148e-06\n",
      "            test  score: 0.9717366946778713 with variance: 0.00047520498395436597\n",
      "          Refitted train score: 0.9976415094339622,  RMSE: 0.04856429311786321, Log-Loss:0.0814593782898847\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9597058031982073 using:10,10\n",
      "            train score: 0.9678923525652788 with variance: 8.65643863362521e-06\n",
      "            test  score: 0.9597058031982073 with variance: 0.00041649719651216493\n",
      "          Refitted train score: 0.9665071770334929,  RMSE: 0.18085983626508062, Log-Loss:1.1297767960832017\n",
      "          Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "        accuracy\n",
      "          CV score: 0.960328317373461 using:10,3\n",
      "            train score: 0.9742979898726407 with variance: 1.1674640650464823e-05\n",
      "            test  score: 0.960328317373461 with variance: 0.000248828039471444\n",
      "          Refitted train score: 0.9766355140186916,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270273\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9693537644814161 using:10,3\n",
      "            train score: 0.9788023812456093 with variance: 1.1648000761572457e-05\n",
      "            test  score: 0.9693537644814161 with variance: 0.00025256177027266726\n",
      "          Refitted train score: 0.9788235294117645,  RMSE: 0.14501047335684952, Log-Loss:0.7262882858562785\n",
      "          Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "        accuracy\n",
      "          CV score: 0.9696853625170998 using:10,3\n",
      "            train score: 0.9789746475031116 with variance: 1.150100410505097e-05\n",
      "            test  score: 0.9696853625170998 with variance: 0.0002470135357932184\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262882858562785\n",
      "          Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9671083755479757 using:10,3\n",
      "            train score: 0.978222821988278 with variance: 5.517147411742172e-06\n",
      "            test  score: 0.9671083755479757 with variance: 0.00023954011453088329\n",
      "          Refitted train score: 0.9788235294117645,  RMSE: 0.14501047335684952, Log-Loss:0.7262882858562785\n",
      "          Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "        accuracy\n",
      "          CV score: 0.967359781121751 using:10,3\n",
      "            train score: 0.9783898521814741 with variance: 5.377169236421611e-06\n",
      "            test  score: 0.967359781121751 with variance: 0.00023581511375268788\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262882858562785\n",
      "          Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9693537644814161 using:10,3\n",
      "            train score: 0.9817524881906671 with variance: 1.1824256046542506e-05\n",
      "            test  score: 0.9693537644814161 with variance: 0.00025256177027266726\n",
      "          Refitted train score: 0.9788235294117645,  RMSE: 0.14501047335684952, Log-Loss:0.7262882858562785\n",
      "          Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "        accuracy\n",
      "          CV score: 0.9696853625170998 using:10,3\n",
      "            train score: 0.9818935092834126 with variance: 1.1584383598616618e-05\n",
      "            test  score: 0.9696853625170998 with variance: 0.0002470135357932184\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262882858562785\n",
      "          Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9691870001012454 using:10,10\n",
      "            train score: 0.9752313737726886 with variance: 1.6187775419178692e-05\n",
      "            test  score: 0.9691870001012454 with variance: 0.0003662074344764707\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.9696853625170998 using:10,10\n",
      "            train score: 0.9754709904011729 with variance: 1.551955036358719e-05\n",
      "            test  score: 0.9696853625170998 with variance: 0.00035518011232107114\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.97176272806685 using:10,3\n",
      "            train score: 0.991792195130687 with variance: 4.812884116105011e-06\n",
      "            test  score: 0.97176272806685 with variance: 0.00030871297159893314\n",
      "          Refitted train score: 0.9929742388758782,  RMSE: 0.08372183582789214, Log-Loss:0.24209609528542678\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.9720383036935705 using:10,3\n",
      "            train score: 0.9918213902102193 with variance: 4.797884652830081e-06\n",
      "            test  score: 0.9720383036935705 with variance: 0.00030108933848091484\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209609528542678\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9764686104197912 using:10,3\n",
      "            train score: 0.9953009875923557 with variance: 2.1004714664828084e-06\n",
      "            test  score: 0.9764686104197912 with variance: 0.00033087691505280037\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.1613961513780883\n",
      "          Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:10,3\n",
      "            train score: 0.9953267522547866 with variance: 2.0499658335782464e-06\n",
      "            test  score: 0.9766894664842681 with variance: 0.00032323167297014586\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.1613961513780883\n",
      "          Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9718715382308515 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9718715382308515 with variance: 0.00041663448763809823\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.9720383036935705 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9720383036935705 with variance: 0.00040925591500876756\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9401068334310467 using:10,10\n",
      "            train score: 0.951780025540026 with variance: 2.8648029300342095e-05\n",
      "            test  score: 0.9401068334310467 with variance: 0.00042369747228682895\n",
      "          Refitted train score: 0.9501187648456058,  RMSE: 0.2220265178934429, Log-Loss:1.70263075369147\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.941313269493844 using:20,3\n",
      "            train score: 0.9653769190960843 with variance: 1.8488098080270776e-05\n",
      "            test  score: 0.941313269493844 with variance: 0.0002215281429595354\n",
      "          Refitted train score: 0.9647887323943662,  RMSE: 0.18764665626020038, Log-Loss:1.2161616063694398\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9543479219689537 using:20,3\n",
      "            train score: 0.9684320522478853 with variance: 9.306048253217118e-06\n",
      "            test  score: 0.9543479219689537 with variance: 0.0003454062154529977\n",
      "          Refitted train score: 0.9691211401425178,  RMSE: 0.1746895300952024, Log-Loss:1.0540077265811267\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9554309165526677 using:20,3\n",
      "            train score: 0.968899430740038 with variance: 8.799123969144098e-06\n",
      "            test  score: 0.9554309165526677 with variance: 0.0002951742361437301\n",
      "          Refitted train score: 0.9694835680751174,  RMSE: 0.1746895300952024, Log-Loss:1.0540077265811267\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9597473442434682 using:10,3\n",
      "            train score: 0.9839190852350885 with variance: 1.6795645184479692e-05\n",
      "            test  score: 0.9597473442434682 with variance: 0.00022346842120404492\n",
      "          Refitted train score: 0.983372921615202,  RMSE: 0.12818706987301454, Log-Loss:0.5675404562483694\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9601094391244871 using:10,3\n",
      "            train score: 0.9841555977229601 with variance: 1.5803799940658e-05\n",
      "            test  score: 0.9601094391244871 with variance: 0.0001978108432314482\n",
      "          Refitted train score: 0.9835680751173709,  RMSE: 0.12818706987301454, Log-Loss:0.5675404562483694\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.96187414500684 using:10,3\n",
      "            train score: 0.9881337935501154 with variance: 7.111646595782178e-06\n",
      "            test  score: 0.96187414500684 with variance: 0.00020392880468447384\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "        accuracy\n",
      "          CV score: 0.962435020519836 using:10,3\n",
      "            train score: 0.9882646196308436 with variance: 6.849640482819212e-06\n",
      "            test  score: 0.962435020519836 with variance: 0.00018864849792555975\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9641723666210671 using:10,3\n",
      "            train score: 0.9935066799678955 with variance: 4.931717409962456e-06\n",
      "            test  score: 0.9641723666210671 with variance: 0.00029340539448051027\n",
      "          Refitted train score: 0.9952830188679246,  RMSE: 0.06851887098275317, Log-Loss:0.16215387978831403\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "        accuracy\n",
      "          CV score: 0.9647879616963065 using:10,3\n",
      "            train score: 0.9935466620665862 with variance: 4.803790983713272e-06\n",
      "            test  score: 0.9647879616963065 with variance: 0.0002768435570709695\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06851887098275317, Log-Loss:0.16215387978831403\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9664132629796105 using:10,3\n",
      "            train score: 0.9923162350391035 with variance: 2.163748033601907e-06\n",
      "            test  score: 0.9664132629796105 with variance: 0.0002104290210766107\n",
      "          Refitted train score: 0.990521327014218,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9671409028727771 using:10,3\n",
      "            train score: 0.9923701914783509 with variance: 2.076213839348522e-06\n",
      "            test  score: 0.9671409028727771 with variance: 0.00018787598645859344\n",
      "          Refitted train score: 0.9906103286384976,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9642257833365905 using:10,10\n",
      "            train score: 0.9863213946091249 with variance: 9.506436677696517e-06\n",
      "            test  score: 0.9642257833365905 with variance: 0.0001235519376628367\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9857142857142858,  RMSE: 0.11867816581938534, Log-Loss:0.4864616393649401\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9648153214774282 using:10,10\n",
      "            train score: 0.9865033638088667 with variance: 8.91976002886934e-06\n",
      "            test  score: 0.9648153214774282 with variance: 0.0001081995130632661\n",
      "          Refitted train score: 0.9859154929577465,  RMSE: 0.11867816581938534, Log-Loss:0.4864616393649401\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9737754355888834 using:20,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9737754355888834 with variance: 0.0001353408113452629\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "        accuracy\n",
      "          CV score: 0.9742270861833106 using:10,10\n",
      "            train score: 0.9964792133862342 with variance: 1.3739655658740281e-06\n",
      "            test  score: 0.9742270861833106 with variance: 0.0001836481330037186\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06851887098275317, Log-Loss:0.16215387978831403\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9441304950042941 using:10,3\n",
      "            train score: 0.9737566884659496 with variance: 3.6438103908404536e-06\n",
      "            test  score: 0.9441304950042941 with variance: 0.0007029073130166211\n",
      "          Refitted train score: 0.979020979020979,  RMSE: 0.14433756729740643, Log-Loss:0.719563394320572\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9445602780005344 using:10,3\n",
      "            train score: 0.973959956437966 with variance: 3.264986814800799e-06\n",
      "            test  score: 0.9445602780005344 with variance: 0.0007057794092081345\n",
      "          Refitted train score: 0.9791666666666666,  RMSE: 0.14433756729740643, Log-Loss:0.719563394320572\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9536749759890201 using:10,10\n",
      "            train score: 0.9672608995314016 with variance: 1.4560887506078441e-05\n",
      "            test  score: 0.9536749759890201 with variance: 0.000575139265287093\n",
      "          Refitted train score: 0.9647058823529412,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9538091419406577 using:10,10\n",
      "            train score: 0.9675931976208428 with variance: 1.47384755417339e-05\n",
      "            test  score: 0.9538091419406577 with variance: 0.0005801509830489725\n",
      "          Refitted train score: 0.9652777777777778,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9651265127666493 using:10,3\n",
      "            train score: 0.9778422487387648 with variance: 1.8570940757549996e-05\n",
      "            test  score: 0.9651265127666493 with variance: 0.00046290769050031847\n",
      "          Refitted train score: 0.9767441860465117,  RMSE: 0.15214515486254615, Log-Loss:0.7995161165250648\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9653835872761294 using:10,3\n",
      "            train score: 0.9780145765267655 with variance: 1.8545005859242707e-05\n",
      "            test  score: 0.9653835872761294 with variance: 0.00047318768644497337\n",
      "          Refitted train score: 0.9768518518518519,  RMSE: 0.15214515486254615, Log-Loss:0.7995161165250648\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9694504833696896 using:10,3\n",
      "            train score: 0.9848292222358023 with variance: 1.4107695584234072e-06\n",
      "            test  score: 0.9694504833696896 with variance: 0.0002501143434671637\n",
      "          Refitted train score: 0.9836829836829837,  RMSE: 0.1272937693043289, Log-Loss:0.5596598008315639\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9699812884255546 using:10,3\n",
      "            train score: 0.9849543436374297 with variance: 1.3175479384386057e-06\n",
      "            test  score: 0.9699812884255546 with variance: 0.00024188927523892176\n",
      "          Refitted train score: 0.9837962962962963,  RMSE: 0.1272937693043289, Log-Loss:0.5596598008315639\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9694504833696896 using:10,3\n",
      "            train score: 0.9924502273547029 with variance: 1.9696754393020358e-06\n",
      "            test  score: 0.9694504833696896 with variance: 0.0002501143434671637\n",
      "          Refitted train score: 0.9906976744186047,  RMSE: 0.09622504486493763, Log-Loss:0.3198053360580402\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9699812884255546 using:10,3\n",
      "            train score: 0.9924771718187149 with variance: 2.0048568491602977e-06\n",
      "            test  score: 0.9699812884255546 with variance: 0.00024188927523892176\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.3198053360580402\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9672095870111461 using:10,3\n",
      "            train score: 0.9895482088136083 with variance: 8.779373334932972e-06\n",
      "            test  score: 0.9672095870111461 with variance: 0.00034670290909550835\n",
      "          Refitted train score: 0.993006993006993,  RMSE: 0.08333333333333333, Log-Loss:0.2398526138535474\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9676824378508421 using:10,3\n",
      "            train score: 0.9895836474826171 with variance: 8.685502829987533e-06\n",
      "            test  score: 0.9676824378508421 with variance: 0.00033639962498252095\n",
      "          Refitted train score: 0.9930555555555556,  RMSE: 0.08333333333333333, Log-Loss:0.2398526138535474\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9672095870111461 using:10,3\n",
      "            train score: 0.9930164263895674 with variance: 2.012853957933449e-06\n",
      "            test  score: 0.9672095870111461 with variance: 0.00034670290909550835\n",
      "          Refitted train score: 0.993006993006993,  RMSE: 0.08333333333333333, Log-Loss:0.2398526138535474\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9676824378508421 using:10,3\n",
      "            train score: 0.9930552065007958 with variance: 2.0145416054990765e-06\n",
      "            test  score: 0.9676824378508421 with variance: 0.00033639962498252095\n",
      "          Refitted train score: 0.9930555555555556,  RMSE: 0.08333333333333333, Log-Loss:0.2398526138535474\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9768976932465776 using:10,3\n",
      "            train score: 0.9994236311239193 with variance: 1.3288043252581252e-06\n",
      "            test  score: 0.9768976932465776 with variance: 0.00025837903729210147\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9769313017909649 using:10,3\n",
      "            train score: 0.9994202898550725 with variance: 1.3442554085275707e-06\n",
      "            test  score: 0.9769313017909649 with variance: 0.00026363262920736245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.940058702131536 using:10,10\n",
      "            train score: 0.9525402675402674 with variance: 2.7676108839089695e-05\n",
      "            test  score: 0.940058702131536 with variance: 5.625751890539489e-05\n",
      "          Refitted train score: 0.9521531100478469,  RMSE: 0.21821789023599236, Log-Loss:1.6447207720835373\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9404761904761905 using:10,10\n",
      "            train score: 0.9529761904761905 with variance: 2.6218820861678264e-05\n",
      "            test  score: 0.9404761904761905 with variance: 5.668934240362772e-05\n",
      "          Refitted train score: 0.9523809523809523,  RMSE: 0.21821789023599236, Log-Loss:1.6447207720835373\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9404787183765165 using:10,3\n",
      "            train score: 0.9723818242776643 with variance: 8.962232427743118e-06\n",
      "            test  score: 0.9404787183765165 with variance: 0.0001587657737782703\n",
      "          Refitted train score: 0.9759615384615385,  RMSE: 0.1543033499620919, Log-Loss:0.8223575303366614\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9404761904761905 using:10,3\n",
      "            train score: 0.9726190476190476 with variance: 8.503401360544156e-06\n",
      "            test  score: 0.9404761904761905 with variance: 0.0001700680272108842\n",
      "          Refitted train score: 0.9761904761904762,  RMSE: 0.1543033499620919, Log-Loss:0.8223575303366614\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9641244790386472 using:10,3\n",
      "            train score: 0.9740434416938621 with variance: 1.7044284183794106e-05\n",
      "            test  score: 0.9641244790386472 with variance: 4.935958026906325e-05\n",
      "          Refitted train score: 0.9758454106280193,  RMSE: 0.1543033499620919, Log-Loss:0.8223556265332562\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9642857142857142 using:10,3\n",
      "            train score: 0.9744047619047619 with variance: 1.6298185941042967e-05\n",
      "            test  score: 0.9642857142857142 with variance: 5.6689342403628236e-05\n",
      "          Refitted train score: 0.9761904761904762,  RMSE: 0.1543033499620919, Log-Loss:0.8223556265332562\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9661377179598126 using:10,3\n",
      "            train score: 0.9819166602550006 with variance: 1.1216797448325031e-05\n",
      "            test  score: 0.9661377179598126 with variance: 8.509190805198137e-05\n",
      "          Refitted train score: 0.983132530120482,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:10,3\n",
      "            train score: 0.9821428571428571 with variance: 1.0629251700680461e-05\n",
      "            test  score: 0.9666666666666666 with variance: 7.936507936507945e-05\n",
      "          Refitted train score: 0.9833333333333333,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9662429060613974 using:10,3\n",
      "            train score: 0.9898112608931792 with variance: 1.3037863211928238e-05\n",
      "            test  score: 0.9662429060613974 with variance: 7.417724425625222e-05\n",
      "          Refitted train score: 0.9904306220095694,  RMSE: 0.09759000729485333, Log-Loss:0.3289426313739841\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:10,3\n",
      "            train score: 0.9898809523809524 with variance: 1.2755102040816236e-05\n",
      "            test  score: 0.9666666666666666 with variance: 7.936507936507945e-05\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.3289426313739841\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9710157667403004 using:10,3\n",
      "            train score: 0.9934292608812226 with variance: 1.2114294454112402e-05\n",
      "            test  score: 0.9710157667403004 with variance: 3.47298767962247e-05\n",
      "          Refitted train score: 0.9928400954653939,  RMSE: 0.08451542547285165, Log-Loss:0.2467074494813396\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:10,3\n",
      "            train score: 0.993452380952381 with variance: 1.2046485260770888e-05\n",
      "            test  score: 0.9714285714285713 with variance: 3.401360544217663e-05\n",
      "          Refitted train score: 0.9928571428571429,  RMSE: 0.08451542547285165, Log-Loss:0.2467074494813396\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.968309315694149 using:10,3\n",
      "            train score: 0.9958101707033695 with variance: 5.7413230812109245e-06\n",
      "            test  score: 0.968309315694149 with variance: 9.691253362333718e-05\n",
      "          Refitted train score: 0.9952153110047847,  RMSE: 0.06900655593423542, Log-Loss:0.16447036378528992\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9690476190476189 using:10,3\n",
      "            train score: 0.9958333333333332 with variance: 5.668934240362771e-06\n",
      "            test  score: 0.9690476190476189 with variance: 9.07029478458052e-05\n",
      "          Refitted train score: 0.9952380952380953,  RMSE: 0.06900655593423542, Log-Loss:0.16447036378528992\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9710009461263425 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9710009461263425 with variance: 9.357243717833913e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714285714285715 with variance: 9.070294784580509e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9477823900644594 using:10,10\n",
      "            train score: 0.9608822361560589 with variance: 4.1607208091505314e-05\n",
      "            test  score: 0.9477823900644594 with variance: 0.0006639288783860649\n",
      "          Refitted train score: 0.957345971563981,  RMSE: 0.20507577810739896, Log-Loss:1.4525765717125556\n",
      "          Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.5243649382561935\n",
      "        accuracy\n",
      "          CV score: 0.9487004103967168 using:10,10\n",
      "            train score: 0.961451247165533 with variance: 3.874652391206703e-05\n",
      "            test  score: 0.9487004103967168 with variance: 0.0006216696203502884\n",
      "          Refitted train score: 0.9579439252336449,  RMSE: 0.20507577810739896, Log-Loss:1.4525765717125556\n",
      "          Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.5243649382561935\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9527170868347339 using:10,10\n",
      "            train score: 0.9645768607639551 with variance: 2.8150860486254523e-05\n",
      "            test  score: 0.9527170868347339 with variance: 0.0007963781591067816\n",
      "          Refitted train score: 0.9645390070921985,  RMSE: 0.18720771611224418, Log-Loss:1.2104804764271297\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919856\n",
      "        accuracy\n",
      "          CV score: 0.9533789329685363 using:10,10\n",
      "            train score: 0.9649566092101001 with variance: 2.7022914814084314e-05\n",
      "            test  score: 0.9533789329685363 with variance: 0.0007533738427767015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9649532710280374,  RMSE: 0.18720771611224418, Log-Loss:1.2104804764271297\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919856\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9598879551820729 using:10,3\n",
      "            train score: 0.9799893436004952 with variance: 3.3160128658170666e-05\n",
      "            test  score: 0.9598879551820729 with variance: 0.0006992098800304441\n",
      "          Refitted train score: 0.9811320754716981,  RMSE: 0.13671718540493263, Log-Loss:0.6455883419489399\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9603830369357045 using:10,3\n",
      "            train score: 0.9801408282611291 with variance: 3.2119580830240575e-05\n",
      "            test  score: 0.9603830369357045 with variance: 0.0006807128514244122\n",
      "          Refitted train score: 0.9813084112149533,  RMSE: 0.13671718540493263, Log-Loss:0.6455883419489399\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9598879551820729 using:10,3\n",
      "            train score: 0.9847300022440658 with variance: 1.5051012624384027e-05\n",
      "            test  score: 0.9598879551820729 with variance: 0.0006992098800304441\n",
      "          Refitted train score: 0.9859154929577464,  RMSE: 0.11840055569457876, Log-Loss:0.4841921905708526\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9603830369357045 using:10,3\n",
      "            train score: 0.9848123710637136 with variance: 1.5067741875060278e-05\n",
      "            test  score: 0.9603830369357045 with variance: 0.0006807128514244122\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.4841921905708526\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9644797678107387 using:10,3\n",
      "            train score: 0.9899878023013331 with variance: 1.2531075121908754e-05\n",
      "            test  score: 0.9644797678107387 with variance: 0.0007185142304967333\n",
      "          Refitted train score: 0.988235294117647,  RMSE: 0.10808442529177922, Log-Loss:0.4034922466635141\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.965061559507524 using:10,3\n",
      "            train score: 0.9900721190731933 with variance: 1.226390147244422e-05\n",
      "            test  score: 0.965061559507524 with variance: 0.0007018221763938615\n",
      "          Refitted train score: 0.9883177570093458,  RMSE: 0.10808442529177922, Log-Loss:0.4034922466635141\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9644797678107387 using:10,3\n",
      "            train score: 0.9917611333346261 with variance: 4.931616324213334e-06\n",
      "            test  score: 0.9644797678107387 with variance: 0.0007185142304967333\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.965061559507524 using:10,3\n",
      "            train score: 0.9918213902102193 with variance: 4.797884652830081e-06\n",
      "            test  score: 0.965061559507524 with variance: 0.0007018221763938615\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9694561031724696 using:20,3\n",
      "            train score: 0.9953009975920193 with variance: 5.520333408712313e-06\n",
      "            test  score: 0.9694561031724696 with variance: 0.00035145935338898055\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9697127222982218 using:10,3\n",
      "            train score: 0.995325047312158 with variance: 5.463839260830984e-06\n",
      "            test  score: 0.9697127222982218 with variance: 0.00035619815068839195\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9622292124161671 using:10,3\n",
      "            train score: 0.9994169096209913 with variance: 1.3599775603702421e-06\n",
      "            test  score: 0.9622292124161671 with variance: 0.0006290298072651962\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.962735978112175 using:10,3\n",
      "            train score: 0.9994169096209913 with variance: 1.3599775603702421e-06\n",
      "            test  score: 0.962735978112175 with variance: 0.0006150344055797485\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9483392636054935 using:10,10\n",
      "            train score: 0.9577512765932246 with variance: 4.772267315477219e-06\n",
      "            test  score: 0.9483392636054935 with variance: 0.00047365972961696117\n",
      "          Refitted train score: 0.9558823529411764,  RMSE: 0.2090199042874853, Log-Loss:1.5089892531320486\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9490743461651483 using:10,10\n",
      "            train score: 0.9581320806852721 with variance: 5.06120202521576e-06\n",
      "            test  score: 0.9490743461651483 with variance: 0.000434609865679182\n",
      "          Refitted train score: 0.9563106796116505,  RMSE: 0.2090199042874853, Log-Loss:1.5089892531320486\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9460023600027669 using:10,10\n",
      "            train score: 0.966407177344955 with variance: 1.4449243790466345e-05\n",
      "            test  score: 0.9460023600027669 with variance: 0.0006135755125997357\n",
      "          Refitted train score: 0.9656862745098039,  RMSE: 0.18433822860240315, Log-Loss:1.173657445426944\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9466059359388774 using:10,10\n",
      "            train score: 0.9666224555586258 with variance: 1.4985619148047993e-05\n",
      "            test  score: 0.9466059359388774 with variance: 0.0005701922963169948\n",
      "          Refitted train score: 0.9660194174757282,  RMSE: 0.18433822860240315, Log-Loss:1.173657445426944\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9552546938274282 using:10,3\n",
      "            train score: 0.9747985946614264 with variance: 1.5730080355216618e-06\n",
      "            test  score: 0.9552546938274282 with variance: 0.0007806579009499484\n",
      "          Refitted train score: 0.9704433497536945,  RMSE: 0.1706640371965723, Log-Loss:1.00598960080393\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.956362033499853 using:10,3\n",
      "            train score: 0.9751220410794879 with variance: 1.4348147663450956e-06\n",
      "            test  score: 0.956362033499853 with variance: 0.0007406474158209778\n",
      "          Refitted train score: 0.970873786407767,  RMSE: 0.1706640371965723, Log-Loss:1.00598960080393\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9605146705146705 using:10,3\n",
      "            train score: 0.9828293830433011 with variance: 1.3996242636703863e-05\n",
      "            test  score: 0.9605146705146705 with variance: 0.00047179285005162724\n",
      "          Refitted train score: 0.9902439024390244,  RMSE: 0.0985329278164293, Log-Loss:0.3353298669346439\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9612106964443139 using:10,3\n",
      "            train score: 0.9830081974762825 with variance: 1.3299825477869442e-05\n",
      "            test  score: 0.9612106964443139 with variance: 0.00043570999953455956\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9902912621359223,  RMSE: 0.0985329278164293, Log-Loss:0.3353298669346439\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9653016204740343 using:10,3\n",
      "            train score: 0.9896468826445683 with variance: 2.3557598560477316e-06\n",
      "            test  score: 0.9653016204740343 with variance: 0.0004258439633079517\n",
      "          Refitted train score: 0.9902439024390244,  RMSE: 0.0985329278164293, Log-Loss:0.3353298669346439\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9660299735527476 using:10,3\n",
      "            train score: 0.9896840747904578 with variance: 2.2175119563019276e-06\n",
      "            test  score: 0.9660299735527476 with variance: 0.00037991231570491224\n",
      "          Refitted train score: 0.9902912621359223,  RMSE: 0.0985329278164293, Log-Loss:0.3353298669346439\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9653016204740343 using:10,3\n",
      "            train score: 0.9920860311137961 with variance: 5.96280251776213e-06\n",
      "            test  score: 0.9653016204740343 with variance: 0.0004258439633079517\n",
      "          Refitted train score: 0.9902439024390244,  RMSE: 0.0985329278164293, Log-Loss:0.3353298669346439\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9660299735527476 using:10,3\n",
      "            train score: 0.9921101593442019 with variance: 5.926291965105986e-06\n",
      "            test  score: 0.9660299735527476 with variance: 0.00037991231570491224\n",
      "          Refitted train score: 0.9902912621359223,  RMSE: 0.0985329278164293, Log-Loss:0.3353298669346439\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9662221784995146 using:10,3\n",
      "            train score: 0.9963450794517236 with variance: 5.210772033313123e-06\n",
      "            test  score: 0.9662221784995146 with variance: 0.0004095871835634667\n",
      "          Refitted train score: 0.9951456310679612,  RMSE: 0.06967330142916177, Log-Loss:0.16766590385255337\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9660593593887746 using:10,3\n",
      "            train score: 0.9963562678456295 with variance: 5.178140005557831e-06\n",
      "            test  score: 0.9660593593887746 with variance: 0.0004335598164106295\n",
      "          Refitted train score: 0.9951456310679612,  RMSE: 0.06967330142916177, Log-Loss:0.16766590385255337\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9663542934201447 using:10,10\n",
      "            train score: 0.9902991904130449 with variance: 5.0060060265940365e-06\n",
      "            test  score: 0.9663542934201447 with variance: 0.0003363120219158827\n",
      "          Refitted train score: 0.9878934624697338,  RMSE: 0.11016316230980794, Log-Loss:0.41916573001661267\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9660887452248016 using:10,3\n",
      "            train score: 0.9993920972644377 with variance: 1.4781829436165328e-06\n",
      "            test  score: 0.9660887452248016 with variance: 0.0004319916507266711\n",
      "          Refitted train score: 0.9975728155339806,  RMSE: 0.04926646390821465, Log-Loss:0.08383392231150799\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9332230197019525 using:10,3\n",
      "            train score: 0.9733278034020889 with variance: 1.169426383055725e-05\n",
      "            test  score: 0.9332230197019525 with variance: 0.0008183472448054502\n",
      "          Refitted train score: 0.9720101781170485,  RMSE: 0.1662473787906861, Log-Loss:0.9545953244630865\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9346835443037975 using:10,3\n",
      "            train score: 0.9736144792097947 with variance: 1.0446922460783398e-05\n",
      "            test  score: 0.9346835443037975 with variance: 0.0007253985739464822\n",
      "          Refitted train score: 0.9723618090452262,  RMSE: 0.1662473787906861, Log-Loss:0.9545953244630865\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.948424742898427 using:10,3\n",
      "            train score: 0.9801827719816169 with variance: 6.0878508010487335e-06\n",
      "            test  score: 0.948424742898427 with variance: 0.0009302127302066515\n",
      "          Refitted train score: 0.9768637532133677,  RMSE: 0.15037641213512565, Log-Loss:0.7810276069200917\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9496835443037975 using:10,3\n",
      "            train score: 0.9805268034936219 with variance: 5.568354784370959e-06\n",
      "            test  score: 0.9496835443037975 with variance: 0.0008348922448325581\n",
      "          Refitted train score: 0.9773869346733668,  RMSE: 0.15037641213512565, Log-Loss:0.7810276069200917\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9635823542841087 using:10,3\n",
      "            train score: 0.9796012053562956 with variance: 1.925011233987103e-05\n",
      "            test  score: 0.9635823542841087 with variance: 0.0006880538936021933\n",
      "          Refitted train score: 0.9770992366412214,  RMSE: 0.15037641213512565, Log-Loss:0.7810316249976305\n",
      "          Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.964746835443038 using:10,3\n",
      "            train score: 0.9798959011060507 with variance: 1.8263234719412368e-05\n",
      "            test  score: 0.964746835443038 with variance: 0.000601560246755328\n",
      "          Refitted train score: 0.9773869346733668,  RMSE: 0.15037641213512565, Log-Loss:0.7810316249976305\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9605587599134824 using:10,3\n",
      "            train score: 0.9917861027460442 with variance: 6.424599367881851e-06\n",
      "            test  score: 0.9605587599134824 with variance: 0.00104688691833583\n",
      "          Refitted train score: 0.9847715736040609,  RMSE: 0.1227818263605087, Log-Loss:0.5206870803188308\n",
      "          Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9622151898734177 using:10,3\n",
      "            train score: 0.9918377003607972 with variance: 6.244840276810982e-06\n",
      "            test  score: 0.9622151898734177 with variance: 0.0008957538855952577\n",
      "          Refitted train score: 0.9849246231155779,  RMSE: 0.1227818263605087, Log-Loss:0.5206870803188308\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9765384615384616 using:10,3\n",
      "            train score: 0.993678872339576 with variance: 3.980630853565509e-06\n",
      "            test  score: 0.9765384615384616 with variance: 0.000594937541091387\n",
      "          Refitted train score: 0.9924050632911393,  RMSE: 0.0868198620259849, Log-Loss:0.26034253564003124\n",
      "          Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9773417721518989 using:10,3\n",
      "            train score: 0.9937205496737052 with variance: 3.918495783691719e-06\n",
      "            test  score: 0.9773417721518989 with variance: 0.0005377583720557605\n",
      "          Refitted train score: 0.992462311557789,  RMSE: 0.0868198620259849, Log-Loss:0.26034253564003124\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9817480764849187 using:10,3\n",
      "            train score: 0.993678872339576 with variance: 3.980630853565509e-06\n",
      "            test  score: 0.9817480764849187 with variance: 0.0003861088489479479\n",
      "          Refitted train score: 0.9949494949494949,  RMSE: 0.0708881205008336, Log-Loss:0.17356169042668781\n",
      "          Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9823417721518988 using:10,3\n",
      "            train score: 0.9937205496737052 with variance: 3.918495783691719e-06\n",
      "            test  score: 0.9823417721518988 with variance: 0.0003579714789296595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.0708881205008336, Log-Loss:0.17356169042668781\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9764094133714387 using:10,3\n",
      "            train score: 0.993678872339576 with variance: 3.980630853565509e-06\n",
      "            test  score: 0.9764094133714387 with variance: 0.000529644198309837\n",
      "          Refitted train score: 0.9924050632911393,  RMSE: 0.0868198620259849, Log-Loss:0.26034253564003124\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9773101265822784 using:10,3\n",
      "            train score: 0.9937205496737052 with variance: 3.918495783691719e-06\n",
      "            test  score: 0.9773101265822784 with variance: 0.00047461945201089607\n",
      "          Refitted train score: 0.992462311557789,  RMSE: 0.0868198620259849, Log-Loss:0.26034253564003124\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9714183185235818 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714183185235818 with variance: 0.0003042007709885533\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9723101265822784 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9723101265822784 with variance: 0.0002804438391283451\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9414815509693559 using:10,3\n",
      "            train score: 0.9685058429061764 with variance: 5.204935901887649e-05\n",
      "            test  score: 0.9414815509693559 with variance: 0.0012587819560458545\n",
      "          Refitted train score: 0.9721518987341773,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758617\n",
      "          Refitted test  score: 0.9438202247191011,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "        accuracy\n",
      "          CV score: 0.9429320987654319 using:10,3\n",
      "            train score: 0.9690612697320644 with variance: 4.971392590931256e-05\n",
      "            test  score: 0.9429320987654319 with variance: 0.0011034941319920753\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758617\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9522582638245289 using:10,3\n",
      "            train score: 0.9730324583854136 with variance: 2.2365360845071437e-05\n",
      "            test  score: 0.9522582638245289 with variance: 0.0005469371270877571\n",
      "          Refitted train score: 0.9722921914357682,  RMSE: 0.16500825061880156, Log-Loss:0.9404161869774214\n",
      "          Refitted test  score: 0.9333333333333332,  RMSE: 0.3038218101251, Log-Loss:3.188207045644528\n",
      "        accuracy\n",
      "          CV score: 0.9529012345679012 using:10,3\n",
      "            train score: 0.9733937239613194 with variance: 2.130633347557253e-05\n",
      "            test  score: 0.9529012345679012 with variance: 0.000522313671696387\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404161869774214\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.188207045644528\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9678179626280892 using:10,3\n",
      "            train score: 0.975618642943483 with variance: 1.2822982243391028e-05\n",
      "            test  score: 0.9678179626280892 with variance: 0.00027033882078174234\n",
      "          Refitted train score: 0.9724310776942354,  RMSE: 0.16500825061880156, Log-Loss:0.9404181661789814\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "        accuracy\n",
      "          CV score: 0.9678086419753086 using:10,3\n",
      "            train score: 0.9758666819554334 with variance: 1.3017686716673183e-05\n",
      "            test  score: 0.9678086419753086 with variance: 0.0002813938424020719\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404181661789814\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9678179626280892 using:10,3\n",
      "            train score: 0.9793100852427242 with variance: 1.0201861657684327e-05\n",
      "            test  score: 0.9678179626280892 with variance: 0.00027033882078174234\n",
      "          Refitted train score: 0.985,  RMSE: 0.12186666955535813, Log-Loss:0.5129541038784521\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "        accuracy\n",
      "          CV score: 0.9678086419753086 using:10,3\n",
      "            train score: 0.979581852234071 with variance: 9.836865930009503e-06\n",
      "            test  score: 0.9678086419753086 with variance: 0.0002813938424020719\n",
      "          Refitted train score: 0.9851485148514851,  RMSE: 0.12186666955535813, Log-Loss:0.5129541038784521\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9725795880699037 using:10,3\n",
      "            train score: 0.9875155397025364 with variance: 1.5601179424495405e-05\n",
      "            test  score: 0.9725795880699037 with variance: 0.000204991849958936\n",
      "          Refitted train score: 0.99,  RMSE: 0.09950371902099892, Log-Loss:0.3419680831179285\n",
      "          Refitted test  score: 0.9565217391304347,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9727777777777777 using:10,3\n",
      "            train score: 0.9876218323586745 with variance: 1.5371731935749567e-05\n",
      "            test  score: 0.9727777777777777 with variance: 0.00020699588477366207\n",
      "          Refitted train score: 0.9900990099009901,  RMSE: 0.09950371902099892, Log-Loss:0.3419680831179285\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9701128564892482 using:10,3\n",
      "            train score: 0.9925388081193255 with variance: 6.178004258605168e-06\n",
      "            test  score: 0.9701128564892482 with variance: 0.00022055237201607905\n",
      "          Refitted train score: 0.99,  RMSE: 0.09950371902099892, Log-Loss:0.3419680831179285\n",
      "          Refitted test  score: 0.9565217391304347,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9702777777777778 using:10,3\n",
      "            train score: 0.9925753927301914 with variance: 6.11327143171027e-06\n",
      "            test  score: 0.9702777777777778 with variance: 0.00022088477366255074\n",
      "          Refitted train score: 0.9900990099009901,  RMSE: 0.09950371902099892, Log-Loss:0.3419680831179285\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9700524061715787 using:10,3\n",
      "            train score: 0.9937810800874596 with variance: 3.882039759921003e-06\n",
      "            test  score: 0.9700524061715787 with variance: 0.00027463355407080127\n",
      "          Refitted train score: 0.9975186104218362,  RMSE: 0.04975185951049946, Log-Loss:0.08549202077948286\n",
      "          Refitted test  score: 0.9565217391304347,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9703086419753086 using:10,3\n",
      "            train score: 0.9938118717272484 with variance: 3.834083491949563e-06\n",
      "            test  score: 0.9703086419753086 with variance: 0.0002798506325255288\n",
      "          Refitted train score: 0.9975247524752475,  RMSE: 0.04975185951049946, Log-Loss:0.08549202077948286\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9733158737087152 using:10,3\n",
      "            train score: 0.9993808049535604 with variance: 1.5336100221415305e-06\n",
      "            test  score: 0.9733158737087152 with variance: 0.00033310040708851835\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9787234042553191,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9728086419753087 using:10,3\n",
      "            train score: 0.9993808049535604 with variance: 1.5336100221415305e-06\n",
      "            test  score: 0.9728086419753087 with variance: 0.000389273738759336\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9396708620337313 using:10,3\n",
      "            train score: 0.9659462339196644 with variance: 1.7825959937223392e-05\n",
      "            test  score: 0.9396708620337313 with variance: 0.00015755394699859142\n",
      "          Refitted train score: 0.9672544080604534,  RMSE: 0.18027756377319948, Log-Loss:1.1225202278024755\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9400000000000001 using:10,3\n",
      "            train score: 0.9662499999999999 with variance: 1.7187500000000184e-05\n",
      "            test  score: 0.9400000000000001 with variance: 0.00014999999999999993\n",
      "          Refitted train score: 0.9675,  RMSE: 0.18027756377319948, Log-Loss:1.1225202278024755\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.94974449132677 using:10,3\n",
      "            train score: 0.971640451379602 with variance: 8.167621882242516e-06\n",
      "            test  score: 0.94974449132677 with variance: 0.0002517165678796941\n",
      "          Refitted train score: 0.9773299748110831,  RMSE: 0.15, Log-Loss:0.7771284658662176\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.95 using:10,3\n",
      "            train score: 0.971875 with variance: 7.812499999999944e-06\n",
      "            test  score: 0.95 with variance: 0.0002499999999999999\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771284658662176\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.962523771743181 using:10,3\n",
      "            train score: 0.9804135243774837 with variance: 5.718751272329401e-06\n",
      "            test  score: 0.962523771743181 with variance: 0.0001768674467614873\n",
      "          Refitted train score: 0.9822784810126582,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045133\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9625 using:10,3\n",
      "            train score: 0.9806250000000001 with variance: 5.468749999999933e-06\n",
      "            test  score: 0.9625 with variance: 0.0001874999999999998\n",
      "          Refitted train score: 0.9825,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045133\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9671463089184609 using:10,3\n",
      "            train score: 0.9848579315051467 with variance: 9.780165992055233e-06\n",
      "            test  score: 0.9671463089184609 with variance: 3.47989193008641e-05\n",
      "          Refitted train score: 0.9847715736040609,  RMSE: 0.1224744871391589, Log-Loss:0.5180816459236612\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9674999999999999 using:10,3\n",
      "            train score: 0.985 with variance: 9.375000000000018e-06\n",
      "            test  score: 0.9674999999999999 with variance: 3.749999999999973e-05\n",
      "          Refitted train score: 0.985,  RMSE: 0.1224744871391589, Log-Loss:0.5180816459236612\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9696763316383569 using:10,3\n",
      "            train score: 0.9886474509127321 with variance: 1.0390271116266468e-05\n",
      "            test  score: 0.9696763316383569 with variance: 0.00016933190196428096\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.97 using:10,3\n",
      "            train score: 0.9887499999999999 with variance: 1.0156249999999983e-05\n",
      "            test  score: 0.97 with variance: 0.00016250000000000053\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9721446860687367 using:10,3\n",
      "            train score: 0.9905322593566737 with variance: 4.056337998289322e-06\n",
      "            test  score: 0.9721446860687367 with variance: 0.00021998439711285004\n",
      "          Refitted train score: 0.9924433249370278,  RMSE: 0.08660254037844387, Log-Loss:0.2590408229618311\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9724999999999999 using:10,3\n",
      "            train score: 0.990625 with variance: 3.906249999999972e-06\n",
      "            test  score: 0.9724999999999999 with variance: 0.00021250000000000083\n",
      "          Refitted train score: 0.9925,  RMSE: 0.08660254037844387, Log-Loss:0.2590408229618311\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9795471601378776 using:10,3\n",
      "            train score: 0.9968612606218332 with variance: 3.955563055925291e-06\n",
      "            test  score: 0.9795471601378776 with variance: 0.00011134174310078898\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:10,3\n",
      "            train score: 0.996875 with variance: 3.906249999999972e-06\n",
      "            test  score: 0.9800000000000001 with variance: 0.00010000000000000029\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9744822461489129 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9744822461489129 with variance: 7.09047862047124e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.975 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.975 with variance: 6.250000000000011e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9476748200283673 using:10,3\n",
      "            train score: 0.9714538756262894 with variance: 1.3756062789823493e-05\n",
      "            test  score: 0.9476748200283673 with variance: 0.0008466670993935128\n",
      "          Refitted train score: 0.9675810473815462,  RMSE: 0.17894050529015934, Log-Loss:1.1059292894668964\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9483288166214996 using:10,3\n",
      "            train score: 0.9716752136752136 with variance: 1.2855869676382587e-05\n",
      "            test  score: 0.9483288166214996 with variance: 0.0008090494903410003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9679802955665024,  RMSE: 0.17894050529015934, Log-Loss:1.1059292894668964\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9579406380461233 using:10,10\n",
      "            train score: 0.9621864749790632 with variance: 2.0408204211293293e-05\n",
      "            test  score: 0.9579406380461233 with variance: 0.0004048035703642949\n",
      "          Refitted train score: 0.9627791563275433,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9581451370069256 using:10,10\n",
      "            train score: 0.9624368471035136 with variance: 2.0573700249547107e-05\n",
      "            test  score: 0.9581451370069256 with variance: 0.000400651334961943\n",
      "          Refitted train score: 0.9630541871921182,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9580454206999255 using:10,10\n",
      "            train score: 0.9702354998180542 with variance: 5.363606066834661e-06\n",
      "            test  score: 0.9580454206999255 with variance: 0.00039005460596823314\n",
      "          Refitted train score: 0.9702970297029703,  RMSE: 0.17192047651837583, Log-Loss:1.020860381098718\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9581752484191508 using:10,10\n",
      "            train score: 0.9704444444444444 with variance: 5.997224048506128e-06\n",
      "            test  score: 0.9581752484191508 with variance: 0.0003965204227638652\n",
      "          Refitted train score: 0.9704433497536946,  RMSE: 0.17192047651837583, Log-Loss:1.020860381098718\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9677546714888488 using:10,3\n",
      "            train score: 0.9919504643962848 with variance: 6.13444008856612e-06\n",
      "            test  score: 0.9677546714888488 with variance: 0.00040399948261096605\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "        accuracy\n",
      "          CV score: 0.9680216802168022 using:10,3\n",
      "            train score: 0.9919943019943019 with variance: 6.073327326888628e-06\n",
      "            test  score: 0.9680216802168022 with variance: 0.00039827216165031946\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9700495653500077 using:10,3\n",
      "            train score: 0.9907158727547294 with variance: 3.763229303185706e-06\n",
      "            test  score: 0.9700495653500077 with variance: 0.0003545035267391203\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "        accuracy\n",
      "          CV score: 0.970460704607046 using:10,3\n",
      "            train score: 0.9907635327635328 with variance: 3.787112117596476e-06\n",
      "            test  score: 0.970460704607046 with variance: 0.0003401057263274296\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9700495653500077 using:10,3\n",
      "            train score: 0.9925734578940484 with variance: 2.3100285814086503e-06\n",
      "            test  score: 0.9700495653500077 with variance: 0.0003545035267391203\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "        accuracy\n",
      "          CV score: 0.970460704607046 using:10,3\n",
      "            train score: 0.9926096866096866 with variance: 2.293358008457746e-06\n",
      "            test  score: 0.970460704607046 with variance: 0.0003401057263274296\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9699320778017906 using:10,3\n",
      "            train score: 0.9938118479869276 with variance: 3.834230674574468e-06\n",
      "            test  score: 0.9699320778017906 with variance: 0.00029809666192964307\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "        accuracy\n",
      "          CV score: 0.970430593194821 using:10,3\n",
      "            train score: 0.9938423551756885 with variance: 3.787039968109954e-06\n",
      "            test  score: 0.970430593194821 with variance: 0.00028105435458985085\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.97541289933695 using:10,3\n",
      "            train score: 0.9993846153846153 with variance: 1.514792899408295e-06\n",
      "            test  score: 0.97541289933695 with variance: 0.0004130815131158464\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "        accuracy\n",
      "          CV score: 0.9754290876242095 using:10,3\n",
      "            train score: 0.9993846153846153 with variance: 1.514792899408295e-06\n",
      "            test  score: 0.9754290876242095 with variance: 0.00042087430811074125\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9543712488860168 using:10,3\n",
      "            train score: 0.9673993424193108 with variance: 3.500583020221593e-05\n",
      "            test  score: 0.9543712488860168 with variance: 0.0005908698554229127\n",
      "          Refitted train score: 0.9743589743589743,  RMSE: 0.15971914124998499, Log-Loss:0.8810993937214999\n",
      "          Refitted test  score: 0.9724770642201834,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9541707237909769 using:10,3\n",
      "            train score: 0.9674752243544088 with variance: 3.4132958012844874e-05\n",
      "            test  score: 0.9541707237909769 with variance: 0.0006130547910095086\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810993937214999\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9594660103141116 using:10,3\n",
      "            train score: 0.9699591235490239 with variance: 4.7628285991577587e-05\n",
      "            test  score: 0.9594660103141116 with variance: 0.00039680556714975334\n",
      "          Refitted train score: 0.9743589743589743,  RMSE: 0.15971914124998499, Log-Loss:0.8810993937214999\n",
      "          Refitted test  score: 0.9724770642201834,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9592664719246997 using:10,3\n",
      "            train score: 0.9700229950550456 with variance: 4.732261362103439e-05\n",
      "            test  score: 0.9592664719246997 with variance: 0.0004074453669562935\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810993937214999\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9668085037325543 using:10,3\n",
      "            train score: 0.9767775797129712 with variance: 1.81775691530001e-05\n",
      "            test  score: 0.9668085037325543 with variance: 0.0005389093076146659\n",
      "          Refitted train score: 0.9742268041237113,  RMSE: 0.15971914124998499, Log-Loss:0.8810973539321372\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9668938656280428 using:10,3\n",
      "            train score: 0.9770415742455384 with variance: 1.7919405828635134e-05\n",
      "            test  score: 0.9668938656280428 with variance: 0.0005499148227754342\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810973539321372\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9668717948717948 using:10,3\n",
      "            train score: 0.9793750481543292 with variance: 2.3371409340418692e-05\n",
      "            test  score: 0.9668717948717948 with variance: 0.0006040144641683093\n",
      "          Refitted train score: 0.9793814432989691,  RMSE: 0.14285714285714285, Log-Loss:0.7048770672299649\n",
      "          Refitted test  score: 0.9724770642201834,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9669263226225251 using:10,3\n",
      "            train score: 0.9795893449461752 with variance: 2.293292665140215e-05\n",
      "            test  score: 0.9669263226225251 with variance: 0.0006153281501167062\n",
      "          Refitted train score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048770672299649\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9693401493021746 using:10,3\n",
      "            train score: 0.9813705525443244 with variance: 1.8420707241860297e-05\n",
      "            test  score: 0.9693401493021746 with variance: 0.000668512140822691\n",
      "          Refitted train score: 0.9820051413881749,  RMSE: 0.1336306209562122, Log-Loss:0.6167679437735599\n",
      "          Refitted test  score: 0.9724770642201834,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9694579681921454 using:10,3\n",
      "            train score: 0.9815083128141471 with variance: 1.7773516117871305e-05\n",
      "            test  score: 0.9694579681921454 with variance: 0.0006802421390813285\n",
      "          Refitted train score: 0.9821428571428571,  RMSE: 0.1336306209562122, Log-Loss:0.6167679437735599\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9693401493021746 using:10,3\n",
      "            train score: 0.9910130632377513 with variance: 2.220975143446245e-05\n",
      "            test  score: 0.9693401493021746 with variance: 0.000668512140822691\n",
      "          Refitted train score: 0.9896907216494846,  RMSE: 0.10101525445522107, Log-Loss:0.35243649382562015\n",
      "          Refitted test  score: 0.9724770642201834,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9694579681921454 using:10,3\n",
      "            train score: 0.9910685578234061 with variance: 2.1977889454849163e-05\n",
      "            test  score: 0.9694579681921454 with variance: 0.0006802421390813285\n",
      "          Refitted train score: 0.9897959183673469,  RMSE: 0.10101525445522107, Log-Loss:0.35243649382562015\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9693401493021746 using:10,3\n",
      "            train score: 0.9948551722272991 with variance: 1.086068236516719e-05\n",
      "            test  score: 0.9693401493021746 with variance: 0.000668512140822691\n",
      "          Refitted train score: 0.9948717948717948,  RMSE: 0.07142857142857142, Log-Loss:0.1762182469128106\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9694579681921454 using:10,3\n",
      "            train score: 0.9948963187562321 with variance: 1.059489757109702e-05\n",
      "            test  score: 0.9694579681921454 with variance: 0.0006802421390813285\n",
      "          Refitted train score: 0.9948979591836735,  RMSE: 0.07142857142857142, Log-Loss:0.1762182469128106\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9670561986848906 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9670561986848906 with variance: 0.0008919192852497884\n",
      "          Refitted train score: 0.9974424552429668,  RMSE: 0.050507627227610534, Log-Loss:0.08810912345640579\n",
      "          Refitted test  score: 0.9724770642201834,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9669263226225251 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9669263226225251 with variance: 0.0009357896146256009\n",
      "          Refitted train score: 0.9974489795918368,  RMSE: 0.050507627227610534, Log-Loss:0.08810912345640579\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9425484301182216 using:10,10\n",
      "            train score: 0.954866012274687 with variance: 5.983331140190755e-05\n",
      "            test  score: 0.9425484301182216 with variance: 0.0006498446446805645\n",
      "          Refitted train score: 0.9530864197530864,  RMSE: 0.21527067476698758, Log-Loss:1.6005910943544261\n",
      "          Refitted test  score: 0.9523809523809523,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        accuracy\n",
      "          CV score: 0.9439024390243901 using:10,10\n",
      "            train score: 0.9554878048780487 with variance: 5.428316478286744e-05\n",
      "            test  score: 0.9439024390243901 with variance: 0.0005710886377156447\n",
      "          Refitted train score: 0.9536585365853658,  RMSE: 0.21527067476698758, Log-Loss:1.6005910943544261\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9532595018221377 using:10,10\n",
      "            train score: 0.9610706588097893 with variance: 3.0472197276418385e-05\n",
      "            test  score: 0.9532595018221377 with variance: 0.0004415502831456626\n",
      "          Refitted train score: 0.9631449631449631,  RMSE: 0.19127301391900148, Log-Loss:1.2636254719713211\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9536585365853657 using:10,10\n",
      "            train score: 0.9615853658536585 with variance: 2.8256989886972093e-05\n",
      "            test  score: 0.9536585365853657 with variance: 0.00044021415823914295\n",
      "          Refitted train score: 0.9634146341463414,  RMSE: 0.19127301391900148, Log-Loss:1.2636254719713211\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9578849900330946 using:10,3\n",
      "            train score: 0.9839994397862837 with variance: 2.0738650816386314e-05\n",
      "            test  score: 0.9578849900330946 with variance: 0.00040081552274626707\n",
      "          Refitted train score: 0.9852216748768473,  RMSE: 0.12097167578182678, Log-Loss:0.5054474584558406\n",
      "          Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9585365853658537 using:10,3\n",
      "            train score: 0.9841463414634145 with variance: 2.0077334919690693e-05\n",
      "            test  score: 0.9585365853658537 with variance: 0.00039262343842950563\n",
      "          Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.5054474584558406\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9578283437144197 using:10,3\n",
      "            train score: 0.9877148555499806 with variance: 1.1293510250333778e-05\n",
      "            test  score: 0.9578283437144197 with variance: 0.00029704225398927505\n",
      "          Refitted train score: 0.9901477832512315,  RMSE: 0.09877295966495896, Log-Loss:0.336963672145471\n",
      "          Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9585365853658537 using:10,3\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.9585365853658537 with variance: 0.0002736466389054126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9902439024390244,  RMSE: 0.09877295966495896, Log-Loss:0.336963672145471\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9700593842787935 using:10,3\n",
      "            train score: 0.9932420837825239 with variance: 5.338948067526237e-06\n",
      "            test  score: 0.9700593842787935 with variance: 0.00040405379967241246\n",
      "          Refitted train score: 0.9926289926289926,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9707317073170731 using:10,3\n",
      "            train score: 0.9932926829268294 with variance: 5.205234979179069e-06\n",
      "            test  score: 0.9707317073170731 with variance: 0.00039262343842950704\n",
      "          Refitted train score: 0.9926829268292683,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9676519768713863 using:10,3\n",
      "            train score: 0.992634192382509 with variance: 2.318907797283071e-06\n",
      "            test  score: 0.9676519768713863 with variance: 0.0004034480916046012\n",
      "          Refitted train score: 0.9926289926289926,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:10,3\n",
      "            train score: 0.9926829268292684 with variance: 2.2308149910767443e-06\n",
      "            test  score: 0.9682926829268294 with variance: 0.00039262343842950693\n",
      "          Refitted train score: 0.9926829268292683,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9676489657301637 using:10,3\n",
      "            train score: 0.9950957768146939 with variance: 2.2721040911234e-06\n",
      "            test  score: 0.9676489657301637 with variance: 0.000342733097826247\n",
      "          Refitted train score: 0.9926289926289926,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:10,3\n",
      "            train score: 0.9951219512195122 with variance: 2.2308149910767443e-06\n",
      "            test  score: 0.9682926829268294 with variance: 0.00033313503866746043\n",
      "          Refitted train score: 0.9926829268292683,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9775925925925926 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9775925925925926 with variance: 0.00014725651577503468\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:10,3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9455623192712395 using:10,3\n",
      "            train score: 0.9712277277277833 with variance: 8.067185411093903e-05\n",
      "            test  score: 0.9455623192712395 with variance: 0.00022462530747162216\n",
      "          Refitted train score: 0.9711286089238844,  RMSE: 0.1692508000965825, Log-Loss:0.9894003612857777\n",
      "          Refitted test  score: 0.9913043478260869,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "        accuracy\n",
      "          CV score: 0.9452836637047163 using:10,3\n",
      "            train score: 0.9713651169677228 with variance: 8.133545315034547e-05\n",
      "            test  score: 0.9452836637047163 with variance: 0.00023304860049832527\n",
      "          Refitted train score: 0.9713541666666666,  RMSE: 0.1692508000965825, Log-Loss:0.9894003612857777\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9405393931884717 using:10,10\n",
      "            train score: 0.9564261793233747 with variance: 5.571864386134314e-05\n",
      "            test  score: 0.9405393931884717 with variance: 0.0003123850333818318\n",
      "          Refitted train score: 0.9560723514211885,  RMSE: 0.2104063528825433, Log-Loss:1.529081236166104\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9400888585099112 using:10,10\n",
      "            train score: 0.956381403612674 with variance: 5.3363128389726216e-05\n",
      "            test  score: 0.9400888585099112 with variance: 0.0003122312087308312\n",
      "          Refitted train score: 0.9557291666666666,  RMSE: 0.2104063528825433, Log-Loss:1.529081236166104\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9426939026939026 using:10,3\n",
      "            train score: 0.9755811929672188 with variance: 3.2732474531849664e-05\n",
      "            test  score: 0.9426939026939026 with variance: 0.00071873713989774\n",
      "          Refitted train score: 0.9762532981530343,  RMSE: 0.15309310892394862, Log-Loss:0.8095067363256688\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9426862611073137 using:10,3\n",
      "            train score: 0.9759169169592623 with variance: 3.1898507450902125e-05\n",
      "            test  score: 0.9426862611073137 with variance: 0.0007179089213121667\n",
      "          Refitted train score: 0.9765625,  RMSE: 0.15309310892394862, Log-Loss:0.8095067363256688\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9506690950254679 using:10,3\n",
      "            train score: 0.9822727592521862 with variance: 3.2466430237142405e-05\n",
      "            test  score: 0.9506690950254679 with variance: 0.0007939970362581478\n",
      "          Refitted train score: 0.9842931937172775,  RMSE: 0.125, Log-Loss:0.5396725457404293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.950580997949419 using:10,3\n",
      "            train score: 0.9824273446423284 with variance: 3.1969516461618296e-05\n",
      "            test  score: 0.950580997949419 with variance: 0.0008333890090914238\n",
      "          Refitted train score: 0.984375,  RMSE: 0.125, Log-Loss:0.5396725457404293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9680921204605415 using:20,3\n",
      "            train score: 0.9914839114928347 with variance: 2.832972150516082e-05\n",
      "            test  score: 0.9680921204605415 with variance: 0.0001402598062060212\n",
      "          Refitted train score: 0.9921671018276764,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702151\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9687628161312372 using:20,3\n",
      "            train score: 0.991541520368882 with variance: 2.784600101902594e-05\n",
      "            test  score: 0.9687628161312372 with variance: 0.00010725253449288433\n",
      "          Refitted train score: 0.9921875,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702151\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9658668254303684 using:10,3\n",
      "            train score: 0.9934554104749413 with variance: 1.2816563209021317e-05\n",
      "            test  score: 0.9658668254303684 with variance: 0.00024644623688626363\n",
      "          Refitted train score: 0.9921671018276764,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702151\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9661995898838003 using:10,3\n",
      "            train score: 0.9934916874656288 with variance: 1.2691053228463569e-05\n",
      "            test  score: 0.9661995898838003 with variance: 0.00024145836535662763\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Refitted train score: 0.9921875,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702151\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.963782666428196 using:10,3\n",
      "            train score: 0.995422693667631 with variance: 6.829393927589955e-06\n",
      "            test  score: 0.963782666428196 with variance: 0.00033693559467695645\n",
      "          Refitted train score: 0.9973890339425587,  RMSE: 0.05103103630798288, Log-Loss:0.08994473019508091\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.963568010936432 using:10,3\n",
      "            train score: 0.9954439697110707 with variance: 6.774059193644579e-06\n",
      "            test  score: 0.963568010936432 with variance: 0.00036290938618527963\n",
      "          Refitted train score: 0.9973958333333334,  RMSE: 0.05103103630798288, Log-Loss:0.08994473019508091\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9607362870556491 using:10,3\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440926614e-06\n",
      "            test  score: 0.9607362870556491 with variance: 0.0004873392626197386\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9609706083390295 using:10,3\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440927772e-06\n",
      "            test  score: 0.9609706083390295 with variance: 0.0004704983112724961\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "max_depths = [10, 20, 30]\n",
    "min_samples_leafs = [3, 10]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "    print(tab * 2 + f\"random state: {randomstate}\")\n",
    "    \n",
    "    for ncomponents in ncomponentss:\n",
    "        print(tab * 3 + f\"ncomponents: {ncomponents}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)                     \n",
    "        \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "        \n",
    "        pca = PCA(n_components = ncomponents)        \n",
    "        pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for max_depth in max_depths:\n",
    "            for min_samples_leaf in min_samples_leafs:\n",
    "                    \n",
    "                rf = RandomForestClassifier(max_depth = max_depth, min_samples_leaf = min_samples_leaf, random_state = randomstate)\n",
    "                cv_results = cross_validate(rf, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    " \n",
    "                for score in scores:\n",
    "                    avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                    var_score_test = np.var(cv_results['test_' + score])\n",
    "                    avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                    var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                    if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                        best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, max_depth, min_samples_leaf]\n",
    "\n",
    "        for score in scores: \n",
    "\n",
    "            print(tab * 4 + str(score))\n",
    "            print(tab * 5 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 6 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 6 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            rf = RandomForestClassifier(max_depth = best_avg_scores[score][4], min_samples_leaf = best_avg_scores[score][5], random_state = randomstate)\n",
    "\n",
    "            rf.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = rf.predict(X_train), rf.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(rf, X_train, y_train), get_scorer(score)(rf, X_test, y_test)\n",
    "\n",
    "            print(tab * 5 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 5 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")\n",
    "\n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/pca/RandomForestClassifier\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66745011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.9662</td>\n",
       "      <td>0.993492</td>\n",
       "      <td>0.000241458</td>\n",
       "      <td>1.26911e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.963783</td>\n",
       "      <td>0.995423</td>\n",
       "      <td>0.000336936</td>\n",
       "      <td>6.82939e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.0899447</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.963568</td>\n",
       "      <td>0.995444</td>\n",
       "      <td>0.000362909</td>\n",
       "      <td>6.77406e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.0899447</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.960736</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000487339</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.960971</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000470498</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "443  accuracy     0.9662    0.993492   0.000241458    1.26911e-05         0   \n",
       "444        f1   0.963783    0.995423   0.000336936    6.82939e-06         0   \n",
       "445  accuracy   0.963568    0.995444   0.000362909    6.77406e-06         0   \n",
       "446        f1   0.960736    0.999349   0.000487339    1.69763e-06         0   \n",
       "447  accuracy   0.960971    0.999349   0.000470498    1.69763e-06         0   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "443  0.0883883   9.99201e-16       0.269836       0.2         2050   \n",
       "444   0.051031   9.99201e-16      0.0899447       0.2         2050   \n",
       "445   0.051031   9.99201e-16      0.0899447       0.2         2050   \n",
       "446          0   9.99201e-16    9.99201e-16       0.2         2050   \n",
       "447          0   9.99201e-16    9.99201e-16       0.2         2050   \n",
       "\n",
       "                            estimator estimator params  \n",
       "443  Smote/pca/RandomForestClassifier             10,3  \n",
       "444  Smote/pca/RandomForestClassifier             10,3  \n",
       "445  Smote/pca/RandomForestClassifier             10,3  \n",
       "446  Smote/pca/RandomForestClassifier             10,3  \n",
       "447  Smote/pca/RandomForestClassifier             10,3  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "143af887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9317709592443 using:2\n",
      "            train score: 0.9917230708730054 with variance: 2.4605176642625934e-05\n",
      "            test  score: 0.9317709592443 with variance: 0.00037920192970407687\n",
      "          Refitted train score: 0.9490022172949001,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9322981366459627 using:2\n",
      "            train score: 0.9918062566072571 with variance: 2.390474923258006e-05\n",
      "            test  score: 0.9322981366459627 with variance: 0.00035841378754609206\n",
      "          Refitted train score: 0.9497816593886463,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9530820145735529 using:3\n",
      "            train score: 0.9989010989010989 with variance: 4.830334500664138e-06\n",
      "            test  score: 0.9530820145735529 with variance: 0.0003767083012135547\n",
      "          Refitted train score: 0.966740576496674,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9541328236980412 using:3\n",
      "            train score: 0.9989071038251366 with variance: 4.77768819612411e-06\n",
      "            test  score: 0.9541328236980412 with variance: 0.00031045628170620293\n",
      "          Refitted train score: 0.9672489082969432,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9538030537571991 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9538030537571991 with variance: 0.0005659657013375649\n",
      "          Refitted train score: 0.9711751662971175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9541089345437171 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9541089345437171 with variance: 0.0005471700654400736\n",
      "          Refitted train score: 0.9716157205240175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9685554722013837 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9685554722013837 with variance: 0.00041351233032063965\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.1477635311413854, Log-Loss:0.7541217553473957\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9693741041567128 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9693741041567128 with variance: 0.0003589342583713047\n",
      "          Refitted train score: 0.9781659388646288,  RMSE: 0.1477635311413854, Log-Loss:0.7541217553473957\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9777190917320453 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9777190917320453 with variance: 0.0001584410555516609\n",
      "          Refitted train score: 0.988962472406181,  RMSE: 0.10448459488214322, Log-Loss:0.3770608776736984\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9781414237935977 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9781414237935977 with variance: 0.0001454464852125788\n",
      "          Refitted train score: 0.9890829694323144,  RMSE: 0.10448459488214322, Log-Loss:0.3770608776736984\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.966635694859689 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.966635694859689 with variance: 0.0003467509644760901\n",
      "          Refitted train score: 0.9934065934065934,  RMSE: 0.08093341918275387, Log-Loss:0.2262365266042194\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9672001911132346 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9672001911132346 with variance: 0.0003391997395819653\n",
      "          Refitted train score: 0.9934497816593887,  RMSE: 0.08093341918275387, Log-Loss:0.2262365266042194\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9708241505126933 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9708241505126933 with variance: 0.00013905962082213691\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.971571906354515 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.971571906354515 with variance: 0.0001264481587089031\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9568070871472809 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9568070871472809 with variance: 0.00035495680888880004\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9584567606306738 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9584567606306738 with variance: 0.0003098193897753499\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9350305579005598 using:2\n",
      "            train score: 0.9950862793386653 with variance: 1.3290615944046575e-05\n",
      "            test  score: 0.9350305579005598 with variance: 0.002126623507984732\n",
      "          Refitted train score: 0.9606986899563319,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9411764705882353,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        accuracy\n",
      "          CV score: 0.9351799906498364 using:2\n",
      "            train score: 0.9951292756170804 with variance: 1.2925917433637404e-05\n",
      "            test  score: 0.9351799906498364 with variance: 0.0021692335903863358\n",
      "          Refitted train score: 0.961038961038961,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9578830379531642 using:3\n",
      "            train score: 0.9989071038251366 with variance: 4.77768819612411e-06\n",
      "            test  score: 0.9578830379531642 with variance: 0.0004419549250395295\n",
      "          Refitted train score: 0.9692982456140351,  RMSE: 0.17407765595569785, Log-Loss:1.0466365106460405\n",
      "          Refitted test  score: 0.8823529411764706,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "        accuracy\n",
      "          CV score: 0.9588826554464702 using:3\n",
      "            train score: 0.9989159891598917 with variance: 4.7003180058901364e-06\n",
      "            test  score: 0.9588826554464702 with variance: 0.0003921713908160763\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466365106460405\n",
      "          Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9578320729745018 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9578320729745018 with variance: 0.0012409641549000403\n",
      "          Refitted train score: 0.971677559912854,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        accuracy\n",
      "          CV score: 0.9589060308555399 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9589060308555399 with variance: 0.0011767731706693366\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9738551506972559 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9738551506972559 with variance: 0.00026675342800473506\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.37379628133020315\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9741000467508181 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9741000467508181 with variance: 0.00025718741919965717\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.37379628133020315\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9692286457503849 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9692286457503849 with variance: 0.00025666994057696056\n",
      "          Refitted train score: 0.991304347826087,  RMSE: 0.09304842103984709, Log-Loss:0.29903875579453104\n",
      "          Refitted test  score: 0.8888888888888888,  RMSE: 0.3922322702763681, Log-Loss:5.313719414403966\n",
      "        accuracy\n",
      "          CV score: 0.9697755960729312 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9697755960729312 with variance: 0.00024723729766720103\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903875579453104\n",
      "          Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313719414403966\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9735712986776817 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9735712986776817 with variance: 0.00042802011770650084\n",
      "          Refitted train score: 0.9934924078091107,  RMSE: 0.08058229640253803, Log-Loss:0.2242794995284907\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9741000467508181 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9741000467508181 with variance: 0.00039593178270989107\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242794995284907\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9642293914856438 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9642293914856438 with variance: 0.0008570200536122147\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.965474520804114 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.965474520804114 with variance: 0.0007559720946355456\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9671210891599502 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9671210891599502 with variance: 0.00032791653239245514\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.967601683029453 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.967601683029453 with variance: 0.0003217446382450547\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9287255619473994 using:2\n",
      "            train score: 0.985779946773097 with variance: 4.612827974304008e-05\n",
      "            test  score: 0.9287255619473994 with variance: 0.0005850386542920993\n",
      "          Refitted train score: 0.9370932754880694,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9308087891538103 using:2\n",
      "            train score: 0.9859342269098367 with variance: 4.492053833340418e-05\n",
      "            test  score: 0.9308087891538103 with variance: 0.00048713521958350153\n",
      "          Refitted train score: 0.9372294372294372,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9447014906396675 using:3\n",
      "            train score: 0.9978201634877385 with variance: 1.0097335342901061e-05\n",
      "            test  score: 0.9447014906396675 with variance: 5.9596037767655556e-05\n",
      "          Refitted train score: 0.9542483660130718,  RMSE: 0.21320071635561044, Log-Loss:1.5699599581601653\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9459093034128097 using:3\n",
      "            train score: 0.9978363729583242 with variance: 9.93585081992354e-06\n",
      "            test  score: 0.9459093034128097 with variance: 4.431055219950723e-05\n",
      "          Refitted train score: 0.9545454545454546,  RMSE: 0.21320071635561044, Log-Loss:1.5699599581601653\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9628011232266551 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9628011232266551 with variance: 0.00035406716116089714\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9632772323515661 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9632772323515661 with variance: 0.00035010876832467056\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9608266733266735 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9608266733266735 with variance: 0.0008675072430067423\n",
      "          Refitted train score: 0.9802197802197802,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9611734455352968 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9611734455352968 with variance: 0.0008597451413791517\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9651245976245978 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9651245976245978 with variance: 0.00042154452305134875\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9654511453950443 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9654511453950443 with variance: 0.0004341586087620951\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.969352020976735 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.969352020976735 with variance: 0.0005481838038770794\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9697755960729312 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9697755960729312 with variance: 0.0005287694568315536\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9571084362108205 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9571084362108205 with variance: 0.0009788494059158525\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9589060308555399 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9589060308555399 with variance: 0.0008189184977403768\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9563638795363103 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9563638795363103 with variance: 0.0013173598855695636\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "        accuracy\n",
      "          CV score: 0.9588826554464704 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9588826554464704 with variance: 0.0010578405318446508\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9396774089452059 using:2\n",
      "            train score: 0.9891155615048668 with variance: 4.454839281934686e-05\n",
      "            test  score: 0.9396774089452059 with variance: 0.0004403214403430625\n",
      "          Refitted train score: 0.9501084598698483,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9394576905095839 using:2\n",
      "            train score: 0.9891789350325937 with variance: 4.3899167642541946e-05\n",
      "            test  score: 0.9394576905095839 with variance: 0.0004428760299004162\n",
      "          Refitted train score: 0.9502164502164502,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9565789666349577 using:3\n",
      "            train score: 0.9983680843501956 with variance: 4.7291259689882015e-06\n",
      "            test  score: 0.9565789666349577 with variance: 0.00021283245480364625\n",
      "          Refitted train score: 0.9692982456140351,  RMSE: 0.17407765595569785, Log-Loss:1.0466365106460405\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9567788686302009 using:3\n",
      "            train score: 0.9983769134988648 with variance: 4.6781211060301995e-06\n",
      "            test  score: 0.9567788686302009 with variance: 0.00022775669728965486\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466365106460405\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9503509855017838 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9503509855017838 with variance: 0.0007666349677399144\n",
      "          Refitted train score: 0.9649122807017544,  RMSE: 0.18609684207969418, Log-Loss:1.1961567539084899\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9503272557269753 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9503272557269753 with variance: 0.0008108010345066494\n",
      "          Refitted train score: 0.9653679653679653,  RMSE: 0.18609684207969418, Log-Loss:1.1961567539084899\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9570738618107038 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9570738618107038 with variance: 0.0006363924146389154\n",
      "          Refitted train score: 0.9734513274336283,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9568256194483403 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9568256194483403 with variance: 0.0006902335377124358\n",
      "          Refitted train score: 0.974025974025974,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9607070349005834 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9607070349005834 with variance: 0.0006287698624913963\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9611500701262271 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9611500701262271 with variance: 0.0006271942449502442\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9647743560787039 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9647743560787039 with variance: 0.0004494139551898435\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208184\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9654511453950443 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9654511453950443 with variance: 0.0004341586087620951\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208184\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9580122553361848 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9580122553361848 with variance: 0.00036183069789568877\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9589294062646097 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9589294062646097 with variance: 0.00034268961675038744\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9562552900496941 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9562552900496941 with variance: 0.00031661927496860173\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9567788686302011 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9567788686302011 with variance: 0.0003202529396298101\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.933711276683413 using:2\n",
      "            train score: 0.996121799331301 with variance: 1.4221481496921525e-05\n",
      "            test  score: 0.933711276683413 with variance: 0.0009631170667449793\n",
      "          Refitted train score: 0.953229398663697,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9360927960927962 using:2\n",
      "            train score: 0.9961493052402144 with variance: 1.3877245406047032e-05\n",
      "            test  score: 0.9360927960927962 with variance: 0.0007484967074710676\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9517848708872553 using:3\n",
      "            train score: 0.9966820135754857 with variance: 1.0425642231016573e-05\n",
      "            test  score: 0.9517848708872553 with variance: 2.5389942288853563e-05\n",
      "          Refitted train score: 0.9621380846325166,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9515506715506715 using:3\n",
      "            train score: 0.9966972421517877 with variance: 1.0307785507792036e-05\n",
      "            test  score: 0.9515506715506715 with variance: 2.816144647646517e-05\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9537858038461782 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9537858038461782 with variance: 0.00031258823567065024\n",
      "          Refitted train score: 0.9621380846325166,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9537728937728938 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9537728937728938 with variance: 0.0003555340874022185\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9580618126862952 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9580618126862952 with variance: 0.00015205004382480057\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9581440781440781 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9581440781440781 with variance: 0.00016469890169523867\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9688970215409348 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9688970215409348 with variance: 0.0002624663793376963\n",
      "          Refitted train score: 0.9866666666666667,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9692063492063493 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9692063492063493 with variance: 0.0002598743814861032\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9621096923873461 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9621096923873461 with variance: 0.00048586902096971836\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129427 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9626129426129427 with variance: 0.0005107297532205951\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9663386036696776 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9663386036696776 with variance: 0.00026702691562911866\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.967008547008547 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.967008547008547 with variance: 0.00024044570271676522\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9682137484265144 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9682137484265144 with variance: 0.000574268412581178\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307691 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9692307692307691 with variance: 0.0005023547880690732\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9266102903604377 using:2\n",
      "            train score: 0.9900153124736832 with variance: 4.489254339608884e-05\n",
      "            test  score: 0.9266102903604377 with variance: 0.00011192377101032422\n",
      "          Refitted train score: 0.9466666666666668,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9273015873015874 using:2\n",
      "            train score: 0.9900932400932401 with variance: 4.412195072774193e-05\n",
      "            test  score: 0.9273015873015874 with variance: 0.0001272083499189724\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9404313134050295 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9404313134050295 with variance: 0.0006132507703820994\n",
      "          Refitted train score: 0.9664429530201342,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9405860805860806 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9405860805860806 with variance: 0.0006530826926431317\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9515278920210744 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9515278920210744 with variance: 0.0012048753527778805\n",
      "          Refitted train score: 0.9664429530201342,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9516483516483518 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9516483516483518 with variance: 0.0012365656321700268\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9597941010300561 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9597941010300561 with variance: 0.00043610606441611097\n",
      "          Refitted train score: 0.9797752808988764,  RMSE: 0.14079697633917962, Log-Loss:0.6846893998991113\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9604151404151404 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9604151404151404 with variance: 0.00041401572244063097\n",
      "          Refitted train score: 0.9801762114537445,  RMSE: 0.14079697633917962, Log-Loss:0.6846893998991113\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9663684085815462 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9663684085815462 with variance: 0.00015725401048298496\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9670085470085471 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9670085470085471 with variance: 0.00014383901270348154\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9642367843530184 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9642367843530184 with variance: 0.00021015144803310405\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9648107448107449 with variance: 0.000211356354946099\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9617288654497959 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9617288654497959 with variance: 0.00017345167757758587\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9625885225885226 with variance: 0.00017239881269185252\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9585150956433873 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9585150956433873 with variance: 0.001078173473316926\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9582173382173383 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9582173382173383 with variance: 0.0011287978877722472\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9402132666226463 using:2\n",
      "            train score: 0.9888350053769377 with variance: 5.7186310629663374e-05\n",
      "            test  score: 0.9402132666226463 with variance: 0.0005072701723380271\n",
      "          Refitted train score: 0.9443207126948775,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9405372405372405 using:2\n",
      "            train score: 0.9889913117185845 with variance: 5.446639382950992e-05\n",
      "            test  score: 0.9405372405372405 with variance: 0.0005110016831628552\n",
      "          Refitted train score: 0.9449339207048458,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9402130475561844 using:3\n",
      "            train score: 0.9977839165131982 with variance: 7.366633240894259e-06\n",
      "            test  score: 0.9402130475561844 with variance: 1.6000594655640795e-05\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9405128205128206 using:3\n",
      "            train score: 0.9977991705264433 with variance: 7.265498468510233e-06\n",
      "            test  score: 0.9405128205128206 with variance: 3.100001341759561e-05\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9404839659998856 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9404839659998856 with variance: 0.00010711579949494406\n",
      "          Refitted train score: 0.9621380846325166,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9405616605616606 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9405616605616606 with variance: 0.0001226213211561195\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9638177444202339 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9638177444202339 with variance: 0.00019474837591972765\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863248 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9647863247863248 with variance: 0.0001629528252238872\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9655996352029185 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9655996352029185 with variance: 0.00043514989092429486\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9670329670329672 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9670329670329672 with variance: 0.0003864267600531333\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9706143095076534 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9706143095076534 with variance: 0.0002416897338777545\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714285714285715 with variance: 0.00022219538703055155\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9703574977993583 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9703574977993583 with variance: 0.0003027851601364256\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714285714285715 with variance: 0.00027049873203719295\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9632718635145329 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9632718635145329 with variance: 0.0005809557254287743\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.964835164835165 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.964835164835165 with variance: 0.0005023547880690732\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9220428193558888 using:2\n",
      "            train score: 0.990995205248041 with variance: 2.6676739662807637e-05\n",
      "            test  score: 0.9220428193558888 with variance: 0.0008028075988348043\n",
      "          Refitted train score: 0.9457013574660633,  RMSE: 0.23145502494313785, Log-Loss:1.850307655925733\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9241448189762795 using:2\n",
      "            train score: 0.9910692332830177 with variance: 2.6138410015520772e-05\n",
      "            test  score: 0.9241448189762795 with variance: 0.0007159627244970009\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.23145502494313785, Log-Loss:1.850307655925733\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9314690609993168 using:3\n",
      "            train score: 0.9949453672907682 with variance: 1.073845438728139e-05\n",
      "            test  score: 0.9314690609993168 with variance: 0.0009263792637007705\n",
      "          Refitted train score: 0.9638009049773757,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9330337078651685 using:3\n",
      "            train score: 0.9949767355005369 with variance: 1.0580194368437097e-05\n",
      "            test  score: 0.9330337078651685 with variance: 0.0008003017451656099\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9563532055110656 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9563532055110656 with variance: 0.0010689547092702417\n",
      "          Refitted train score: 0.963963963963964,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9575530586766542 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9575530586766542 with variance: 0.00092588384369725\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9626827910894515 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9626827910894515 with variance: 0.0015813066569628064\n",
      "          Refitted train score: 0.9749430523917996,  RMSE: 0.15669579263200217, Log-Loss:0.8480520980835894\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.964219725343321 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.964219725343321 with variance: 0.001382252209706656\n",
      "          Refitted train score: 0.9754464285714286,  RMSE: 0.15669579263200217, Log-Loss:0.8480520980835894\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9740416210295727 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9740416210295727 with variance: 0.0009553318321578669\n",
      "          Refitted train score: 0.9864253393665159,  RMSE: 0.11572751247156893, Log-Loss:0.46257289814612623\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9753807740324595 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9753807740324595 with variance: 0.0008286420999967263\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11572751247156893, Log-Loss:0.46257289814612623\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9769482665384848 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9769482665384848 with variance: 0.0004912089268786548\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0668153104781061, Log-Loss:0.15419096604870938\n",
      "          Refitted test  score: 0.96,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9776529338327091 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9776529338327091 with variance: 0.00045282971815817027\n",
      "          Refitted train score: 0.9955357142857143,  RMSE: 0.0668153104781061, Log-Loss:0.15419096604870938\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9607891333772777 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9607891333772777 with variance: 0.0002785220851910607\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9619975031210986 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9619975031210986 with variance: 0.0002352402817327285\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.960420810358591 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.960420810358591 with variance: 0.00037931546481088734\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.96,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9619975031210986 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9619975031210986 with variance: 0.0003340057138314944\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9454690730744565 using:2\n",
      "            train score: 0.9938531488597991 with variance: 2.320779352026644e-05\n",
      "            test  score: 0.9454690730744565 with variance: 0.00048641165803298467\n",
      "          Refitted train score: 0.9485458612975392,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9466666666666667 using:2\n",
      "            train score: 0.993888888888889 with variance: 2.2839506172839343e-05\n",
      "            test  score: 0.9466666666666667 with variance: 0.0004641975308641966\n",
      "          Refitted train score: 0.9488888888888889,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9458453155501576 using:3\n",
      "            train score: 0.9988826815642458 with variance: 4.993601947504648e-06\n",
      "            test  score: 0.9458453155501576 with variance: 0.0006376508160949824\n",
      "          Refitted train score: 0.9641255605381166,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.139912993398857\n",
      "        accuracy\n",
      "          CV score: 0.9466666666666667 using:3\n",
      "            train score: 0.9988888888888889 with variance: 4.938271604938236e-06\n",
      "            test  score: 0.9466666666666667 with variance: 0.0006123456790123455\n",
      "          Refitted train score: 0.9644444444444444,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.139912993398857\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9613797763366616 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9613797763366616 with variance: 0.001014348257888559\n",
      "          Refitted train score: 0.970917225950783,  RMSE: 0.1699673171197595, Log-Loss:0.997795758046645\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9622222222222222 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9622222222222222 with variance: 0.0009679012345679017\n",
      "          Refitted train score: 0.9711111111111111,  RMSE: 0.1699673171197595, Log-Loss:0.997795758046645\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9705810918170469 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9705810918170469 with variance: 0.0003949062469902727\n",
      "          Refitted train score: 0.9819004524886877,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9711111111111113 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9711111111111113 with variance: 0.00037530864197530845\n",
      "          Refitted train score: 0.9822222222222222,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9682787581354029 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9682787581354029 with variance: 0.00028127469602270456\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9166666666666666,  RMSE: 0.3481553119113957, Log-Loss:4.18656681134858\n",
      "        accuracy\n",
      "          CV score: 0.9688888888888888 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9688888888888888 with variance: 0.0002666666666666668\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.18656681134858\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9660270247639484 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9660270247639484 with variance: 0.00021409675221512964\n",
      "          Refitted train score: 0.9933184855233853,  RMSE: 0.08164965809277261, Log-Loss:0.23026028618258373\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9666666666666666 with variance: 0.00019753086419753142\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23026028618258373\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9748015368636651 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9748015368636651 with variance: 0.0003589733598153225\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9755555555555556 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9755555555555556 with variance: 0.0003160493827160503\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9702686652255504 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9702686652255504 with variance: 0.00019379808658972252\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.971111111111111 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.971111111111111 with variance: 0.0001777777777777773\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.943296209254379 using:2\n",
      "            train score: 0.9905999562987727 with variance: 3.24924786818245e-05\n",
      "            test  score: 0.943296209254379 with variance: 0.0009340133027599493\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.944981684981685 using:2\n",
      "            train score: 0.9906442042805679 with variance: 3.1967813855348e-05\n",
      "            test  score: 0.944981684981685 with variance: 0.0008179581102658031\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.950166601191383 using:3\n",
      "            train score: 0.9983379501385041 with variance: 1.1049638968393511e-05\n",
      "            test  score: 0.950166601191383 with variance: 0.00023952963894100274\n",
      "          Refitted train score: 0.9530201342281879,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9515262515262515 using:3\n",
      "            train score: 0.9983471074380166 with variance: 1.0928215285841059e-05\n",
      "            test  score: 0.9515262515262515 with variance: 0.00022386513229004048\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9536206451676623 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9536206451676623 with variance: 0.000767487816352075\n",
      "          Refitted train score: 0.9709172259507829,  RMSE: 0.16921690587373409, Log-Loss:0.9890010835377309\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9537973137973138 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9537973137973138 with variance: 0.0007898229026434159\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9890010835377309\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9643644619019923 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9643644619019923 with variance: 0.0006550144712966138\n",
      "          Refitted train score: 0.9799554565701558,  RMSE: 0.14079697633917962, Log-Loss:0.6846929223547509\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9648107448107449 with variance: 0.0006460864600058742\n",
      "          Refitted train score: 0.9801762114537445,  RMSE: 0.14079697633917962, Log-Loss:0.6846929223547509\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9614348523972364 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9614348523972364 with variance: 0.0006615418886051262\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129426 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9626129426129426 with variance: 0.0006073364432338797\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9617086697893618 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9617086697893618 with variance: 0.0007329599462274548\n",
      "          Refitted train score: 0.9911504424778761,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "          Refitted test  score: 0.9302325581395349,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129426 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9626129426129426 with variance: 0.0007039431332471633\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9630928700637591 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9630928700637591 with variance: 0.0012425111714829723\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863248 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9647863247863248 with variance: 0.0010324130353434392\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9614733103377617 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9614733103377617 with variance: 0.0005799892726531979\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129426 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9626129426129426 with variance: 0.0005107297532205965\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9365478927548724 using:2\n",
      "            train score: 0.9889741543372829 with variance: 3.623293592772968e-05\n",
      "            test  score: 0.9365478927548724 with variance: 0.0003613543698582778\n",
      "          Refitted train score: 0.9534368070953437,  RMSE: 0.215070933898399, Log-Loss:1.59762445081497\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9361660561660562 using:2\n",
      "            train score: 0.9889897980807071 with variance: 3.632763897292757e-05\n",
      "            test  score: 0.9361660561660562 with variance: 0.00040192199606119063\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.59762445081497\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9407172249564631 using:3\n",
      "            train score: 0.9988950276243094 with variance: 4.883855804157357e-06\n",
      "            test  score: 0.9407172249564631 with variance: 0.00021202721971868115\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9405860805860806 using:3\n",
      "            train score: 0.9989010989010989 with variance: 4.830334500664137e-06\n",
      "            test  score: 0.9405860805860806 with variance: 0.0002183525875833564\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9494940584231293 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9494940584231293 with variance: 0.0005017679196520995\n",
      "          Refitted train score: 0.9707865168539326,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9494017094017094 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9494017094017094 with variance: 0.0005575374835448095\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9516483467131321 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9516483467131321 with variance: 0.0007505429028155698\n",
      "          Refitted train score: 0.9798657718120806,  RMSE: 0.14079697633917962, Log-Loss:0.6846911611269312\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9515995115995116 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9515995115995116 with variance: 0.0007992688901113815\n",
      "          Refitted train score: 0.9801762114537445,  RMSE: 0.14079697633917962, Log-Loss:0.6846911611269312\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9620610499389667 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9620610499389667 with variance: 0.0006426150853687476\n",
      "          Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129427 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9626129426129427 with variance: 0.0006556397882405211\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9641764153673928 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9641764153673928 with variance: 0.00034692280102260404\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9648107448107449 with variance: 0.0003562663899660236\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9578238307889233 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9578238307889233 with variance: 0.00042536649510924553\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.958119658119658 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.958119658119658 with variance: 0.00045733129982214124\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9628449907447848 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9628449907447848 with variance: 0.00032237250491137527\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9625885225885226 with variance: 0.00036561219271841926\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9342125179857869 using:2\n",
      "            train score: 0.9954929398647966 with variance: 8.252471926628554e-06\n",
      "            test  score: 0.9342125179857869 with variance: 0.0002840969630018618\n",
      "          Refitted train score: 0.9500000000000001,  RMSE: 0.22209762326528773, Log-Loss:1.703720801496585\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9350062421972535 using:2\n",
      "            train score: 0.9955166336197401 with variance: 8.154847077368088e-06\n",
      "            test  score: 0.9350062421972535 with variance: 0.00026810182652458464\n",
      "          Refitted train score: 0.9506726457399103,  RMSE: 0.22209762326528773, Log-Loss:1.703720801496585\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9411501645713191 using:3\n",
      "            train score: 0.9983130153469839 with variance: 1.8973113515022527e-06\n",
      "            test  score: 0.9411501645713191 with variance: 2.2652670052528144e-05\n",
      "          Refitted train score: 0.9573033707865168,  RMSE: 0.20639984704690686, Log-Loss:1.4713989862784194\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9416978776529337 using:3\n",
      "            train score: 0.9983177540679193 with variance: 1.8866425053872802e-06\n",
      "            test  score: 0.9416978776529337 with variance: 2.0822910188731105e-05\n",
      "          Refitted train score: 0.9573991031390134,  RMSE: 0.20639984704690686, Log-Loss:1.4713989862784194\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9569813907023208 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9569813907023208 with variance: 0.00011560943890377611\n",
      "          Refitted train score: 0.9636363636363637,  RMSE: 0.18940548952415134, Log-Loss:1.2390682069635028\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9574282147315856 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9574282147315856 with variance: 0.00011789258433200665\n",
      "          Refitted train score: 0.9641255605381166,  RMSE: 0.18940548952415134, Log-Loss:1.2390682069635028\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9703197787048466 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9703197787048466 with variance: 0.00033410872735813787\n",
      "          Refitted train score: 0.9749430523917996,  RMSE: 0.15704673549630008, Log-Loss:0.8518568151095927\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9709113607990012 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9709113607990012 with variance: 0.00032662043855916686\n",
      "          Refitted train score: 0.9753363228699552,  RMSE: 0.15704673549630008, Log-Loss:0.8518568151095927\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9750690145738036 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9750690145738036 with variance: 0.00016998507343004245\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9753807740324595 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9753807740324595 with variance: 0.00016769549922771235\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.975017942050821 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.975017942050821 with variance: 0.00022024299908929081\n",
      "          Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9753807740324595 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9753807740324595 with variance: 0.00021819417363750935\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.96801602413358 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.96801602413358 with variance: 0.00022376091674302357\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877653 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9686641697877653 with variance: 0.00021608445123994484\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      ncomponents: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9628606727552633 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9628606727552633 with variance: 0.00026073217393852294\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.964119850187266 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.964119850187266 with variance: 0.00022255326908779752\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9343140594009277 using:2\n",
      "            train score: 0.9949135461550058 with variance: 5.591250229153827e-05\n",
      "            test  score: 0.9343140594009277 with variance: 0.0002041900918758477\n",
      "          Refitted train score: 0.9457013574660634,  RMSE: 0.23197340190811772, Log-Loss:1.8586067924936291\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9350062421972535 using:2\n",
      "            train score: 0.9949579831932773 with variance: 5.4610079325848245e-05\n",
      "            test  score: 0.9350062421972535 with variance: 0.00016710447770499067\n",
      "          Refitted train score: 0.9461883408071748,  RMSE: 0.23197340190811772, Log-Loss:1.8586067924936291\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9415856552935205 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9415856552935205 with variance: 0.0006463819862760794\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9417727840199751 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9417727840199751 with variance: 0.0006642732788758129\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9464501498834332 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9464501498834332 with variance: 0.000745842906603637\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9462921348314606 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9462921348314606 with variance: 0.0007566721373563938\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9679637775296094 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9679637775296094 with variance: 0.0005398874108589563\n",
      "          Refitted train score: 0.9818181818181819,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527266\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877653 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9686641697877653 with variance: 0.0005190764976987257\n",
      "          Refitted train score: 0.9820627802690582,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527266\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9587522281639929 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9587522281639929 with variance: 0.00033529824828975615\n",
      "          Refitted train score: 0.9887133182844242,  RMSE: 0.10588088747190667, Log-Loss:0.38720780621521084\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9597003745318352 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9597003745318352 with variance: 0.00032530123862026326\n",
      "          Refitted train score: 0.9887892376681614,  RMSE: 0.10588088747190667, Log-Loss:0.38720780621521084\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9589239409616829 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9589239409616829 with variance: 0.0005882542129535342\n",
      "          Refitted train score: 0.9954954954954954,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834488\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.959725343320849 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.959725343320849 with variance: 0.0005725527235774246\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834488\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9656684491978611 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9656684491978611 with variance: 0.00010353741885670196\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9663920099875156 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9663920099875156 with variance: 9.879286347745646e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9658216667668089 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9658216667668089 with variance: 0.00025398817844501974\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9664169787765294 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9664169787765294 with variance: 0.00024694475226815394\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9315204733578824 using:2\n",
      "            train score: 0.9866963641017484 with variance: 6.31946030428588e-05\n",
      "            test  score: 0.9315204733578824 with variance: 0.0007737473546295117\n",
      "          Refitted train score: 0.944954128440367,  RMSE: 0.23354968324845687, Log-Loss:1.883951430573088\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9318181818181819 using:2\n",
      "            train score: 0.9869318181818182 with variance: 6.004648760330569e-05\n",
      "            test  score: 0.9318181818181819 with variance: 0.0008264462809917366\n",
      "          Refitted train score: 0.9454545454545454,  RMSE: 0.23354968324845687, Log-Loss:1.883951430573088\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.944256084884582 using:3\n",
      "            train score: 0.9971379451494066 with variance: 1.3117458068522315e-05\n",
      "            test  score: 0.944256084884582 with variance: 0.00014242884905969503\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9454545454545455 using:3\n",
      "            train score: 0.9971590909090908 with variance: 1.291322314049597e-05\n",
      "            test  score: 0.9454545454545455 with variance: 0.0001239669421487607\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9565261085590592 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9565261085590592 with variance: 0.00019930416725147263\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9568181818181818 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9568181818181818 with variance: 0.00022727272727272795\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9644475863248724 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9644475863248724 with variance: 0.0004936873952693561\n",
      "          Refitted train score: 0.9768518518518517,  RMSE: 0.15075567228888181, Log-Loss:0.7849740080603123\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9659090909090908 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9659090909090908 with variance: 0.00041322314049586846\n",
      "          Refitted train score: 0.9772727272727273,  RMSE: 0.15075567228888181, Log-Loss:0.7849740080603123\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9694046664375454 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9694046664375454 with variance: 0.00031693374760658887\n",
      "          Refitted train score: 0.9908256880733944,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9704545454545455 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9704545454545455 with variance: 0.00028925619834710696\n",
      "          Refitted train score: 0.990909090909091,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9691256721237108 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9691256721237108 with variance: 0.0004424185157181666\n",
      "          Refitted train score: 0.9931350114416476,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802837\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9704545454545455 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9704545454545455 with variance: 0.0003925619834710736\n",
      "          Refitted train score: 0.9931818181818182,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802837\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.962208411951778 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.962208411951778 with variance: 0.0006700392023736175\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9636363636363636 with variance: 0.000588842975206612\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9572399986653763 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9572399986653763 with variance: 0.0006162162582794828\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.959090909090909 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.959090909090909 with variance: 0.000547520661157025\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9315280272938539 using:2\n",
      "            train score: 0.9916736790823331 with variance: 2.2773919180805367e-05\n",
      "            test  score: 0.9315280272938539 with variance: 0.0004534124681707588\n",
      "          Refitted train score: 0.9523809523809524,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9316246498599439 using:2\n",
      "            train score: 0.9917456186014227 with variance: 2.2270138394153022e-05\n",
      "            test  score: 0.9316246498599439 with variance: 0.00040713069541541987\n",
      "          Refitted train score: 0.9528301886792453,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9401337703582928 using:3\n",
      "            train score: 0.9994100294985252 with variance: 1.3922607704423433e-06\n",
      "            test  score: 0.9401337703582928 with variance: 0.001048013824653272\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9410924369747897 using:3\n",
      "            train score: 0.9994100294985252 with variance: 1.3922607704423433e-06\n",
      "            test  score: 0.9410924369747897 with variance: 0.0009372501941953259\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9588209237183245 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9588209237183245 with variance: 0.0009913890132135297\n",
      "          Refitted train score: 0.9665071770334929,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9599439775910363 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9599439775910363 with variance: 0.0008618349300504518\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9684809554585894 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9684809554585894 with variance: 0.000782731273751377\n",
      "          Refitted train score: 0.9808612440191388,  RMSE: 0.13736056394868904, Log-Loss:0.6516769121620662\n",
      "          Refitted test  score: 0.9473684210526315,  RMSE: 0.2857142857142857, Log-Loss:2.8195409055496605\n",
      "        accuracy\n",
      "          CV score: 0.9693837535014005 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9693837535014005 with variance: 0.0006965264537187436\n",
      "          Refitted train score: 0.9811320754716981,  RMSE: 0.13736056394868904, Log-Loss:0.6516769121620662\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195409055496605\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9730064303123541 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9730064303123541 with variance: 0.0005997191066514499\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9487179487179488,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "        accuracy\n",
      "          CV score: 0.9740896358543418 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9740896358543418 with variance: 0.0005196274588266681\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9677562276668755 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9677562276668755 with variance: 0.0009460090900266889\n",
      "          Refitted train score: 0.9952606635071091,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976837\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9694117647058824 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9694117647058824 with variance: 0.0008083044982698972\n",
      "          Refitted train score: 0.9952830188679245,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976837\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9655250808574154 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9655250808574154 with variance: 0.0008131193700111566\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.961038961038961,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9670028011204481 with variance: 0.0006854632048898004\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.967878022033886 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.967878022033886 with variance: 0.0009421362905437354\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9487179487179488,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "        accuracy\n",
      "          CV score: 0.9694117647058824 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9694117647058824 with variance: 0.0008083044982698972\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9530872257502917 using:2\n",
      "            train score: 0.9976539287688263 with variance: 4.836308402109701e-06\n",
      "            test  score: 0.9530872257502917 with variance: 0.0006424847233680685\n",
      "          Refitted train score: 0.9647058823529412,  RMSE: 0.18720771611224418, Log-Loss:1.2104823446454247\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.953296853625171 using:2\n",
      "            train score: 0.9976625236560789 with variance: 4.785815497298013e-06\n",
      "            test  score: 0.953296853625171 with variance: 0.0006548277288200312\n",
      "          Refitted train score: 0.9649532710280374,  RMSE: 0.18720771611224418, Log-Loss:1.2104823446454247\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9605200020862672 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9605200020862672 with variance: 0.00027234844924630807\n",
      "          Refitted train score: 0.976303317535545,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.960328317373461 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.960328317373461 with variance: 0.00030035126066460657\n",
      "          Refitted train score: 0.9766355140186916,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.955691538857933 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.955691538857933 with variance: 2.2196758033083947e-05\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        accuracy\n",
      "          CV score: 0.9556224350205198 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9556224350205198 with variance: 2.0672167317599938e-05\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9739410845351852 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9739410845351852 with variance: 7.582032092910895e-05\n",
      "          Refitted train score: 0.9858490566037736,  RMSE: 0.11840055569457876, Log-Loss:0.4841903223525577\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9743091655266758 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9743091655266758 with variance: 7.65055833041707e-05\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.4841903223525577\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9714225438003725 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714225438003725 with variance: 9.223452817010323e-05\n",
      "          Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9719835841313269 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9719835841313269 with variance: 8.681322177329547e-05\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9811738648947952 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9811738648947952 with variance: 0.00030500031272649616\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9813406292749658 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9813406292749658 with variance: 0.00030338741038361686\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      ncomponents: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9712557794202018 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9712557794202018 with variance: 0.0002065701897755781\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9719835841313269 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9719835841313269 with variance: 0.00019497979830114824\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9740569940500716 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9740569940500716 with variance: 0.0002977294656785113\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9743365253077976 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9743365253077976 with variance: 0.00029360376225061275\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9186353993442815 using:2\n",
      "            train score: 0.9899733317435551 with variance: 4.055922580761278e-05\n",
      "            test  score: 0.9186353993442815 with variance: 0.000550002997490738\n",
      "          Refitted train score: 0.9408983451536642,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9201094391244871 using:2\n",
      "            train score: 0.9900189753320683 with variance: 4.00615987836887e-05\n",
      "            test  score: 0.9201094391244871 with variance: 0.000416946596027779\n",
      "          Refitted train score: 0.9413145539906104,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.939701973812781 using:3\n",
      "            train score: 0.9964566655064392 with variance: 2.2375419623318506e-05\n",
      "            test  score: 0.939701973812781 with variance: 0.0002321903380383109\n",
      "          Refitted train score: 0.9640287769784172,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.941340629274966 using:3\n",
      "            train score: 0.9964809384164223 with variance: 2.201563454046659e-05\n",
      "            test  score: 0.941340629274966 with variance: 0.0002176985221601124\n",
      "          Refitted train score: 0.9647887323943662,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.964410715190469 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.964410715190469 with variance: 0.00027351940355232476\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.96484268125855 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.96484268125855 with variance: 0.00027045386920078414\n",
      "          Refitted train score: 0.971830985915493,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9565991181033231 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9565991181033231 with variance: 0.00015376485599485928\n",
      "          Refitted train score: 0.9784172661870503,  RMSE: 0.14535047493345277, Log-Loss:0.7296924590474096\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9577838577291382 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9577838577291382 with variance: 0.00013951317554986237\n",
      "          Refitted train score: 0.9788732394366197,  RMSE: 0.14535047493345277, Log-Loss:0.7296924590474096\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9668391518710442 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9668391518710442 with variance: 0.0005002023530007776\n",
      "          Refitted train score: 0.9857142857142858,  RMSE: 0.11867816581938534, Log-Loss:0.48646163936494013\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "        accuracy\n",
      "          CV score: 0.9672229822161423 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9672229822161423 with variance: 0.0005081628337397389\n",
      "          Refitted train score: 0.9859154929577465,  RMSE: 0.11867816581938534, Log-Loss:0.48646163936494013\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9669561785576406 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9669561785576406 with variance: 0.00021738430001017224\n",
      "          Refitted train score: 0.9929078014184397,  RMSE: 0.08391813582966891, Log-Loss:0.24323081968247054\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9671956224350206 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9671956224350206 with variance: 0.00023659211656539323\n",
      "          Refitted train score: 0.9929577464788732,  RMSE: 0.08391813582966891, Log-Loss:0.24323081968247054\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9657259381723836 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9657259381723836 with variance: 0.0005065699121489985\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9600000000000001,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "        accuracy\n",
      "          CV score: 0.9671409028727771 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9671409028727771 with variance: 0.00040932927365582407\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9712839318972195 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9712839318972195 with variance: 0.0002729337660652322\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9459459459459458,  RMSE: 0.2857142857142857, Log-Loss:2.8195409055496605\n",
      "        accuracy\n",
      "          CV score: 0.97187414500684 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.97187414500684 with variance: 0.00025059912680753344\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195409055496605\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9459748025547162 using:2\n",
      "            train score: 0.9924469160768453 with variance: 1.8917495892635435e-05\n",
      "            test  score: 0.9459748025547162 with variance: 0.0004952257006628493\n",
      "          Refitted train score: 0.951048951048951,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9468056669339748 using:2\n",
      "            train score: 0.9924788472815615 with variance: 1.8765363541295392e-05\n",
      "            test  score: 0.9468056669339748 with variance: 0.00045878262512378507\n",
      "          Refitted train score: 0.9513888888888888,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9385326590114552 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9385326590114552 with variance: 0.0010545010161445378\n",
      "          Refitted train score: 0.9601873536299765,  RMSE: 0.19837301190396806, Log-Loss:1.3591759173566276\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9398021919272921 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9398021919272921 with variance: 0.0009411635416758204\n",
      "          Refitted train score: 0.9606481481481481,  RMSE: 0.19837301190396806, Log-Loss:1.3591759173566276\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9416134670922632 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9416134670922632 with variance: 0.000730106844355763\n",
      "          Refitted train score: 0.9647058823529412,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9421812349639135 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9421812349639135 with variance: 0.0007449160172777844\n",
      "          Refitted train score: 0.9652777777777778,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9559845587910789 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9559845587910789 with variance: 0.0004477599508041833\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.15957118462605635, Log-Loss:0.8794614350496482\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.956081261694734 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.956081261694734 with variance: 0.0004960857318367785\n",
      "          Refitted train score: 0.9745370370370371,  RMSE: 0.15957118462605635, Log-Loss:0.8794614350496482\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9622002784509874 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9622002784509874 with variance: 0.0005609140896534153\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9630580058807805 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9630580058807805 with variance: 0.0005501475839975491\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9718090443489402 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9718090443489402 with variance: 0.00029588737998220195\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9723068698209035 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9723068698209035 with variance: 0.00029374177970102497\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9669408452649761 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9669408452649761 with variance: 0.0006230739853736878\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9676022453889335 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9676022453889335 with variance: 0.0006047167572663567\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9645318816795421 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9645318816795421 with variance: 0.00031693393426701996\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.965330125634857 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.965330125634857 with variance: 0.00031465055471990497\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9249651818336991 using:2\n",
      "            train score: 0.990990936925186 with variance: 1.8144576444737736e-05\n",
      "            test  score: 0.9249651818336991 with variance: 0.00018430581031825887\n",
      "          Refitted train score: 0.935251798561151,  RMSE: 0.253546276418555, Log-Loss:2.2203727567422646\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9261904761904761 using:2\n",
      "            train score: 0.9910714285714286 with variance: 1.7715419501133662e-05\n",
      "            test  score: 0.9261904761904761 with variance: 0.0001927437641723356\n",
      "          Refitted train score: 0.9357142857142857,  RMSE: 0.253546276418555, Log-Loss:2.2203727567422646\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9363292767596929 using:3\n",
      "            train score: 0.9970149253731343 with variance: 1.0692804633548631e-05\n",
      "            test  score: 0.9363292767596929 with variance: 0.0006100897729171706\n",
      "          Refitted train score: 0.9542168674698795,  RMSE: 0.21269248984883138, Log-Loss:1.5624817825840827\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9380952380952381 using:3\n",
      "            train score: 0.9970238095238095 with variance: 1.0629251700680197e-05\n",
      "            test  score: 0.9380952380952381 with variance: 0.0005328798185941042\n",
      "          Refitted train score: 0.9547619047619048,  RMSE: 0.21269248984883138, Log-Loss:1.5624817825840827\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9615917432706995 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9615917432706995 with variance: 0.00027935733309131645\n",
      "          Refitted train score: 0.961352657004831,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9619047619047618 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9619047619047618 with variance: 0.0003061224489795912\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9736052963647992 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9736052963647992 with variance: 0.0001940035842080496\n",
      "          Refitted train score: 0.9734939759036144,  RMSE: 0.1618347187425374, Log-Loss:0.9045927122293059\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "        accuracy\n",
      "          CV score: 0.9738095238095237 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9738095238095237 with variance: 0.00019274376417233538\n",
      "          Refitted train score: 0.9738095238095238,  RMSE: 0.1618347187425374, Log-Loss:0.9045927122293059\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9550756980955611 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9550756980955611 with variance: 0.0012701780106973224\n",
      "          Refitted train score: 0.9855769230769231,  RMSE: 0.11952286093343936, Log-Loss:0.4934129951592731\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9571428571428571 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9571428571428571 with variance: 0.001054421768707483\n",
      "          Refitted train score: 0.9857142857142858,  RMSE: 0.11952286093343936, Log-Loss:0.4934129951592731\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9580456134673001 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9580456134673001 with variance: 0.00044144246315155466\n",
      "          Refitted train score: 0.9952380952380953,  RMSE: 0.06900655593423542, Log-Loss:0.1644722675886952\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "        accuracy\n",
      "          CV score: 0.9595238095238094 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9595238095238094 with variance: 0.00037414965986394587\n",
      "          Refitted train score: 0.9952380952380953,  RMSE: 0.06900655593423542, Log-Loss:0.1644722675886952\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9658209687085701 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9658209687085701 with variance: 0.0005629426027912297\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.975,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9666666666666666 with variance: 0.0005328798185941043\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9606849426178391 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9606849426178391 with variance: 0.0005967851270495033\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9619047619047618 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9619047619047618 with variance: 0.0005328798185941042\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9270457896494702 using:2\n",
      "            train score: 0.9970708785649363 with variance: 1.3739702019096648e-05\n",
      "            test  score: 0.9270457896494702 with variance: 0.0003547246224301263\n",
      "          Refitted train score: 0.9505882352941175,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.927578659370725 using:2\n",
      "            train score: 0.9970794332770702 with variance: 1.365952838817252e-05\n",
      "            test  score: 0.927578659370725 with variance: 0.00034604770932010356\n",
      "          Refitted train score: 0.9509345794392523,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9343813557925271 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9343813557925271 with variance: 0.0003467868276630198\n",
      "          Refitted train score: 0.966824644549763,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "        accuracy\n",
      "          CV score: 0.9346374829001368 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9346374829001368 with variance: 0.0003536216153499234\n",
      "          Refitted train score: 0.9672897196261683,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9642550032061017 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9642550032061017 with variance: 0.00039553489847206705\n",
      "          Refitted train score: 0.966824644549763,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9650341997264021 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9650341997264021 with variance: 0.00037604989885115165\n",
      "          Refitted train score: 0.9672897196261683,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9647502208195284 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9647502208195284 with variance: 0.0004847486289222605\n",
      "          Refitted train score: 0.983372921615202,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9649794801641587 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9649794801641587 with variance: 0.0004931871899333969\n",
      "          Refitted train score: 0.9836448598130841,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9715353106779278 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9715353106779278 with variance: 0.00013950303562224246\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9720109439124487 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9720109439124487 with variance: 0.00013922872365311072\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.963788875983998 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.963788875983998 with variance: 0.00011928222693419798\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9649794801641587 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9649794801641587 with variance: 0.0001069239708736223\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9712516308315863 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9712516308315863 with variance: 0.00015436257577420756\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9720109439124487 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9720109439124487 with variance: 0.00013922872365311072\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9687299968474019 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9687299968474019 with variance: 0.00026930490160212797\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9696580027359781 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9696580027359781 with variance: 0.00024727403384603244\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9323423613291947 using:2\n",
      "            train score: 0.9926339171729243 with variance: 3.2755177790234975e-05\n",
      "            test  score: 0.9323423613291947 with variance: 0.0011695986350969154\n",
      "          Refitted train score: 0.9486552567237164,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9344989714957389 using:2\n",
      "            train score: 0.9927162199502625 with variance: 3.1651351345871355e-05\n",
      "            test  score: 0.9344989714957389 with variance: 0.0010405970980817687\n",
      "          Refitted train score: 0.9490291262135923,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9376913803496082 using:3\n",
      "            train score: 0.9975535168195719 with variance: 1.2718719898250393e-05\n",
      "            test  score: 0.9376913803496082 with variance: 0.0014168885190138643\n",
      "          Refitted train score: 0.9582309582309582,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9393182486041727 using:3\n",
      "            train score: 0.997573915446256 with variance: 1.2490768037439417e-05\n",
      "            test  score: 0.9393182486041727 with variance: 0.0013074495037265084\n",
      "          Refitted train score: 0.9587378640776699,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9404550548918719 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9404550548918719 with variance: 0.000734823052614004\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9417572729944166 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9417572729944166 with variance: 0.0006754390108328634\n",
      "          Refitted train score: 0.9611650485436893,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9619321993857785 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9619321993857785 with variance: 0.0011715411847637892\n",
      "          Refitted train score: 0.9776674937965261,  RMSE: 0.14779939172464399, Log-Loss:0.7544878338694092\n",
      "          Refitted test  score: 0.9767441860465116,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9635027916544224 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9635027916544224 with variance: 0.0010141835232244383\n",
      "          Refitted train score: 0.9781553398058253,  RMSE: 0.14779939172464399, Log-Loss:0.7544878338694092\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9672175809895108 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9672175809895108 with variance: 0.0007808482972267985\n",
      "          Refitted train score: 0.9901960784313726,  RMSE: 0.0985329278164293, Log-Loss:0.3353279261641823\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9684396121069645 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9684396121069645 with variance: 0.0006872503380493721\n",
      "          Refitted train score: 0.9902912621359223,  RMSE: 0.0985329278164293, Log-Loss:0.3353279261641823\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9624415733563019 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9624415733563019 with variance: 0.001366052315133204\n",
      "          Refitted train score: 0.9951219512195122,  RMSE: 0.06967330142916177, Log-Loss:0.1676639630820917\n",
      "          Refitted test  score: 0.9761904761904763,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "        accuracy\n",
      "          CV score: 0.9636203349985306 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9636203349985306 with variance: 0.001237906191396175\n",
      "          Refitted train score: 0.9951456310679612,  RMSE: 0.06967330142916177, Log-Loss:0.1676639630820917\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "      ncomponents: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9618183334850002 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9618183334850002 with variance: 0.0014483392484312594\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9885057471264368,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9635909491625035 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9635909491625035 with variance: 0.0011883898055759512\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9631114251890509 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9631114251890509 with variance: 0.0019480648668846086\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9659712018806935 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9659712018806935 with variance: 0.0015133196072781192\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9110613437195715 using:2\n",
      "            train score: 0.9949525306992946 with variance: 1.4332683830113677e-05\n",
      "            test  score: 0.9110613437195715 with variance: 0.0004989340179114982\n",
      "          Refitted train score: 0.9414758269720102,  RMSE: 0.24039331256010033, Log-Loss:1.9959775212558235\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.912120253164557 using:2\n",
      "            train score: 0.9949744681690029 with variance: 1.4188003768878735e-05\n",
      "            test  score: 0.912120253164557 with variance: 0.0004970918122095816\n",
      "          Refitted train score: 0.9422110552763819,  RMSE: 0.24039331256010033, Log-Loss:1.9959775212558235\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9444586127512956 using:3\n",
      "            train score: 0.9993690851735015 with variance: 1.5922140731821196e-06\n",
      "            test  score: 0.9444586127512956 with variance: 0.000418530844174559\n",
      "          Refitted train score: 0.9644670050761421,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9447468354430381 using:3\n",
      "            train score: 0.9993710691823899 with variance: 1.5822158933586482e-06\n",
      "            test  score: 0.9447468354430381 with variance: 0.00041643366447684585\n",
      "          Refitted train score: 0.964824120603015,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9740841354876443 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9740841354876443 with variance: 0.00034795269570047504\n",
      "          Refitted train score: 0.9669211195928753,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9748101265822784 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9748101265822784 with variance: 0.000318893206216953\n",
      "          Refitted train score: 0.9673366834170855,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9641548924093895 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9641548924093895 with variance: 0.00023536026662442848\n",
      "          Refitted train score: 0.9746192893401016,  RMSE: 0.15851065623706034, Log-Loss:0.8678144792497432\n",
      "          Refitted test  score: 0.9504950495049505,  RMSE: 0.2773500981126146, Log-Loss:2.6568658579514466\n",
      "        accuracy\n",
      "          CV score: 0.9648417721518987 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9648417721518987 with variance: 0.00021174891844255697\n",
      "          Refitted train score: 0.9748743718592965,  RMSE: 0.15851065623706034, Log-Loss:0.8678144792497432\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568658579514466\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9689509970211724 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9689509970211724 with variance: 0.0002581273733991593\n",
      "          Refitted train score: 0.9898477157360407,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.970873786407767,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "        accuracy\n",
      "          CV score: 0.9697784810126582 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9697784810126582 with variance: 0.00023156345136997368\n",
      "          Refitted train score: 0.9899497487437185,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941342765695798\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9766832907183784 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9766832907183784 with variance: 0.00023250340422560937\n",
      "          Refitted train score: 0.9974811083123425,  RMSE: 0.05012547071170855, Log-Loss:0.08678084521334442\n",
      "          Refitted test  score: 0.9514563106796116,  RMSE: 0.2773500981126146, Log-Loss:2.656878159450373\n",
      "        accuracy\n",
      "          CV score: 0.9773417721518987 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9773417721518987 with variance: 0.0002157046146450889\n",
      "          Refitted train score: 0.9974874371859297,  RMSE: 0.05012547071170855, Log-Loss:0.08678084521334442\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656878159450373\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9740795870795871 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9740795870795871 with variance: 0.00020821714460475662\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9423076923076924,  RMSE: 0.3038218101251, Log-Loss:3.1882562516402326\n",
      "        accuracy\n",
      "          CV score: 0.9748417721518987 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9748417721518987 with variance: 0.0001899134754045824\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1882562516402326\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9714155844155845 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714155844155845 with variance: 0.00023511620846685755\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9514563106796116,  RMSE: 0.2773500981126146, Log-Loss:2.656878159450373\n",
      "        accuracy\n",
      "          CV score: 0.9723101265822784 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9723101265822784 with variance: 0.00021635154622656603\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656878159450373\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9365145602653528 using:2\n",
      "            train score: 0.995615117851055 with variance: 2.9885900972501117e-05\n",
      "            test  score: 0.9365145602653528 with variance: 0.000719892121601718\n",
      "          Refitted train score: 0.9528535980148882,  RMSE: 0.2168633278595001, Log-Loss:1.6243662076241956\n",
      "          Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        accuracy\n",
      "          CV score: 0.9380246913580248 using:2\n",
      "            train score: 0.9956656346749225 with variance: 2.9138590420688493e-05\n",
      "            test  score: 0.9380246913580248 with variance: 0.000628196921201036\n",
      "          Refitted train score: 0.9529702970297029,  RMSE: 0.2168633278595001, Log-Loss:1.6243662076241956\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9438512531137206 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9438512531137206 with variance: 0.0009531338761558005\n",
      "          Refitted train score: 0.9595959595959594,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9555555555555556,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        accuracy\n",
      "          CV score: 0.945462962962963 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.945462962962963 with variance: 0.0008431984453589388\n",
      "          Refitted train score: 0.9603960396039604,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9571272238260912 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9571272238260912 with variance: 0.0004216846750845671\n",
      "          Refitted train score: 0.9696969696969696,  RMSE: 0.1723454968864278, Log-Loss:1.025908207756903\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        accuracy\n",
      "          CV score: 0.9579012345679011 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9579012345679011 with variance: 0.00040426764212772364\n",
      "          Refitted train score: 0.9702970297029703,  RMSE: 0.1723454968864278, Log-Loss:1.025908207756903\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9676970198222294 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9676970198222294 with variance: 0.0002592661205742516\n",
      "          Refitted train score: 0.9875311720698253,  RMSE: 0.1112485398724962, Log-Loss:0.4274620830989703\n",
      "          Refitted test  score: 0.9574468085106385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9678395061728395 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9678395061728395 with variance: 0.00027954580094497817\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.4274620830989703\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.967584051741199 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.967584051741199 with variance: 0.00021365208221474355\n",
      "          Refitted train score: 0.9925187032418953,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9574468085106385,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615867\n",
      "        accuracy\n",
      "          CV score: 0.9678395061728395 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9678395061728395 with variance: 0.0002185794848346283\n",
      "          Refitted train score: 0.9925742574257426,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615867\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9694806834047339 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9694806834047339 with variance: 0.00023657429807997813\n",
      "          Refitted train score: 0.9950248756218906,  RMSE: 0.07035975447302918, Log-Loss:0.17098404155896477\n",
      "          Refitted test  score: 0.9263157894736843,  RMSE: 0.3281650616569468, Log-Loss:3.71960974083224\n",
      "        accuracy\n",
      "          CV score: 0.9702777777777778 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9702777777777778 with variance: 0.00022088477366255074\n",
      "          Refitted train score: 0.995049504950495,  RMSE: 0.07035975447302918, Log-Loss:0.17098404155896477\n",
      "          Refitted test  score: 0.8923076923076924,  RMSE: 0.3281650616569468, Log-Loss:3.71960974083224\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9695481265101519 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9695481265101519 with variance: 0.00016803260501422219\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.9703086419753086 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9703086419753086 with variance: 0.0001579180003048313\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.974676331638357 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.974676331638357 with variance: 0.0003225685855807126\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.975246913580247 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.975246913580247 with variance: 0.0003048468221307727\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9287574763102189 using:2\n",
      "            train score: 0.9924839717553701 with variance: 6.2398148757340004e-06\n",
      "            test  score: 0.9287574763102189 with variance: 0.0005123780050394811\n",
      "          Refitted train score: 0.93734335839599,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.93 using:2\n",
      "            train score: 0.9924999999999999 with variance: 6.249999999999984e-06\n",
      "            test  score: 0.93 with variance: 0.0004750000000000003\n",
      "          Refitted train score: 0.9375,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9281772313850929 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9281772313850929 with variance: 0.0005823798347012455\n",
      "          Refitted train score: 0.9543147208121826,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.93 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.93 with variance: 0.0005374999999999997\n",
      "          Refitted train score: 0.955,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9455418338993515 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9455418338993515 with variance: 0.0004906747715520582\n",
      "          Refitted train score: 0.9772151898734178,  RMSE: 0.15, Log-Loss:0.7771264668726423\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.945 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.945 with variance: 0.0005374999999999998\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771264668726423\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9624389867160952 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9624389867160952 with variance: 0.0002289196614408475\n",
      "          Refitted train score: 0.9772151898734178,  RMSE: 0.15, Log-Loss:0.7771264668726423\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        accuracy\n",
      "          CV score: 0.9625 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9625 with variance: 0.0002499999999999999\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771264668726423\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9623188584596427 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9623188584596427 with variance: 0.0004064691830107501\n",
      "          Refitted train score: 0.9873417721518987,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9625 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9625 with variance: 0.0004374999999999997\n",
      "          Refitted train score: 0.9875,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9771382471598586 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9771382471598586 with variance: 9.549430007163131e-05\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9484536082474228,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9820162959403465 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9820162959403465 with variance: 0.00017576363176604936\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9494949494949495,  RMSE: 0.2773500981126146, Log-Loss:2.6568658579514466\n",
      "        accuracy\n",
      "          CV score: 0.9824999999999999 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9824999999999999 with variance: 0.00016250000000000005\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568658579514466\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9742821879430806 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9742821879430806 with variance: 0.0002131954955901144\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.975 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.975 with variance: 0.00018750000000000087\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9299608251624736 using:2\n",
      "            train score: 0.9962886164120965 with variance: 5.3726767362812485e-06\n",
      "            test  score: 0.9299608251624736 with variance: 0.0002935535763061172\n",
      "          Refitted train score: 0.9502487562189056,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9310448660042157 using:2\n",
      "            train score: 0.9963076923076922 with variance: 5.301775147929033e-06\n",
      "            test  score: 0.9310448660042157 with variance: 0.0002787912385129401\n",
      "          Refitted train score: 0.9507389162561576,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9548360063127996 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9548360063127996 with variance: 0.0005602896246264182\n",
      "          Refitted train score: 0.96,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "        accuracy\n",
      "          CV score: 0.9556760012044565 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9556760012044565 with variance: 0.0005231787605105464\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627438828807942\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9583769792537332 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9583769792537332 with variance: 0.00046374094192149493\n",
      "          Refitted train score: 0.9603960396039605,  RMSE: 0.19851666679418606, Log-Loss:1.3611478312822232\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        accuracy\n",
      "          CV score: 0.9582053598313761 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9582053598313761 with variance: 0.0005128424130438894\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.19851666679418606, Log-Loss:1.3611478312822232\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9681063076173524 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9681063076173524 with variance: 0.0003688556523832155\n",
      "          Refitted train score: 0.985,  RMSE: 0.12156613477096616, Log-Loss:0.5104252669198632\n",
      "          Refitted test  score: 0.9662921348314606,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        accuracy\n",
      "          CV score: 0.9680517916290274 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9680517916290274 with variance: 0.0003935464561243355\n",
      "          Refitted train score: 0.9852216748768473,  RMSE: 0.12156613477096616, Log-Loss:0.5104252669198632\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9612301340689132 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9612301340689132 with variance: 0.0010586468800967488\n",
      "          Refitted train score: 0.9900497512437811,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "        accuracy\n",
      "          CV score: 0.9606744956338453 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9606744956338453 with variance: 0.0011094201209334502\n",
      "          Refitted train score: 0.9901477832512315,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "      ncomponents: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9656611148712022 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9656611148712022 with variance: 0.0005143316572917024\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "        accuracy\n",
      "          CV score: 0.9656127672387835 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9656127672387835 with variance: 0.0005589388959565915\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9700866417533083 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9700866417533083 with variance: 0.00014927384625875354\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9704908160192712 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9704908160192712 with variance: 0.00015381210388101753\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9683233697908411 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9683233697908411 with variance: 0.0005149980445856272\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        accuracy\n",
      "          CV score: 0.9680819030412527 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9680819030412527 with variance: 0.0005702399691868036\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9407317496098491 using:2\n",
      "            train score: 0.9879725343746337 with variance: 0.00011350344613171335\n",
      "            test  score: 0.9407317496098491 with variance: 0.00037378230732194363\n",
      "          Refitted train score: 0.9509043927648579,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9413502109704641 using:2\n",
      "            train score: 0.9878838444476099 with variance: 0.0001155088058683636\n",
      "            test  score: 0.9413502109704641 with variance: 0.00035839221891752996\n",
      "          Refitted train score: 0.951530612244898,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9479979011797981 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9479979011797981 with variance: 0.0006796639106123949\n",
      "          Refitted train score: 0.9565217391304348,  RMSE: 0.20824828195876072, Log-Loss:1.4978714170737846\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9488802336903603 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9488802336903603 with variance: 0.000653406388434059\n",
      "          Refitted train score: 0.9566326530612245,  RMSE: 0.20824828195876072, Log-Loss:1.4978714170737846\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9539279935566854 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9539279935566854 with variance: 0.0005690608701806192\n",
      "          Refitted train score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9541058098020123 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9541058098020123 with variance: 0.0006137163616857466\n",
      "          Refitted train score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9537368421052632 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9537368421052632 with variance: 0.0007632243767313018\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9541707237909769 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9541707237909769 with variance: 0.0008020238163336527\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9540454840805717 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9540454840805717 with variance: 0.00043470978893579736\n",
      "          Refitted train score: 0.9818181818181818,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9541707237909769 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9541707237909769 with variance: 0.00048156235182476105\n",
      "          Refitted train score: 0.9821428571428571,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9689260312944523 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9689260312944523 with variance: 0.0003822807759470169\n",
      "          Refitted train score: 0.9974424552429668,  RMSE: 0.050507627227610534, Log-Loss:0.0881091234564058\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "        accuracy\n",
      "          CV score: 0.9694255111976631 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9694255111976631 with variance: 0.0003635857594172959\n",
      "          Refitted train score: 0.9974489795918368,  RMSE: 0.050507627227610534, Log-Loss:0.0881091234564058\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9689504091289567 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9689504091289567 with variance: 0.00042707316232246096\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "        accuracy\n",
      "          CV score: 0.9694579681921454 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9694579681921454 with variance: 0.00042387296747421467\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "      ncomponents: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9656705306325559 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9656705306325559 with variance: 0.0006012143629605479\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9668614086335605 with variance: 0.0005568613148759335\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.926235094990884 using:2\n",
      "            train score: 0.9926566955380833 with variance: 3.9851534921464134e-05\n",
      "            test  score: 0.926235094990884 with variance: 0.0013045734624781793\n",
      "          Refitted train score: 0.9484029484029484,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9523809523809523,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        accuracy\n",
      "          CV score: 0.9268292682926831 using:2\n",
      "            train score: 0.9926829268292682 with variance: 3.9411064842355815e-05\n",
      "            test  score: 0.9268292682926831 with variance: 0.001249256395002973\n",
      "          Refitted train score: 0.948780487804878,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.955486966332392 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.955486966332392 with variance: 0.0009964710921847762\n",
      "          Refitted train score: 0.9679012345679012,  RMSE: 0.178065485350673, Log-Loss:1.095139735423317\n",
      "          Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9560975609756097 using:3\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9560975609756097 with variance: 0.0009875074360499688\n",
      "          Refitted train score: 0.9682926829268292,  RMSE: 0.178065485350673, Log-Loss:1.095139735423317\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9651234567901235 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9651234567901235 with variance: 0.0007134583142813598\n",
      "          Refitted train score: 0.9776674937965261,  RMSE: 0.14815943949743843, Log-Loss:0.7581702125649433\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "        accuracy\n",
      "          CV score: 0.9658536585365853 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9658536585365853 with variance: 0.0006781677572873284\n",
      "          Refitted train score: 0.9780487804878049,  RMSE: 0.14815943949743843, Log-Loss:0.7581702125649433\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9599343647444913 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9599343647444913 with variance: 0.0007202469553413429\n",
      "          Refitted train score: 0.9800995024875622,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9609756097560975 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9609756097560975 with variance: 0.0006781677572873287\n",
      "          Refitted train score: 0.9804878048780488,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9647452726988593 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9647452726988593 with variance: 0.0005453778415770069\n",
      "          Refitted train score: 0.9901477832512315,  RMSE: 0.09877295966495896, Log-Loss:0.336963672145471\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706541\n",
      "        accuracy\n",
      "          CV score: 0.9658536585365853 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9658536585365853 with variance: 0.0004997025580011907\n",
      "          Refitted train score: 0.9902439024390244,  RMSE: 0.09877295966495896, Log-Loss:0.336963672145471\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706541\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9651165387884539 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9651165387884539 with variance: 0.00034068815132634096\n",
      "          Refitted train score: 0.9950980392156863,  RMSE: 0.06984302957695782, Log-Loss:0.16848183607273606\n",
      "          Refitted test  score: 0.9438202247191012,  RMSE: 0.2773500981126146, Log-Loss:2.6568658579514466\n",
      "        accuracy\n",
      "          CV score: 0.9658536585365853 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9658536585365853 with variance: 0.0003212373587150511\n",
      "          Refitted train score: 0.9951219512195122,  RMSE: 0.06984302957695782, Log-Loss:0.16848183607273606\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568658579514466\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9672744539411205 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9672744539411205 with variance: 0.00023549154994232388\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9682926829268294 with variance: 0.0002141582391433674\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9697435897435899 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9697435897435899 with variance: 0.0003605193951347786\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9707317073170731 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9707317073170731 with variance: 0.0003331350386674605\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9283560419067666 using:2\n",
      "            train score: 0.9914492267302304 with variance: 2.429499040728255e-05\n",
      "            test  score: 0.9283560419067666 with variance: 0.0004310341676623807\n",
      "          Refitted train score: 0.9343832020997376,  RMSE: 0.2551551815399144, Log-Loss:2.2486411600117173\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9296992481203008 using:2\n",
      "            train score: 0.991539405220187 with variance: 2.368995171013259e-05\n",
      "            test  score: 0.9296992481203008 with variance: 0.0003086804191239925\n",
      "          Refitted train score: 0.9348958333333334,  RMSE: 0.2551551815399144, Log-Loss:2.2486411600117173\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9390087775188517 using:3\n",
      "            train score: 0.9986927964970365 with variance: 2.563217120211298e-06\n",
      "            test  score: 0.9390087775188517 with variance: 0.0006445909789545384\n",
      "          Refitted train score: 0.9506493506493506,  RMSE: 0.22243913025065232, Log-Loss:1.7089706965562634\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9400546821599451 using:3\n",
      "            train score: 0.9986991835526038 with variance: 2.538196329359937e-06\n",
      "            test  score: 0.9400546821599451 with variance: 0.0005203588726990537\n",
      "          Refitted train score: 0.9505208333333334,  RMSE: 0.22243913025065232, Log-Loss:1.7089706965562634\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.947756412592194 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.947756412592194 with variance: 0.0014968097487260102\n",
      "          Refitted train score: 0.9578947368421052,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9480177717019822 using:5\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9480177717019822 with variance: 0.0016165016406049619\n",
      "          Refitted train score: 0.9583333333333334,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9531026857619376 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9531026857619376 with variance: 0.0017695227752588896\n",
      "          Refitted train score: 0.9736842105263158,  RMSE: 0.1613743060919757, Log-Loss:0.8994535488057235\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9532467532467532 using:10\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9532467532467532 with variance: 0.0017945690672963414\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.1613743060919757, Log-Loss:0.8994535488057235\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.958037818037818 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.958037818037818 with variance: 0.0010065556805087547\n",
      "          Refitted train score: 0.9868766404199474,  RMSE: 0.11410886614690961, Log-Loss:0.44972573326037496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9584415584415584 using:15\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9584415584415584 with variance: 0.000971496036431102\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.44972573326037496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9545461467246945 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9545461467246945 with variance: 0.0006803178065756008\n",
      "          Refitted train score: 0.9947643979057591,  RMSE: 0.07216878364870322, Log-Loss:0.17988946039016082\n",
      "          Refitted test  score: 0.9913043478260869,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "        accuracy\n",
      "          CV score: 0.9558099794941901 using:25\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9558099794941901 with variance: 0.000578073220084948\n",
      "          Refitted train score: 0.9947916666666666,  RMSE: 0.07216878364870322, Log-Loss:0.17988946039016082\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.951609613630658 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.951609613630658 with variance: 0.0015819432890361394\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9913043478260869,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "        accuracy\n",
      "          CV score: 0.9532467532467532 using:50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9532467532467532 with variance: 0.001457244054646653\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9520046107387878 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9520046107387878 with variance: 0.001047408519293992\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9531784005468216 using:100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9531784005468216 with variance: 0.0009821670936179705\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#AdaBoostRegressor\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "    print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        \n",
    "    for ncomponents in ncomponentss:\n",
    "        print(tab * 3 + f\"ncomponents: {ncomponents}\")\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "                     \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        pca = PCA(n_components = ncomponents)        \n",
    "        pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        ab = AdaBoostClassifier(random_state = randomstate)\n",
    "        cv_results = cross_validate(ab, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "\n",
    "        for score in scores:\n",
    "            avg_score_test = np.mean(cv_results['test_' + score])\n",
    "            var_score_test = np.var(cv_results['test_' + score])\n",
    "            avg_score_train = np.mean(cv_results['train_' + score])\n",
    "            var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "            if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, ncomponents]\n",
    "\n",
    "\n",
    "        for score in scores: \n",
    "\n",
    "            print(tab * 4 + str(score))\n",
    "            print(tab * 5 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 6 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 6 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            ab = LogisticRegression(C = best_avg_scores[score][4], solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "\n",
    "            ab.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = ab.predict(X_train), ab.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(ab, X_train, y_train), get_scorer(score)(ab, X_test, y_test)\n",
    "\n",
    "            print(tab * 5 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 5 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\") \n",
    "\n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/pca/AdaBoostRegressor\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad96026",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "74e2c8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9489213670251899 using:1.0,2\n",
      "            train score: 0.9494998259759744 with variance: 4.04793329733307e-05\n",
      "            test  score: 0.9489213670251899 with variance: 0.0004620864930584774\n",
      "          Refitted train score: 0.9490022172949001,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9497611084567608 using:1.0,2\n",
      "            train score: 0.9503238486621701 with variance: 3.721663701949046e-05\n",
      "            test  score: 0.9497611084567608 with variance: 0.0004127676058958381\n",
      "          Refitted train score: 0.9497816593886463,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        f1\n",
      "          CV score: 0.9489213670251899 using:1.0,2\n",
      "            train score: 0.9494998259759744 with variance: 4.04793329733307e-05\n",
      "            test  score: 0.9489213670251899 with variance: 0.0004620864930584774\n",
      "          Refitted train score: 0.9490022172949001,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9497611084567608 using:1.0,2\n",
      "            train score: 0.9503238486621701 with variance: 3.721663701949046e-05\n",
      "            test  score: 0.9497611084567608 with variance: 0.0004127676058958381\n",
      "          Refitted train score: 0.9497816593886463,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        f1\n",
      "          CV score: 0.9489213670251899 using:1.0,2\n",
      "            train score: 0.9494998259759744 with variance: 4.04793329733307e-05\n",
      "            test  score: 0.9489213670251899 with variance: 0.0004620864930584774\n",
      "          Refitted train score: 0.9490022172949001,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.975609756097561,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "        accuracy\n",
      "          CV score: 0.9497611084567608 using:1.0,2\n",
      "            train score: 0.9503238486621701 with variance: 3.721663701949046e-05\n",
      "            test  score: 0.9497611084567608 with variance: 0.0004127676058958381\n",
      "          Refitted train score: 0.9497816593886463,  RMSE: 0.22409449036367163, Log-Loss:1.7344940040663481\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9659878859955615 using:1.0,3\n",
      "            train score: 0.9672474208174595 with variance: 3.974612669448303e-05\n",
      "            test  score: 0.9659878859955615 with variance: 0.0006822137982299122\n",
      "          Refitted train score: 0.966740576496674,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9671524128045867 using:1.0,3\n",
      "            train score: 0.9677893420288559 with variance: 3.725632131939219e-05\n",
      "            test  score: 0.9671524128045867 with variance: 0.0005817574062655995\n",
      "          Refitted train score: 0.9672489082969432,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9659878859955615 using:1.0,3\n",
      "            train score: 0.9672474208174595 with variance: 3.974612669448303e-05\n",
      "            test  score: 0.9659878859955615 with variance: 0.0006822137982299122\n",
      "          Refitted train score: 0.966740576496674,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9671524128045867 using:1.0,3\n",
      "            train score: 0.9677893420288559 with variance: 3.725632131939219e-05\n",
      "            test  score: 0.9671524128045867 with variance: 0.0005817574062655995\n",
      "          Refitted train score: 0.9672489082969432,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9659878859955615 using:1.0,3\n",
      "            train score: 0.9672474208174595 with variance: 3.974612669448303e-05\n",
      "            test  score: 0.9659878859955615 with variance: 0.0006822137982299122\n",
      "          Refitted train score: 0.966740576496674,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9671524128045867 using:1.0,3\n",
      "            train score: 0.9677893420288559 with variance: 3.725632131939219e-05\n",
      "            test  score: 0.9671524128045867 with variance: 0.0005817574062655995\n",
      "          Refitted train score: 0.9672489082969432,  RMSE: 0.18097262694412314, Log-Loss:1.1311896164047628\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9681384236299699 using:1.0,5\n",
      "            train score: 0.9711439230048841 with variance: 3.40367959983578e-05\n",
      "            test  score: 0.9681384236299699 with variance: 0.0008007535879125477\n",
      "          Refitted train score: 0.9711751662971175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.969326325848065 using:1.0,5\n",
      "            train score: 0.9716100117627791 with variance: 3.1879386892757785e-05\n",
      "            test  score: 0.969326325848065 with variance: 0.0006962176152437675\n",
      "          Refitted train score: 0.9716157205240175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9681384236299699 using:1.0,5\n",
      "            train score: 0.9711439230048841 with variance: 3.40367959983578e-05\n",
      "            test  score: 0.9681384236299699 with variance: 0.0008007535879125477\n",
      "          Refitted train score: 0.9711751662971175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.969326325848065 using:1.0,5\n",
      "            train score: 0.9716100117627791 with variance: 3.1879386892757785e-05\n",
      "            test  score: 0.969326325848065 with variance: 0.0006962176152437675\n",
      "          Refitted train score: 0.9716157205240175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9706555234931711 using:1.5,5\n",
      "            train score: 0.9711439230048841 with variance: 3.40367959983578e-05\n",
      "            test  score: 0.9706555234931711 with variance: 0.0005719131399035983\n",
      "          Refitted train score: 0.9711751662971175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9715241280458672 using:1.5,5\n",
      "            train score: 0.9716100117627791 with variance: 3.1879386892757785e-05\n",
      "            test  score: 0.9715241280458672 with variance: 0.0005122448751315153\n",
      "          Refitted train score: 0.9716157205240175,  RMSE: 0.16847634693327884, Log-Loss:0.9803635194893664\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9682654038467993 using:1.0,10\n",
      "            train score: 0.97651700850544 with variance: 2.157148442654264e-05\n",
      "            test  score: 0.9682654038467993 with variance: 0.0004100025379998702\n",
      "          Refitted train score: 0.9753914988814317,  RMSE: 0.15497569889795076, Log-Loss:0.8295339308821352\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9693741041567128 using:1.0,10\n",
      "            train score: 0.9770715147183633 with variance: 1.978198943882795e-05\n",
      "            test  score: 0.9693741041567128 with variance: 0.0003589342583713047\n",
      "          Refitted train score: 0.9759825327510917,  RMSE: 0.15497569889795076, Log-Loss:0.8295339308821352\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9682654038467993 using:1.0,10\n",
      "            train score: 0.97651700850544 with variance: 2.157148442654264e-05\n",
      "            test  score: 0.9682654038467993 with variance: 0.0004100025379998702\n",
      "          Refitted train score: 0.9753914988814317,  RMSE: 0.15497569889795076, Log-Loss:0.8295339308821352\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9693741041567128 using:1.0,10\n",
      "            train score: 0.9770715147183633 with variance: 1.978198943882795e-05\n",
      "            test  score: 0.9693741041567128 with variance: 0.0003589342583713047\n",
      "          Refitted train score: 0.9759825327510917,  RMSE: 0.15497569889795076, Log-Loss:0.8295339308821352\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9682654038467993 using:1.0,10\n",
      "            train score: 0.97651700850544 with variance: 2.157148442654264e-05\n",
      "            test  score: 0.9682654038467993 with variance: 0.0004100025379998702\n",
      "          Refitted train score: 0.9753914988814317,  RMSE: 0.15497569889795076, Log-Loss:0.8295339308821352\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9693741041567128 using:1.0,10\n",
      "            train score: 0.9770715147183633 with variance: 1.978198943882795e-05\n",
      "            test  score: 0.9693741041567128 with variance: 0.0003589342583713047\n",
      "          Refitted train score: 0.9759825327510917,  RMSE: 0.15497569889795076, Log-Loss:0.8295339308821352\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9773696672263119 using:1.0,15\n",
      "            train score: 0.9821908416358884 with variance: 3.677518581622341e-05\n",
      "            test  score: 0.9773696672263119 with variance: 0.0003712374855616511\n",
      "          Refitted train score: 0.9799554565701559,  RMSE: 0.14018079405479933, Log-Loss:0.6787095798126561\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9781175346392738 using:1.0,15\n",
      "            train score: 0.982530039755215 with variance: 3.461762575595098e-05\n",
      "            test  score: 0.9781175346392738 with variance: 0.00033813711164715595\n",
      "          Refitted train score: 0.980349344978166,  RMSE: 0.14018079405479933, Log-Loss:0.6787095798126561\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9773696672263119 using:1.0,15\n",
      "            train score: 0.9821908416358884 with variance: 3.677518581622341e-05\n",
      "            test  score: 0.9773696672263119 with variance: 0.0003712374855616511\n",
      "          Refitted train score: 0.9799554565701559,  RMSE: 0.14018079405479933, Log-Loss:0.6787095798126561\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9781175346392738 using:1.0,15\n",
      "            train score: 0.982530039755215 with variance: 3.461762575595098e-05\n",
      "            test  score: 0.9781175346392738 with variance: 0.00033813711164715595\n",
      "          Refitted train score: 0.980349344978166,  RMSE: 0.14018079405479933, Log-Loss:0.6787095798126561\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9773696672263119 using:1.0,15\n",
      "            train score: 0.9821908416358884 with variance: 3.677518581622341e-05\n",
      "            test  score: 0.9773696672263119 with variance: 0.0003712374855616511\n",
      "          Refitted train score: 0.9799554565701559,  RMSE: 0.14018079405479933, Log-Loss:0.6787095798126561\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9781175346392738 using:1.0,15\n",
      "            train score: 0.982530039755215 with variance: 3.461762575595098e-05\n",
      "            test  score: 0.9781175346392738 with variance: 0.00033813711164715595\n",
      "          Refitted train score: 0.980349344978166,  RMSE: 0.14018079405479933, Log-Loss:0.6787095798126561\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9752769452769453 using:1.0,25\n",
      "            train score: 0.9861309389178476 with variance: 4.0363267763349904e-05\n",
      "            test  score: 0.9752769452769453 with variance: 0.00012698202748152873\n",
      "          Refitted train score: 0.9867256637168141,  RMSE: 0.11445713905747734, Log-Loss:0.45247305320843784\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9759436215957955 using:1.0,25\n",
      "            train score: 0.9863507094891381 with variance: 3.873776505570931e-05\n",
      "            test  score: 0.9759436215957955 with variance: 0.00011698951456736142\n",
      "          Refitted train score: 0.9868995633187773,  RMSE: 0.11445713905747734, Log-Loss:0.45247305320843784\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9752769452769453 using:1.0,25\n",
      "            train score: 0.9861309389178476 with variance: 4.0363267763349904e-05\n",
      "            test  score: 0.9752769452769453 with variance: 0.00012698202748152873\n",
      "          Refitted train score: 0.9867256637168141,  RMSE: 0.11445713905747734, Log-Loss:0.45247305320843784\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9759436215957955 using:1.0,25\n",
      "            train score: 0.9863507094891381 with variance: 3.873776505570931e-05\n",
      "            test  score: 0.9759436215957955 with variance: 0.00011698951456736142\n",
      "          Refitted train score: 0.9868995633187773,  RMSE: 0.11445713905747734, Log-Loss:0.45247305320843784\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9775235875235875 using:1.5,25\n",
      "            train score: 0.988947122901514 with variance: 1.843320251949439e-05\n",
      "            test  score: 0.9775235875235875 with variance: 0.00015840858491541243\n",
      "          Refitted train score: 0.988962472406181,  RMSE: 0.10448459488214322, Log-Loss:0.3770608776736984\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9781175346392738 using:1.5,25\n",
      "            train score: 0.9890799720075639 with variance: 1.7900266353505185e-05\n",
      "            test  score: 0.9781175346392738 with variance: 0.00014596809742118037\n",
      "          Refitted train score: 0.9890829694323144,  RMSE: 0.10448459488214322, Log-Loss:0.3770608776736984\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9797213897213897 using:1.0,50\n",
      "            train score: 0.9911783849239384 with variance: 1.0449141922561896e-05\n",
      "            test  score: 0.9797213897213897 with variance: 0.00022822399539016344\n",
      "          Refitted train score: 0.9911894273127753,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9802914476827521 using:1.0,50\n",
      "            train score: 0.991262786438558 with variance: 1.017544468670683e-05\n",
      "            test  score: 0.9802914476827521 with variance: 0.00021275386363983905\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9797213897213897 using:1.0,50\n",
      "            train score: 0.9911783849239384 with variance: 1.0449141922561896e-05\n",
      "            test  score: 0.9797213897213897 with variance: 0.00022822399539016344\n",
      "          Refitted train score: 0.9911894273127753,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9802914476827521 using:1.0,50\n",
      "            train score: 0.991262786438558 with variance: 1.017544468670683e-05\n",
      "            test  score: 0.9802914476827521 with variance: 0.00021275386363983905\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9797213897213897 using:1.0,50\n",
      "            train score: 0.9911783849239384 with variance: 1.0449141922561896e-05\n",
      "            test  score: 0.9797213897213897 with variance: 0.00022822399539016344\n",
      "          Refitted train score: 0.9911894273127753,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9802914476827521 using:1.0,50\n",
      "            train score: 0.991262786438558 with variance: 1.017544468670683e-05\n",
      "            test  score: 0.9802914476827521 with variance: 0.00021275386363983905\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9773702925427064 using:1.0,100\n",
      "            train score: 0.996164367109797 with variance: 1.801607925698314e-06\n",
      "            test  score: 0.9773702925427064 with variance: 0.00026184871391381155\n",
      "          Refitted train score: 0.9956140350877193,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9780936454849499 using:1.0,100\n",
      "            train score: 0.996179330266077 with variance: 1.785159433562593e-06\n",
      "            test  score: 0.9780936454849499 with variance: 0.00024205089245908474\n",
      "          Refitted train score: 0.9956331877729258,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9773702925427064 using:1.0,100\n",
      "            train score: 0.996164367109797 with variance: 1.801607925698314e-06\n",
      "            test  score: 0.9773702925427064 with variance: 0.00026184871391381155\n",
      "          Refitted train score: 0.9956140350877193,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9780936454849499 using:1.0,100\n",
      "            train score: 0.996179330266077 with variance: 1.785159433562593e-06\n",
      "            test  score: 0.9780936454849499 with variance: 0.00024205089245908474\n",
      "          Refitted train score: 0.9956331877729258,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9773702925427064 using:1.0,100\n",
      "            train score: 0.996164367109797 with variance: 1.801607925698314e-06\n",
      "            test  score: 0.9773702925427064 with variance: 0.00026184871391381155\n",
      "          Refitted train score: 0.9956140350877193,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9780936454849499 using:1.0,100\n",
      "            train score: 0.996179330266077 with variance: 1.785159433562593e-06\n",
      "            test  score: 0.9780936454849499 with variance: 0.00024205089245908474\n",
      "          Refitted train score: 0.9956331877729258,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9580302851270593 using:1.0,2\n",
      "            train score: 0.9595413837870568 with variance: 4.73820127257015e-05\n",
      "            test  score: 0.9580302851270593 with variance: 0.0006723978505941958\n",
      "          Refitted train score: 0.9606986899563319,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9411764705882353,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        accuracy\n",
      "          CV score: 0.9589527816736793 using:1.0,2\n",
      "            train score: 0.9599619131326447 with variance: 4.477067063365416e-05\n",
      "            test  score: 0.9589527816736793 with variance: 0.0006175490200578277\n",
      "          Refitted train score: 0.961038961038961,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        f1\n",
      "          CV score: 0.9580302851270593 using:1.0,2\n",
      "            train score: 0.9595413837870568 with variance: 4.73820127257015e-05\n",
      "            test  score: 0.9580302851270593 with variance: 0.0006723978505941958\n",
      "          Refitted train score: 0.9606986899563319,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9411764705882353,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        accuracy\n",
      "          CV score: 0.9589527816736793 using:1.0,2\n",
      "            train score: 0.9599619131326447 with variance: 4.477067063365416e-05\n",
      "            test  score: 0.9589527816736793 with variance: 0.0006175490200578277\n",
      "          Refitted train score: 0.961038961038961,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        f1\n",
      "          CV score: 0.9584630284221463 using:1.5,2\n",
      "            train score: 0.9590141067751563 with variance: 3.448465973245385e-05\n",
      "            test  score: 0.9584630284221463 with variance: 0.0005933636762039786\n",
      "          Refitted train score: 0.9606986899563319,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9411764705882353,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        accuracy\n",
      "          CV score: 0.9589527816736793 using:1.0,2\n",
      "            train score: 0.9599619131326447 with variance: 4.477067063365416e-05\n",
      "            test  score: 0.9589527816736793 with variance: 0.0006175490200578277\n",
      "          Refitted train score: 0.961038961038961,  RMSE: 0.19738550848793068, Log-Loss:1.3456787279013074\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9689758769280334 using:1.0,3\n",
      "            train score: 0.9698592519191342 with variance: 6.228667426474062e-06\n",
      "            test  score: 0.9689758769280334 with variance: 0.00022598729053117402\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496316\n",
      "          Refitted test  score: 0.8823529411764706,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "        accuracy\n",
      "          CV score: 0.9697054698457223 using:1.0,3\n",
      "            train score: 0.9702380429209697 with variance: 5.86109741642428e-06\n",
      "            test  score: 0.9697054698457223 with variance: 0.00020331578920910657\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496316\n",
      "          Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "        f1\n",
      "          CV score: 0.9689758769280334 using:1.0,3\n",
      "            train score: 0.9698592519191342 with variance: 6.228667426474062e-06\n",
      "            test  score: 0.9689758769280334 with variance: 0.00022598729053117402\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496316\n",
      "          Refitted test  score: 0.8823529411764706,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "        accuracy\n",
      "          CV score: 0.9697054698457223 using:1.0,3\n",
      "            train score: 0.9702380429209697 with variance: 5.86109741642428e-06\n",
      "            test  score: 0.9697054698457223 with variance: 0.00020331578920910657\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496316\n",
      "          Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "        f1\n",
      "          CV score: 0.9689758769280334 using:1.0,3\n",
      "            train score: 0.9698592519191342 with variance: 6.228667426474062e-06\n",
      "            test  score: 0.9689758769280334 with variance: 0.00022598729053117402\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496316\n",
      "          Refitted test  score: 0.8823529411764706,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "        accuracy\n",
      "          CV score: 0.9697054698457223 using:1.0,3\n",
      "            train score: 0.9702380429209697 with variance: 5.86109741642428e-06\n",
      "            test  score: 0.9697054698457223 with variance: 0.00020331578920910657\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496316\n",
      "          Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313688660656651\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9625821498384021 using:1.0,5\n",
      "            train score: 0.9722451604291044 with variance: 4.9613256826155545e-05\n",
      "            test  score: 0.9625821498384021 with variance: 0.001090315974261396\n",
      "          Refitted train score: 0.971677559912854,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        accuracy\n",
      "          CV score: 0.9632538569424964 using:1.0,5\n",
      "            train score: 0.9724031348421592 with variance: 4.814153081540048e-05\n",
      "            test  score: 0.9632538569424964 with variance: 0.0010426186490521655\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        f1\n",
      "          CV score: 0.9625821498384021 using:1.0,5\n",
      "            train score: 0.9722451604291044 with variance: 4.9613256826155545e-05\n",
      "            test  score: 0.9625821498384021 with variance: 0.001090315974261396\n",
      "          Refitted train score: 0.971677559912854,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        accuracy\n",
      "          CV score: 0.9632538569424964 using:1.0,5\n",
      "            train score: 0.9724031348421592 with variance: 4.814153081540048e-05\n",
      "            test  score: 0.9632538569424964 with variance: 0.0010426186490521655\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        f1\n",
      "          CV score: 0.9625821498384021 using:1.0,5\n",
      "            train score: 0.9722451604291044 with variance: 4.9613256826155545e-05\n",
      "            test  score: 0.9625821498384021 with variance: 0.001090315974261396\n",
      "          Refitted train score: 0.971677559912854,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        accuracy\n",
      "          CV score: 0.9632538569424964 using:1.0,5\n",
      "            train score: 0.9724031348421592 with variance: 4.814153081540048e-05\n",
      "            test  score: 0.9632538569424964 with variance: 0.0010426186490521655\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718789851103684\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.975373049889179 using:1.0,10\n",
      "            train score: 0.9812999857288315 with variance: 1.4014067754511421e-05\n",
      "            test  score: 0.975373049889179 with variance: 0.0004934582320452793\n",
      "          Refitted train score: 0.9802197802197802,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9762505843852267 using:1.0,10\n",
      "            train score: 0.9816011133084304 with variance: 1.2942333354357699e-05\n",
      "            test  score: 0.9762505843852267 with variance: 0.0004333324372213452\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.975373049889179 using:1.0,10\n",
      "            train score: 0.9812999857288315 with variance: 1.4014067754511421e-05\n",
      "            test  score: 0.975373049889179 with variance: 0.0004934582320452793\n",
      "          Refitted train score: 0.9802197802197802,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9762505843852267 using:1.0,10\n",
      "            train score: 0.9816011133084304 with variance: 1.2942333354357699e-05\n",
      "            test  score: 0.9762505843852267 with variance: 0.0004333324372213452\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.975373049889179 using:1.0,10\n",
      "            train score: 0.9812999857288315 with variance: 1.4014067754511421e-05\n",
      "            test  score: 0.975373049889179 with variance: 0.0004934582320452793\n",
      "          Refitted train score: 0.9802197802197802,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9762505843852267 using:1.0,10\n",
      "            train score: 0.9816011133084304 with variance: 1.2942333354357699e-05\n",
      "            test  score: 0.9762505843852267 with variance: 0.0004333324372213452\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728350371247332\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9731264076425367 using:1.0,15\n",
      "            train score: 0.9879657722955049 with variance: 8.086918166390049e-06\n",
      "            test  score: 0.9731264076425367 with variance: 0.0004523686972064828\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.37379628133020315\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9740766713417486 using:1.0,15\n",
      "            train score: 0.9880963890719988 with variance: 7.5875115164253745e-06\n",
      "            test  score: 0.9740766713417486 with variance: 0.0003962366793499304\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.37379628133020315\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        f1\n",
      "          CV score: 0.9731264076425367 using:1.0,15\n",
      "            train score: 0.9879657722955049 with variance: 8.086918166390049e-06\n",
      "            test  score: 0.9731264076425367 with variance: 0.0004523686972064828\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.37379628133020315\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9740766713417486 using:1.0,15\n",
      "            train score: 0.9880963890719988 with variance: 7.5875115164253745e-06\n",
      "            test  score: 0.9740766713417486 with variance: 0.0003962366793499304\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.37379628133020315\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        f1\n",
      "          CV score: 0.9732682683746514 using:1.5,15\n",
      "            train score: 0.988522749564811 with variance: 4.371507451497907e-06\n",
      "            test  score: 0.9732682683746514 with variance: 0.00045277407282796005\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.2990370250641627\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9741000467508181 using:1.5,15\n",
      "            train score: 0.9886369296125392 with variance: 4.093971833037376e-06\n",
      "            test  score: 0.9741000467508181 with variance: 0.00039593178270989107\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.2990370250641627\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,25\n",
      "            train score: 0.9912626882654131 with variance: 1.267537383093412e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,25\n",
      "            train score: 0.9913410971947558 with variance: 1.1894868860102244e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,25\n",
      "            train score: 0.9912626882654131 with variance: 1.267537383093412e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,25\n",
      "            train score: 0.9913410971947558 with variance: 1.1894868860102244e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,25\n",
      "            train score: 0.9912626882654131 with variance: 1.267537383093412e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,25\n",
      "            train score: 0.9913410971947558 with variance: 1.1894868860102244e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,50\n",
      "            train score: 0.993457447673376 with variance: 4.810449113900845e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,50\n",
      "            train score: 0.9935076539954588 with variance: 4.67818548219003e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,50\n",
      "            train score: 0.993457447673376 with variance: 4.810449113900845e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,50\n",
      "            train score: 0.9935076539954588 with variance: 4.67818548219003e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,50\n",
      "            train score: 0.993457447673376 with variance: 4.810449113900845e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,50\n",
      "            train score: 0.9935076539954588 with variance: 4.67818548219003e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,100\n",
      "            train score: 0.9956491799415499 with variance: 1.794918619337425e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,100\n",
      "            train score: 0.9956712810371346 with variance: 1.754722443287246e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,100\n",
      "            train score: 0.9956491799415499 with variance: 1.794918619337425e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,100\n",
      "            train score: 0.9956712810371346 with variance: 1.754722443287246e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9799185044346335 using:1.0,100\n",
      "            train score: 0.9956491799415499 with variance: 1.794918619337425e-06\n",
      "            test  score: 0.9799185044346335 with variance: 0.000180149514044479\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,100\n",
      "            train score: 0.9956712810371346 with variance: 1.754722443287246e-06\n",
      "            test  score: 0.9805516596540439 with variance: 0.0001566480253516632\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.938775528907702 using:1.0,2\n",
      "            train score: 0.9379840429135248 with variance: 6.54275087366067e-05\n",
      "            test  score: 0.938775528907702 with variance: 0.00016975067303569326\n",
      "          Refitted train score: 0.9370932754880694,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9393408134642357 using:1.0,2\n",
      "            train score: 0.9383051344026953 with variance: 6.63282894773163e-05\n",
      "            test  score: 0.9393408134642357 with variance: 0.0001277178147719037\n",
      "          Refitted train score: 0.9372294372294372,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.938775528907702 using:1.0,2\n",
      "            train score: 0.9379840429135248 with variance: 6.54275087366067e-05\n",
      "            test  score: 0.938775528907702 with variance: 0.00016975067303569326\n",
      "          Refitted train score: 0.9370932754880694,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9393408134642357 using:1.0,2\n",
      "            train score: 0.9383051344026953 with variance: 6.63282894773163e-05\n",
      "            test  score: 0.9393408134642357 with variance: 0.0001277178147719037\n",
      "          Refitted train score: 0.9372294372294372,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.938775528907702 using:1.0,2\n",
      "            train score: 0.9379840429135248 with variance: 6.54275087366067e-05\n",
      "            test  score: 0.938775528907702 with variance: 0.00016975067303569326\n",
      "          Refitted train score: 0.9370932754880694,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9393408134642357 using:1.0,2\n",
      "            train score: 0.9383051344026953 with variance: 6.63282894773163e-05\n",
      "            test  score: 0.9393408134642357 with variance: 0.0001277178147719037\n",
      "          Refitted train score: 0.9372294372294372,  RMSE: 0.2505405411716091, Log-Loss:2.168042661940331\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9557589815891001 using:1.0,3\n",
      "            train score: 0.9594808134084628 with variance: 4.884631889851349e-05\n",
      "            test  score: 0.9557589815891001 with variance: 0.0005357020628940501\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18609684207969418, Log-Loss:1.1961550231781213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.956708742402992 using:1.0,3\n",
      "            train score: 0.9599531238555628 with variance: 4.82414039895379e-05\n",
      "            test  score: 0.956708742402992 with variance: 0.00047163138936043986\n",
      "          Refitted train score: 0.9653679653679653,  RMSE: 0.18609684207969418, Log-Loss:1.1961550231781213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9557589815891001 using:1.0,3\n",
      "            train score: 0.9594808134084628 with variance: 4.884631889851349e-05\n",
      "            test  score: 0.9557589815891001 with variance: 0.0005357020628940501\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18609684207969418, Log-Loss:1.1961550231781213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.956708742402992 using:1.0,3\n",
      "            train score: 0.9599531238555628 with variance: 4.82414039895379e-05\n",
      "            test  score: 0.956708742402992 with variance: 0.00047163138936043986\n",
      "          Refitted train score: 0.9653679653679653,  RMSE: 0.18609684207969418, Log-Loss:1.1961550231781213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9557589815891001 using:1.0,3\n",
      "            train score: 0.9594808134084628 with variance: 4.884631889851349e-05\n",
      "            test  score: 0.9557589815891001 with variance: 0.0005357020628940501\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18609684207969418, Log-Loss:1.1961550231781213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.956708742402992 using:1.0,3\n",
      "            train score: 0.9599531238555628 with variance: 4.82414039895379e-05\n",
      "            test  score: 0.956708742402992 with variance: 0.00047163138936043986\n",
      "          Refitted train score: 0.9653679653679653,  RMSE: 0.18609684207969418, Log-Loss:1.1961550231781213\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9650828496831634 using:1.0,5\n",
      "            train score: 0.9691576052408275 with variance: 3.194717728997936e-05\n",
      "            test  score: 0.9650828496831634 with variance: 0.0006016503236807708\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9654511453950445 using:1.0,5\n",
      "            train score: 0.9697004321394566 with variance: 3.0214250994459905e-05\n",
      "            test  score: 0.9654511453950445 with variance: 0.0006201619514783778\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9650828496831634 using:1.0,5\n",
      "            train score: 0.9691576052408275 with variance: 3.194717728997936e-05\n",
      "            test  score: 0.9650828496831634 with variance: 0.0006016503236807708\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9654511453950445 using:1.0,5\n",
      "            train score: 0.9697004321394566 with variance: 3.0214250994459905e-05\n",
      "            test  score: 0.9654511453950445 with variance: 0.0006201619514783778\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9650828496831634 using:1.0,5\n",
      "            train score: 0.9691576052408275 with variance: 3.194717728997936e-05\n",
      "            test  score: 0.9650828496831634 with variance: 0.0006016503236807708\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9654511453950445 using:1.0,5\n",
      "            train score: 0.9697004321394566 with variance: 3.0214250994459905e-05\n",
      "            test  score: 0.9654511453950445 with variance: 0.0006201619514783778\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156723\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9686153990453453 using:1.0,10\n",
      "            train score: 0.9773310454700255 with variance: 1.0558017392782994e-05\n",
      "            test  score: 0.9686153990453453 with variance: 0.0003914537126974883\n",
      "          Refitted train score: 0.9801324503311257,  RMSE: 0.13957263155977062, Log-Loss:0.6728333063943648\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.969728845254792 using:1.0,10\n",
      "            train score: 0.9778158646451329 with variance: 9.855805502969465e-06\n",
      "            test  score: 0.969728845254792 with variance: 0.00034701390350534966\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728333063943648\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9686153990453453 using:1.0,10\n",
      "            train score: 0.9773310454700255 with variance: 1.0558017392782994e-05\n",
      "            test  score: 0.9686153990453453 with variance: 0.0003914537126974883\n",
      "          Refitted train score: 0.9801324503311257,  RMSE: 0.13957263155977062, Log-Loss:0.6728333063943648\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.969728845254792 using:1.0,10\n",
      "            train score: 0.9778158646451329 with variance: 9.855805502969465e-06\n",
      "            test  score: 0.969728845254792 with variance: 0.00034701390350534966\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728333063943648\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9686153990453453 using:1.0,10\n",
      "            train score: 0.9773310454700255 with variance: 1.0558017392782994e-05\n",
      "            test  score: 0.9686153990453453 with variance: 0.0003914537126974883\n",
      "          Refitted train score: 0.9801324503311257,  RMSE: 0.13957263155977062, Log-Loss:0.6728333063943648\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.969728845254792 using:1.0,10\n",
      "            train score: 0.9778158646451329 with variance: 9.855805502969465e-06\n",
      "            test  score: 0.969728845254792 with variance: 0.00034701390350534966\n",
      "          Refitted train score: 0.9805194805194806,  RMSE: 0.13957263155977062, Log-Loss:0.6728333063943648\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9775725357965299 using:1.0,15\n",
      "            train score: 0.9834859354020816 with variance: 9.428145820437268e-06\n",
      "            test  score: 0.9775725357965299 with variance: 0.00025936551742583\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105658 using:1.0,15\n",
      "            train score: 0.9837676701091336 with variance: 8.758041769280388e-06\n",
      "            test  score: 0.9783777466105658 with variance: 0.00023277055314807407\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9775725357965299 using:1.0,15\n",
      "            train score: 0.9834859354020816 with variance: 9.428145820437268e-06\n",
      "            test  score: 0.9775725357965299 with variance: 0.00025936551742583\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105658 using:1.0,15\n",
      "            train score: 0.9837676701091336 with variance: 8.758041769280388e-06\n",
      "            test  score: 0.9783777466105658 with variance: 0.00023277055314807407\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9775725357965299 using:1.0,15\n",
      "            train score: 0.9834859354020816 with variance: 9.428145820437268e-06\n",
      "            test  score: 0.9775725357965299 with variance: 0.00025936551742583\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105658 using:1.0,15\n",
      "            train score: 0.9837676701091336 with variance: 8.758041769280388e-06\n",
      "            test  score: 0.9783777466105658 with variance: 0.00023277055314807407\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9798191780431722 using:1.0,25\n",
      "            train score: 0.990148741745832 with variance: 1.1064009314722893e-05\n",
      "            test  score: 0.9798191780431722 with variance: 0.00028047733357513274\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,25\n",
      "            train score: 0.990258551234161 with variance: 1.0560029189009102e-05\n",
      "            test  score: 0.9805516596540439 with variance: 0.0002511659837637619\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9798191780431722 using:1.0,25\n",
      "            train score: 0.990148741745832 with variance: 1.1064009314722893e-05\n",
      "            test  score: 0.9798191780431722 with variance: 0.00028047733357513274\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:1.0,25\n",
      "            train score: 0.990258551234161 with variance: 1.0560029189009102e-05\n",
      "            test  score: 0.9805516596540439 with variance: 0.0002511659837637619\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.98212124953698 using:1.5,25\n",
      "            train score: 0.9907026754235027 with variance: 8.029001678921947e-06\n",
      "            test  score: 0.98212124953698 with variance: 0.00018314169657587128\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9826788218793828 using:1.5,25\n",
      "            train score: 0.9907990917747016 with variance: 7.65085765755679e-06\n",
      "            test  score: 0.9826788218793828 with variance: 0.00016801771941247378\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9821685141003735 using:1.0,50\n",
      "            train score: 0.9918136607437035 with variance: 3.018881245111284e-06\n",
      "            test  score: 0.9821685141003735 with variance: 0.0001838019133879517\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:1.0,50\n",
      "            train score: 0.9918831026148099 with variance: 2.921956636766094e-06\n",
      "            test  score: 0.9827021972884525 with variance: 0.00016832152323301462\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9821685141003735 using:1.0,50\n",
      "            train score: 0.9918136607437035 with variance: 3.018881245111284e-06\n",
      "            test  score: 0.9821685141003735 with variance: 0.0001838019133879517\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:1.0,50\n",
      "            train score: 0.9918831026148099 with variance: 2.921956636766094e-06\n",
      "            test  score: 0.9827021972884525 with variance: 0.00016832152323301462\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9821685141003735 using:1.0,50\n",
      "            train score: 0.9918136607437035 with variance: 3.018881245111284e-06\n",
      "            test  score: 0.9821685141003735 with variance: 0.0001838019133879517\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:1.0,50\n",
      "            train score: 0.9918831026148099 with variance: 2.921956636766094e-06\n",
      "            test  score: 0.9827021972884525 with variance: 0.00016832152323301462\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9774158342605181 using:1.0,100\n",
      "            train score: 0.996197116988348 with variance: 1.7754266111907995e-06\n",
      "            test  score: 0.9774158342605181 with variance: 0.0004250644713911404\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.978354371201496 using:1.0,100\n",
      "            train score: 0.9962118215776753 with variance: 1.7594734038721166e-06\n",
      "            test  score: 0.978354371201496 with variance: 0.00037707408944640165\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9774158342605181 using:1.0,100\n",
      "            train score: 0.996197116988348 with variance: 1.7754266111907995e-06\n",
      "            test  score: 0.9774158342605181 with variance: 0.0004250644713911404\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.978354371201496 using:1.0,100\n",
      "            train score: 0.9962118215776753 with variance: 1.7594734038721166e-06\n",
      "            test  score: 0.978354371201496 with variance: 0.00037707408944640165\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9774158342605181 using:1.0,100\n",
      "            train score: 0.996197116988348 with variance: 1.7754266111907995e-06\n",
      "            test  score: 0.9774158342605181 with variance: 0.0004250644713911404\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.978354371201496 using:1.0,100\n",
      "            train score: 0.9962118215776753 with variance: 1.7594734038721166e-06\n",
      "            test  score: 0.978354371201496 with variance: 0.00037707408944640165\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.945272416502295 using:1.0,2\n",
      "            train score: 0.9483944510100237 with variance: 9.143603068346128e-06\n",
      "            test  score: 0.945272416502295 with variance: 0.0001692870993512102\n",
      "          Refitted train score: 0.9501084598698483,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9459093034128097 using:1.0,2\n",
      "            train score: 0.9485959129861568 with variance: 8.500494213095515e-06\n",
      "            test  score: 0.9459093034128097 with variance: 0.00013882851061160494\n",
      "          Refitted train score: 0.9502164502164502,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.945272416502295 using:1.0,2\n",
      "            train score: 0.9483944510100237 with variance: 9.143603068346128e-06\n",
      "            test  score: 0.945272416502295 with variance: 0.0001692870993512102\n",
      "          Refitted train score: 0.9501084598698483,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9459093034128097 using:1.0,2\n",
      "            train score: 0.9485959129861568 with variance: 8.500494213095515e-06\n",
      "            test  score: 0.9459093034128097 with variance: 0.00013882851061160494\n",
      "          Refitted train score: 0.9502164502164502,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.945272416502295 using:1.0,2\n",
      "            train score: 0.9483944510100237 with variance: 9.143603068346128e-06\n",
      "            test  score: 0.945272416502295 with variance: 0.0001692870993512102\n",
      "          Refitted train score: 0.9501084598698483,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9459093034128097 using:1.0,2\n",
      "            train score: 0.9485959129861568 with variance: 8.500494213095515e-06\n",
      "            test  score: 0.9459093034128097 with variance: 0.00013882851061160494\n",
      "          Refitted train score: 0.9502164502164502,  RMSE: 0.2231222754086866, Log-Loss:1.719481932152983\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9671165310371622 using:1.0,3\n",
      "            train score: 0.9702989383746103 with variance: 7.1449117041520705e-06\n",
      "            test  score: 0.9671165310371622 with variance: 0.0002347852421853306\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496317\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.967601683029453 using:1.0,3\n",
      "            train score: 0.9707815132205375 with variance: 6.902871058162562e-06\n",
      "            test  score: 0.967601683029453 with variance: 0.00022924839590489845\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496317\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9671165310371622 using:1.0,3\n",
      "            train score: 0.9702989383746103 with variance: 7.1449117041520705e-06\n",
      "            test  score: 0.9671165310371622 with variance: 0.0002347852421853306\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496317\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.967601683029453 using:1.0,3\n",
      "            train score: 0.9707815132205375 with variance: 6.902871058162562e-06\n",
      "            test  score: 0.967601683029453 with variance: 0.00022924839590489845\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496317\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9671165310371622 using:1.0,3\n",
      "            train score: 0.9702989383746103 with variance: 7.1449117041520705e-06\n",
      "            test  score: 0.9671165310371622 with variance: 0.0002347852421853306\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496317\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.967601683029453 using:1.0,3\n",
      "            train score: 0.9707815132205375 with variance: 6.902871058162562e-06\n",
      "            test  score: 0.967601683029453 with variance: 0.00022924839590489845\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718755236496317\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9630463862737022 using:1.0,5\n",
      "            train score: 0.9676077438407227 with variance: 2.1898985213701243e-05\n",
      "            test  score: 0.9630463862737022 with variance: 0.00038926981822124925\n",
      "          Refitted train score: 0.967032967032967,  RMSE: 0.1801874925391118, Log-Loss:1.1213957669120809\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9633006077606359 using:1.0,5\n",
      "            train score: 0.968078810517835 with variance: 2.135370950372719e-05\n",
      "            test  score: 0.9633006077606359 with variance: 0.00039453515939100214\n",
      "          Refitted train score: 0.9675324675324676,  RMSE: 0.1801874925391118, Log-Loss:1.1213957669120809\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9630463862737022 using:1.0,5\n",
      "            train score: 0.9676077438407227 with variance: 2.1898985213701243e-05\n",
      "            test  score: 0.9630463862737022 with variance: 0.00038926981822124925\n",
      "          Refitted train score: 0.967032967032967,  RMSE: 0.1801874925391118, Log-Loss:1.1213957669120809\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9633006077606359 using:1.0,5\n",
      "            train score: 0.968078810517835 with variance: 2.135370950372719e-05\n",
      "            test  score: 0.9633006077606359 with variance: 0.00039453515939100214\n",
      "          Refitted train score: 0.9675324675324676,  RMSE: 0.1801874925391118, Log-Loss:1.1213957669120809\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9630463862737022 using:1.0,5\n",
      "            train score: 0.9676077438407227 with variance: 2.1898985213701243e-05\n",
      "            test  score: 0.9630463862737022 with variance: 0.00038926981822124925\n",
      "          Refitted train score: 0.967032967032967,  RMSE: 0.1801874925391118, Log-Loss:1.1213957669120809\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9633006077606359 using:1.0,5\n",
      "            train score: 0.968078810517835 with variance: 2.135370950372719e-05\n",
      "            test  score: 0.9633006077606359 with variance: 0.00039453515939100214\n",
      "          Refitted train score: 0.9675324675324676,  RMSE: 0.1801874925391118, Log-Loss:1.1213957669120809\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9604660854614602 using:1.0,10\n",
      "            train score: 0.9739884618026144 with variance: 2.0208927271342298e-05\n",
      "            test  score: 0.9604660854614602 with variance: 0.00026064005284776417\n",
      "          Refitted train score: 0.9734513274336283,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9611033193080878 using:1.0,10\n",
      "            train score: 0.9745667618838351 with variance: 1.9336036198585862e-05\n",
      "            test  score: 0.9611033193080878 with variance: 0.0002566071320460364\n",
      "          Refitted train score: 0.974025974025974,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9604660854614602 using:1.0,10\n",
      "            train score: 0.9739884618026144 with variance: 2.0208927271342298e-05\n",
      "            test  score: 0.9604660854614602 with variance: 0.00026064005284776417\n",
      "          Refitted train score: 0.9734513274336283,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9611033193080878 using:1.0,10\n",
      "            train score: 0.9745667618838351 with variance: 1.9336036198585862e-05\n",
      "            test  score: 0.9611033193080878 with variance: 0.0002566071320460364\n",
      "          Refitted train score: 0.974025974025974,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9627515174883596 using:1.5,10\n",
      "            train score: 0.974554562368715 with variance: 1.6631974454256615e-05\n",
      "            test  score: 0.9627515174883596 with variance: 0.0003064992287596101\n",
      "          Refitted train score: 0.9734513274336283,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9632772323515661 using:1.5,10\n",
      "            train score: 0.9751087673038892 with variance: 1.5766335226544956e-05\n",
      "            test  score: 0.9632772323515661 with variance: 0.00030386064715459194\n",
      "          Refitted train score: 0.974025974025974,  RMSE: 0.16116459280507606, Log-Loss:0.8971128059228545\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9776218895906243 using:1.0,15\n",
      "            train score: 0.9840672568034965 with variance: 1.3457959683405889e-05\n",
      "            test  score: 0.9776218895906243 with variance: 0.0002583569807611655\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105656 using:1.0,15\n",
      "            train score: 0.9843067457701604 with variance: 1.2875566693274957e-05\n",
      "            test  score: 0.9783777466105656 with variance: 0.00023479226922001702\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9776218895906243 using:1.0,15\n",
      "            train score: 0.9840672568034965 with variance: 1.3457959683405889e-05\n",
      "            test  score: 0.9776218895906243 with variance: 0.0002583569807611655\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105656 using:1.0,15\n",
      "            train score: 0.9843067457701604 with variance: 1.2875566693274957e-05\n",
      "            test  score: 0.9783777466105656 with variance: 0.00023479226922001702\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9821163066324357 using:1.5,15\n",
      "            train score: 0.985175149038333 with variance: 2.0198969133177618e-05\n",
      "            test  score: 0.9821163066324357 with variance: 0.00023943781721792916\n",
      "          Refitted train score: 0.9846153846153847,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9826788218793828 using:1.5,15\n",
      "            train score: 0.9853892917307551 with variance: 1.9297213082551012e-05\n",
      "            test  score: 0.9826788218793828 with variance: 0.00021729841469046604\n",
      "          Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.523314793862284\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9753747335987277 using:1.0,25\n",
      "            train score: 0.9890529909790109 with variance: 6.103893663245563e-06\n",
      "            test  score: 0.9753747335987277 with variance: 0.00018010459519345374\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302031\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9761804581580178 using:1.0,25\n",
      "            train score: 0.9891789350325937 with variance: 5.8200898027040475e-06\n",
      "            test  score: 0.9761804581580178 with variance: 0.00016008931395196046\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302031\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9753747335987277 using:1.0,25\n",
      "            train score: 0.9890529909790109 with variance: 6.103893663245563e-06\n",
      "            test  score: 0.9753747335987277 with variance: 0.00018010459519345374\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302031\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9761804581580178 using:1.0,25\n",
      "            train score: 0.9891789350325937 with variance: 5.8200898027040475e-06\n",
      "            test  score: 0.9761804581580178 with variance: 0.00016008931395196046\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302031\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9753747335987277 using:1.0,25\n",
      "            train score: 0.9890529909790109 with variance: 6.103893663245563e-06\n",
      "            test  score: 0.9753747335987277 with variance: 0.00018010459519345374\n",
      "          Refitted train score: 0.9890590809628008,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302031\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9761804581580178 using:1.0,25\n",
      "            train score: 0.9891789350325937 with variance: 5.8200898027040475e-06\n",
      "            test  score: 0.9761804581580178 with variance: 0.00016008931395196046\n",
      "          Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302031\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9778233960473903 using:1.0,50\n",
      "            train score: 0.9912627457781727 with variance: 4.219741001296655e-06\n",
      "            test  score: 0.9778233960473903 with variance: 0.00020193140595992044\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105656 using:1.0,50\n",
      "            train score: 0.991344026953783 with variance: 4.066908095505349e-06\n",
      "            test  score: 0.9783777466105656 with variance: 0.0001855115739420245\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9778233960473903 using:1.0,50\n",
      "            train score: 0.9912627457781727 with variance: 4.219741001296655e-06\n",
      "            test  score: 0.9778233960473903 with variance: 0.00020193140595992044\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105656 using:1.0,50\n",
      "            train score: 0.991344026953783 with variance: 4.066908095505349e-06\n",
      "            test  score: 0.9783777466105656 with variance: 0.0001855115739420245\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9778233960473903 using:1.0,50\n",
      "            train score: 0.9912627457781727 with variance: 4.219741001296655e-06\n",
      "            test  score: 0.9778233960473903 with variance: 0.00020193140595992044\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105656 using:1.0,50\n",
      "            train score: 0.991344026953783 with variance: 4.066908095505349e-06\n",
      "            test  score: 0.9783777466105656 with variance: 0.0001855115739420245\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9732699520842003 using:1.0,100\n",
      "            train score: 0.9945563079774079 with variance: 2.986041893456708e-06\n",
      "            test  score: 0.9732699520842003 with variance: 0.00013942752365760298\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812225\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9740532959326789 using:1.0,100\n",
      "            train score: 0.9945901999560537 with variance: 2.9139568259890397e-06\n",
      "            test  score: 0.9740532959326789 with variance: 0.00012006261418597692\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812225\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9732699520842003 using:1.0,100\n",
      "            train score: 0.9945563079774079 with variance: 2.986041893456708e-06\n",
      "            test  score: 0.9732699520842003 with variance: 0.00013942752365760298\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812225\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9740532959326789 using:1.0,100\n",
      "            train score: 0.9945901999560537 with variance: 2.9139568259890397e-06\n",
      "            test  score: 0.9740532959326789 with variance: 0.00012006261418597692\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812225\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9732699520842003 using:1.0,100\n",
      "            train score: 0.9945563079774079 with variance: 2.986041893456708e-06\n",
      "            test  score: 0.9732699520842003 with variance: 0.00013942752365760298\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812225\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9740532959326789 using:1.0,100\n",
      "            train score: 0.9945901999560537 with variance: 2.9139568259890397e-06\n",
      "            test  score: 0.9740532959326789 with variance: 0.00012006261418597692\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.22427776879812225\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9507762995414565 using:1.0,2\n",
      "            train score: 0.9526951719326661 with variance: 2.1964049672927774e-05\n",
      "            test  score: 0.9507762995414565 with variance: 0.0003390648257262866\n",
      "          Refitted train score: 0.953229398663697,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9515995115995116 using:1.0,2\n",
      "            train score: 0.9531968031968032 with variance: 2.093571094817802e-05\n",
      "            test  score: 0.9515995115995116 with variance: 0.0003162354400449632\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9507762995414565 using:1.0,2\n",
      "            train score: 0.9526951719326661 with variance: 2.1964049672927774e-05\n",
      "            test  score: 0.9507762995414565 with variance: 0.0003390648257262866\n",
      "          Refitted train score: 0.953229398663697,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9515995115995116 using:1.0,2\n",
      "            train score: 0.9531968031968032 with variance: 2.093571094817802e-05\n",
      "            test  score: 0.9515995115995116 with variance: 0.0003162354400449632\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9507762995414565 using:1.0,2\n",
      "            train score: 0.9526951719326661 with variance: 2.1964049672927774e-05\n",
      "            test  score: 0.9507762995414565 with variance: 0.0003390648257262866\n",
      "          Refitted train score: 0.953229398663697,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9515995115995116 using:1.0,2\n",
      "            train score: 0.9531968031968032 with variance: 2.093571094817802e-05\n",
      "            test  score: 0.9515995115995116 with variance: 0.0003162354400449632\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976226895871504\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9558859259463002 using:1.0,3\n",
      "            train score: 0.9649363540994516 with variance: 1.4587100838627285e-05\n",
      "            test  score: 0.9558859259463002 with variance: 0.000293558548011306\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597409\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.955995115995116 using:1.0,3\n",
      "            train score: 0.9653119607665062 with variance: 1.366566693801439e-05\n",
      "            test  score: 0.955995115995116 with variance: 0.00033598614111434534\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597409\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9558859259463002 using:1.0,3\n",
      "            train score: 0.9649363540994516 with variance: 1.4587100838627285e-05\n",
      "            test  score: 0.9558859259463002 with variance: 0.000293558548011306\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597409\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.955995115995116 using:1.0,3\n",
      "            train score: 0.9653119607665062 with variance: 1.366566693801439e-05\n",
      "            test  score: 0.955995115995116 with variance: 0.00033598614111434534\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597409\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9558859259463002 using:1.0,3\n",
      "            train score: 0.9649363540994516 with variance: 1.4587100838627285e-05\n",
      "            test  score: 0.9558859259463002 with variance: 0.000293558548011306\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597409\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.955995115995116 using:1.0,3\n",
      "            train score: 0.9653119607665062 with variance: 1.366566693801439e-05\n",
      "            test  score: 0.955995115995116 with variance: 0.00033598614111434534\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597409\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9603803079687723 using:1.0,5\n",
      "            train score: 0.9643666886168711 with variance: 1.9728184011225048e-05\n",
      "            test  score: 0.9603803079687723 with variance: 0.000467895383338085\n",
      "          Refitted train score: 0.9621380846325166,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604151404151405 using:1.0,5\n",
      "            train score: 0.9647609965791784 with variance: 1.9154793388823775e-05\n",
      "            test  score: 0.9604151404151405 with variance: 0.0005106224124539135\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9603803079687723 using:1.0,5\n",
      "            train score: 0.9643666886168711 with variance: 1.9728184011225048e-05\n",
      "            test  score: 0.9603803079687723 with variance: 0.000467895383338085\n",
      "          Refitted train score: 0.9621380846325166,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604151404151405 using:1.0,5\n",
      "            train score: 0.9647609965791784 with variance: 1.9154793388823775e-05\n",
      "            test  score: 0.9604151404151405 with variance: 0.0005106224124539135\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9603803079687723 using:1.0,5\n",
      "            train score: 0.9643666886168711 with variance: 1.9728184011225048e-05\n",
      "            test  score: 0.9603803079687723 with variance: 0.000467895383338085\n",
      "          Refitted train score: 0.9621380846325166,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604151404151405 using:1.0,5\n",
      "            train score: 0.9647609965791784 with variance: 1.9154793388823775e-05\n",
      "            test  score: 0.9604151404151405 with variance: 0.0005106224124539135\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9707118429249805 using:1.0,10\n",
      "            train score: 0.9770335905530096 with variance: 1.0577633550307027e-05\n",
      "            test  score: 0.9707118429249805 with variance: 0.00013878586369869456\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:1.0,10\n",
      "            train score: 0.977425604698332 with variance: 1.017189580692206e-05\n",
      "            test  score: 0.9714041514041515 with variance: 0.0001247323562341876\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9707118429249805 using:1.0,10\n",
      "            train score: 0.9770335905530096 with variance: 1.0577633550307027e-05\n",
      "            test  score: 0.9707118429249805 with variance: 0.00013878586369869456\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:1.0,10\n",
      "            train score: 0.977425604698332 with variance: 1.017189580692206e-05\n",
      "            test  score: 0.9714041514041515 with variance: 0.0001247323562341876\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9707118429249805 using:1.0,10\n",
      "            train score: 0.9770335905530096 with variance: 1.0577633550307027e-05\n",
      "            test  score: 0.9707118429249805 with variance: 0.00013878586369869456\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:1.0,10\n",
      "            train score: 0.977425604698332 with variance: 1.017189580692206e-05\n",
      "            test  score: 0.9714041514041515 with variance: 0.0001247323562341876\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9704457563783124 using:1.0,15\n",
      "            train score: 0.9849577508190273 with variance: 1.459218782868621e-05\n",
      "            test  score: 0.9704457563783124 with variance: 0.00026492606891075955\n",
      "          Refitted train score: 0.9821428571428572,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,15\n",
      "            train score: 0.9851345624072897 with variance: 1.387087614909386e-05\n",
      "            test  score: 0.9714041514041514 with variance: 0.0002213390462474715\n",
      "          Refitted train score: 0.9823788546255506,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9704457563783124 using:1.0,15\n",
      "            train score: 0.9849577508190273 with variance: 1.459218782868621e-05\n",
      "            test  score: 0.9704457563783124 with variance: 0.00026492606891075955\n",
      "          Refitted train score: 0.9821428571428572,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,15\n",
      "            train score: 0.9851345624072897 with variance: 1.387087614909386e-05\n",
      "            test  score: 0.9714041514041514 with variance: 0.0002213390462474715\n",
      "          Refitted train score: 0.9823788546255506,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9704457563783124 using:1.0,15\n",
      "            train score: 0.9849577508190273 with variance: 1.459218782868621e-05\n",
      "            test  score: 0.9704457563783124 with variance: 0.00026492606891075955\n",
      "          Refitted train score: 0.9821428571428572,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,15\n",
      "            train score: 0.9851345624072897 with variance: 1.387087614909386e-05\n",
      "            test  score: 0.9714041514041514 with variance: 0.0002213390462474715\n",
      "          Refitted train score: 0.9823788546255506,  RMSE: 0.1327446623199944, Log-Loss:0.6086145611381412\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9657284542206614 using:1.0,25\n",
      "            train score: 0.9894426831624559 with variance: 4.470224770798966e-06\n",
      "            test  score: 0.9657284542206614 with variance: 0.0004097850155983131\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.967008547008547 using:1.0,25\n",
      "            train score: 0.9895392486301577 with variance: 4.200052994234004e-06\n",
      "            test  score: 0.967008547008547 with variance: 0.00033705239273004847\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9657284542206614 using:1.0,25\n",
      "            train score: 0.9894426831624559 with variance: 4.470224770798966e-06\n",
      "            test  score: 0.9657284542206614 with variance: 0.0004097850155983131\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.967008547008547 using:1.0,25\n",
      "            train score: 0.9895392486301577 with variance: 4.200052994234004e-06\n",
      "            test  score: 0.967008547008547 with variance: 0.00033705239273004847\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9657284542206614 using:1.0,25\n",
      "            train score: 0.9894426831624559 with variance: 4.470224770798966e-06\n",
      "            test  score: 0.9657284542206614 with variance: 0.0004097850155983131\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.967008547008547 using:1.0,25\n",
      "            train score: 0.9895392486301577 with variance: 4.200052994234004e-06\n",
      "            test  score: 0.967008547008547 with variance: 0.00033705239273004847\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9753648077934738 using:1.0,50\n",
      "            train score: 0.9905538964468606 with variance: 5.0387219159646525e-06\n",
      "            test  score: 0.9753648077934738 with variance: 0.00016958579859946361\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,50\n",
      "            train score: 0.9906396633669361 with variance: 4.83711615554986e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00016423137302258172\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9753648077934738 using:1.0,50\n",
      "            train score: 0.9905538964468606 with variance: 5.0387219159646525e-06\n",
      "            test  score: 0.9753648077934738 with variance: 0.00016958579859946361\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,50\n",
      "            train score: 0.9906396633669361 with variance: 4.83711615554986e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00016423137302258172\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9776619363827374 using:1.5,50\n",
      "            train score: 0.9916743016119739 with variance: 6.241473991064282e-06\n",
      "            test  score: 0.9776619363827374 with variance: 0.00014901080473775325\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9780219780219781 using:1.5,50\n",
      "            train score: 0.9917415917415919 with variance: 6.038018934213728e-06\n",
      "            test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9729590339362165 using:1.0,100\n",
      "            train score: 0.9933455850838113 with variance: 1.8796619299333876e-06\n",
      "            test  score: 0.9729590339362165 with variance: 0.0002401188256821179\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637116\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,100\n",
      "            train score: 0.9933929706656979 with variance: 1.8064404091600394e-06\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637116\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9729590339362165 using:1.0,100\n",
      "            train score: 0.9933455850838113 with variance: 1.8796619299333876e-06\n",
      "            test  score: 0.9729590339362165 with variance: 0.0002401188256821179\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637116\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,100\n",
      "            train score: 0.9933929706656979 with variance: 1.8064404091600394e-06\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637116\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9752561625254799 using:1.5,100\n",
      "            train score: 0.997790046816483 with variance: 4.273406439392184e-06\n",
      "            test  score: 0.9752561625254799 with variance: 0.0002305965756340247\n",
      "          Refitted train score: 0.9977924944812362,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.5,100\n",
      "            train score: 0.997797656888566 with variance: 4.248202743921832e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00021253471802922308\n",
      "          Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9466468314294401 using:1.0,2\n",
      "            train score: 0.9456783374164054 with variance: 1.694665642343136e-05\n",
      "            test  score: 0.9466468314294401 with variance: 0.0001682331009147859\n",
      "          Refitted train score: 0.9466666666666668,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9471794871794872 using:1.0,2\n",
      "            train score: 0.9460372960372959 with variance: 1.6758303182622672e-05\n",
      "            test  score: 0.9471794871794872 with variance: 0.00016135464047551973\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9466468314294401 using:1.0,2\n",
      "            train score: 0.9456783374164054 with variance: 1.694665642343136e-05\n",
      "            test  score: 0.9466468314294401 with variance: 0.0001682331009147859\n",
      "          Refitted train score: 0.9466666666666668,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9471794871794872 using:1.0,2\n",
      "            train score: 0.9460372960372959 with variance: 1.6758303182622672e-05\n",
      "            test  score: 0.9471794871794872 with variance: 0.00016135464047551973\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9489376215182667 using:1.5,2\n",
      "            train score: 0.9456783374164054 with variance: 1.694665642343136e-05\n",
      "            test  score: 0.9489376215182667 with variance: 0.00013486709013866595\n",
      "          Refitted train score: 0.9466666666666668,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9493772893772894 using:1.5,2\n",
      "            train score: 0.9460372960372959 with variance: 1.6758303182622672e-05\n",
      "            test  score: 0.9493772893772894 with variance: 0.0001230339867702507\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.82585601200916\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9664907501986153 using:1.0,3\n",
      "            train score: 0.9658603199033674 with variance: 3.618741401599311e-05\n",
      "            test  score: 0.9664907501986153 with variance: 0.0004916306150004074\n",
      "          Refitted train score: 0.96875,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543408\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9670329670329672 using:1.0,3\n",
      "            train score: 0.9664154027790393 with variance: 3.410131331796447e-05\n",
      "            test  score: 0.9670329670329672 with variance: 0.0004830334500664166\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543408\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9664907501986153 using:1.0,3\n",
      "            train score: 0.9658603199033674 with variance: 3.618741401599311e-05\n",
      "            test  score: 0.9664907501986153 with variance: 0.0004916306150004074\n",
      "          Refitted train score: 0.96875,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543408\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9670329670329672 using:1.0,3\n",
      "            train score: 0.9664154027790393 with variance: 3.410131331796447e-05\n",
      "            test  score: 0.9670329670329672 with variance: 0.0004830334500664166\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543408\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9688350725429377 using:1.5,3\n",
      "            train score: 0.9664362806247346 with variance: 4.4483222680594634e-05\n",
      "            test  score: 0.9688350725429377 with variance: 0.00035815065754217984\n",
      "          Refitted train score: 0.96875,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543408\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:1.5,3\n",
      "            train score: 0.9669663669663671 with variance: 4.1967226518212526e-05\n",
      "            test  score: 0.9692307692307693 with variance: 0.00035744475304914854\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543408\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9664907501986153 using:1.0,5\n",
      "            train score: 0.9670216833251406 with variance: 3.253012443083969e-05\n",
      "            test  score: 0.9664907501986153 with variance: 0.0004916306150004074\n",
      "          Refitted train score: 0.9664429530201342,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9670329670329672 using:1.0,5\n",
      "            train score: 0.9675158175158176 with variance: 3.117216077809191e-05\n",
      "            test  score: 0.9670329670329672 with variance: 0.0004830334500664166\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9664907501986153 using:1.0,5\n",
      "            train score: 0.9670216833251406 with variance: 3.253012443083969e-05\n",
      "            test  score: 0.9664907501986153 with variance: 0.0004916306150004074\n",
      "          Refitted train score: 0.9664429530201342,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9670329670329672 using:1.0,5\n",
      "            train score: 0.9675158175158176 with variance: 3.117216077809191e-05\n",
      "            test  score: 0.9670329670329672 with variance: 0.0004830334500664166\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        f1\n",
      "          CV score: 0.9664907501986153 using:1.0,5\n",
      "            train score: 0.9670216833251406 with variance: 3.253012443083969e-05\n",
      "            test  score: 0.9664907501986153 with variance: 0.0004916306150004074\n",
      "          Refitted train score: 0.9664429530201342,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9670329670329672 using:1.0,5\n",
      "            train score: 0.9675158175158176 with variance: 3.117216077809191e-05\n",
      "            test  score: 0.9670329670329672 with variance: 0.0004830334500664166\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411560447431308\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9683228582235637 using:1.0,10\n",
      "            train score: 0.9774993731080401 with variance: 1.284619679189091e-05\n",
      "            test  score: 0.9683228582235637 with variance: 0.0003811292627632821\n",
      "          Refitted train score: 0.9774774774774774,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:1.0,10\n",
      "            train score: 0.9779765688856598 with variance: 1.1976585815969722e-05\n",
      "            test  score: 0.9692307692307693 with variance: 0.00035744475304914854\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9683228582235637 using:1.0,10\n",
      "            train score: 0.9774993731080401 with variance: 1.284619679189091e-05\n",
      "            test  score: 0.9683228582235637 with variance: 0.0003811292627632821\n",
      "          Refitted train score: 0.9774774774774774,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:1.0,10\n",
      "            train score: 0.9779765688856598 with variance: 1.1976585815969722e-05\n",
      "            test  score: 0.9692307692307693 with variance: 0.00035744475304914854\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9683228582235637 using:1.0,10\n",
      "            train score: 0.9774993731080401 with variance: 1.284619679189091e-05\n",
      "            test  score: 0.9683228582235637 with variance: 0.0003811292627632821\n",
      "          Refitted train score: 0.9774774774774774,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9692307692307693 using:1.0,10\n",
      "            train score: 0.9779765688856598 with variance: 1.1976585815969722e-05\n",
      "            test  score: 0.9692307692307693 with variance: 0.00035744475304914854\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9774259448416751 using:1.0,15\n",
      "            train score: 0.9854871966682441 with variance: 1.6940001234994617e-05\n",
      "            test  score: 0.9774259448416751 with variance: 0.00015151167364501383\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9780219780219781 using:1.0,15\n",
      "            train score: 0.9856855265946175 with variance: 1.628769299115487e-05\n",
      "            test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9774259448416751 using:1.0,15\n",
      "            train score: 0.9854871966682441 with variance: 1.6940001234994617e-05\n",
      "            test  score: 0.9774259448416751 with variance: 0.00015151167364501383\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9780219780219781 using:1.0,15\n",
      "            train score: 0.9856855265946175 with variance: 1.628769299115487e-05\n",
      "            test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        f1\n",
      "          CV score: 0.9797242083758937 using:1.5,15\n",
      "            train score: 0.9854871966682441 with variance: 1.6940001234994617e-05\n",
      "            test  score: 0.9797242083758937 with variance: 0.00017193546603286037\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:1.5,15\n",
      "            train score: 0.9856855265946175 with variance: 1.628769299115487e-05\n",
      "            test  score: 0.9802197802197803 with variance: 0.0001642313730225819\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327412\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9705781957506096 using:1.0,25\n",
      "            train score: 0.9882945591675615 with variance: 1.378836209518149e-05\n",
      "            test  score: 0.9705781957506096 with variance: 0.00028376021714399493\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:1.0,25\n",
      "            train score: 0.9884373202555021 with variance: 1.3323578271027498e-05\n",
      "            test  score: 0.9714285714285715 with variance: 0.00027049873203719295\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9705781957506096 using:1.0,25\n",
      "            train score: 0.9882945591675615 with variance: 1.378836209518149e-05\n",
      "            test  score: 0.9705781957506096 with variance: 0.00028376021714399493\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:1.0,25\n",
      "            train score: 0.9884373202555021 with variance: 1.3323578271027498e-05\n",
      "            test  score: 0.9714285714285715 with variance: 0.00027049873203719295\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9728764592848282 using:1.5,25\n",
      "            train score: 0.9899876199319098 with variance: 8.069651006417165e-06\n",
      "            test  score: 0.9728764592848282 with variance: 0.00033565987358679045\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.5,25\n",
      "            train score: 0.9900886991796082 with variance: 7.879403194831709e-06\n",
      "            test  score: 0.9736263736263737 with variance: 0.0003188020770438349\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9727255116057906 using:1.0,50\n",
      "            train score: 0.9894211799449814 with variance: 1.3788515788189292e-05\n",
      "            test  score: 0.9727255116057906 with variance: 0.000237687371716605\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,50\n",
      "            train score: 0.9895377349922804 with variance: 1.3350182519855814e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9727255116057906 using:1.0,50\n",
      "            train score: 0.9894211799449814 with variance: 1.3788515788189292e-05\n",
      "            test  score: 0.9727255116057906 with variance: 0.000237687371716605\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,50\n",
      "            train score: 0.9895377349922804 with variance: 1.3350182519855814e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.972929292929293 using:1.5,50\n",
      "            train score: 0.990547792292636 with variance: 8.093865776959594e-06\n",
      "            test  score: 0.972929292929293 with variance: 0.00028207325783083305\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,50\n",
      "            train score: 0.9895377349922804 with variance: 1.3350182519855814e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9752786289864941 using:1.0,100\n",
      "            train score: 0.996124927517009 with variance: 4.900964347076177e-06\n",
      "            test  score: 0.9752786289864941 with variance: 0.000217771148699673\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,100\n",
      "            train score: 0.9961462779644599 with variance: 4.847013705923293e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00021253471802922308\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9752786289864941 using:1.0,100\n",
      "            train score: 0.996124927517009 with variance: 4.900964347076177e-06\n",
      "            test  score: 0.9752786289864941 with variance: 0.000217771148699673\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,100\n",
      "            train score: 0.9961462779644599 with variance: 4.847013705923293e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00021253471802922308\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        f1\n",
      "          CV score: 0.9752786289864941 using:1.0,100\n",
      "            train score: 0.996124927517009 with variance: 4.900964347076177e-06\n",
      "            test  score: 0.9752786289864941 with variance: 0.000217771148699673\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,100\n",
      "            train score: 0.9961462779644599 with variance: 4.847013705923293e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00021253471802922308\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9463372203740855 using:1.0,2\n",
      "            train score: 0.9460198081089446 with variance: 3.3017576458942524e-05\n",
      "            test  score: 0.9463372203740855 with variance: 0.00028230434997592903\n",
      "          Refitted train score: 0.9443207126948775,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9471550671550671 using:1.0,2\n",
      "            train score: 0.9465852329488694 with variance: 3.224421211392907e-05\n",
      "            test  score: 0.9471550671550671 with variance: 0.0002591587763748934\n",
      "          Refitted train score: 0.9449339207048458,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9463372203740855 using:1.0,2\n",
      "            train score: 0.9460198081089446 with variance: 3.3017576458942524e-05\n",
      "            test  score: 0.9463372203740855 with variance: 0.00028230434997592903\n",
      "          Refitted train score: 0.9443207126948775,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9471550671550671 using:1.0,2\n",
      "            train score: 0.9465852329488694 with variance: 3.224421211392907e-05\n",
      "            test  score: 0.9471550671550671 with variance: 0.0002591587763748934\n",
      "          Refitted train score: 0.9449339207048458,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9463372203740855 using:1.0,2\n",
      "            train score: 0.9460198081089446 with variance: 3.3017576458942524e-05\n",
      "            test  score: 0.9463372203740855 with variance: 0.00028230434997592903\n",
      "          Refitted train score: 0.9443207126948775,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9471550671550671 using:1.0,2\n",
      "            train score: 0.9465852329488694 with variance: 3.224421211392907e-05\n",
      "            test  score: 0.9471550671550671 with variance: 0.0002591587763748934\n",
      "          Refitted train score: 0.9449339207048458,  RMSE: 0.23466162723196604, Log-Loss:1.9019326119979503\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9619327342490408 using:1.0,3\n",
      "            train score: 0.9647775001449117 with variance: 1.7860885890083962e-05\n",
      "            test  score: 0.9619327342490408 with variance: 0.0002845281493795597\n",
      "          Refitted train score: 0.96875,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543406\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129426 using:1.0,3\n",
      "            train score: 0.9653104471286289 with variance: 1.683778601076184e-05\n",
      "            test  score: 0.9626129426129426 with variance: 0.000269213028187388\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543406\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9619327342490408 using:1.0,3\n",
      "            train score: 0.9647775001449117 with variance: 1.7860885890083962e-05\n",
      "            test  score: 0.9619327342490408 with variance: 0.0002845281493795597\n",
      "          Refitted train score: 0.96875,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543406\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129426 using:1.0,3\n",
      "            train score: 0.9653104471286289 with variance: 1.683778601076184e-05\n",
      "            test  score: 0.9626129426129426 with variance: 0.000269213028187388\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543406\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9622207750216851 using:1.5,3\n",
      "            train score: 0.9653998406348236 with variance: 1.4324682343115038e-05\n",
      "            test  score: 0.9622207750216851 with variance: 0.00022424160536489262\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9626129426129426 using:1.0,3\n",
      "            train score: 0.9653104471286289 with variance: 1.683778601076184e-05\n",
      "            test  score: 0.9626129426129426 with variance: 0.000269213028187388\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650794447543406\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9643312434411268 using:1.0,5\n",
      "            train score: 0.9653597014562628 with variance: 1.455021724530888e-05\n",
      "            test  score: 0.9643312434411268 with variance: 0.00021747158746801996\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107448 using:1.0,5\n",
      "            train score: 0.9658614113159567 with variance: 1.3778819766220737e-05\n",
      "            test  score: 0.9648107448107448 with variance: 0.000211356354946099\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9643312434411268 using:1.0,5\n",
      "            train score: 0.9653597014562628 with variance: 1.455021724530888e-05\n",
      "            test  score: 0.9643312434411268 with variance: 0.00021747158746801996\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107448 using:1.0,5\n",
      "            train score: 0.9658614113159567 with variance: 1.3778819766220737e-05\n",
      "            test  score: 0.9648107448107448 with variance: 0.000211356354946099\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9643312434411268 using:1.0,5\n",
      "            train score: 0.9653597014562628 with variance: 1.455021724530888e-05\n",
      "            test  score: 0.9643312434411268 with variance: 0.00021747158746801996\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107448 using:1.0,5\n",
      "            train score: 0.9658614113159567 with variance: 1.3778819766220737e-05\n",
      "            test  score: 0.9648107448107448 with variance: 0.000211356354946099\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9589678215091423 using:1.0,10\n",
      "            train score: 0.9713105541444446 with variance: 4.3692809379114215e-05\n",
      "            test  score: 0.9589678215091423 with variance: 0.0005867565931969236\n",
      "          Refitted train score: 0.9706546275395034,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604395604395604 using:1.0,10\n",
      "            train score: 0.9719220173765628 with variance: 4.0235375148395953e-05\n",
      "            test  score: 0.9604395604395604 with variance: 0.000512015457070402\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9589678215091423 using:1.0,10\n",
      "            train score: 0.9713105541444446 with variance: 4.3692809379114215e-05\n",
      "            test  score: 0.9589678215091423 with variance: 0.0005867565931969236\n",
      "          Refitted train score: 0.9706546275395034,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604395604395604 using:1.0,10\n",
      "            train score: 0.9719220173765628 with variance: 4.0235375148395953e-05\n",
      "            test  score: 0.9604395604395604 with variance: 0.000512015457070402\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9589678215091423 using:1.0,10\n",
      "            train score: 0.9713105541444446 with variance: 4.3692809379114215e-05\n",
      "            test  score: 0.9589678215091423 with variance: 0.0005867565931969236\n",
      "          Refitted train score: 0.9706546275395034,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604395604395604 using:1.0,10\n",
      "            train score: 0.9719220173765628 with variance: 4.0235375148395953e-05\n",
      "            test  score: 0.9604395604395604 with variance: 0.000512015457070402\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9725475336023004 using:1.0,15\n",
      "            train score: 0.9871610710521207 with variance: 1.5039367080236558e-05\n",
      "            test  score: 0.9725475336023004 with variance: 0.0004177324646262785\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.45645959993274127\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,15\n",
      "            train score: 0.9873353918808464 with variance: 1.394738054772231e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.0003671054220504775\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.45645959993274127\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9725475336023004 using:1.0,15\n",
      "            train score: 0.9871610710521207 with variance: 1.5039367080236558e-05\n",
      "            test  score: 0.9725475336023004 with variance: 0.0004177324646262785\n",
      "          Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.45645959993274127\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,15\n",
      "            train score: 0.9873353918808464 with variance: 1.394738054772231e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.0003671054220504775\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.45645959993274127\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.975009913903258 using:1.5,15\n",
      "            train score: 0.9877339465070978 with variance: 8.47005528888226e-06\n",
      "            test  score: 0.975009913903258 with variance: 0.0002874907564405879\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.5,15\n",
      "            train score: 0.9878863560681742 with variance: 7.867810230736474e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00026083806303586505\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9727632716566157 using:1.0,25\n",
      "            train score: 0.989418016338736 with variance: 7.549297046765105e-06\n",
      "            test  score: 0.9727632716566157 with variance: 0.000244769548307299\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,25\n",
      "            train score: 0.9895392486301577 with variance: 7.235668351412157e-06\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9727632716566157 using:1.0,25\n",
      "            train score: 0.989418016338736 with variance: 7.549297046765105e-06\n",
      "            test  score: 0.9727632716566157 with variance: 0.000244769548307299\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.0,25\n",
      "            train score: 0.9895392486301577 with variance: 7.235668351412157e-06\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9772675213202142 using:1.5,25\n",
      "            train score: 0.9899813094368481 with variance: 5.049394679440048e-06\n",
      "            test  score: 0.9772675213202142 with variance: 0.0002102543772575834\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9780219780219781 using:1.5,25\n",
      "            train score: 0.9900886991796083 with variance: 4.843787837653557e-06\n",
      "            test  score: 0.9780219780219781 with variance: 0.00019321338002656693\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9704661430673521 using:1.0,50\n",
      "            train score: 0.9911048094768823 with variance: 4.418193865012882e-06\n",
      "            test  score: 0.9704661430673521 with variance: 0.0002428388165858289\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:1.0,50\n",
      "            train score: 0.9911906275542639 with variance: 4.223321402010533e-06\n",
      "            test  score: 0.9714285714285715 with variance: 0.00022219538703055155\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9704661430673521 using:1.0,50\n",
      "            train score: 0.9911048094768823 with variance: 4.418193865012882e-06\n",
      "            test  score: 0.9704661430673521 with variance: 0.0002428388165858289\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:1.0,50\n",
      "            train score: 0.9911906275542639 with variance: 4.223321402010533e-06\n",
      "            test  score: 0.9714285714285715 with variance: 0.00022219538703055155\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9727632716566157 using:1.5,50\n",
      "            train score: 0.9916618869626876 with variance: 6.311250329280633e-06\n",
      "            test  score: 0.9727632716566157 with variance: 0.000244769548307299\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:1.5,50\n",
      "            train score: 0.9917415917415919 with variance: 6.038018934213728e-06\n",
      "            test  score: 0.9736263736263737 with variance: 0.00022219538703055147\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9750748476629918 using:1.0,100\n",
      "            train score: 0.9950168858438759 with variance: 4.3107610364304376e-06\n",
      "            test  score: 0.9750748476629918 with variance: 0.00017434276420762174\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,100\n",
      "            train score: 0.9950458632276813 with variance: 4.2199214101690665e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00016423137302258172\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9750748476629918 using:1.0,100\n",
      "            train score: 0.9950168858438759 with variance: 4.3107610364304376e-06\n",
      "            test  score: 0.9750748476629918 with variance: 0.00017434276420762174\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,100\n",
      "            train score: 0.9950458632276813 with variance: 4.2199214101690665e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00016423137302258172\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        f1\n",
      "          CV score: 0.9750748476629918 using:1.0,100\n",
      "            train score: 0.9950168858438759 with variance: 4.3107610364304376e-06\n",
      "            test  score: 0.9750748476629918 with variance: 0.00017434276420762174\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:1.0,100\n",
      "            train score: 0.9950458632276813 with variance: 4.2199214101690665e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00016423137302258172\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9449022694887053 using:1.0,2\n",
      "            train score: 0.9473292056059718 with variance: 7.220256369609333e-05\n",
      "            test  score: 0.9449022694887053 with variance: 0.0008768497767502416\n",
      "          Refitted train score: 0.9457013574660633,  RMSE: 0.23145502494313785, Log-Loss:1.850307655925733\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9463670411985017 using:1.0,2\n",
      "            train score: 0.9480976019669785 with variance: 6.761294939571817e-05\n",
      "            test  score: 0.9463670411985017 with variance: 0.0007292794119709916\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.23145502494313785, Log-Loss:1.850307655925733\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9449022694887053 using:1.0,2\n",
      "            train score: 0.9473292056059718 with variance: 7.220256369609333e-05\n",
      "            test  score: 0.9449022694887053 with variance: 0.0008768497767502416\n",
      "          Refitted train score: 0.9457013574660633,  RMSE: 0.23145502494313785, Log-Loss:1.850307655925733\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9464169787765293 using:0.001,2\n",
      "            train score: 0.9464278489285881 with variance: 5.721993131244445e-05\n",
      "            test  score: 0.9464169787765293 with variance: 0.0009277005490951542\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.23145502494313785, Log-Loss:1.850295162215886\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9449022694887053 using:1.0,2\n",
      "            train score: 0.9473292056059718 with variance: 7.220256369609333e-05\n",
      "            test  score: 0.9449022694887053 with variance: 0.0008768497767502416\n",
      "          Refitted train score: 0.9457013574660633,  RMSE: 0.23145502494313785, Log-Loss:1.850307655925733\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9464169787765293 using:0.001,2\n",
      "            train score: 0.9464278489285881 with variance: 5.721993131244445e-05\n",
      "            test  score: 0.9464169787765293 with variance: 0.0009277005490951542\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.23145502494313785, Log-Loss:1.850295162215886\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9600264505142555 using:1.0,3\n",
      "            train score: 0.9637773180288891 with variance: 6.019425325644267e-05\n",
      "            test  score: 0.9600264505142555 with variance: 0.0017959715993656668\n",
      "          Refitted train score: 0.9638009049773757,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9619225967540576 using:1.0,3\n",
      "            train score: 0.9642800454396913 with variance: 5.761618012271813e-05\n",
      "            test  score: 0.9619225967540576 with variance: 0.0014970300856763014\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9600264505142555 using:1.0,3\n",
      "            train score: 0.9637773180288891 with variance: 6.019425325644267e-05\n",
      "            test  score: 0.9600264505142555 with variance: 0.0017959715993656668\n",
      "          Refitted train score: 0.9638009049773757,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9619225967540576 using:1.0,3\n",
      "            train score: 0.9642800454396913 with variance: 5.761618012271813e-05\n",
      "            test  score: 0.9619225967540576 with variance: 0.0014970300856763014\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9600264505142555 using:1.0,3\n",
      "            train score: 0.9637773180288891 with variance: 6.019425325644267e-05\n",
      "            test  score: 0.9600264505142555 with variance: 0.0017959715993656668\n",
      "          Refitted train score: 0.9638009049773757,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9619225967540576 using:1.0,3\n",
      "            train score: 0.9642800454396913 with variance: 5.761618012271813e-05\n",
      "            test  score: 0.9619225967540576 with variance: 0.0014970300856763014\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335366524681302\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9585962555671447 using:1.0,5\n",
      "            train score: 0.9633569387028779 with variance: 6.130457982243785e-05\n",
      "            test  score: 0.9585962555671447 with variance: 0.0010881310916041052\n",
      "          Refitted train score: 0.963963963963964,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9597503121098626 using:1.0,5\n",
      "            train score: 0.9637229423756244 with variance: 5.9388177292719535e-05\n",
      "            test  score: 0.9597503121098626 with variance: 0.0009364237275191275\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9585962555671447 using:1.0,5\n",
      "            train score: 0.9633569387028779 with variance: 6.130457982243785e-05\n",
      "            test  score: 0.9585962555671447 with variance: 0.0010881310916041052\n",
      "          Refitted train score: 0.963963963963964,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9597503121098626 using:1.0,5\n",
      "            train score: 0.9637229423756244 with variance: 5.9388177292719535e-05\n",
      "            test  score: 0.9597503121098626 with variance: 0.0009364237275191275\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9585962555671447 using:1.0,5\n",
      "            train score: 0.9633569387028779 with variance: 6.130457982243785e-05\n",
      "            test  score: 0.9585962555671447 with variance: 0.0010881310916041052\n",
      "          Refitted train score: 0.963963963963964,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9597503121098626 using:1.0,5\n",
      "            train score: 0.9637229423756244 with variance: 5.9388177292719535e-05\n",
      "            test  score: 0.9597503121098626 with variance: 0.0009364237275191275\n",
      "          Refitted train score: 0.9642857142857143,  RMSE: 0.1889822365046136, Log-Loss:1.2335384372838227\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.967299460955371 using:1.0,10\n",
      "            train score: 0.9760645345179387 with variance: 2.857982972716457e-05\n",
      "            test  score: 0.967299460955371 with variance: 0.0007354551738701708\n",
      "          Refitted train score: 0.9771689497716896,  RMSE: 0.1494035761667992, Log-Loss:0.7709548302435429\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,10\n",
      "            train score: 0.9765596551563156 with variance: 2.6850272710415856e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0006277758295264496\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.1494035761667992, Log-Loss:0.7709548302435429\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.967299460955371 using:1.0,10\n",
      "            train score: 0.9760645345179387 with variance: 2.857982972716457e-05\n",
      "            test  score: 0.967299460955371 with variance: 0.0007354551738701708\n",
      "          Refitted train score: 0.9771689497716896,  RMSE: 0.1494035761667992, Log-Loss:0.7709548302435429\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,10\n",
      "            train score: 0.9765596551563156 with variance: 2.6850272710415856e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0006277758295264496\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.1494035761667992, Log-Loss:0.7709548302435429\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.967299460955371 using:1.0,10\n",
      "            train score: 0.9760645345179387 with variance: 2.857982972716457e-05\n",
      "            test  score: 0.967299460955371 with variance: 0.0007354551738701708\n",
      "          Refitted train score: 0.9771689497716896,  RMSE: 0.1494035761667992, Log-Loss:0.7709548302435429\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,10\n",
      "            train score: 0.9765596551563156 with variance: 2.6850272710415856e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0006277758295264496\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.1494035761667992, Log-Loss:0.7709548302435429\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9677339006939938 using:1.0,15\n",
      "            train score: 0.9835400488396656 with variance: 3.408240123486439e-05\n",
      "            test  score: 0.9677339006939938 with variance: 0.0005293474193884542\n",
      "          Refitted train score: 0.9818181818181818,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657928 using:1.0,15\n",
      "            train score: 0.9838113319120462 with variance: 3.2514381017291035e-05\n",
      "            test  score: 0.9687141073657928 with variance: 0.0004739369171806158\n",
      "          Refitted train score: 0.9821428571428571,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9677339006939938 using:1.0,15\n",
      "            train score: 0.9835400488396656 with variance: 3.408240123486439e-05\n",
      "            test  score: 0.9677339006939938 with variance: 0.0005293474193884542\n",
      "          Refitted train score: 0.9818181818181818,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657928 using:1.0,15\n",
      "            train score: 0.9838113319120462 with variance: 3.2514381017291035e-05\n",
      "            test  score: 0.9687141073657928 with variance: 0.0004739369171806158\n",
      "          Refitted train score: 0.9821428571428571,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9677339006939938 using:1.0,15\n",
      "            train score: 0.9835400488396656 with variance: 3.408240123486439e-05\n",
      "            test  score: 0.9677339006939938 with variance: 0.0005293474193884542\n",
      "          Refitted train score: 0.9818181818181818,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657928 using:1.0,15\n",
      "            train score: 0.9838113319120462 with variance: 3.2514381017291035e-05\n",
      "            test  score: 0.9687141073657928 with variance: 0.0004739369171806158\n",
      "          Refitted train score: 0.9821428571428571,  RMSE: 0.1336306209562122, Log-Loss:0.6167638641948345\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.967299460955371 using:1.0,25\n",
      "            train score: 0.9869911464565876 with variance: 3.091068227330463e-05\n",
      "            test  score: 0.967299460955371 with variance: 0.0007354551738701708\n",
      "          Refitted train score: 0.9887133182844243,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,25\n",
      "            train score: 0.9871601749116883 with variance: 2.9975749071537068e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0006277758295264496\n",
      "          Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.967299460955371 using:1.0,25\n",
      "            train score: 0.9869911464565876 with variance: 3.091068227330463e-05\n",
      "            test  score: 0.967299460955371 with variance: 0.0007354551738701708\n",
      "          Refitted train score: 0.9887133182844243,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,25\n",
      "            train score: 0.9871601749116883 with variance: 2.9975749071537068e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0006277758295264496\n",
      "          Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9675289043331897 using:1.5,25\n",
      "            train score: 0.9881338310379544 with variance: 3.031959021978105e-05\n",
      "            test  score: 0.9675289043331897 with variance: 0.0004300018431629608\n",
      "          Refitted train score: 0.9887133182844243,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,25\n",
      "            train score: 0.9871601749116883 with variance: 2.9975749071537068e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0006277758295264496\n",
      "          Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9769465445530356 using:1.0,50\n",
      "            train score: 0.989282935295226 with variance: 1.7298743191232584e-05\n",
      "            test  score: 0.9769465445530356 with variance: 0.0003890745014931847\n",
      "          Refitted train score: 0.9887133182844243,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9776279650436954 using:1.0,50\n",
      "            train score: 0.9893932556293864 with variance: 1.6870939063120138e-05\n",
      "            test  score: 0.9776279650436954 with variance: 0.00035350568343877297\n",
      "          Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9769465445530356 using:1.0,50\n",
      "            train score: 0.989282935295226 with variance: 1.7298743191232584e-05\n",
      "            test  score: 0.9769465445530356 with variance: 0.0003890745014931847\n",
      "          Refitted train score: 0.9887133182844243,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9776279650436954 using:1.0,50\n",
      "            train score: 0.9893932556293864 with variance: 1.6870939063120138e-05\n",
      "            test  score: 0.9776279650436954 with variance: 0.00035350568343877297\n",
      "          Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.38547741512177197\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9791437979862441 using:1.5,50\n",
      "            train score: 0.9926886811062452 with variance: 5.085808706872326e-06\n",
      "            test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "          Refitted train score: 0.9909909909909909,  RMSE: 0.0944911182523068, Log-Loss:0.3083819320974178\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9798501872659177 using:1.5,50\n",
      "            train score: 0.9927436547828388 with variance: 4.997161721086043e-06\n",
      "            test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "          Refitted train score: 0.9910714285714286,  RMSE: 0.0944911182523068, Log-Loss:0.3083819320974178\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9791437979862441 using:1.0,100\n",
      "            train score: 0.9983193277310924 with variance: 1.883106183649917e-06\n",
      "            test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "          Refitted train score: 0.9977628635346756,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9798501872659177 using:1.0,100\n",
      "            train score: 0.998325578500179 with variance: 1.8691329780909068e-06\n",
      "            test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "          Refitted train score: 0.9977678571428571,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9791437979862441 using:1.0,100\n",
      "            train score: 0.9983193277310924 with variance: 1.883106183649917e-06\n",
      "            test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "          Refitted train score: 0.9977628635346756,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9798501872659177 using:1.0,100\n",
      "            train score: 0.998325578500179 with variance: 1.8691329780909068e-06\n",
      "            test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "          Refitted train score: 0.9977678571428571,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9791437979862441 using:1.0,100\n",
      "            train score: 0.9983193277310924 with variance: 1.883106183649917e-06\n",
      "            test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "          Refitted train score: 0.9977628635346756,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9798501872659177 using:1.0,100\n",
      "            train score: 0.998325578500179 with variance: 1.8691329780909068e-06\n",
      "            test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "          Refitted train score: 0.9977678571428571,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9460840245577344 using:1.0,2\n",
      "            train score: 0.9473702330094049 with variance: 1.9879981151179464e-05\n",
      "            test  score: 0.9460840245577344 with variance: 0.0003283305530879316\n",
      "          Refitted train score: 0.9485458612975392,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9466666666666667 using:1.0,2\n",
      "            train score: 0.9477777777777776 with variance: 1.9753086419752944e-05\n",
      "            test  score: 0.9466666666666667 with variance: 0.0003160493827160485\n",
      "          Refitted train score: 0.9488888888888889,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        f1\n",
      "          CV score: 0.9460840245577344 using:1.0,2\n",
      "            train score: 0.9473702330094049 with variance: 1.9879981151179464e-05\n",
      "            test  score: 0.9460840245577344 with variance: 0.0003283305530879316\n",
      "          Refitted train score: 0.9485458612975392,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9466666666666667 using:1.0,2\n",
      "            train score: 0.9477777777777776 with variance: 1.9753086419752944e-05\n",
      "            test  score: 0.9466666666666667 with variance: 0.0003160493827160485\n",
      "          Refitted train score: 0.9488888888888889,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        f1\n",
      "          CV score: 0.9460840245577344 using:1.0,2\n",
      "            train score: 0.9473702330094049 with variance: 1.9879981151179464e-05\n",
      "            test  score: 0.9460840245577344 with variance: 0.0003283305530879316\n",
      "          Refitted train score: 0.9485458612975392,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9466666666666667 using:1.0,2\n",
      "            train score: 0.9477777777777776 with variance: 1.9753086419752944e-05\n",
      "            test  score: 0.9466666666666667 with variance: 0.0003160493827160485\n",
      "          Refitted train score: 0.9488888888888889,  RMSE: 0.22607766610417562, Log-Loss:1.7653330067938846\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9570143984710023 using:1.0,3\n",
      "            train score: 0.9647026295296224 with variance: 3.350830396939911e-05\n",
      "            test  score: 0.9570143984710023 with variance: 0.0006874867956666674\n",
      "          Refitted train score: 0.9641255605381166,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9577777777777777 using:1.0,3\n",
      "            train score: 0.9650000000000001 with variance: 3.271604938271582e-05\n",
      "            test  score: 0.9577777777777777 with variance: 0.0006617283950617292\n",
      "          Refitted train score: 0.9644444444444444,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        f1\n",
      "          CV score: 0.9570143984710023 using:1.0,3\n",
      "            train score: 0.9647026295296224 with variance: 3.350830396939911e-05\n",
      "            test  score: 0.9570143984710023 with variance: 0.0006874867956666674\n",
      "          Refitted train score: 0.9641255605381166,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.9577777777777777 using:1.0,3\n",
      "            train score: 0.9650000000000001 with variance: 3.271604938271582e-05\n",
      "            test  score: 0.9577777777777777 with variance: 0.0006617283950617292\n",
      "          Refitted train score: 0.9644444444444444,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        f1\n",
      "          CV score: 0.9594177422536564 using:1.5,3\n",
      "            train score: 0.9647434392751514 with variance: 3.967358739558565e-05\n",
      "            test  score: 0.9594177422536564 with variance: 0.0006409629855745602\n",
      "          Refitted train score: 0.9641255605381166,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.96 using:1.5,3\n",
      "            train score: 0.9650000000000001 with variance: 3.888888888888861e-05\n",
      "            test  score: 0.96 with variance: 0.0006222222222222228\n",
      "          Refitted train score: 0.9644444444444444,  RMSE: 0.18856180831641267, Log-Loss:1.2280560442292277\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.961685428093797 using:1.0,5\n",
      "            train score: 0.9714596674693403 with variance: 2.328700427562577e-05\n",
      "            test  score: 0.961685428093797 with variance: 0.0010517394198343339\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16329931618554522, Log-Loss:0.921041144730332\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9622222222222222 using:1.0,5\n",
      "            train score: 0.9716666666666667 with variance: 2.2839506172839347e-05\n",
      "            test  score: 0.9622222222222222 with variance: 0.0010172839506172849\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16329931618554522, Log-Loss:0.921041144730332\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        f1\n",
      "          CV score: 0.961685428093797 using:1.0,5\n",
      "            train score: 0.9714596674693403 with variance: 2.328700427562577e-05\n",
      "            test  score: 0.961685428093797 with variance: 0.0010517394198343339\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16329931618554522, Log-Loss:0.921041144730332\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9622222222222222 using:1.0,5\n",
      "            train score: 0.9716666666666667 with variance: 2.2839506172839347e-05\n",
      "            test  score: 0.9622222222222222 with variance: 0.0010172839506172849\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16329931618554522, Log-Loss:0.921041144730332\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        f1\n",
      "          CV score: 0.961685428093797 using:1.0,5\n",
      "            train score: 0.9714596674693403 with variance: 2.328700427562577e-05\n",
      "            test  score: 0.961685428093797 with variance: 0.0010517394198343339\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16329931618554522, Log-Loss:0.921041144730332\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9622222222222222 using:1.0,5\n",
      "            train score: 0.9716666666666667 with variance: 2.2839506172839347e-05\n",
      "            test  score: 0.9622222222222222 with variance: 0.0010172839506172849\n",
      "          Refitted train score: 0.9733333333333334,  RMSE: 0.16329931618554522, Log-Loss:0.921041144730332\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9704260739905839 using:1.0,10\n",
      "            train score: 0.9796321631071621 with variance: 1.426634383800774e-05\n",
      "            test  score: 0.9704260739905839 with variance: 0.0002450770882935794\n",
      "          Refitted train score: 0.9819004524886877,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.971111111111111 using:1.0,10\n",
      "            train score: 0.9800000000000001 with variance: 1.3580246913580421e-05\n",
      "            test  score: 0.971111111111111 with variance: 0.00022716049382716087\n",
      "          Refitted train score: 0.9822222222222222,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        f1\n",
      "          CV score: 0.9704260739905839 using:1.0,10\n",
      "            train score: 0.9796321631071621 with variance: 1.426634383800774e-05\n",
      "            test  score: 0.9704260739905839 with variance: 0.0002450770882935794\n",
      "          Refitted train score: 0.9819004524886877,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.971111111111111 using:1.0,10\n",
      "            train score: 0.9800000000000001 with variance: 1.3580246913580421e-05\n",
      "            test  score: 0.971111111111111 with variance: 0.00022716049382716087\n",
      "          Refitted train score: 0.9822222222222222,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        f1\n",
      "          CV score: 0.9704260739905839 using:1.0,10\n",
      "            train score: 0.9796321631071621 with variance: 1.426634383800774e-05\n",
      "            test  score: 0.9704260739905839 with variance: 0.0002450770882935794\n",
      "          Refitted train score: 0.9819004524886877,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.971111111111111 using:1.0,10\n",
      "            train score: 0.9800000000000001 with variance: 1.3580246913580421e-05\n",
      "            test  score: 0.971111111111111 with variance: 0.00022716049382716087\n",
      "          Refitted train score: 0.9822222222222222,  RMSE: 0.13333333333333333, Log-Loss:0.6140226914650797\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,15\n",
      "            train score: 0.9870990649781038 with variance: 5.057976140968052e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9887640449438202,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,15\n",
      "            train score: 0.9872222222222223 with variance: 4.938271604938237e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9888888888888889,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,15\n",
      "            train score: 0.9870990649781038 with variance: 5.057976140968052e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9887640449438202,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,15\n",
      "            train score: 0.9872222222222223 with variance: 4.938271604938237e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9888888888888889,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,15\n",
      "            train score: 0.9870990649781038 with variance: 5.057976140968052e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9887640449438202,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,15\n",
      "            train score: 0.9872222222222223 with variance: 4.938271604938237e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9888888888888889,  RMSE: 0.10540925533894598, Log-Loss:0.3837641821656752\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9795181571624811 using:1.0,25\n",
      "            train score: 0.9899096365682045 with variance: 1.8978427163552435e-06\n",
      "            test  score: 0.9795181571624811 with variance: 7.541648705545392e-05\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,25\n",
      "            train score: 0.99 with variance: 1.8518518518518385e-06\n",
      "            test  score: 0.9800000000000001 with variance: 6.91358024691361e-05\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        f1\n",
      "          CV score: 0.9795181571624811 using:1.0,25\n",
      "            train score: 0.9899096365682045 with variance: 1.8978427163552435e-06\n",
      "            test  score: 0.9795181571624811 with variance: 7.541648705545392e-05\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,25\n",
      "            train score: 0.99 with variance: 1.8518518518518385e-06\n",
      "            test  score: 0.9800000000000001 with variance: 6.91358024691361e-05\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        f1\n",
      "          CV score: 0.9795181571624811 using:1.0,25\n",
      "            train score: 0.9899096365682045 with variance: 1.8978427163552435e-06\n",
      "            test  score: 0.9795181571624811 with variance: 7.541648705545392e-05\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,25\n",
      "            train score: 0.99 with variance: 1.8518518518518385e-06\n",
      "            test  score: 0.9800000000000001 with variance: 6.91358024691361e-05\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,50\n",
      "            train score: 0.9927202078603029 with variance: 5.049631032265769e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,50\n",
      "            train score: 0.9927777777777778 with variance: 4.938271604938236e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,50\n",
      "            train score: 0.9927202078603029 with variance: 5.049631032265769e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,50\n",
      "            train score: 0.9927777777777778 with variance: 4.938271604938236e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,50\n",
      "            train score: 0.9927202078603029 with variance: 5.049631032265769e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,50\n",
      "            train score: 0.9927777777777778 with variance: 4.938271604938236e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,100\n",
      "            train score: 0.996094053936291 with variance: 1.8830475760486648e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,100\n",
      "            train score: 0.9961111111111112 with variance: 1.8518518518518385e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,100\n",
      "            train score: 0.996094053936291 with variance: 1.8830475760486648e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,100\n",
      "            train score: 0.9961111111111112 with variance: 1.8518518518518385e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:1.0,100\n",
      "            train score: 0.996094053936291 with variance: 1.8830475760486648e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.0001659335528021366\n",
      "          Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9777777777777779 using:1.0,100\n",
      "            train score: 0.9961111111111112 with variance: 1.8518518518518385e-06\n",
      "            test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "          Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "    random state: 850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9459064119967481 using:1.0,2\n",
      "            train score: 0.9474696607600155 with variance: 4.93196108470287e-05\n",
      "            test  score: 0.9459064119967481 with variance: 0.00024273824268117474\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9471550671550671 using:1.0,2\n",
      "            train score: 0.9482411527866074 with variance: 4.636722835879084e-05\n",
      "            test  score: 0.9471550671550671 with variance: 0.0001625520863616102\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9459064119967481 using:1.0,2\n",
      "            train score: 0.9474696607600155 with variance: 4.93196108470287e-05\n",
      "            test  score: 0.9459064119967481 with variance: 0.00024273824268117474\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9471550671550671 using:1.0,2\n",
      "            train score: 0.9482411527866074 with variance: 4.636722835879084e-05\n",
      "            test  score: 0.9471550671550671 with variance: 0.0001625520863616102\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9459064119967481 using:1.0,2\n",
      "            train score: 0.9474696607600155 with variance: 4.93196108470287e-05\n",
      "            test  score: 0.9459064119967481 with variance: 0.00024273824268117474\n",
      "          Refitted train score: 0.9464285714285714,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9471550671550671 using:1.0,2\n",
      "            train score: 0.9482411527866074 with variance: 4.636722835879084e-05\n",
      "            test  score: 0.9471550671550671 with variance: 0.0001625520863616102\n",
      "          Refitted train score: 0.947136563876652,  RMSE: 0.22992049957180422, Log-Loss:1.8258542507813404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9527489735649128 using:1.0,3\n",
      "            train score: 0.9552530922129441 with variance: 3.77087669901712e-05\n",
      "            test  score: 0.9527489735649128 with variance: 0.0004175759655886253\n",
      "          Refitted train score: 0.9530201342281879,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9537973137973138 using:1.0,3\n",
      "            train score: 0.9559516241334423 with variance: 3.5955335284105645e-05\n",
      "            test  score: 0.9537973137973138 with variance: 0.0003550927975836393\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9527489735649128 using:1.0,3\n",
      "            train score: 0.9552530922129441 with variance: 3.77087669901712e-05\n",
      "            test  score: 0.9527489735649128 with variance: 0.0004175759655886253\n",
      "          Refitted train score: 0.9530201342281879,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9537973137973138 using:1.0,3\n",
      "            train score: 0.9559516241334423 with variance: 3.5955335284105645e-05\n",
      "            test  score: 0.9537973137973138 with variance: 0.0003550927975836393\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9527489735649128 using:1.0,3\n",
      "            train score: 0.9552530922129441 with variance: 3.77087669901712e-05\n",
      "            test  score: 0.9527489735649128 with variance: 0.0004175759655886253\n",
      "          Refitted train score: 0.9530201342281879,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9537973137973138 using:1.0,3\n",
      "            train score: 0.9559516241334423 with variance: 3.5955335284105645e-05\n",
      "            test  score: 0.9537973137973138 with variance: 0.0003550927975836393\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976209283593303\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9688089063464368 using:1.0,5\n",
      "            train score: 0.9713748195323841 with variance: 4.8033451158729996e-05\n",
      "            test  score: 0.9688089063464368 with variance: 0.00045819456303198864\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9692063492063493 using:1.0,5\n",
      "            train score: 0.9719189901008083 with variance: 4.656966075712597e-05\n",
      "            test  score: 0.9692063492063493 with variance: 0.00045308776151267005\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9688089063464368 using:1.0,5\n",
      "            train score: 0.9713748195323841 with variance: 4.8033451158729996e-05\n",
      "            test  score: 0.9688089063464368 with variance: 0.00045819456303198864\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9692063492063493 using:1.0,5\n",
      "            train score: 0.9719189901008083 with variance: 4.656966075712597e-05\n",
      "            test  score: 0.9692063492063493 with variance: 0.00045308776151267005\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9710509562206076 using:1.5,5\n",
      "            train score: 0.9702795241096949 with variance: 3.6303114358520606e-05\n",
      "            test  score: 0.9710509562206076 with variance: 0.00037708505715624153\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:1.5,5\n",
      "            train score: 0.9708170617261527 with variance: 3.507435249247134e-05\n",
      "            test  score: 0.9714041514041515 with variance: 0.0003662490812673958\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9704043219632748 using:1.0,10\n",
      "            train score: 0.978717445018402 with variance: 1.785099893386224e-05\n",
      "            test  score: 0.9704043219632748 with variance: 0.0005671380897773078\n",
      "          Refitted train score: 0.9752808988764046,  RMSE: 0.15565691404453527, Log-Loss:0.8368443611045111\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,10\n",
      "            train score: 0.9790754699845609 with variance: 1.697334579328622e-05\n",
      "            test  score: 0.9714041514041514 with variance: 0.0005111591162873222\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368443611045111\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        f1\n",
      "          CV score: 0.9704043219632748 using:1.0,10\n",
      "            train score: 0.978717445018402 with variance: 1.785099893386224e-05\n",
      "            test  score: 0.9704043219632748 with variance: 0.0005671380897773078\n",
      "          Refitted train score: 0.9752808988764046,  RMSE: 0.15565691404453527, Log-Loss:0.8368443611045111\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,10\n",
      "            train score: 0.9790754699845609 with variance: 1.697334579328622e-05\n",
      "            test  score: 0.9714041514041514 with variance: 0.0005111591162873222\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368443611045111\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        f1\n",
      "          CV score: 0.9704043219632748 using:1.0,10\n",
      "            train score: 0.978717445018402 with variance: 1.785099893386224e-05\n",
      "            test  score: 0.9704043219632748 with variance: 0.0005671380897773078\n",
      "          Refitted train score: 0.9752808988764046,  RMSE: 0.15565691404453527, Log-Loss:0.8368443611045111\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,10\n",
      "            train score: 0.9790754699845609 with variance: 1.697334579328622e-05\n",
      "            test  score: 0.9714041514041514 with variance: 0.0005111591162873222\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368443611045111\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9727184626191681 using:1.0,15\n",
      "            train score: 0.9821446301556369 with variance: 1.1164690592181812e-05\n",
      "            test  score: 0.9727184626191681 with variance: 0.00044707491199943257\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9735775335775336 using:1.0,15\n",
      "            train score: 0.9823797414706507 with variance: 1.089363801032295e-05\n",
      "            test  score: 0.9735775335775336 with variance: 0.000414988945391876\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        f1\n",
      "          CV score: 0.9727184626191681 using:1.0,15\n",
      "            train score: 0.9821446301556369 with variance: 1.1164690592181812e-05\n",
      "            test  score: 0.9727184626191681 with variance: 0.00044707491199943257\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9735775335775336 using:1.0,15\n",
      "            train score: 0.9823797414706507 with variance: 1.089363801032295e-05\n",
      "            test  score: 0.9735775335775336 with variance: 0.000414988945391876\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        f1\n",
      "          CV score: 0.9729742125872713 using:1.5,15\n",
      "            train score: 0.9827110182707715 with variance: 1.0586452314927515e-05\n",
      "            test  score: 0.9729742125872713 with variance: 0.0003364761167990651\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9735775335775336 using:1.0,15\n",
      "            train score: 0.9823797414706507 with variance: 1.089363801032295e-05\n",
      "            test  score: 0.9735775335775336 with variance: 0.000414988945391876\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9819673683757373 using:1.0,25\n",
      "            train score: 0.9883193281645749 with variance: 1.997172917944751e-05\n",
      "            test  score: 0.9819673683757373 with variance: 0.0003329473907221455\n",
      "          Refitted train score: 0.9866666666666667,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9823931623931624 using:1.0,25\n",
      "            train score: 0.9884358066176249 with variance: 1.9434756598419343e-05\n",
      "            test  score: 0.9823931623931624 with variance: 0.0003184824400941613\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9819673683757373 using:1.0,25\n",
      "            train score: 0.9883193281645749 with variance: 1.997172917944751e-05\n",
      "            test  score: 0.9819673683757373 with variance: 0.0003329473907221455\n",
      "          Refitted train score: 0.9866666666666667,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9823931623931624 using:1.0,25\n",
      "            train score: 0.9884358066176249 with variance: 1.9434756598419343e-05\n",
      "            test  score: 0.9823931623931624 with variance: 0.0003184824400941613\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9819673683757373 using:1.0,25\n",
      "            train score: 0.9883193281645749 with variance: 1.997172917944751e-05\n",
      "            test  score: 0.9819673683757373 with variance: 0.0003329473907221455\n",
      "          Refitted train score: 0.9866666666666667,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9823931623931624 using:1.0,25\n",
      "            train score: 0.9884358066176249 with variance: 1.9434756598419343e-05\n",
      "            test  score: 0.9823931623931624 with variance: 0.0003184824400941613\n",
      "          Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564613611605611\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9773637923206776 using:1.0,50\n",
      "            train score: 0.9905631476335909 with variance: 1.4284108977335644e-05\n",
      "            test  score: 0.9773637923206776 with variance: 0.00036473114611327694\n",
      "          Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.977997557997558 using:1.0,50\n",
      "            train score: 0.9906366360911816 with variance: 1.3987218187976335e-05\n",
      "            test  score: 0.977997557997558 with variance: 0.00033758909656345505\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9773637923206776 using:1.0,50\n",
      "            train score: 0.9905631476335909 with variance: 1.4284108977335644e-05\n",
      "            test  score: 0.9773637923206776 with variance: 0.00036473114611327694\n",
      "          Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.977997557997558 using:1.0,50\n",
      "            train score: 0.9906366360911816 with variance: 1.3987218187976335e-05\n",
      "            test  score: 0.977997557997558 with variance: 0.00033758909656345505\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9797695661779351 using:1.5,50\n",
      "            train score: 0.9922467771639042 with variance: 7.380651715887816e-06\n",
      "            test  score: 0.9797695661779351 with variance: 0.00027300441389287817\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9801953601953602 using:1.5,50\n",
      "            train score: 0.992289528653165 with variance: 7.2988568790288886e-06\n",
      "            test  score: 0.9801953601953602 with variance: 0.0002604110853195101\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.3043063999551612\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9704043219632748 using:1.0,100\n",
      "            train score: 0.9961218412147594 with variance: 4.928190882592142e-06\n",
      "            test  score: 0.9704043219632748 with variance: 0.0005671380897773078\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,100\n",
      "            train score: 0.9961432506887054 with variance: 4.856984571484825e-06\n",
      "            test  score: 0.9714041514041514 with variance: 0.0005111591162873222\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9704043219632748 using:1.0,100\n",
      "            train score: 0.9961218412147594 with variance: 4.928190882592142e-06\n",
      "            test  score: 0.9704043219632748 with variance: 0.0005671380897773078\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,100\n",
      "            train score: 0.9961432506887054 with variance: 4.856984571484825e-06\n",
      "            test  score: 0.9714041514041514 with variance: 0.0005111591162873222\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9704043219632748 using:1.0,100\n",
      "            train score: 0.9961218412147594 with variance: 4.928190882592142e-06\n",
      "            test  score: 0.9704043219632748 with variance: 0.0005671380897773078\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041514 using:1.0,100\n",
      "            train score: 0.9961432506887054 with variance: 4.856984571484825e-06\n",
      "            test  score: 0.9714041514041514 with variance: 0.0005111591162873222\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9557356170399649 using:1.0,2\n",
      "            train score: 0.9549300953340824 with variance: 1.0095223238334897e-05\n",
      "            test  score: 0.9557356170399649 with variance: 0.0001809885145395254\n",
      "          Refitted train score: 0.9576837416481068,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9559462759462759 using:1.0,2\n",
      "            train score: 0.9553976326703599 with variance: 1.021032212980774e-05\n",
      "            test  score: 0.9559462759462759 with variance: 0.00019325154563249762\n",
      "          Refitted train score: 0.9581497797356828,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9557356170399649 using:1.0,2\n",
      "            train score: 0.9549300953340824 with variance: 1.0095223238334897e-05\n",
      "            test  score: 0.9557356170399649 with variance: 0.0001809885145395254\n",
      "          Refitted train score: 0.9576837416481068,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9559462759462759 using:1.0,2\n",
      "            train score: 0.9553976326703599 with variance: 1.021032212980774e-05\n",
      "            test  score: 0.9559462759462759 with variance: 0.00019325154563249762\n",
      "          Refitted train score: 0.9581497797356828,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9557356170399649 using:1.0,2\n",
      "            train score: 0.9549300953340824 with variance: 1.0095223238334897e-05\n",
      "            test  score: 0.9557356170399649 with variance: 0.0001809885145395254\n",
      "          Refitted train score: 0.9576837416481068,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9559462759462759 using:1.0,2\n",
      "            train score: 0.9553976326703599 with variance: 1.021032212980774e-05\n",
      "            test  score: 0.9559462759462759 with variance: 0.00019325154563249762\n",
      "          Refitted train score: 0.9581497797356828,  RMSE: 0.20457326380619043, Log-Loss:1.4454677283817505\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.964564198838997 using:1.0,3\n",
      "            train score: 0.9664816494357279 with variance: 3.2022030244863166e-05\n",
      "            test  score: 0.964564198838997 with variance: 0.00014490104301869837\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863248 using:1.0,3\n",
      "            train score: 0.9669633396906125 with variance: 3.316005627743465e-05\n",
      "            test  score: 0.9647863247863248 with variance: 0.0001629528252238872\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.964564198838997 using:1.0,3\n",
      "            train score: 0.9664816494357279 with variance: 3.2022030244863166e-05\n",
      "            test  score: 0.964564198838997 with variance: 0.00014490104301869837\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863248 using:1.0,3\n",
      "            train score: 0.9669633396906125 with variance: 3.316005627743465e-05\n",
      "            test  score: 0.9647863247863248 with variance: 0.0001629528252238872\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.964564198838997 using:1.0,3\n",
      "            train score: 0.9664816494357279 with variance: 3.2022030244863166e-05\n",
      "            test  score: 0.964564198838997 with variance: 0.00014490104301869837\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863248 using:1.0,3\n",
      "            train score: 0.9669633396906125 with variance: 3.316005627743465e-05\n",
      "            test  score: 0.9647863247863248 with variance: 0.0001629528252238872\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9625146362862591 using:1.0,5\n",
      "            train score: 0.971947730301606 with variance: 2.1814840261149232e-05\n",
      "            test  score: 0.9625146362862591 with variance: 0.00038997789833081654\n",
      "          Refitted train score: 0.9707865168539326,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:1.0,5\n",
      "            train score: 0.9724684406502588 with variance: 2.1158680763538812e-05\n",
      "            test  score: 0.9625885225885226 with variance: 0.0004139155377250618\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9625146362862591 using:1.0,5\n",
      "            train score: 0.971947730301606 with variance: 2.1814840261149232e-05\n",
      "            test  score: 0.9625146362862591 with variance: 0.00038997789833081654\n",
      "          Refitted train score: 0.9707865168539326,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:1.0,5\n",
      "            train score: 0.9724684406502588 with variance: 2.1158680763538812e-05\n",
      "            test  score: 0.9625885225885226 with variance: 0.0004139155377250618\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9625146362862591 using:1.0,5\n",
      "            train score: 0.971947730301606 with variance: 2.1814840261149232e-05\n",
      "            test  score: 0.9625146362862591 with variance: 0.00038997789833081654\n",
      "          Refitted train score: 0.9707865168539326,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:1.0,5\n",
      "            train score: 0.9724684406502588 with variance: 2.1158680763538812e-05\n",
      "            test  score: 0.9625885225885226 with variance: 0.0004139155377250618\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9602766798418972 using:1.0,10\n",
      "            train score: 0.9725235572877006 with variance: 1.6698540948018433e-05\n",
      "            test  score: 0.9602766798418972 with variance: 0.0004332984424065361\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9603907203907204 using:1.0,10\n",
      "            train score: 0.9730194048375866 with variance: 1.6283349066268556e-05\n",
      "            test  score: 0.9603907203907204 with variance: 0.0004620042011983395\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9602766798418972 using:1.0,10\n",
      "            train score: 0.9725235572877006 with variance: 1.6698540948018433e-05\n",
      "            test  score: 0.9602766798418972 with variance: 0.0004332984424065361\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9603907203907204 using:1.0,10\n",
      "            train score: 0.9730194048375866 with variance: 1.6283349066268556e-05\n",
      "            test  score: 0.9603907203907204 with variance: 0.0004620042011983395\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9602766798418972 using:1.0,10\n",
      "            train score: 0.9725235572877006 with variance: 1.6698540948018433e-05\n",
      "            test  score: 0.9602766798418972 with variance: 0.0004332984424065361\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9603907203907204 using:1.0,10\n",
      "            train score: 0.9730194048375866 with variance: 1.6283349066268556e-05\n",
      "            test  score: 0.9603907203907204 with variance: 0.0004620042011983395\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129227223211211\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.980067257824952 using:1.0,15\n",
      "            train score: 0.9855275883726888 with variance: 1.0446815572066016e-05\n",
      "            test  score: 0.980067257824952 with variance: 0.00020807817745908675\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:1.0,15\n",
      "            train score: 0.9856855265946175 with variance: 1.0216462276798663e-05\n",
      "            test  score: 0.9802197802197803 with variance: 0.0002125347180292233\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.980067257824952 using:1.0,15\n",
      "            train score: 0.9855275883726888 with variance: 1.0446815572066016e-05\n",
      "            test  score: 0.980067257824952 with variance: 0.00020807817745908675\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:1.0,15\n",
      "            train score: 0.9856855265946175 with variance: 1.0216462276798663e-05\n",
      "            test  score: 0.9802197802197803 with variance: 0.0002125347180292233\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.980067257824952 using:1.0,15\n",
      "            train score: 0.9855275883726888 with variance: 1.0446815572066016e-05\n",
      "            test  score: 0.980067257824952 with variance: 0.00020807817745908675\n",
      "          Refitted train score: 0.9844097995545658,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:1.0,15\n",
      "            train score: 0.9856855265946175 with variance: 1.0216462276798663e-05\n",
      "            test  score: 0.9802197802197803 with variance: 0.0002125347180292233\n",
      "          Refitted train score: 0.9845814977973568,  RMSE: 0.12417126158110488, Log-Loss:0.532537961149351\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9711739771925411 using:1.0,25\n",
      "            train score: 0.9877589750356608 with variance: 1.4331838730064758e-05\n",
      "            test  score: 0.9711739771925411 with variance: 0.0003503483743643319\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9713797313797313 using:1.0,25\n",
      "            train score: 0.9878863560681743 with variance: 1.3939040945092779e-05\n",
      "            test  score: 0.9713797313797313 with variance: 0.00036647091885187103\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9711739771925411 using:1.0,25\n",
      "            train score: 0.9877589750356608 with variance: 1.4331838730064758e-05\n",
      "            test  score: 0.9711739771925411 with variance: 0.0003503483743643319\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9713797313797313 using:1.0,25\n",
      "            train score: 0.9878863560681743 with variance: 1.3939040945092779e-05\n",
      "            test  score: 0.9713797313797313 with variance: 0.00036647091885187103\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9711739771925411 using:1.0,25\n",
      "            train score: 0.9877589750356608 with variance: 1.4331838730064758e-05\n",
      "            test  score: 0.9711739771925411 with variance: 0.0003503483743643319\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9713797313797313 using:1.0,25\n",
      "            train score: 0.9878863560681743 with variance: 1.3939040945092779e-05\n",
      "            test  score: 0.9713797313797313 with variance: 0.00036647091885187103\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.973377745849656 using:1.0,50\n",
      "            train score: 0.991123388581952 with variance: 7.353443815497527e-06\n",
      "            test  score: 0.973377745849656 with variance: 0.000652643668654295\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736019536019537 using:1.0,50\n",
      "            train score: 0.9911906275542639 with variance: 7.258936759188687e-06\n",
      "            test  score: 0.9736019536019537 with variance: 0.0006561764920739276\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.973377745849656 using:1.0,50\n",
      "            train score: 0.991123388581952 with variance: 7.353443815497527e-06\n",
      "            test  score: 0.973377745849656 with variance: 0.000652643668654295\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736019536019537 using:1.0,50\n",
      "            train score: 0.9911906275542639 with variance: 7.258936759188687e-06\n",
      "            test  score: 0.9736019536019537 with variance: 0.0006561764920739276\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.973377745849656 using:1.0,50\n",
      "            train score: 0.991123388581952 with variance: 7.353443815497527e-06\n",
      "            test  score: 0.973377745849656 with variance: 0.000652643668654295\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9736019536019537 using:1.0,50\n",
      "            train score: 0.9911906275542639 with variance: 7.258936759188687e-06\n",
      "            test  score: 0.9736019536019537 with variance: 0.0006561764920739276\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9624155490366839 using:1.0,100\n",
      "            train score: 0.9966819881385426 with variance: 4.30407190577584e-06\n",
      "            test  score: 0.9624155490366839 with variance: 0.0004993630703822758\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758103\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:1.0,100\n",
      "            train score: 0.9966957285139104 with variance: 4.251538584973643e-06\n",
      "            test  score: 0.9625885225885226 with variance: 0.0005105222277383443\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758103\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9624155490366839 using:1.0,100\n",
      "            train score: 0.9966819881385426 with variance: 4.30407190577584e-06\n",
      "            test  score: 0.9624155490366839 with variance: 0.0004993630703822758\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758103\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:1.0,100\n",
      "            train score: 0.9966957285139104 with variance: 4.251538584973643e-06\n",
      "            test  score: 0.9625885225885226 with variance: 0.0005105222277383443\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758103\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9646627400479199 using:1.5,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9646627400479199 with variance: 0.0006379827464704031\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863248 using:1.5,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9647863247863248 with variance: 0.0006459862752903036\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9523247361520086 using:1.0,2\n",
      "            train score: 0.9476576643520083 with variance: 2.55370743392144e-05\n",
      "            test  score: 0.9523247361520086 with variance: 0.00044803901585932314\n",
      "          Refitted train score: 0.9476082004555809,  RMSE: 0.22708920433710053, Log-Loss:1.781162004175757\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9529088639200998 using:1.0,2\n",
      "            train score: 0.9484279104900388 with variance: 2.413875387742432e-05\n",
      "            test  score: 0.9529088639200998 with variance: 0.000424677642335346\n",
      "          Refitted train score: 0.9484304932735426,  RMSE: 0.22708920433710053, Log-Loss:1.781162004175757\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9523247361520086 using:1.0,2\n",
      "            train score: 0.9476576643520083 with variance: 2.55370743392144e-05\n",
      "            test  score: 0.9523247361520086 with variance: 0.00044803901585932314\n",
      "          Refitted train score: 0.9476082004555809,  RMSE: 0.22708920433710053, Log-Loss:1.781162004175757\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9529088639200998 using:1.0,2\n",
      "            train score: 0.9484279104900388 with variance: 2.413875387742432e-05\n",
      "            test  score: 0.9529088639200998 with variance: 0.000424677642335346\n",
      "          Refitted train score: 0.9484304932735426,  RMSE: 0.22708920433710053, Log-Loss:1.781162004175757\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9523247361520086 using:1.0,2\n",
      "            train score: 0.9476576643520083 with variance: 2.55370743392144e-05\n",
      "            test  score: 0.9523247361520086 with variance: 0.00044803901585932314\n",
      "          Refitted train score: 0.9476082004555809,  RMSE: 0.22708920433710053, Log-Loss:1.781162004175757\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9529088639200998 using:1.0,2\n",
      "            train score: 0.9484279104900388 with variance: 2.413875387742432e-05\n",
      "            test  score: 0.9529088639200998 with variance: 0.000424677642335346\n",
      "          Refitted train score: 0.9484304932735426,  RMSE: 0.22708920433710053, Log-Loss:1.781162004175757\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9596286126599622 using:1.0,3\n",
      "            train score: 0.9615878099548688 with variance: 4.625441816076528e-06\n",
      "            test  score: 0.9596286126599622 with variance: 0.0003540939667333572\n",
      "          Refitted train score: 0.9616252821670428,  RMSE: 0.19523470984497382, Log-Loss:1.316512995281375\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9597003745318352 using:1.0,3\n",
      "            train score: 0.9618843042835111 with variance: 4.954525433354145e-06\n",
      "            test  score: 0.9597003745318352 with variance: 0.0003757999130300606\n",
      "          Refitted train score: 0.9618834080717489,  RMSE: 0.19523470984497382, Log-Loss:1.316512995281375\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9596286126599622 using:1.0,3\n",
      "            train score: 0.9615878099548688 with variance: 4.625441816076528e-06\n",
      "            test  score: 0.9596286126599622 with variance: 0.0003540939667333572\n",
      "          Refitted train score: 0.9616252821670428,  RMSE: 0.19523470984497382, Log-Loss:1.316512995281375\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9597003745318352 using:1.0,3\n",
      "            train score: 0.9618843042835111 with variance: 4.954525433354145e-06\n",
      "            test  score: 0.9597003745318352 with variance: 0.0003757999130300606\n",
      "          Refitted train score: 0.9618834080717489,  RMSE: 0.19523470984497382, Log-Loss:1.316512995281375\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9596286126599622 using:1.0,3\n",
      "            train score: 0.9615878099548688 with variance: 4.625441816076528e-06\n",
      "            test  score: 0.9596286126599622 with variance: 0.0003540939667333572\n",
      "          Refitted train score: 0.9616252821670428,  RMSE: 0.19523470984497382, Log-Loss:1.316512995281375\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9597003745318352 using:1.0,3\n",
      "            train score: 0.9618843042835111 with variance: 4.954525433354145e-06\n",
      "            test  score: 0.9597003745318352 with variance: 0.0003757999130300606\n",
      "          Refitted train score: 0.9618834080717489,  RMSE: 0.19523470984497382, Log-Loss:1.316512995281375\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9618090152784571 using:1.0,5\n",
      "            train score: 0.966420065182777 with variance: 1.276070410094127e-06\n",
      "            test  score: 0.9618090152784571 with variance: 0.0006704124520561309\n",
      "          Refitted train score: 0.9680365296803654,  RMSE: 0.1771726122433938, Log-Loss:1.0841822159664585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9619975031210986 using:1.0,5\n",
      "            train score: 0.9669294684165802 with variance: 1.1790215540384645e-06\n",
      "            test  score: 0.9619975031210986 with variance: 0.0007167919002620006\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.1771726122433938, Log-Loss:1.0841822159664585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9618090152784571 using:1.0,5\n",
      "            train score: 0.966420065182777 with variance: 1.276070410094127e-06\n",
      "            test  score: 0.9618090152784571 with variance: 0.0006704124520561309\n",
      "          Refitted train score: 0.9680365296803654,  RMSE: 0.1771726122433938, Log-Loss:1.0841822159664585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9619975031210986 using:1.0,5\n",
      "            train score: 0.9669294684165802 with variance: 1.1790215540384645e-06\n",
      "            test  score: 0.9619975031210986 with variance: 0.0007167919002620006\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.1771726122433938, Log-Loss:1.0841822159664585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9618090152784571 using:1.0,5\n",
      "            train score: 0.966420065182777 with variance: 1.276070410094127e-06\n",
      "            test  score: 0.9618090152784571 with variance: 0.0006704124520561309\n",
      "          Refitted train score: 0.9680365296803654,  RMSE: 0.1771726122433938, Log-Loss:1.0841822159664585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9619975031210986 using:1.0,5\n",
      "            train score: 0.9669294684165802 with variance: 1.1790215540384645e-06\n",
      "            test  score: 0.9619975031210986 with variance: 0.0007167919002620006\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.1771726122433938, Log-Loss:1.0841822159664585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9656132673914201 using:1.0,10\n",
      "            train score: 0.974771851078145 with variance: 1.1107430474771403e-05\n",
      "            test  score: 0.9656132673914201 with variance: 0.00019996882538674422\n",
      "          Refitted train score: 0.9701149425287355,  RMSE: 0.1707278010834213, Log-Loss:1.006737427648586\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9664169787765294 using:1.0,10\n",
      "            train score: 0.9753375507506373 with variance: 1.0615146345935146e-05\n",
      "            test  score: 0.9664169787765294 with variance: 0.00019644607785835743\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.006737427648586\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9656132673914201 using:1.0,10\n",
      "            train score: 0.974771851078145 with variance: 1.1107430474771403e-05\n",
      "            test  score: 0.9656132673914201 with variance: 0.00019996882538674422\n",
      "          Refitted train score: 0.9701149425287355,  RMSE: 0.1707278010834213, Log-Loss:1.006737427648586\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9664169787765294 using:1.0,10\n",
      "            train score: 0.9753375507506373 with variance: 1.0615146345935146e-05\n",
      "            test  score: 0.9664169787765294 with variance: 0.00019644607785835743\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.006737427648586\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9656132673914201 using:1.0,10\n",
      "            train score: 0.974771851078145 with variance: 1.1107430474771403e-05\n",
      "            test  score: 0.9656132673914201 with variance: 0.00019996882538674422\n",
      "          Refitted train score: 0.9701149425287355,  RMSE: 0.1707278010834213, Log-Loss:1.006737427648586\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9664169787765294 using:1.0,10\n",
      "            train score: 0.9753375507506373 with variance: 1.0615146345935146e-05\n",
      "            test  score: 0.9664169787765294 with variance: 0.00019644607785835743\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.006737427648586\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9725013963606433 using:1.0,15\n",
      "            train score: 0.9852107641988941 with variance: 1.1347421943983095e-05\n",
      "            test  score: 0.9725013963606433 with variance: 8.952753105591929e-05\n",
      "          Refitted train score: 0.9863636363636364,  RMSE: 0.11598670095405886, Log-Loss:0.46464721607503257\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.973083645443196 using:1.0,15\n",
      "            train score: 0.985424731690429 with variance: 1.0713608637446839e-05\n",
      "            test  score: 0.973083645443196 with variance: 8.125673120833619e-05\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.46464721607503257\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9725013963606433 using:1.0,15\n",
      "            train score: 0.9852107641988941 with variance: 1.1347421943983095e-05\n",
      "            test  score: 0.9725013963606433 with variance: 8.952753105591929e-05\n",
      "          Refitted train score: 0.9863636363636364,  RMSE: 0.11598670095405886, Log-Loss:0.46464721607503257\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.973083645443196 using:1.0,15\n",
      "            train score: 0.985424731690429 with variance: 1.0713608637446839e-05\n",
      "            test  score: 0.973083645443196 with variance: 8.125673120833619e-05\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.46464721607503257\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9725013963606433 using:1.0,15\n",
      "            train score: 0.9852107641988941 with variance: 1.1347421943983095e-05\n",
      "            test  score: 0.9725013963606433 with variance: 8.952753105591929e-05\n",
      "          Refitted train score: 0.9863636363636364,  RMSE: 0.11598670095405886, Log-Loss:0.46464721607503257\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.973083645443196 using:1.0,15\n",
      "            train score: 0.985424731690429 with variance: 1.0713608637446839e-05\n",
      "            test  score: 0.973083645443196 with variance: 8.125673120833619e-05\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.46464721607503257\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9745375314340834 using:1.0,25\n",
      "            train score: 0.9880728190450082 with variance: 1.7686772914130986e-05\n",
      "            test  score: 0.9745375314340834 with variance: 0.0001968705896288427\n",
      "          Refitted train score: 0.9863636363636364,  RMSE: 0.11598670095405886, Log-Loss:0.4646472160750325\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9753058676654183 using:1.0,25\n",
      "            train score: 0.9882274258017814 with variance: 1.6983467455170258e-05\n",
      "            test  score: 0.9753058676654183 with variance: 0.00017237130241380536\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.4646472160750325\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9745375314340834 using:1.0,25\n",
      "            train score: 0.9880728190450082 with variance: 1.7686772914130986e-05\n",
      "            test  score: 0.9745375314340834 with variance: 0.0001968705896288427\n",
      "          Refitted train score: 0.9863636363636364,  RMSE: 0.11598670095405886, Log-Loss:0.4646472160750325\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9753058676654183 using:1.0,25\n",
      "            train score: 0.9882274258017814 with variance: 1.6983467455170258e-05\n",
      "            test  score: 0.9753058676654183 with variance: 0.00017237130241380536\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.4646472160750325\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9745375314340834 using:1.0,25\n",
      "            train score: 0.9880728190450082 with variance: 1.7686772914130986e-05\n",
      "            test  score: 0.9745375314340834 with variance: 0.0001968705896288427\n",
      "          Refitted train score: 0.9863636363636364,  RMSE: 0.11598670095405886, Log-Loss:0.4646472160750325\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9753058676654183 using:1.0,25\n",
      "            train score: 0.9882274258017814 with variance: 1.6983467455170258e-05\n",
      "            test  score: 0.9753058676654183 with variance: 0.00017237130241380536\n",
      "          Refitted train score: 0.9865470852017937,  RMSE: 0.11598670095405886, Log-Loss:0.4646472160750325\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9793013680031937 using:1.0,50\n",
      "            train score: 0.9897982985247248 with variance: 8.538007828772394e-06\n",
      "            test  score: 0.9793013680031937 with variance: 0.00018597116760350345\n",
      "          Refitted train score: 0.9886621315192743,  RMSE: 0.10588088747190667, Log-Loss:0.3872060133958606\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9798002496878901 using:1.0,50\n",
      "            train score: 0.9899080980706889 with variance: 8.222086718693988e-06\n",
      "            test  score: 0.9798002496878901 with variance: 0.00017214686386087292\n",
      "          Refitted train score: 0.9887892376681614,  RMSE: 0.10588088747190667, Log-Loss:0.3872060133958606\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9793013680031937 using:1.0,50\n",
      "            train score: 0.9897982985247248 with variance: 8.538007828772394e-06\n",
      "            test  score: 0.9793013680031937 with variance: 0.00018597116760350345\n",
      "          Refitted train score: 0.9886621315192743,  RMSE: 0.10588088747190667, Log-Loss:0.3872060133958606\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9798002496878901 using:1.0,50\n",
      "            train score: 0.9899080980706889 with variance: 8.222086718693988e-06\n",
      "            test  score: 0.9798002496878901 with variance: 0.00017214686386087292\n",
      "          Refitted train score: 0.9887892376681614,  RMSE: 0.10588088747190667, Log-Loss:0.3872060133958606\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9814991702009959 using:1.5,50\n",
      "            train score: 0.9920806932204339 with variance: 1.0990978351075392e-05\n",
      "            test  score: 0.9814991702009959 with variance: 0.0002479721583876784\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9820224719101123 using:1.5,50\n",
      "            train score: 0.9921505680924054 with variance: 1.0713410524184044e-05\n",
      "            test  score: 0.9820224719101123 with variance: 0.00023229390228506476\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9767869931953621 using:1.0,100\n",
      "            train score: 0.9977527912573481 with variance: 1.2625365910042964e-06\n",
      "            test  score: 0.9767869931953621 with variance: 0.0002810383050642718\n",
      "          Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9775530586766543 using:1.0,100\n",
      "            train score: 0.9977575299782835 with variance: 1.2571772361335248e-06\n",
      "            test  score: 0.9775530586766543 with variance: 0.0002530569621930141\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9767869931953621 using:1.0,100\n",
      "            train score: 0.9977527912573481 with variance: 1.2625365910042964e-06\n",
      "            test  score: 0.9767869931953621 with variance: 0.0002810383050642718\n",
      "          Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9775530586766543 using:1.0,100\n",
      "            train score: 0.9977575299782835 with variance: 1.2571772361335248e-06\n",
      "            test  score: 0.9775530586766543 with variance: 0.0002530569621930141\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9767869931953621 using:1.0,100\n",
      "            train score: 0.9977527912573481 with variance: 1.2625365910042964e-06\n",
      "            test  score: 0.9767869931953621 with variance: 0.0002810383050642718\n",
      "          Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9775530586766543 using:1.0,100\n",
      "            train score: 0.9977575299782835 with variance: 1.2571772361335248e-06\n",
      "            test  score: 0.9775530586766543 with variance: 0.0002530569621930141\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9476840788338045 using:1.0,2\n",
      "            train score: 0.9489763069791399 with variance: 6.456974275036474e-05\n",
      "            test  score: 0.9476840788338045 with variance: 0.0006445328784316779\n",
      "          Refitted train score: 0.9457013574660634,  RMSE: 0.23197340190811772, Log-Loss:1.8586067924936291\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9485143570536829 using:1.0,2\n",
      "            train score: 0.9495593743115224 with variance: 6.219883756666743e-05\n",
      "            test  score: 0.9485143570536829 with variance: 0.0005706824023029891\n",
      "          Refitted train score: 0.9461883408071748,  RMSE: 0.23197340190811772, Log-Loss:1.8586067924936291\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9476840788338045 using:1.0,2\n",
      "            train score: 0.9489763069791399 with variance: 6.456974275036474e-05\n",
      "            test  score: 0.9476840788338045 with variance: 0.0006445328784316779\n",
      "          Refitted train score: 0.9457013574660634,  RMSE: 0.23197340190811772, Log-Loss:1.8586067924936291\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9485393258426967 using:0.001,2\n",
      "            train score: 0.9484373524690776 with variance: 5.4696654821603556e-05\n",
      "            test  score: 0.9485393258426967 with variance: 0.0008667592475697508\n",
      "          Refitted train score: 0.9484304932735426,  RMSE: 0.22708920433710053, Log-Loss:1.7811512472596556\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        f1\n",
      "          CV score: 0.9476840788338045 using:1.0,2\n",
      "            train score: 0.9489763069791399 with variance: 6.456974275036474e-05\n",
      "            test  score: 0.9476840788338045 with variance: 0.0006445328784316779\n",
      "          Refitted train score: 0.9457013574660634,  RMSE: 0.23197340190811772, Log-Loss:1.8586067924936291\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9485393258426967 using:0.001,2\n",
      "            train score: 0.9484373524690776 with variance: 5.4696654821603556e-05\n",
      "            test  score: 0.9485393258426967 with variance: 0.0008667592475697508\n",
      "          Refitted train score: 0.9484304932735426,  RMSE: 0.22708920433710053, Log-Loss:1.7811512472596556\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.967761415275449 using:1.0,3\n",
      "            train score: 0.9709559141297536 with variance: 2.509761498095945e-05\n",
      "            test  score: 0.967761415275449 with variance: 0.00039504712021895376\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877654 using:1.0,3\n",
      "            train score: 0.9714159821231864 with variance: 2.307044792018887e-05\n",
      "            test  score: 0.9686641697877654 with variance: 0.00036758047446933535\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.967761415275449 using:1.0,3\n",
      "            train score: 0.9709559141297536 with variance: 2.509761498095945e-05\n",
      "            test  score: 0.967761415275449 with variance: 0.00039504712021895376\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877654 using:1.0,3\n",
      "            train score: 0.9714159821231864 with variance: 2.307044792018887e-05\n",
      "            test  score: 0.9686641697877654 with variance: 0.00036758047446933535\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.967761415275449 using:1.0,3\n",
      "            train score: 0.9709559141297536 with variance: 2.509761498095945e-05\n",
      "            test  score: 0.967761415275449 with variance: 0.00039504712021895376\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877654 using:1.0,3\n",
      "            train score: 0.9714159821231864 with variance: 2.307044792018887e-05\n",
      "            test  score: 0.9686641697877654 with variance: 0.00036758047446933535\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9680197130928324 using:1.0,5\n",
      "            train score: 0.970373163547003 with variance: 1.9093754867355186e-05\n",
      "            test  score: 0.9680197130928324 with variance: 0.00038227889911163074\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877654 using:1.0,5\n",
      "            train score: 0.9708541843703774 with variance: 1.7465377966440538e-05\n",
      "            test  score: 0.9686641697877654 with variance: 0.00036758047446933535\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9680197130928324 using:1.0,5\n",
      "            train score: 0.970373163547003 with variance: 1.9093754867355186e-05\n",
      "            test  score: 0.9680197130928324 with variance: 0.00038227889911163074\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877654 using:1.0,5\n",
      "            train score: 0.9708541843703774 with variance: 1.7465377966440538e-05\n",
      "            test  score: 0.9686641697877654 with variance: 0.00036758047446933535\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9680197130928324 using:1.0,5\n",
      "            train score: 0.970373163547003 with variance: 1.9093754867355186e-05\n",
      "            test  score: 0.9680197130928324 with variance: 0.00038227889911163074\n",
      "          Refitted train score: 0.9703872437357632,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9686641697877654 using:1.0,5\n",
      "            train score: 0.9708541843703774 with variance: 1.7465377966440538e-05\n",
      "            test  score: 0.9686641697877654 with variance: 0.00036758047446933535\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9700436180838585 using:1.0,10\n",
      "            train score: 0.9789237339095695 with variance: 4.7844531543307116e-05\n",
      "            test  score: 0.9700436180838585 with variance: 0.00039883571349757314\n",
      "          Refitted train score: 0.9772727272727272,  RMSE: 0.14973818705886996, Log-Loss:0.7744156124304207\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9709113607990012 using:1.0,10\n",
      "            train score: 0.9792669876939539 with variance: 4.570596788933312e-05\n",
      "            test  score: 0.9709113607990012 with variance: 0.0003771191129689635\n",
      "          Refitted train score: 0.9775784753363229,  RMSE: 0.14973818705886996, Log-Loss:0.7744156124304207\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        f1\n",
      "          CV score: 0.9700436180838585 using:1.0,10\n",
      "            train score: 0.9789237339095695 with variance: 4.7844531543307116e-05\n",
      "            test  score: 0.9700436180838585 with variance: 0.00039883571349757314\n",
      "          Refitted train score: 0.9772727272727272,  RMSE: 0.14973818705886996, Log-Loss:0.7744156124304207\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9709113607990012 using:1.0,10\n",
      "            train score: 0.9792669876939539 with variance: 4.570596788933312e-05\n",
      "            test  score: 0.9709113607990012 with variance: 0.0003771191129689635\n",
      "          Refitted train score: 0.9775784753363229,  RMSE: 0.14973818705886996, Log-Loss:0.7744156124304207\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        f1\n",
      "          CV score: 0.9700436180838585 using:1.0,10\n",
      "            train score: 0.9789237339095695 with variance: 4.7844531543307116e-05\n",
      "            test  score: 0.9700436180838585 with variance: 0.00039883571349757314\n",
      "          Refitted train score: 0.9772727272727272,  RMSE: 0.14973818705886996, Log-Loss:0.7744156124304207\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9709113607990012 using:1.0,10\n",
      "            train score: 0.9792669876939539 with variance: 4.570596788933312e-05\n",
      "            test  score: 0.9709113607990012 with variance: 0.0003771191129689635\n",
      "          Refitted train score: 0.9775784753363229,  RMSE: 0.14973818705886996, Log-Loss:0.7744156124304207\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9677005347593584 using:1.0,15\n",
      "            train score: 0.9835111025195771 with variance: 3.4098984799045545e-05\n",
      "            test  score: 0.9677005347593584 with variance: 0.0004880722926020181\n",
      "          Refitted train score: 0.9818181818181819,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,15\n",
      "            train score: 0.9837503540742139 with variance: 3.257354490050731e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0004640042643325053\n",
      "          Refitted train score: 0.9820627802690582,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9677005347593584 using:1.0,15\n",
      "            train score: 0.9835111025195771 with variance: 3.4098984799045545e-05\n",
      "            test  score: 0.9677005347593584 with variance: 0.0004880722926020181\n",
      "          Refitted train score: 0.9818181818181819,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,15\n",
      "            train score: 0.9837503540742139 with variance: 3.257354490050731e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0004640042643325053\n",
      "          Refitted train score: 0.9820627802690582,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9677005347593584 using:1.0,15\n",
      "            train score: 0.9835111025195771 with variance: 3.4098984799045545e-05\n",
      "            test  score: 0.9677005347593584 with variance: 0.0004880722926020181\n",
      "          Refitted train score: 0.9818181818181819,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,15\n",
      "            train score: 0.9837503540742139 with variance: 3.257354490050731e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0004640042643325053\n",
      "          Refitted train score: 0.9820627802690582,  RMSE: 0.133929906036485, Log-Loss:0.6195314142527265\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9677005347593584 using:1.0,25\n",
      "            train score: 0.989241465999774 with variance: 1.0998159632578078e-05\n",
      "            test  score: 0.9677005347593584 with variance: 0.0004880722926020181\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,25\n",
      "            train score: 0.9893525949705726 with variance: 1.0639236918667059e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0004640042643325053\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9677005347593584 using:1.0,25\n",
      "            train score: 0.989241465999774 with variance: 1.0998159632578078e-05\n",
      "            test  score: 0.9677005347593584 with variance: 0.0004880722926020181\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,25\n",
      "            train score: 0.9893525949705726 with variance: 1.0639236918667059e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0004640042643325053\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9677005347593584 using:1.0,25\n",
      "            train score: 0.989241465999774 with variance: 1.0998159632578078e-05\n",
      "            test  score: 0.9677005347593584 with variance: 0.0004880722926020181\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9686891385767791 using:1.0,25\n",
      "            train score: 0.9893525949705726 with variance: 1.0639236918667059e-05\n",
      "            test  score: 0.9686891385767791 with variance: 0.0004640042643325053\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9680142220557844 using:1.0,50\n",
      "            train score: 0.989241465999774 with variance: 1.0998159632578078e-05\n",
      "            test  score: 0.9680142220557844 with variance: 0.0006747348420920519\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657927 using:1.0,50\n",
      "            train score: 0.9893525949705726 with variance: 1.0639236918667059e-05\n",
      "            test  score: 0.9687141073657927 with variance: 0.0006603081977740044\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9680142220557844 using:1.0,50\n",
      "            train score: 0.989241465999774 with variance: 1.0998159632578078e-05\n",
      "            test  score: 0.9680142220557844 with variance: 0.0006747348420920519\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657927 using:1.0,50\n",
      "            train score: 0.9893525949705726 with variance: 1.0639236918667059e-05\n",
      "            test  score: 0.9687141073657927 with variance: 0.0006603081977740044\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9727635380170877 using:1.5,50\n",
      "            train score: 0.9909475846598467 with variance: 4.527595697861079e-06\n",
      "            test  score: 0.9727635380170877 with variance: 0.0005259283305873984\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9731835205992511 using:1.5,50\n",
      "            train score: 0.9910332672394802 with variance: 4.372795554723444e-06\n",
      "            test  score: 0.9731835205992511 with variance: 0.0005232560423066667\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9680142220557844 using:1.0,100\n",
      "            train score: 0.9966228477545231 with variance: 1.2911880328071358e-06\n",
      "            test  score: 0.9680142220557844 with variance: 0.0006747348420920519\n",
      "          Refitted train score: 0.9954954954954954,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834485\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657927 using:1.0,100\n",
      "            train score: 0.9966370817990118 with variance: 1.2536508200592913e-06\n",
      "            test  score: 0.9687141073657927 with variance: 0.0006603081977740044\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834485\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9680142220557844 using:1.0,100\n",
      "            train score: 0.9966228477545231 with variance: 1.2911880328071358e-06\n",
      "            test  score: 0.9680142220557844 with variance: 0.0006747348420920519\n",
      "          Refitted train score: 0.9954954954954954,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834485\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657927 using:1.0,100\n",
      "            train score: 0.9966370817990118 with variance: 1.2536508200592913e-06\n",
      "            test  score: 0.9687141073657927 with variance: 0.0006603081977740044\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834485\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        f1\n",
      "          CV score: 0.9680142220557844 using:1.0,100\n",
      "            train score: 0.9966228477545231 with variance: 1.2911880328071358e-06\n",
      "            test  score: 0.9680142220557844 with variance: 0.0006747348420920519\n",
      "          Refitted train score: 0.9954954954954954,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834485\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9687141073657927 using:1.0,100\n",
      "            train score: 0.9966370817990118 with variance: 1.2536508200592913e-06\n",
      "            test  score: 0.9687141073657927 with variance: 0.0006603081977740044\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834485\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9447073355793133 using:1.0,2\n",
      "            train score: 0.9481597534760298 with variance: 9.597531656968126e-06\n",
      "            test  score: 0.9447073355793133 with variance: 0.00018331115747789495\n",
      "          Refitted train score: 0.9471264367816091,  RMSE: 0.22863229709016894, Log-Loss:1.8054523942268585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9454545454545453 using:1.0,2\n",
      "            train score: 0.9488636363636364 with variance: 9.684917355371693e-06\n",
      "            test  score: 0.9454545454545453 with variance: 0.0001756198347107447\n",
      "          Refitted train score: 0.9477272727272728,  RMSE: 0.22863229709016894, Log-Loss:1.8054523942268585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9447073355793133 using:1.0,2\n",
      "            train score: 0.9481597534760298 with variance: 9.597531656968126e-06\n",
      "            test  score: 0.9447073355793133 with variance: 0.00018331115747789495\n",
      "          Refitted train score: 0.9471264367816091,  RMSE: 0.22863229709016894, Log-Loss:1.8054523942268585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9454545454545453 using:1.0,2\n",
      "            train score: 0.9488636363636364 with variance: 9.684917355371693e-06\n",
      "            test  score: 0.9454545454545453 with variance: 0.0001756198347107447\n",
      "          Refitted train score: 0.9477272727272728,  RMSE: 0.22863229709016894, Log-Loss:1.8054523942268585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9447073355793133 using:1.0,2\n",
      "            train score: 0.9481597534760298 with variance: 9.597531656968126e-06\n",
      "            test  score: 0.9447073355793133 with variance: 0.00018331115747789495\n",
      "          Refitted train score: 0.9471264367816091,  RMSE: 0.22863229709016894, Log-Loss:1.8054523942268585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9454545454545453 using:1.0,2\n",
      "            train score: 0.9488636363636364 with variance: 9.684917355371693e-06\n",
      "            test  score: 0.9454545454545453 with variance: 0.0001756198347107447\n",
      "          Refitted train score: 0.9477272727272728,  RMSE: 0.22863229709016894, Log-Loss:1.8054523942268585\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9653002928954626 using:1.0,3\n",
      "            train score: 0.9659937001792723 with variance: 4.666332490105221e-06\n",
      "            test  score: 0.9653002928954626 with variance: 0.00026805018162293683\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:1.0,3\n",
      "            train score: 0.9664772727272727 with variance: 4.519628099173608e-06\n",
      "            test  score: 0.965909090909091 with variance: 0.00025826446280991693\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9653002928954626 using:1.0,3\n",
      "            train score: 0.9659937001792723 with variance: 4.666332490105221e-06\n",
      "            test  score: 0.9653002928954626 with variance: 0.00026805018162293683\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:1.0,3\n",
      "            train score: 0.9664772727272727 with variance: 4.519628099173608e-06\n",
      "            test  score: 0.965909090909091 with variance: 0.00025826446280991693\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9653002928954626 using:1.0,3\n",
      "            train score: 0.9659937001792723 with variance: 4.666332490105221e-06\n",
      "            test  score: 0.9653002928954626 with variance: 0.00026805018162293683\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:1.0,3\n",
      "            train score: 0.9664772727272727 with variance: 4.519628099173608e-06\n",
      "            test  score: 0.965909090909091 with variance: 0.00025826446280991693\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9634544376013313 using:1.0,5\n",
      "            train score: 0.9666269170890059 with variance: 2.1912258072979687e-05\n",
      "            test  score: 0.9634544376013313 with variance: 0.00021425063399916575\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:1.0,5\n",
      "            train score: 0.9670454545454545 with variance: 2.1306818181818204e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9634544376013313 using:1.0,5\n",
      "            train score: 0.9666269170890059 with variance: 2.1912258072979687e-05\n",
      "            test  score: 0.9634544376013313 with variance: 0.00021425063399916575\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:1.0,5\n",
      "            train score: 0.9670454545454545 with variance: 2.1306818181818204e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9634544376013313 using:1.0,5\n",
      "            train score: 0.9666269170890059 with variance: 2.1912258072979687e-05\n",
      "            test  score: 0.9634544376013313 with variance: 0.00021425063399916575\n",
      "          Refitted train score: 0.967741935483871,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:1.0,5\n",
      "            train score: 0.9670454545454545 with variance: 2.1306818181818204e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9681818181818181,  RMSE: 0.17837651700316892, Log-Loss:1.0989683361783424\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.964560260103285 using:1.0,10\n",
      "            train score: 0.9721387715506836 with variance: 2.994644459969846e-05\n",
      "            test  score: 0.964560260103285 with variance: 0.0005953827180770878\n",
      "          Refitted train score: 0.9720930232558139,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189972\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:1.0,10\n",
      "            train score: 0.9727272727272727 with variance: 2.7763429752066048e-05\n",
      "            test  score: 0.965909090909091 with variance: 0.0005165289256198353\n",
      "          Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189972\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.964560260103285 using:1.0,10\n",
      "            train score: 0.9721387715506836 with variance: 2.994644459969846e-05\n",
      "            test  score: 0.964560260103285 with variance: 0.0005953827180770878\n",
      "          Refitted train score: 0.9720930232558139,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189972\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:1.0,10\n",
      "            train score: 0.9727272727272727 with variance: 2.7763429752066048e-05\n",
      "            test  score: 0.965909090909091 with variance: 0.0005165289256198353\n",
      "          Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189972\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.964560260103285 using:1.0,10\n",
      "            train score: 0.9721387715506836 with variance: 2.994644459969846e-05\n",
      "            test  score: 0.964560260103285 with variance: 0.0005953827180770878\n",
      "          Refitted train score: 0.9720930232558139,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189972\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.965909090909091 using:1.0,10\n",
      "            train score: 0.9727272727272727 with variance: 2.7763429752066048e-05\n",
      "            test  score: 0.965909090909091 with variance: 0.0005165289256198353\n",
      "          Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189972\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9788713253608302 using:1.0,15\n",
      "            train score: 0.9850273438826079 with variance: 1.1679398635464773e-05\n",
      "            test  score: 0.9788713253608302 with variance: 0.00030790170234719203\n",
      "          Refitted train score: 0.9839080459770115,  RMSE: 0.12613124477737825, Log-Loss:0.549482350822285\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9795454545454545 using:1.0,15\n",
      "            train score: 0.9852272727272726 with variance: 1.0976239669421582e-05\n",
      "            test  score: 0.9795454545454545 with variance: 0.00027892561983471027\n",
      "          Refitted train score: 0.9840909090909091,  RMSE: 0.12613124477737825, Log-Loss:0.549482350822285\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9788713253608302 using:1.0,15\n",
      "            train score: 0.9850273438826079 with variance: 1.1679398635464773e-05\n",
      "            test  score: 0.9788713253608302 with variance: 0.00030790170234719203\n",
      "          Refitted train score: 0.9839080459770115,  RMSE: 0.12613124477737825, Log-Loss:0.549482350822285\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9795454545454545 using:1.0,15\n",
      "            train score: 0.9852272727272726 with variance: 1.0976239669421582e-05\n",
      "            test  score: 0.9795454545454545 with variance: 0.00027892561983471027\n",
      "          Refitted train score: 0.9840909090909091,  RMSE: 0.12613124477737825, Log-Loss:0.549482350822285\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9788713253608302 using:1.0,15\n",
      "            train score: 0.9850273438826079 with variance: 1.1679398635464773e-05\n",
      "            test  score: 0.9788713253608302 with variance: 0.00030790170234719203\n",
      "          Refitted train score: 0.9839080459770115,  RMSE: 0.12613124477737825, Log-Loss:0.549482350822285\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9795454545454545 using:1.0,15\n",
      "            train score: 0.9852272727272726 with variance: 1.0976239669421582e-05\n",
      "            test  score: 0.9795454545454545 with variance: 0.00027892561983471027\n",
      "          Refitted train score: 0.9840909090909091,  RMSE: 0.12613124477737825, Log-Loss:0.549482350822285\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9742207496106265 using:1.0,25\n",
      "            train score: 0.988512202186057 with variance: 3.436617043656408e-06\n",
      "            test  score: 0.9742207496106265 with variance: 0.0002495522983397169\n",
      "          Refitted train score: 0.9885057471264368,  RMSE: 0.10660035817780522, Log-Loss:0.3924860953967133\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.975 using:1.0,25\n",
      "            train score: 0.9886363636363636 with variance: 3.228305785123898e-06\n",
      "            test  score: 0.975 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9886363636363636,  RMSE: 0.10660035817780522, Log-Loss:0.3924860953967133\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9742207496106265 using:1.0,25\n",
      "            train score: 0.988512202186057 with variance: 3.436617043656408e-06\n",
      "            test  score: 0.9742207496106265 with variance: 0.0002495522983397169\n",
      "          Refitted train score: 0.9885057471264368,  RMSE: 0.10660035817780522, Log-Loss:0.3924860953967133\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.975 using:1.0,25\n",
      "            train score: 0.9886363636363636 with variance: 3.228305785123898e-06\n",
      "            test  score: 0.975 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9886363636363636,  RMSE: 0.10660035817780522, Log-Loss:0.3924860953967133\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9742207496106265 using:1.0,25\n",
      "            train score: 0.988512202186057 with variance: 3.436617043656408e-06\n",
      "            test  score: 0.9742207496106265 with variance: 0.0002495522983397169\n",
      "          Refitted train score: 0.9885057471264368,  RMSE: 0.10660035817780522, Log-Loss:0.3924860953967133\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.975 using:1.0,25\n",
      "            train score: 0.9886363636363636 with variance: 3.228305785123898e-06\n",
      "            test  score: 0.975 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9886363636363636,  RMSE: 0.10660035817780522, Log-Loss:0.3924860953967133\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9742207496106264 using:1.0,50\n",
      "            train score: 0.9908210462922448 with variance: 4.680968307211825e-06\n",
      "            test  score: 0.9742207496106264 with variance: 0.0002495522983397169\n",
      "          Refitted train score: 0.9908256880733944,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.975 using:1.0,50\n",
      "            train score: 0.9909090909090909 with variance: 4.519628099173458e-06\n",
      "            test  score: 0.975 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.990909090909091,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9742207496106264 using:1.0,50\n",
      "            train score: 0.9908210462922448 with variance: 4.680968307211825e-06\n",
      "            test  score: 0.9742207496106264 with variance: 0.0002495522983397169\n",
      "          Refitted train score: 0.9908256880733944,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.975 using:1.0,50\n",
      "            train score: 0.9909090909090909 with variance: 4.519628099173458e-06\n",
      "            test  score: 0.975 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.990909090909091,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.9768498942917547 using:1.5,50\n",
      "            train score: 0.991397386857124 with variance: 6.681615043810283e-06\n",
      "            test  score: 0.9768498942917547 with variance: 0.00021637784998815505\n",
      "          Refitted train score: 0.9908256880733944,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9772727272727273 using:1.5,50\n",
      "            train score: 0.9914772727272727 with variance: 6.456611570247796e-06\n",
      "            test  score: 0.9772727272727273 with variance: 0.0002066115702479335\n",
      "          Refitted train score: 0.990909090909091,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.976742299165055 using:1.0,100\n",
      "            train score: 0.9954318274318276 with variance: 1.9703630155402194e-06\n",
      "            test  score: 0.976742299165055 with variance: 0.00016235958144333727\n",
      "          Refitted train score: 0.995433789954338,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868594\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9772727272727273 using:1.0,100\n",
      "            train score: 0.9954545454545455 with variance: 1.9369834710744903e-06\n",
      "            test  score: 0.9772727272727273 with variance: 0.00015495867768595012\n",
      "          Refitted train score: 0.9954545454545455,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868594\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.976742299165055 using:1.0,100\n",
      "            train score: 0.9954318274318276 with variance: 1.9703630155402194e-06\n",
      "            test  score: 0.976742299165055 with variance: 0.00016235958144333727\n",
      "          Refitted train score: 0.995433789954338,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868594\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9772727272727273 using:1.0,100\n",
      "            train score: 0.9954545454545455 with variance: 1.9369834710744903e-06\n",
      "            test  score: 0.9772727272727273 with variance: 0.00015495867768595012\n",
      "          Refitted train score: 0.9954545454545455,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868594\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        f1\n",
      "          CV score: 0.976742299165055 using:1.0,100\n",
      "            train score: 0.9954318274318276 with variance: 1.9703630155402194e-06\n",
      "            test  score: 0.976742299165055 with variance: 0.00016235958144333727\n",
      "          Refitted train score: 0.995433789954338,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868594\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9772727272727273 using:1.0,100\n",
      "            train score: 0.9954545454545455 with variance: 1.9369834710744903e-06\n",
      "            test  score: 0.9772727272727273 with variance: 0.00015495867768595012\n",
      "          Refitted train score: 0.9954545454545455,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868594\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9490618000330724 using:1.0,2\n",
      "            train score: 0.9516761695206866 with variance: 3.5234293979303285e-05\n",
      "            test  score: 0.9490618000330724 with variance: 0.0007370250562121998\n",
      "          Refitted train score: 0.9523809523809524,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9504761904761905 using:1.0,2\n",
      "            train score: 0.9522401526982474 with variance: 3.275397038958835e-05\n",
      "            test  score: 0.9504761904761905 with variance: 0.0005753014931462778\n",
      "          Refitted train score: 0.9528301886792453,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9490618000330724 using:1.0,2\n",
      "            train score: 0.9516761695206866 with variance: 3.5234293979303285e-05\n",
      "            test  score: 0.9490618000330724 with variance: 0.0007370250562121998\n",
      "          Refitted train score: 0.9523809523809524,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9504761904761905 using:1.0,2\n",
      "            train score: 0.9522401526982474 with variance: 3.275397038958835e-05\n",
      "            test  score: 0.9504761904761905 with variance: 0.0005753014931462778\n",
      "          Refitted train score: 0.9528301886792453,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9490618000330724 using:1.0,2\n",
      "            train score: 0.9516761695206866 with variance: 3.5234293979303285e-05\n",
      "            test  score: 0.9490618000330724 with variance: 0.0007370250562121998\n",
      "          Refitted train score: 0.9523809523809524,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9504761904761905 using:1.0,2\n",
      "            train score: 0.9522401526982474 with variance: 3.275397038958835e-05\n",
      "            test  score: 0.9504761904761905 with variance: 0.0005753014931462778\n",
      "          Refitted train score: 0.9528301886792453,  RMSE: 0.2171861213815347, Log-Loss:1.6292026525416403\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9607183696376582 using:1.0,3\n",
      "            train score: 0.9624162662129319 with variance: 8.102319727600489e-05\n",
      "            test  score: 0.9607183696376582 with variance: 0.0011672690157539297\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9622689075630252 using:1.0,3\n",
      "            train score: 0.9628544161027243 with variance: 7.861153542847533e-05\n",
      "            test  score: 0.9622689075630252 with variance: 0.0009629545936021466\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9607183696376582 using:1.0,3\n",
      "            train score: 0.9624162662129319 with variance: 8.102319727600489e-05\n",
      "            test  score: 0.9607183696376582 with variance: 0.0011672690157539297\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9622689075630252 using:1.0,3\n",
      "            train score: 0.9628544161027243 with variance: 7.861153542847533e-05\n",
      "            test  score: 0.9622689075630252 with variance: 0.0009629545936021466\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9607183696376582 using:1.0,3\n",
      "            train score: 0.9624162662129319 with variance: 8.102319727600489e-05\n",
      "            test  score: 0.9607183696376582 with variance: 0.0011672690157539297\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9622689075630252 using:1.0,3\n",
      "            train score: 0.9628544161027243 with variance: 7.861153542847533e-05\n",
      "            test  score: 0.9622689075630252 with variance: 0.0009629545936021466\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.19425717247145283, Log-Loss:1.3033613676961142\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9658065899306439 using:1.0,5\n",
      "            train score: 0.9670448440808777 with variance: 4.838530970763359e-05\n",
      "            test  score: 0.9658065899306439 with variance: 0.0008717520933544356\n",
      "          Refitted train score: 0.9665071770334929,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:1.0,5\n",
      "            train score: 0.9675707096998091 with variance: 4.5249932336548446e-05\n",
      "            test  score: 0.9670028011204481 with variance: 0.0007408265266891076\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9658065899306439 using:1.0,5\n",
      "            train score: 0.9670448440808777 with variance: 4.838530970763359e-05\n",
      "            test  score: 0.9658065899306439 with variance: 0.0008717520933544356\n",
      "          Refitted train score: 0.9665071770334929,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:1.0,5\n",
      "            train score: 0.9675707096998091 with variance: 4.5249932336548446e-05\n",
      "            test  score: 0.9670028011204481 with variance: 0.0007408265266891076\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9658065899306439 using:1.0,5\n",
      "            train score: 0.9670448440808777 with variance: 4.838530970763359e-05\n",
      "            test  score: 0.9658065899306439 with variance: 0.0008717520933544356\n",
      "          Refitted train score: 0.9665071770334929,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:1.0,5\n",
      "            train score: 0.9675707096998091 with variance: 4.5249932336548446e-05\n",
      "            test  score: 0.9670028011204481 with variance: 0.0007408265266891076\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.18171094607790775, Log-Loss:1.1404388394303555\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9655250808574154 using:1.0,10\n",
      "            train score: 0.9783780850155654 with variance: 3.441496372762655e-05\n",
      "            test  score: 0.9655250808574154 with variance: 0.0008131193700111566\n",
      "          Refitted train score: 0.9784172661870504,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519498\n",
      "          Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:1.0,10\n",
      "            train score: 0.9787749436057608 with variance: 3.265338075330155e-05\n",
      "            test  score: 0.9670028011204481 with variance: 0.0006854632048898004\n",
      "          Refitted train score: 0.9787735849056604,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519498\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        f1\n",
      "          CV score: 0.9655250808574154 using:1.0,10\n",
      "            train score: 0.9783780850155654 with variance: 3.441496372762655e-05\n",
      "            test  score: 0.9655250808574154 with variance: 0.0008131193700111566\n",
      "          Refitted train score: 0.9784172661870504,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519498\n",
      "          Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:1.0,10\n",
      "            train score: 0.9787749436057608 with variance: 3.265338075330155e-05\n",
      "            test  score: 0.9670028011204481 with variance: 0.0006854632048898004\n",
      "          Refitted train score: 0.9787735849056604,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519498\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        f1\n",
      "          CV score: 0.9655250808574154 using:1.0,10\n",
      "            train score: 0.9783780850155654 with variance: 3.441496372762655e-05\n",
      "            test  score: 0.9655250808574154 with variance: 0.0008131193700111566\n",
      "          Refitted train score: 0.9784172661870504,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519498\n",
      "          Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9670028011204481 using:1.0,10\n",
      "            train score: 0.9787749436057608 with variance: 3.265338075330155e-05\n",
      "            test  score: 0.9670028011204481 with variance: 0.0006854632048898004\n",
      "          Refitted train score: 0.9787735849056604,  RMSE: 0.14569287935358963, Log-Loss:0.7331362904519498\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.98048210270275 using:1.0,15\n",
      "            train score: 0.9868512969259238 with variance: 1.2947968369816636e-05\n",
      "            test  score: 0.98048210270275 with variance: 0.0004668758769927\n",
      "          Refitted train score: 0.985645933014354,  RMSE: 0.11895773785772162, Log-Loss:0.4887562697393031\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9811484593837536 using:1.0,15\n",
      "            train score: 0.9870293250043382 with variance: 1.2499936393795913e-05\n",
      "            test  score: 0.9811484593837536 with variance: 0.0004203689318864806\n",
      "          Refitted train score: 0.9858490566037735,  RMSE: 0.11895773785772162, Log-Loss:0.4887562697393031\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        f1\n",
      "          CV score: 0.98048210270275 using:1.0,15\n",
      "            train score: 0.9868512969259238 with variance: 1.2947968369816636e-05\n",
      "            test  score: 0.98048210270275 with variance: 0.0004668758769927\n",
      "          Refitted train score: 0.985645933014354,  RMSE: 0.11895773785772162, Log-Loss:0.4887562697393031\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9811484593837536 using:1.0,15\n",
      "            train score: 0.9870293250043382 with variance: 1.2499936393795913e-05\n",
      "            test  score: 0.9811484593837536 with variance: 0.0004203689318864806\n",
      "          Refitted train score: 0.9858490566037735,  RMSE: 0.11895773785772162, Log-Loss:0.4887562697393031\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        f1\n",
      "          CV score: 0.98048210270275 using:1.0,15\n",
      "            train score: 0.9868512969259238 with variance: 1.2947968369816636e-05\n",
      "            test  score: 0.98048210270275 with variance: 0.0004668758769927\n",
      "          Refitted train score: 0.985645933014354,  RMSE: 0.11895773785772162, Log-Loss:0.4887562697393031\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9811484593837536 using:1.0,15\n",
      "            train score: 0.9870293250043382 with variance: 1.2499936393795913e-05\n",
      "            test  score: 0.9811484593837536 with variance: 0.0004203689318864806\n",
      "          Refitted train score: 0.9858490566037735,  RMSE: 0.11895773785772162, Log-Loss:0.4887562697393031\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9757201979408453 using:1.0,25\n",
      "            train score: 0.9892643392203022 with variance: 1.64344712942235e-05\n",
      "            test  score: 0.9757201979408453 with variance: 0.00037169408867421917\n",
      "          Refitted train score: 0.9880668257756563,  RMSE: 0.10859306069076735, Log-Loss:0.40729689144941944\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9764425770308124 using:1.0,25\n",
      "            train score: 0.9893874718028804 with variance: 1.599481202206324e-05\n",
      "            test  score: 0.9764425770308124 with variance: 0.0003315239821418771\n",
      "          Refitted train score: 0.9882075471698113,  RMSE: 0.10859306069076735, Log-Loss:0.40729689144941944\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        f1\n",
      "          CV score: 0.9757201979408453 using:1.0,25\n",
      "            train score: 0.9892643392203022 with variance: 1.64344712942235e-05\n",
      "            test  score: 0.9757201979408453 with variance: 0.00037169408867421917\n",
      "          Refitted train score: 0.9880668257756563,  RMSE: 0.10859306069076735, Log-Loss:0.40729689144941944\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9764425770308124 using:1.0,25\n",
      "            train score: 0.9893874718028804 with variance: 1.599481202206324e-05\n",
      "            test  score: 0.9764425770308124 with variance: 0.0003315239821418771\n",
      "          Refitted train score: 0.9882075471698113,  RMSE: 0.10859306069076735, Log-Loss:0.40729689144941944\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        f1\n",
      "          CV score: 0.9757201979408453 using:1.0,25\n",
      "            train score: 0.9892643392203022 with variance: 1.64344712942235e-05\n",
      "            test  score: 0.9757201979408453 with variance: 0.00037169408867421917\n",
      "          Refitted train score: 0.9880668257756563,  RMSE: 0.10859306069076735, Log-Loss:0.40729689144941944\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9764425770308124 using:1.0,25\n",
      "            train score: 0.9893874718028804 with variance: 1.599481202206324e-05\n",
      "            test  score: 0.9764425770308124 with variance: 0.0003315239821418771\n",
      "          Refitted train score: 0.9882075471698113,  RMSE: 0.10859306069076735, Log-Loss:0.40729689144941944\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9781291615262795 using:1.0,50\n",
      "            train score: 0.9910731632216198 with variance: 1.0650573954626005e-05\n",
      "            test  score: 0.9781291615262795 with variance: 0.0003971722772547758\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9787955182072829 using:1.0,50\n",
      "            train score: 0.9911573833073053 with variance: 1.0401199632580373e-05\n",
      "            test  score: 0.9787955182072829 with variance: 0.0003538011282944559\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        f1\n",
      "          CV score: 0.9781291615262795 using:1.0,50\n",
      "            train score: 0.9910731632216198 with variance: 1.0650573954626005e-05\n",
      "            test  score: 0.9781291615262795 with variance: 0.0003971722772547758\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9787955182072829 using:1.0,50\n",
      "            train score: 0.9911573833073053 with variance: 1.0401199632580373e-05\n",
      "            test  score: 0.9787955182072829 with variance: 0.0003538011282944559\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        f1\n",
      "          CV score: 0.9781291615262795 using:1.0,50\n",
      "            train score: 0.9910731632216198 with variance: 1.0650573954626005e-05\n",
      "            test  score: 0.9781291615262795 with variance: 0.0003971722772547758\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9787955182072829 using:1.0,50\n",
      "            train score: 0.9911573833073053 with variance: 1.0401199632580373e-05\n",
      "            test  score: 0.9787955182072829 with variance: 0.0003538011282944559\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9781291615262795 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9781291615262795 with variance: 0.0003971722772547758\n",
      "          Refitted train score: 0.9976359338061466,  RMSE: 0.04856429311786321, Log-Loss:0.08145937828988467\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9787955182072829 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9787955182072829 with variance: 0.0003538011282944559\n",
      "          Refitted train score: 0.9976415094339622,  RMSE: 0.04856429311786321, Log-Loss:0.08145937828988467\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        f1\n",
      "          CV score: 0.9781291615262795 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9781291615262795 with variance: 0.0003971722772547758\n",
      "          Refitted train score: 0.9976359338061466,  RMSE: 0.04856429311786321, Log-Loss:0.08145937828988467\n",
      "          Refitted test  score: 0.9736842105263158,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9787955182072829 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9787955182072829 with variance: 0.0003538011282944559\n",
      "          Refitted train score: 0.9976415094339622,  RMSE: 0.04856429311786321, Log-Loss:0.08145937828988467\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        f1\n",
      "          CV score: 0.9805388000804964 using:1.5,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9805388000804964 with variance: 0.00046773576068161936\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.961038961038961,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "        accuracy\n",
      "          CV score: 0.9811764705882353 using:1.5,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9811764705882353 with variance: 0.00042076124567474104\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9597058031982073 using:1.0,2\n",
      "            train score: 0.9623144702120834 with variance: 3.912135834848892e-05\n",
      "            test  score: 0.9597058031982073 with variance: 0.00041649719651216493\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.1933472978091327, Log-Loss:1.2911804203344683\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.960328317373461 using:1.0,2\n",
      "            train score: 0.962619132866179 with variance: 3.8756290858740995e-05\n",
      "            test  score: 0.960328317373461 with variance: 0.0004110779042632233\n",
      "          Refitted train score: 0.9626168224299065,  RMSE: 0.1933472978091327, Log-Loss:1.2911804203344683\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        f1\n",
      "          CV score: 0.9597058031982073 using:1.0,2\n",
      "            train score: 0.9623144702120834 with variance: 3.912135834848892e-05\n",
      "            test  score: 0.9597058031982073 with variance: 0.00041649719651216493\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.1933472978091327, Log-Loss:1.2911804203344683\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.960328317373461 using:1.0,2\n",
      "            train score: 0.962619132866179 with variance: 3.8756290858740995e-05\n",
      "            test  score: 0.960328317373461 with variance: 0.0004110779042632233\n",
      "          Refitted train score: 0.9626168224299065,  RMSE: 0.1933472978091327, Log-Loss:1.2911804203344683\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        f1\n",
      "          CV score: 0.9597058031982073 using:1.0,2\n",
      "            train score: 0.9623144702120834 with variance: 3.912135834848892e-05\n",
      "            test  score: 0.9597058031982073 with variance: 0.00041649719651216493\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.1933472978091327, Log-Loss:1.2911804203344683\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.960328317373461 using:1.0,2\n",
      "            train score: 0.962619132866179 with variance: 3.8756290858740995e-05\n",
      "            test  score: 0.960328317373461 with variance: 0.0004110779042632233\n",
      "          Refitted train score: 0.9626168224299065,  RMSE: 0.1933472978091327, Log-Loss:1.2911804203344683\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9737768809227056 using:1.0,3\n",
      "            train score: 0.9744803455251217 with variance: 5.624471019168703e-06\n",
      "            test  score: 0.9737768809227056 with variance: 0.00019598291781702023\n",
      "          Refitted train score: 0.976303317535545,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9743091655266758 using:1.0,3\n",
      "            train score: 0.9748844901369068 with variance: 5.381482971202419e-06\n",
      "            test  score: 0.9743091655266758 with variance: 0.00018467215983202347\n",
      "          Refitted train score: 0.9766355140186916,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        f1\n",
      "          CV score: 0.9737768809227056 using:1.0,3\n",
      "            train score: 0.9744803455251217 with variance: 5.624471019168703e-06\n",
      "            test  score: 0.9737768809227056 with variance: 0.00019598291781702023\n",
      "          Refitted train score: 0.976303317535545,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9743091655266758 using:1.0,3\n",
      "            train score: 0.9748844901369068 with variance: 5.381482971202419e-06\n",
      "            test  score: 0.9743091655266758 with variance: 0.00018467215983202347\n",
      "          Refitted train score: 0.9766355140186916,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        f1\n",
      "          CV score: 0.9737768809227056 using:1.0,3\n",
      "            train score: 0.9744803455251217 with variance: 5.624471019168703e-06\n",
      "            test  score: 0.9737768809227056 with variance: 0.00019598291781702023\n",
      "          Refitted train score: 0.976303317535545,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9743091655266758 using:1.0,3\n",
      "            train score: 0.9748844901369068 with variance: 5.381482971202419e-06\n",
      "            test  score: 0.9743091655266758 with variance: 0.00018467215983202347\n",
      "          Refitted train score: 0.9766355140186916,  RMSE: 0.15285446012893575, Log-Loss:0.8069844933270272\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.966768372190059 using:1.0,5\n",
      "            train score: 0.9745467477359169 with variance: 8.793643686360002e-06\n",
      "            test  score: 0.966768372190059 with variance: 0.0004230694443964985\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        accuracy\n",
      "          CV score: 0.9673324213406292 using:1.0,5\n",
      "            train score: 0.9748861950795356 with variance: 8.717726613377554e-06\n",
      "            test  score: 0.9673324213406292 with variance: 0.00039947825533674826\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        f1\n",
      "          CV score: 0.966768372190059 using:1.0,5\n",
      "            train score: 0.9745467477359169 with variance: 8.793643686360002e-06\n",
      "            test  score: 0.966768372190059 with variance: 0.0004230694443964985\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        accuracy\n",
      "          CV score: 0.9673324213406292 using:1.0,5\n",
      "            train score: 0.9748861950795356 with variance: 8.717726613377554e-06\n",
      "            test  score: 0.9673324213406292 with variance: 0.00039947825533674826\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        f1\n",
      "          CV score: 0.966768372190059 using:1.0,5\n",
      "            train score: 0.9745467477359169 with variance: 8.793643686360002e-06\n",
      "            test  score: 0.966768372190059 with variance: 0.0004230694443964985\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        accuracy\n",
      "          CV score: 0.9673324213406292 using:1.0,5\n",
      "            train score: 0.9748861950795356 with variance: 8.717726613377554e-06\n",
      "            test  score: 0.9673324213406292 with variance: 0.00039947825533674826\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876844372343656\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9761898012216935 using:1.0,10\n",
      "            train score: 0.9828102522918533 with variance: 1.1891531922623791e-05\n",
      "            test  score: 0.9761898012216935 with variance: 0.0001700599936905636\n",
      "          Refitted train score: 0.981042654028436,  RMSE: 0.13671718540493263, Log-Loss:0.645586473730645\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:1.0,10\n",
      "            train score: 0.9830630999266875 with variance: 1.1532537390025206e-05\n",
      "            test  score: 0.9766894664842681 with variance: 0.00016098180817836644\n",
      "          Refitted train score: 0.9813084112149533,  RMSE: 0.13671718540493263, Log-Loss:0.645586473730645\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        f1\n",
      "          CV score: 0.9761898012216935 using:1.0,10\n",
      "            train score: 0.9828102522918533 with variance: 1.1891531922623791e-05\n",
      "            test  score: 0.9761898012216935 with variance: 0.0001700599936905636\n",
      "          Refitted train score: 0.981042654028436,  RMSE: 0.13671718540493263, Log-Loss:0.645586473730645\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:1.0,10\n",
      "            train score: 0.9830630999266875 with variance: 1.1532537390025206e-05\n",
      "            test  score: 0.9766894664842681 with variance: 0.00016098180817836644\n",
      "          Refitted train score: 0.9813084112149533,  RMSE: 0.13671718540493263, Log-Loss:0.645586473730645\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        f1\n",
      "          CV score: 0.9761898012216935 using:1.0,10\n",
      "            train score: 0.9828102522918533 with variance: 1.1891531922623791e-05\n",
      "            test  score: 0.9761898012216935 with variance: 0.0001700599936905636\n",
      "          Refitted train score: 0.981042654028436,  RMSE: 0.13671718540493263, Log-Loss:0.645586473730645\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:1.0,10\n",
      "            train score: 0.9830630999266875 with variance: 1.1532537390025206e-05\n",
      "            test  score: 0.9766894664842681 with variance: 0.00016098180817836644\n",
      "          Refitted train score: 0.9813084112149533,  RMSE: 0.13671718540493263, Log-Loss:0.645586473730645\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9760757314974182 using:1.0,15\n",
      "            train score: 0.9857738286664448 with variance: 3.0239301992651006e-05\n",
      "            test  score: 0.9760757314974182 with variance: 5.8083329136560853e-05\n",
      "          Refitted train score: 0.983372921615202,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9766621067031463 using:1.0,15\n",
      "            train score: 0.9859768468791025 with variance: 2.88127543012604e-05\n",
      "            test  score: 0.9766621067031463 with variance: 5.345899120631929e-05\n",
      "          Refitted train score: 0.9836448598130841,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9760757314974182 using:1.0,15\n",
      "            train score: 0.9857738286664448 with variance: 3.0239301992651006e-05\n",
      "            test  score: 0.9760757314974182 with variance: 5.8083329136560853e-05\n",
      "          Refitted train score: 0.983372921615202,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9766621067031463 using:1.0,15\n",
      "            train score: 0.9859768468791025 with variance: 2.88127543012604e-05\n",
      "            test  score: 0.9766621067031463 with variance: 5.345899120631929e-05\n",
      "          Refitted train score: 0.9836448598130841,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9784846950828523 using:1.5,15\n",
      "            train score: 0.988172393217642 with variance: 2.8428722751722677e-05\n",
      "            test  score: 0.9784846950828523 with variance: 8.184858293474876e-05\n",
      "          Refitted train score: 0.988179669030733,  RMSE: 0.10808442529177922, Log-Loss:0.4034903784452193\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9789876880984952 using:1.5,15\n",
      "            train score: 0.9883143232230236 with variance: 2.7398913192717914e-05\n",
      "            test  score: 0.9789876880984952 with variance: 7.547407089963514e-05\n",
      "          Refitted train score: 0.9883177570093458,  RMSE: 0.10808442529177922, Log-Loss:0.4034903784452193\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9809517059835983 using:1.0,25\n",
      "            train score: 0.9905639013211192 with variance: 4.89820891360369e-06\n",
      "            test  score: 0.9809517059835983 with variance: 3.401200019597729e-05\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.981313269493844 using:1.0,25\n",
      "            train score: 0.9906535045095733 with variance: 4.780007652222471e-06\n",
      "            test  score: 0.981313269493844 with variance: 3.258920467623973e-05\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        f1\n",
      "          CV score: 0.9809517059835983 using:1.0,25\n",
      "            train score: 0.9905639013211192 with variance: 4.89820891360369e-06\n",
      "            test  score: 0.9809517059835983 with variance: 3.401200019597729e-05\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.981313269493844 using:1.0,25\n",
      "            train score: 0.9906535045095733 with variance: 4.780007652222471e-06\n",
      "            test  score: 0.981313269493844 with variance: 3.258920467623973e-05\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        f1\n",
      "          CV score: 0.9809517059835983 using:1.0,25\n",
      "            train score: 0.9905639013211192 with variance: 4.89820891360369e-06\n",
      "            test  score: 0.9809517059835983 with variance: 3.401200019597729e-05\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.981313269493844 using:1.0,25\n",
      "            train score: 0.9906535045095733 with variance: 4.780007652222471e-06\n",
      "            test  score: 0.981313269493844 with variance: 3.258920467623973e-05\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9786547872160913 using:1.0,50\n",
      "            train score: 0.9935276256715024 with variance: 8.353923819969947e-06\n",
      "            test  score: 0.9786547872160913 with variance: 7.69876596305521e-05\n",
      "          Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9789876880984952 using:1.0,50\n",
      "            train score: 0.9935740712325032 with variance: 8.19578795954012e-06\n",
      "            test  score: 0.9789876880984952 with variance: 7.547407089963514e-05\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9786547872160913 using:1.0,50\n",
      "            train score: 0.9935276256715024 with variance: 8.353923819969947e-06\n",
      "            test  score: 0.9786547872160913 with variance: 7.69876596305521e-05\n",
      "          Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9789876880984952 using:1.0,50\n",
      "            train score: 0.9935740712325032 with variance: 8.19578795954012e-06\n",
      "            test  score: 0.9789876880984952 with variance: 7.547407089963514e-05\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9786547872160913 using:1.0,50\n",
      "            train score: 0.9935276256715024 with variance: 8.353923819969947e-06\n",
      "            test  score: 0.9786547872160913 with variance: 7.69876596305521e-05\n",
      "          Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9789876880984952 using:1.0,50\n",
      "            train score: 0.9935740712325032 with variance: 8.19578795954012e-06\n",
      "            test  score: 0.9789876880984952 with variance: 7.547407089963514e-05\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9759575131845274 using:1.0,100\n",
      "            train score: 0.9964809082409671 with variance: 1.3962947123050205e-06\n",
      "            test  score: 0.9759575131845274 with variance: 0.00018133684614820498\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9766621067031463 using:1.0,100\n",
      "            train score: 0.9964946379554329 with variance: 1.3719478837040098e-06\n",
      "            test  score: 0.9766621067031463 with variance: 0.00016162556773417205\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9759575131845274 using:1.0,100\n",
      "            train score: 0.9964809082409671 with variance: 1.3962947123050205e-06\n",
      "            test  score: 0.9759575131845274 with variance: 0.00018133684614820498\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9766621067031463 using:1.0,100\n",
      "            train score: 0.9964946379554329 with variance: 1.3719478837040098e-06\n",
      "            test  score: 0.9766621067031463 with variance: 0.00016162556773417205\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9759575131845274 using:1.0,100\n",
      "            train score: 0.9964809082409671 with variance: 1.3962947123050205e-06\n",
      "            test  score: 0.9759575131845274 with variance: 0.00018133684614820498\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9766621067031463 using:1.0,100\n",
      "            train score: 0.9964946379554329 with variance: 1.3719478837040098e-06\n",
      "            test  score: 0.9766621067031463 with variance: 0.00016162556773417205\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "    random state: 850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.94021254167629 using:1.0,2\n",
      "            train score: 0.9413015366458242 with variance: 4.887912923426613e-05\n",
      "            test  score: 0.94021254167629 with variance: 0.0006478210627856534\n",
      "          Refitted train score: 0.9408983451536642,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9413406292749658 using:1.0,2\n",
      "            train score: 0.9419027082973951 with variance: 4.594574608954252e-05\n",
      "            test  score: 0.9413406292749658 with variance: 0.0005498784529559599\n",
      "          Refitted train score: 0.9413145539906104,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        f1\n",
      "          CV score: 0.94021254167629 using:1.0,2\n",
      "            train score: 0.9413015366458242 with variance: 4.887912923426613e-05\n",
      "            test  score: 0.94021254167629 with variance: 0.0006478210627856534\n",
      "          Refitted train score: 0.9408983451536642,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9413406292749658 using:1.0,2\n",
      "            train score: 0.9419027082973951 with variance: 4.594574608954252e-05\n",
      "            test  score: 0.9413406292749658 with variance: 0.0005498784529559599\n",
      "          Refitted train score: 0.9413145539906104,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        f1\n",
      "          CV score: 0.94021254167629 using:1.0,2\n",
      "            train score: 0.9413015366458242 with variance: 4.887912923426613e-05\n",
      "            test  score: 0.94021254167629 with variance: 0.0006478210627856534\n",
      "          Refitted train score: 0.9408983451536642,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9413406292749658 using:1.0,2\n",
      "            train score: 0.9419027082973951 with variance: 4.594574608954252e-05\n",
      "            test  score: 0.9413406292749658 with variance: 0.0005498784529559599\n",
      "          Refitted train score: 0.9413145539906104,  RMSE: 0.2422507915557546, Log-Loss:2.026944144235914\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.95893968520966 using:1.0,3\n",
      "            train score: 0.9634382756635949 with variance: 2.026016566618674e-05\n",
      "            test  score: 0.95893968520966 with variance: 0.0003627329012971076\n",
      "          Refitted train score: 0.9640287769784172,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9601094391244871 using:1.0,3\n",
      "            train score: 0.964203898568225 with variance: 1.844358117219261e-05\n",
      "            test  score: 0.9601094391244871 with variance: 0.00030853748683006357\n",
      "          Refitted train score: 0.9647887323943662,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        f1\n",
      "          CV score: 0.95893968520966 using:1.0,3\n",
      "            train score: 0.9634382756635949 with variance: 2.026016566618674e-05\n",
      "            test  score: 0.95893968520966 with variance: 0.0003627329012971076\n",
      "          Refitted train score: 0.9640287769784172,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9601094391244871 using:1.0,3\n",
      "            train score: 0.964203898568225 with variance: 1.844358117219261e-05\n",
      "            test  score: 0.9601094391244871 with variance: 0.00030853748683006357\n",
      "          Refitted train score: 0.9647887323943662,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        f1\n",
      "          CV score: 0.95893968520966 using:1.0,3\n",
      "            train score: 0.9634382756635949 with variance: 2.026016566618674e-05\n",
      "            test  score: 0.95893968520966 with variance: 0.0003627329012971076\n",
      "          Refitted train score: 0.9640287769784172,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9601094391244871 using:1.0,3\n",
      "            train score: 0.964203898568225 with variance: 1.844358117219261e-05\n",
      "            test  score: 0.9601094391244871 with variance: 0.00030853748683006357\n",
      "          Refitted train score: 0.9647887323943662,  RMSE: 0.18764665626020038, Log-Loss:1.2161597293801671\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9715235833133414 using:1.0,5\n",
      "            train score: 0.969587307249294 with variance: 1.9224279668992853e-05\n",
      "            test  score: 0.9715235833133414 with variance: 0.0005213364155441941\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9719288645690835 using:1.0,5\n",
      "            train score: 0.9700741762980852 with variance: 1.8398385797868264e-05\n",
      "            test  score: 0.9719288645690835 with variance: 0.000517690475165666\n",
      "          Refitted train score: 0.971830985915493,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9715235833133414 using:1.0,5\n",
      "            train score: 0.969587307249294 with variance: 1.9224279668992853e-05\n",
      "            test  score: 0.9715235833133414 with variance: 0.0005213364155441941\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9719288645690835 using:1.0,5\n",
      "            train score: 0.9700741762980852 with variance: 1.8398385797868264e-05\n",
      "            test  score: 0.9719288645690835 with variance: 0.000517690475165666\n",
      "          Refitted train score: 0.971830985915493,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        f1\n",
      "          CV score: 0.9715235833133414 using:1.0,5\n",
      "            train score: 0.969587307249294 with variance: 1.9224279668992853e-05\n",
      "            test  score: 0.9715235833133414 with variance: 0.0005213364155441941\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9719288645690835 using:1.0,5\n",
      "            train score: 0.9700741762980852 with variance: 1.8398385797868264e-05\n",
      "            test  score: 0.9719288645690835 with variance: 0.000517690475165666\n",
      "          Refitted train score: 0.971830985915493,  RMSE: 0.16783627165933782, Log-Loss:0.9729289096976975\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9684189231248055 using:1.0,10\n",
      "            train score: 0.9777991077725863 with variance: 5.981428213849604e-06\n",
      "            test  score: 0.9684189231248055 with variance: 0.00016717929970341955\n",
      "          Refitted train score: 0.9759615384615384,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415662\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.969466484268126 using:1.0,10\n",
      "            train score: 0.9782887700534759 with variance: 5.419350315601257e-06\n",
      "            test  score: 0.969466484268126 with variance: 0.00014472912506713673\n",
      "          Refitted train score: 0.9765258215962441,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415662\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9684189231248055 using:1.0,10\n",
      "            train score: 0.9777991077725863 with variance: 5.981428213849604e-06\n",
      "            test  score: 0.9684189231248055 with variance: 0.00016717929970341955\n",
      "          Refitted train score: 0.9759615384615384,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415662\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.969466484268126 using:1.0,10\n",
      "            train score: 0.9782887700534759 with variance: 5.419350315601257e-06\n",
      "            test  score: 0.969466484268126 with variance: 0.00014472912506713673\n",
      "          Refitted train score: 0.9765258215962441,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415662\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9684189231248055 using:1.0,10\n",
      "            train score: 0.9777991077725863 with variance: 5.981428213849604e-06\n",
      "            test  score: 0.9684189231248055 with variance: 0.00016717929970341955\n",
      "          Refitted train score: 0.9759615384615384,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415662\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.969466484268126 using:1.0,10\n",
      "            train score: 0.9782887700534759 with variance: 5.419350315601257e-06\n",
      "            test  score: 0.969466484268126 with variance: 0.00014472912506713673\n",
      "          Refitted train score: 0.9765258215962441,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415662\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9732465998447573 using:1.0,15\n",
      "            train score: 0.9827076349095512 with variance: 4.92786534857915e-06\n",
      "            test  score: 0.9732465998447573 with variance: 0.00021563382393878028\n",
      "          Refitted train score: 0.9832935560859188,  RMSE: 0.12818706987301454, Log-Loss:0.5675385792590967\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9741997264021889 using:1.0,15\n",
      "            train score: 0.982982577195101 with variance: 4.775747712207382e-06\n",
      "            test  score: 0.9741997264021889 with variance: 0.0001867172192581427\n",
      "          Refitted train score: 0.9835680751173709,  RMSE: 0.12818706987301454, Log-Loss:0.5675385792590967\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9732465998447573 using:1.0,15\n",
      "            train score: 0.9827076349095512 with variance: 4.92786534857915e-06\n",
      "            test  score: 0.9732465998447573 with variance: 0.00021563382393878028\n",
      "          Refitted train score: 0.9832935560859188,  RMSE: 0.12818706987301454, Log-Loss:0.5675385792590967\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9741997264021889 using:1.0,15\n",
      "            train score: 0.982982577195101 with variance: 4.775747712207382e-06\n",
      "            test  score: 0.9741997264021889 with variance: 0.0001867172192581427\n",
      "          Refitted train score: 0.9835680751173709,  RMSE: 0.12818706987301454, Log-Loss:0.5675385792590967\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9758391924373498 using:1.5,15\n",
      "            train score: 0.9845271212109697 with variance: 1.299181966867055e-06\n",
      "            test  score: 0.9758391924373498 with variance: 0.0001219820442224814\n",
      "          Refitted train score: 0.9832935560859188,  RMSE: 0.12818706987301454, Log-Loss:0.5675385792590967\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9765526675786594 using:1.5,15\n",
      "            train score: 0.9847421079868898 with variance: 1.3661572525854612e-06\n",
      "            test  score: 0.9765526675786594 with variance: 0.00010882231300562738\n",
      "          Refitted train score: 0.9835680751173709,  RMSE: 0.12818706987301454, Log-Loss:0.5675385792590967\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9783062033380956 using:1.0,25\n",
      "            train score: 0.988119829751264 with variance: 3.629421687637462e-06\n",
      "            test  score: 0.9783062033380956 with variance: 8.719842921252403e-05\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:1.0,25\n",
      "            train score: 0.9882628946006555 with variance: 3.4401333436134795e-06\n",
      "            test  score: 0.9788782489740082 with variance: 7.726312361867755e-05\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9783062033380956 using:1.0,25\n",
      "            train score: 0.988119829751264 with variance: 3.629421687637462e-06\n",
      "            test  score: 0.9783062033380956 with variance: 8.719842921252403e-05\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:1.0,25\n",
      "            train score: 0.9882628946006555 with variance: 3.4401333436134795e-06\n",
      "            test  score: 0.9788782489740082 with variance: 7.726312361867755e-05\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9783062033380956 using:1.0,25\n",
      "            train score: 0.988119829751264 with variance: 3.629421687637462e-06\n",
      "            test  score: 0.9783062033380956 with variance: 8.719842921252403e-05\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:1.0,25\n",
      "            train score: 0.9882628946006555 with variance: 3.4401333436134795e-06\n",
      "            test  score: 0.9788782489740082 with variance: 7.726312361867755e-05\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9807151669235298 using:1.0,50\n",
      "            train score: 0.9893173191028499 with variance: 5.805629931920592e-06\n",
      "            test  score: 0.9807151669235298 with variance: 0.00010021743212565593\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9812311901504789 using:1.0,50\n",
      "            train score: 0.9894376401587028 with variance: 5.4858042989704425e-06\n",
      "            test  score: 0.9812311901504789 with variance: 8.807828415621683e-05\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9807151669235298 using:1.0,50\n",
      "            train score: 0.9893173191028499 with variance: 5.805629931920592e-06\n",
      "            test  score: 0.9807151669235298 with variance: 0.00010021743212565593\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9812311901504789 using:1.0,50\n",
      "            train score: 0.9894376401587028 with variance: 5.4858042989704425e-06\n",
      "            test  score: 0.9812311901504789 with variance: 8.807828415621683e-05\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9832445255504494 using:1.5,50\n",
      "            train score: 0.991111865742557 with variance: 7.1283310346401415e-06\n",
      "            test  score: 0.9832445255504494 with variance: 3.600467191095491e-05\n",
      "          Refitted train score: 0.990521327014218,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9835841313269494 using:1.5,50\n",
      "            train score: 0.9911971709504916 with variance: 6.879992920145195e-06\n",
      "            test  score: 0.9835841313269494 with variance: 3.2457458534586593e-05\n",
      "          Refitted train score: 0.9906103286384976,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9783062033380956 using:1.0,100\n",
      "            train score: 0.9988200589970502 with variance: 2.0883911556635148e-06\n",
      "            test  score: 0.9783062033380956 with variance: 8.719842921252403e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:1.0,100\n",
      "            train score: 0.9988252544419527 with variance: 2.0700481285505377e-06\n",
      "            test  score: 0.9788782489740082 with variance: 7.726312361867755e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9783062033380956 using:1.0,100\n",
      "            train score: 0.9988200589970502 with variance: 2.0883911556635148e-06\n",
      "            test  score: 0.9783062033380956 with variance: 8.719842921252403e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:1.0,100\n",
      "            train score: 0.9988252544419527 with variance: 2.0700481285505377e-06\n",
      "            test  score: 0.9788782489740082 with variance: 7.726312361867755e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        f1\n",
      "          CV score: 0.9783062033380956 using:1.0,100\n",
      "            train score: 0.9988200589970502 with variance: 2.0883911556635148e-06\n",
      "            test  score: 0.9783062033380956 with variance: 8.719842921252403e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:1.0,100\n",
      "            train score: 0.9988252544419527 with variance: 2.0700481285505377e-06\n",
      "            test  score: 0.9788782489740082 with variance: 7.726312361867755e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9511239748505658 using:1.0,2\n",
      "            train score: 0.9505046742234757 with variance: 5.325415067468059e-05\n",
      "            test  score: 0.9511239748505658 with variance: 0.000722734733281641\n",
      "          Refitted train score: 0.951048951048951,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9514835605453087 using:1.0,2\n",
      "            train score: 0.9508167881377231 with variance: 5.29019568815136e-05\n",
      "            test  score: 0.9514835605453087 with variance: 0.0007102066790467304\n",
      "          Refitted train score: 0.9513888888888888,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        f1\n",
      "          CV score: 0.9511239748505658 using:1.0,2\n",
      "            train score: 0.9505046742234757 with variance: 5.325415067468059e-05\n",
      "            test  score: 0.9511239748505658 with variance: 0.000722734733281641\n",
      "          Refitted train score: 0.951048951048951,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9514835605453087 using:1.0,2\n",
      "            train score: 0.9508167881377231 with variance: 5.29019568815136e-05\n",
      "            test  score: 0.9514835605453087 with variance: 0.0007102066790467304\n",
      "          Refitted train score: 0.9513888888888888,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        f1\n",
      "          CV score: 0.9511239748505658 using:1.0,2\n",
      "            train score: 0.9505046742234757 with variance: 5.325415067468059e-05\n",
      "            test  score: 0.9511239748505658 with variance: 0.000722734733281641\n",
      "          Refitted train score: 0.951048951048951,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9514835605453087 using:1.0,2\n",
      "            train score: 0.9508167881377231 with variance: 5.29019568815136e-05\n",
      "            test  score: 0.9514835605453087 with variance: 0.0007102066790467304\n",
      "          Refitted train score: 0.9513888888888888,  RMSE: 0.22047927592204922, Log-Loss:1.6789849552546212\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9646319575808887 using:1.0,3\n",
      "            train score: 0.9628710151896801 with variance: 2.32201452499283e-06\n",
      "            test  score: 0.9646319575808887 with variance: 0.00011703246940138284\n",
      "          Refitted train score: 0.9647058823529412,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9653033948142209 using:1.0,3\n",
      "            train score: 0.9635419284577365 with variance: 1.98801379465813e-06\n",
      "            test  score: 0.9653033948142209 with variance: 0.00010573429335635829\n",
      "          Refitted train score: 0.9652777777777778,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9646319575808887 using:1.0,3\n",
      "            train score: 0.9628710151896801 with variance: 2.32201452499283e-06\n",
      "            test  score: 0.9646319575808887 with variance: 0.00011703246940138284\n",
      "          Refitted train score: 0.9647058823529412,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9653033948142209 using:1.0,3\n",
      "            train score: 0.9635419284577365 with variance: 1.98801379465813e-06\n",
      "            test  score: 0.9653033948142209 with variance: 0.00010573429335635829\n",
      "          Refitted train score: 0.9652777777777778,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9646319575808887 using:1.0,3\n",
      "            train score: 0.9628710151896801 with variance: 2.32201452499283e-06\n",
      "            test  score: 0.9646319575808887 with variance: 0.00011703246940138284\n",
      "          Refitted train score: 0.9647058823529412,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9653033948142209 using:1.0,3\n",
      "            train score: 0.9635419284577365 with variance: 1.98801379465813e-06\n",
      "            test  score: 0.9653033948142209 with variance: 0.00010573429335635829\n",
      "          Refitted train score: 0.9652777777777778,  RMSE: 0.18633899812498247, Log-Loss:1.199270472947642\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9626641324656916 using:1.0,5\n",
      "            train score: 0.9675896850318775 with variance: 1.3928402754456225e-05\n",
      "            test  score: 0.9626641324656916 with variance: 0.00032302272695828324\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.1800205749557739, Log-Loss:1.1193177507431493\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9630312750601444 using:1.0,5\n",
      "            train score: 0.9681745832286168 with variance: 1.319235051064538e-05\n",
      "            test  score: 0.9630312750601444 with variance: 0.00033616525692134285\n",
      "          Refitted train score: 0.9675925925925926,  RMSE: 0.1800205749557739, Log-Loss:1.1193177507431493\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9626641324656916 using:1.0,5\n",
      "            train score: 0.9675896850318775 with variance: 1.3928402754456225e-05\n",
      "            test  score: 0.9626641324656916 with variance: 0.00032302272695828324\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.1800205749557739, Log-Loss:1.1193177507431493\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9630312750601444 using:1.0,5\n",
      "            train score: 0.9681745832286168 with variance: 1.319235051064538e-05\n",
      "            test  score: 0.9630312750601444 with variance: 0.00033616525692134285\n",
      "          Refitted train score: 0.9675925925925926,  RMSE: 0.1800205749557739, Log-Loss:1.1193177507431493\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9626641324656916 using:1.0,5\n",
      "            train score: 0.9675896850318775 with variance: 1.3928402754456225e-05\n",
      "            test  score: 0.9626641324656916 with variance: 0.00032302272695828324\n",
      "          Refitted train score: 0.9669811320754716,  RMSE: 0.1800205749557739, Log-Loss:1.1193177507431493\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9630312750601444 using:1.0,5\n",
      "            train score: 0.9681745832286168 with variance: 1.319235051064538e-05\n",
      "            test  score: 0.9630312750601444 with variance: 0.00033616525692134285\n",
      "          Refitted train score: 0.9675925925925926,  RMSE: 0.1800205749557739, Log-Loss:1.1193177507431493\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9642536532685362 using:1.0,10\n",
      "            train score: 0.9727737938713139 with variance: 1.2296013950490423e-05\n",
      "            test  score: 0.9642536532685362 with variance: 0.00016356980403699255\n",
      "          Refitted train score: 0.971563981042654,  RMSE: 0.16666666666666666, Log-Loss:0.9594123063341636\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.965330125634857 using:1.0,10\n",
      "            train score: 0.9733835972187317 with variance: 1.1175349819188662e-05\n",
      "            test  score: 0.965330125634857 with variance: 0.0001561091357742052\n",
      "          Refitted train score: 0.9722222222222222,  RMSE: 0.16666666666666666, Log-Loss:0.9594123063341636\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        f1\n",
      "          CV score: 0.9642536532685362 using:1.0,10\n",
      "            train score: 0.9727737938713139 with variance: 1.2296013950490423e-05\n",
      "            test  score: 0.9642536532685362 with variance: 0.00016356980403699255\n",
      "          Refitted train score: 0.971563981042654,  RMSE: 0.16666666666666666, Log-Loss:0.9594123063341636\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.965330125634857 using:1.0,10\n",
      "            train score: 0.9733835972187317 with variance: 1.1175349819188662e-05\n",
      "            test  score: 0.965330125634857 with variance: 0.0001561091357742052\n",
      "          Refitted train score: 0.9722222222222222,  RMSE: 0.16666666666666666, Log-Loss:0.9594123063341636\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        f1\n",
      "          CV score: 0.9666626168539704 using:1.5,10\n",
      "            train score: 0.9727737938713139 with variance: 1.2296013950490423e-05\n",
      "            test  score: 0.9666626168539704 with variance: 0.00024429296975024117\n",
      "          Refitted train score: 0.971563981042654,  RMSE: 0.16666666666666666, Log-Loss:0.9594123063341636\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9676557070302059 using:1.5,10\n",
      "            train score: 0.9733835972187317 with variance: 1.1175349819188662e-05\n",
      "            test  score: 0.9676557070302059 with variance: 0.00023083110415723926\n",
      "          Refitted train score: 0.9722222222222222,  RMSE: 0.16666666666666666, Log-Loss:0.9594123063341636\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9690715804394046 using:1.0,15\n",
      "            train score: 0.9793995470141967 with variance: 3.4622627569488957e-06\n",
      "            test  score: 0.9690715804394046 with variance: 0.0003134099243515944\n",
      "          Refitted train score: 0.9835294117647059,  RMSE: 0.1272937693043289, Log-Loss:0.5596560989916092\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9699812884255546 using:1.0,15\n",
      "            train score: 0.9797470051101618 with variance: 3.2838510358432645e-06\n",
      "            test  score: 0.9699812884255546 with variance: 0.00029473641488748795\n",
      "          Refitted train score: 0.9837962962962963,  RMSE: 0.1272937693043289, Log-Loss:0.5596560989916092\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9690715804394046 using:1.0,15\n",
      "            train score: 0.9793995470141967 with variance: 3.4622627569488957e-06\n",
      "            test  score: 0.9690715804394046 with variance: 0.0003134099243515944\n",
      "          Refitted train score: 0.9835294117647059,  RMSE: 0.1272937693043289, Log-Loss:0.5596560989916092\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9699812884255546 using:1.0,15\n",
      "            train score: 0.9797470051101618 with variance: 3.2838510358432645e-06\n",
      "            test  score: 0.9699812884255546 with variance: 0.00029473641488748795\n",
      "          Refitted train score: 0.9837962962962963,  RMSE: 0.1272937693043289, Log-Loss:0.5596560989916092\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9690715804394046 using:1.0,15\n",
      "            train score: 0.9793995470141967 with variance: 3.4622627569488957e-06\n",
      "            test  score: 0.9690715804394046 with variance: 0.0003134099243515944\n",
      "          Refitted train score: 0.9835294117647059,  RMSE: 0.1272937693043289, Log-Loss:0.5596560989916092\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9699812884255546 using:1.0,15\n",
      "            train score: 0.9797470051101618 with variance: 3.2838510358432645e-06\n",
      "            test  score: 0.9699812884255546 with variance: 0.00029473641488748795\n",
      "          Refitted train score: 0.9837962962962963,  RMSE: 0.1272937693043289, Log-Loss:0.5596560989916092\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9641354349556455 using:1.0,25\n",
      "            train score: 0.9883006336836765 with variance: 3.500397932655451e-06\n",
      "            test  score: 0.9641354349556455 with variance: 0.00028402814876247247\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9653568564554931 using:1.0,25\n",
      "            train score: 0.9884259026556087 with variance: 3.341510425756056e-06\n",
      "            test  score: 0.9653568564554931 with variance: 0.00026180198599779473\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        f1\n",
      "          CV score: 0.9641354349556455 using:1.0,25\n",
      "            train score: 0.9883006336836765 with variance: 3.500397932655451e-06\n",
      "            test  score: 0.9641354349556455 with variance: 0.00028402814876247247\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9653568564554931 using:1.0,25\n",
      "            train score: 0.9884259026556087 with variance: 3.341510425756056e-06\n",
      "            test  score: 0.9653568564554931 with variance: 0.00026180198599779473\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        f1\n",
      "          CV score: 0.9715920080556739 using:1.5,25\n",
      "            train score: 0.9883006336836765 with variance: 3.500397932655451e-06\n",
      "            test  score: 0.9715920080556739 with variance: 0.00014137743860525917\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9722534081796311 using:1.5,25\n",
      "            train score: 0.9884259026556087 with variance: 3.341510425756056e-06\n",
      "            test  score: 0.9722534081796311 with variance: 0.00013718105668698892\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9740056022408963 using:1.0,50\n",
      "            train score: 0.9906535045095733 with variance: 4.799919433386962e-06\n",
      "            test  score: 0.9740056022408963 with variance: 0.0002984534990466784\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9746057203956161 using:1.0,50\n",
      "            train score: 0.990743067772472 with variance: 4.648795329651178e-06\n",
      "            test  score: 0.9746057203956161 with variance: 0.00028366395307036836\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        f1\n",
      "          CV score: 0.9740056022408963 using:1.0,50\n",
      "            train score: 0.9906535045095733 with variance: 4.799919433386962e-06\n",
      "            test  score: 0.9740056022408963 with variance: 0.0002984534990466784\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9746057203956161 using:1.0,50\n",
      "            train score: 0.990743067772472 with variance: 4.648795329651178e-06\n",
      "            test  score: 0.9746057203956161 with variance: 0.00028366395307036836\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        f1\n",
      "          CV score: 0.976467982541854 using:1.5,50\n",
      "            train score: 0.9918264653882769 with variance: 8.271556294570044e-06\n",
      "            test  score: 0.976467982541854 with variance: 0.0001610311518747406\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9769045709703288 using:1.5,50\n",
      "            train score: 0.9919008125994806 with variance: 7.988054400455297e-06\n",
      "            test  score: 0.9769045709703288 with variance: 0.0001573224192128652\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9739475549255847 using:1.0,100\n",
      "            train score: 0.9959319079357873 with variance: 2.0320594948533025e-06\n",
      "            test  score: 0.9739475549255847 with variance: 0.00035764271912346144\n",
      "          Refitted train score: 0.993006993006993,  RMSE: 0.08333333333333333, Log-Loss:0.23985261385354736\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9745789895749798 using:1.0,100\n",
      "            train score: 0.9959487308368937 with variance: 2.0125372820134557e-06\n",
      "            test  score: 0.9745789895749798 with variance: 0.0003382431298539825\n",
      "          Refitted train score: 0.9930555555555556,  RMSE: 0.08333333333333333, Log-Loss:0.23985261385354736\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9739475549255847 using:1.0,100\n",
      "            train score: 0.9959319079357873 with variance: 2.0320594948533025e-06\n",
      "            test  score: 0.9739475549255847 with variance: 0.00035764271912346144\n",
      "          Refitted train score: 0.993006993006993,  RMSE: 0.08333333333333333, Log-Loss:0.23985261385354736\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9745789895749798 using:1.0,100\n",
      "            train score: 0.9959487308368937 with variance: 2.0125372820134557e-06\n",
      "            test  score: 0.9745789895749798 with variance: 0.0003382431298539825\n",
      "          Refitted train score: 0.9930555555555556,  RMSE: 0.08333333333333333, Log-Loss:0.23985261385354736\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9739475549255847 using:1.0,100\n",
      "            train score: 0.9959319079357873 with variance: 2.0320594948533025e-06\n",
      "            test  score: 0.9739475549255847 with variance: 0.00035764271912346144\n",
      "          Refitted train score: 0.993006993006993,  RMSE: 0.08333333333333333, Log-Loss:0.23985261385354736\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9745789895749798 using:1.0,100\n",
      "            train score: 0.9959487308368937 with variance: 2.0125372820134557e-06\n",
      "            test  score: 0.9745789895749798 with variance: 0.0003382431298539825\n",
      "          Refitted train score: 0.9930555555555556,  RMSE: 0.08333333333333333, Log-Loss:0.23985261385354736\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9352394250231022 using:1.0,2\n",
      "            train score: 0.9392622202398095 with variance: 9.108328981096017e-06\n",
      "            test  score: 0.9352394250231022 with variance: 0.00015204759315913226\n",
      "          Refitted train score: 0.935251798561151,  RMSE: 0.253546276418555, Log-Loss:2.2203727567422646\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9357142857142857 using:1.0,2\n",
      "            train score: 0.9398809523809524 with variance: 8.503401360544158e-06\n",
      "            test  score: 0.9357142857142857 with variance: 0.0001473922902494329\n",
      "          Refitted train score: 0.9357142857142857,  RMSE: 0.253546276418555, Log-Loss:2.2203727567422646\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        f1\n",
      "          CV score: 0.9352935793808145 using:0.001,2\n",
      "            train score: 0.9346511092671601 with variance: 8.921918157161742e-06\n",
      "            test  score: 0.9352935793808145 with variance: 9.002753717130853e-05\n",
      "          Refitted train score: 0.9353233830845771,  RMSE: 0.24880667576405965, Log-Loss:2.1381223444223783\n",
      "          Refitted test  score: 0.9870129870129869,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9380952380952381 using:0.001,2\n",
      "            train score: 0.9375 with variance: 7.086167800453465e-06\n",
      "            test  score: 0.9380952380952381 with variance: 7.93650793650788e-05\n",
      "          Refitted train score: 0.9380952380952381,  RMSE: 0.24880667576405965, Log-Loss:2.1381223444223783\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9352935793808145 using:0.001,2\n",
      "            train score: 0.9346511092671601 with variance: 8.921918157161742e-06\n",
      "            test  score: 0.9352935793808145 with variance: 9.002753717130853e-05\n",
      "          Refitted train score: 0.9353233830845771,  RMSE: 0.24880667576405965, Log-Loss:2.1381223444223783\n",
      "          Refitted test  score: 0.9870129870129869,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9380952380952381 using:0.001,2\n",
      "            train score: 0.9375 with variance: 7.086167800453465e-06\n",
      "            test  score: 0.9380952380952381 with variance: 7.93650793650788e-05\n",
      "          Refitted train score: 0.9380952380952381,  RMSE: 0.24880667576405965, Log-Loss:2.1381223444223783\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9446184738955823 using:1.0,3\n",
      "            train score: 0.9546783012120663 with variance: 4.019415743498782e-06\n",
      "            test  score: 0.9446184738955823 with variance: 0.00031287632292961655\n",
      "          Refitted train score: 0.9565217391304348,  RMSE: 0.20701966780270625, Log-Loss:1.4802446968880332\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9452380952380952 using:1.0,3\n",
      "            train score: 0.9553571428571429 with variance: 3.5430839002268647e-06\n",
      "            test  score: 0.9452380952380952 with variance: 0.0003174603174603166\n",
      "          Refitted train score: 0.9571428571428572,  RMSE: 0.20701966780270625, Log-Loss:1.4802446968880332\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9446184738955823 using:1.0,3\n",
      "            train score: 0.9546783012120663 with variance: 4.019415743498782e-06\n",
      "            test  score: 0.9446184738955823 with variance: 0.00031287632292961655\n",
      "          Refitted train score: 0.9565217391304348,  RMSE: 0.20701966780270625, Log-Loss:1.4802446968880332\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9452380952380952 using:1.0,3\n",
      "            train score: 0.9553571428571429 with variance: 3.5430839002268647e-06\n",
      "            test  score: 0.9452380952380952 with variance: 0.0003174603174603166\n",
      "          Refitted train score: 0.9571428571428572,  RMSE: 0.20701966780270625, Log-Loss:1.4802446968880332\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9446184738955823 using:1.0,3\n",
      "            train score: 0.9546783012120663 with variance: 4.019415743498782e-06\n",
      "            test  score: 0.9446184738955823 with variance: 0.00031287632292961655\n",
      "          Refitted train score: 0.9565217391304348,  RMSE: 0.20701966780270625, Log-Loss:1.4802446968880332\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9452380952380952 using:1.0,3\n",
      "            train score: 0.9553571428571429 with variance: 3.5430839002268647e-06\n",
      "            test  score: 0.9452380952380952 with variance: 0.0003174603174603166\n",
      "          Refitted train score: 0.9571428571428572,  RMSE: 0.20701966780270625, Log-Loss:1.4802446968880332\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9592444524426564 using:1.0,5\n",
      "            train score: 0.961357917435335 with variance: 1.5694081402971057e-05\n",
      "            test  score: 0.9592444524426564 with variance: 0.0003530580507431466\n",
      "          Refitted train score: 0.961352657004831,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9595238095238094 using:1.0,5\n",
      "            train score: 0.9619047619047618 with variance: 1.558956916099762e-05\n",
      "            test  score: 0.9595238095238094 with variance: 0.00037414965986394587\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9592444524426564 using:1.0,5\n",
      "            train score: 0.961357917435335 with variance: 1.5694081402971057e-05\n",
      "            test  score: 0.9592444524426564 with variance: 0.0003530580507431466\n",
      "          Refitted train score: 0.961352657004831,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9595238095238094 using:1.0,5\n",
      "            train score: 0.9619047619047618 with variance: 1.558956916099762e-05\n",
      "            test  score: 0.9595238095238094 with variance: 0.00037414965986394587\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9592444524426564 using:1.0,5\n",
      "            train score: 0.961357917435335 with variance: 1.5694081402971057e-05\n",
      "            test  score: 0.9592444524426564 with variance: 0.0003530580507431466\n",
      "          Refitted train score: 0.961352657004831,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9595238095238094 using:1.0,5\n",
      "            train score: 0.9619047619047618 with variance: 1.558956916099762e-05\n",
      "            test  score: 0.9595238095238094 with variance: 0.00037414965986394587\n",
      "          Refitted train score: 0.9619047619047619,  RMSE: 0.19518001458970666, Log-Loss:1.3157724292993385\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9611780385455744 using:1.0,10\n",
      "            train score: 0.9733035690488769 with variance: 1.3350888838745934e-06\n",
      "            test  score: 0.9611780385455744 with variance: 9.430174264983123e-05\n",
      "          Refitted train score: 0.97323600973236,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 0.9870129870129869,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9619047619047618 using:1.0,10\n",
      "            train score: 0.9738095238095239 with variance: 1.4172335600906926e-06\n",
      "            test  score: 0.9619047619047618 with variance: 7.936507936507965e-05\n",
      "          Refitted train score: 0.9738095238095238,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        f1\n",
      "          CV score: 0.9611780385455744 using:1.0,10\n",
      "            train score: 0.9733035690488769 with variance: 1.3350888838745934e-06\n",
      "            test  score: 0.9611780385455744 with variance: 9.430174264983123e-05\n",
      "          Refitted train score: 0.97323600973236,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 0.9870129870129869,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9619047619047618 using:1.0,10\n",
      "            train score: 0.9738095238095239 with variance: 1.4172335600906926e-06\n",
      "            test  score: 0.9619047619047618 with variance: 7.936507936507965e-05\n",
      "          Refitted train score: 0.9738095238095238,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        f1\n",
      "          CV score: 0.9611780385455744 using:1.0,10\n",
      "            train score: 0.9733035690488769 with variance: 1.3350888838745934e-06\n",
      "            test  score: 0.9611780385455744 with variance: 9.430174264983123e-05\n",
      "          Refitted train score: 0.97323600973236,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 0.9870129870129869,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9619047619047618 using:1.0,10\n",
      "            train score: 0.9738095238095239 with variance: 1.4172335600906926e-06\n",
      "            test  score: 0.9619047619047618 with variance: 7.936507936507965e-05\n",
      "          Refitted train score: 0.9738095238095238,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9656446477369263 using:1.0,15\n",
      "            train score: 0.9806602999080244 with variance: 1.0044314470156887e-05\n",
      "            test  score: 0.9656446477369263 with variance: 0.000293696329275182\n",
      "          Refitted train score: 0.983132530120482,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:1.0,15\n",
      "            train score: 0.9809523809523808 with variance: 9.212018140589688e-06\n",
      "            test  score: 0.9666666666666666 with variance: 0.00024943310657596406\n",
      "          Refitted train score: 0.9833333333333333,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9656446477369263 using:1.0,15\n",
      "            train score: 0.9806602999080244 with variance: 1.0044314470156887e-05\n",
      "            test  score: 0.9656446477369263 with variance: 0.000293696329275182\n",
      "          Refitted train score: 0.983132530120482,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:1.0,15\n",
      "            train score: 0.9809523809523808 with variance: 9.212018140589688e-06\n",
      "            test  score: 0.9666666666666666 with variance: 0.00024943310657596406\n",
      "          Refitted train score: 0.9833333333333333,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9656468244655209 using:1.5,15\n",
      "            train score: 0.9818944710207068 with variance: 1.1356106485977792e-05\n",
      "            test  score: 0.9656468244655209 with variance: 0.00035309535592764846\n",
      "          Refitted train score: 0.983132530120482,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:1.0,15\n",
      "            train score: 0.9809523809523808 with variance: 9.212018140589688e-06\n",
      "            test  score: 0.9666666666666666 with variance: 0.00024943310657596406\n",
      "          Refitted train score: 0.9833333333333333,  RMSE: 0.12909944487358055, Log-Loss:0.5756481770519175\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9706537424671904 using:1.0,25\n",
      "            train score: 0.9891601682630913 with variance: 9.602039655051548e-06\n",
      "            test  score: 0.9706537424671904 with variance: 0.000169320757176364\n",
      "          Refitted train score: 0.9903846153846153,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,25\n",
      "            train score: 0.9892857142857142 with variance: 9.212018140589504e-06\n",
      "            test  score: 0.9714285714285713 with variance: 0.00014739229024943366\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        f1\n",
      "          CV score: 0.9706537424671904 using:1.0,25\n",
      "            train score: 0.9891601682630913 with variance: 9.602039655051548e-06\n",
      "            test  score: 0.9706537424671904 with variance: 0.000169320757176364\n",
      "          Refitted train score: 0.9903846153846153,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,25\n",
      "            train score: 0.9892857142857142 with variance: 9.212018140589504e-06\n",
      "            test  score: 0.9714285714285713 with variance: 0.00014739229024943366\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        f1\n",
      "          CV score: 0.9706537424671904 using:1.0,25\n",
      "            train score: 0.9891601682630913 with variance: 9.602039655051548e-06\n",
      "            test  score: 0.9706537424671904 with variance: 0.000169320757176364\n",
      "          Refitted train score: 0.9903846153846153,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,25\n",
      "            train score: 0.9892857142857142 with variance: 9.212018140589504e-06\n",
      "            test  score: 0.9714285714285713 with variance: 0.00014739229024943366\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9704707884288146 using:1.0,50\n",
      "            train score: 0.9903795144975435 with variance: 5.146021816644774e-06\n",
      "            test  score: 0.9704707884288146 with variance: 0.00035516904003611035\n",
      "          Refitted train score: 0.9903846153846153,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,50\n",
      "            train score: 0.9904761904761905 with variance: 4.960317460317425e-06\n",
      "            test  score: 0.9714285714285713 with variance: 0.00031746031746031816\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9704707884288146 using:1.0,50\n",
      "            train score: 0.9903795144975435 with variance: 5.146021816644774e-06\n",
      "            test  score: 0.9704707884288146 with variance: 0.00035516904003611035\n",
      "          Refitted train score: 0.9903846153846153,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,50\n",
      "            train score: 0.9904761904761905 with variance: 4.960317460317425e-06\n",
      "            test  score: 0.9714285714285713 with variance: 0.00031746031746031816\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9704707884288146 using:1.0,50\n",
      "            train score: 0.9903795144975435 with variance: 5.146021816644774e-06\n",
      "            test  score: 0.9704707884288146 with variance: 0.00035516904003611035\n",
      "          Refitted train score: 0.9903846153846153,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,50\n",
      "            train score: 0.9904761904761905 with variance: 4.960317460317425e-06\n",
      "            test  score: 0.9714285714285713 with variance: 0.00031746031746031816\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09759000729485333, Log-Loss:0.32894072757057885\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9703600464576075 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9703600464576075 with variance: 0.00035382863833615817\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714285714285713 with variance: 0.00031746031746031816\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9703600464576075 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9703600464576075 with variance: 0.00035382863833615817\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714285714285713 with variance: 0.00031746031746031816\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9703600464576075 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9703600464576075 with variance: 0.00035382863833615817\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9714285714285713 with variance: 0.00031746031746031816\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9481792717086834 using:1.0,2\n",
      "            train score: 0.9493597084851639 with variance: 3.1856347593558165e-05\n",
      "            test  score: 0.9481792717086834 with variance: 0.0006390634685246656\n",
      "          Refitted train score: 0.9505882352941175,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9487004103967168 using:1.0,2\n",
      "            train score: 0.9497723901590712 with variance: 3.145105077142017e-05\n",
      "            test  score: 0.9487004103967168 with variance: 0.0006216696203502884\n",
      "          Refitted train score: 0.9509345794392523,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9481792717086834 using:1.0,2\n",
      "            train score: 0.9493597084851639 with variance: 3.1856347593558165e-05\n",
      "            test  score: 0.9481792717086834 with variance: 0.0006390634685246656\n",
      "          Refitted train score: 0.9505882352941175,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9487004103967168 using:1.0,2\n",
      "            train score: 0.9497723901590712 with variance: 3.145105077142017e-05\n",
      "            test  score: 0.9487004103967168 with variance: 0.0006216696203502884\n",
      "          Refitted train score: 0.9509345794392523,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9506963715718845 using:1.5,2\n",
      "            train score: 0.950594982757331 with variance: 3.183491829432125e-05\n",
      "            test  score: 0.9506963715718845 with variance: 0.0005107013776570772\n",
      "          Refitted train score: 0.9505882352941175,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9510259917920656 using:1.5,2\n",
      "            train score: 0.9509402758597174 with variance: 3.152049492499998e-05\n",
      "            test  score: 0.9510259917920656 with variance: 0.0005033226601492255\n",
      "          Refitted train score: 0.9509345794392523,  RMSE: 0.22150715690638004, Log-Loss:1.6946764034345712\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9641374598619936 using:1.0,3\n",
      "            train score: 0.9661297159813481 with variance: 1.6439230436574156e-05\n",
      "            test  score: 0.9641374598619936 with variance: 0.00034594983950118435\n",
      "          Refitted train score: 0.966824644549763,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9650341997264021 using:1.0,3\n",
      "            train score: 0.9667092902323837 with variance: 1.541507310247541e-05\n",
      "            test  score: 0.9650341997264021 with variance: 0.0003245266776579874\n",
      "          Refitted train score: 0.9672897196261683,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9641374598619936 using:1.0,3\n",
      "            train score: 0.9661297159813481 with variance: 1.6439230436574156e-05\n",
      "            test  score: 0.9641374598619936 with variance: 0.00034594983950118435\n",
      "          Refitted train score: 0.966824644549763,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9650341997264021 using:1.0,3\n",
      "            train score: 0.9667092902323837 with variance: 1.541507310247541e-05\n",
      "            test  score: 0.9650341997264021 with variance: 0.0003245266776579874\n",
      "          Refitted train score: 0.9672897196261683,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9666024458563914 using:1.5,3\n",
      "            train score: 0.9649851632047477 with variance: 2.254136251970197e-05\n",
      "            test  score: 0.9666024458563914 with variance: 0.00031229521074389486\n",
      "          Refitted train score: 0.966824644549763,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "        accuracy\n",
      "          CV score: 0.9673597811217511 using:1.5,3\n",
      "            train score: 0.9655414045317375 with variance: 2.149929951414863e-05\n",
      "            test  score: 0.9673597811217511 with variance: 0.0002924584690873769\n",
      "          Refitted train score: 0.9672897196261683,  RMSE: 0.18085983626508062, Log-Loss:1.1297805325197914\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9643057200464943 using:1.0,5\n",
      "            train score: 0.9701740229562198 with variance: 4.574709859870793e-05\n",
      "            test  score: 0.9643057200464943 with variance: 0.00028672588395370704\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051143\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9650341997264021 using:1.0,5\n",
      "            train score: 0.970801152541217 with variance: 4.3902407856089756e-05\n",
      "            test  score: 0.9650341997264021 with variance: 0.0002678833223232984\n",
      "          Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051143\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9643057200464943 using:1.0,5\n",
      "            train score: 0.9701740229562198 with variance: 4.574709859870793e-05\n",
      "            test  score: 0.9643057200464943 with variance: 0.00028672588395370704\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051143\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9650341997264021 using:1.0,5\n",
      "            train score: 0.970801152541217 with variance: 4.3902407856089756e-05\n",
      "            test  score: 0.9650341997264021 with variance: 0.0002678833223232984\n",
      "          Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051143\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        f1\n",
      "          CV score: 0.9643057200464943 using:1.0,5\n",
      "            train score: 0.9701740229562198 with variance: 4.574709859870793e-05\n",
      "            test  score: 0.9643057200464943 with variance: 0.00028672588395370704\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051143\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9650341997264021 using:1.0,5\n",
      "            train score: 0.970801152541217 with variance: 4.3902407856089756e-05\n",
      "            test  score: 0.9650341997264021 with variance: 0.0002678833223232984\n",
      "          Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051143\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9736612693858031 using:1.0,10\n",
      "            train score: 0.9803410986609975 with variance: 9.357034173964538e-06\n",
      "            test  score: 0.9736612693858031 with variance: 0.00025807078544053607\n",
      "          Refitted train score: 0.9785202863961814,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9743638850889192 using:1.0,10\n",
      "            train score: 0.980727328525395 with variance: 8.753027149211663e-06\n",
      "            test  score: 0.9743638850889192 with variance: 0.00023772393569141412\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        f1\n",
      "          CV score: 0.9736612693858031 using:1.0,10\n",
      "            train score: 0.9803410986609975 with variance: 9.357034173964538e-06\n",
      "            test  score: 0.9736612693858031 with variance: 0.00025807078544053607\n",
      "          Refitted train score: 0.9785202863961814,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9743638850889192 using:1.0,10\n",
      "            train score: 0.980727328525395 with variance: 8.753027149211663e-06\n",
      "            test  score: 0.9743638850889192 with variance: 0.00023772393569141412\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        f1\n",
      "          CV score: 0.9736612693858031 using:1.0,10\n",
      "            train score: 0.9803410986609975 with variance: 9.357034173964538e-06\n",
      "            test  score: 0.9736612693858031 with variance: 0.00025807078544053607\n",
      "          Refitted train score: 0.9785202863961814,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9743638850889192 using:1.0,10\n",
      "            train score: 0.980727328525395 with variance: 8.753027149211663e-06\n",
      "            test  score: 0.9743638850889192 with variance: 0.00023772393569141412\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.978485370051635 using:1.0,15\n",
      "            train score: 0.9875721466926806 with variance: 1.5538426927518128e-05\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:1.0,15\n",
      "            train score: 0.9877363476719008 with variance: 1.494812584660434e-05\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:1.0,15\n",
      "            train score: 0.9875721466926806 with variance: 1.5538426927518128e-05\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:1.0,15\n",
      "            train score: 0.9877363476719008 with variance: 1.494812584660434e-05\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:1.0,15\n",
      "            train score: 0.9875721466926806 with variance: 1.5538426927518128e-05\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:1.0,15\n",
      "            train score: 0.9877363476719008 with variance: 1.494812584660434e-05\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9761904761904763 using:1.0,25\n",
      "            train score: 0.9863782106313714 with variance: 9.195212534679101e-06\n",
      "            test  score: 0.9761904761904763 with variance: 0.00022675736961451191\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:1.0,25\n",
      "            train score: 0.9865684619712546 with variance: 8.788467212855211e-06\n",
      "            test  score: 0.9766894664842681 with variance: 0.00021634512997767403\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        f1\n",
      "          CV score: 0.9761904761904763 using:1.0,25\n",
      "            train score: 0.9863782106313714 with variance: 9.195212534679101e-06\n",
      "            test  score: 0.9761904761904763 with variance: 0.00022675736961451191\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:1.0,25\n",
      "            train score: 0.9865684619712546 with variance: 8.788467212855211e-06\n",
      "            test  score: 0.9766894664842681 with variance: 0.00021634512997767403\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        f1\n",
      "          CV score: 0.9761904761904763 using:1.0,25\n",
      "            train score: 0.9863782106313714 with variance: 9.195212534679101e-06\n",
      "            test  score: 0.9761904761904763 with variance: 0.00022675736961451191\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9766894664842681 using:1.0,25\n",
      "            train score: 0.9865684619712546 with variance: 8.788467212855211e-06\n",
      "            test  score: 0.9766894664842681 with variance: 0.00021634512997767403\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:1.0,50\n",
      "            train score: 0.9893664537750988 with variance: 9.229026877886983e-06\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:1.0,50\n",
      "            train score: 0.9894856188089272 with variance: 8.893839777412137e-06\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:1.0,50\n",
      "            train score: 0.9893664537750988 with variance: 9.229026877886983e-06\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:1.0,50\n",
      "            train score: 0.9894856188089272 with variance: 8.893839777412137e-06\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:1.0,50\n",
      "            train score: 0.9893664537750988 with variance: 9.229026877886983e-06\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:1.0,50\n",
      "            train score: 0.9894856188089272 with variance: 8.893839777412137e-06\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9737234652897303 using:1.0,100\n",
      "            train score: 0.9953044476523953 with variance: 2.072272861859629e-06\n",
      "            test  score: 0.9737234652897303 with variance: 0.0002511019407521074\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9743638850889192 using:1.0,100\n",
      "            train score: 0.9953267522547866 with variance: 2.0499658335782464e-06\n",
      "            test  score: 0.9743638850889192 with variance: 0.00023772393569141412\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        f1\n",
      "          CV score: 0.9737234652897303 using:1.0,100\n",
      "            train score: 0.9953044476523953 with variance: 2.072272861859629e-06\n",
      "            test  score: 0.9737234652897303 with variance: 0.0002511019407521074\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9743638850889192 using:1.0,100\n",
      "            train score: 0.9953267522547866 with variance: 2.0499658335782464e-06\n",
      "            test  score: 0.9743638850889192 with variance: 0.00023772393569141412\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        f1\n",
      "          CV score: 0.9737234652897303 using:1.0,100\n",
      "            train score: 0.9953044476523953 with variance: 2.072272861859629e-06\n",
      "            test  score: 0.9737234652897303 with variance: 0.0002511019407521074\n",
      "          Refitted train score: 0.9953051643192489,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9743638850889192 using:1.0,100\n",
      "            train score: 0.9953267522547866 with variance: 2.0499658335782464e-06\n",
      "            test  score: 0.9743638850889192 with variance: 0.00023772393569141412\n",
      "          Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9532268119941225 using:1.0,2\n",
      "            train score: 0.9460075593697139 with variance: 2.5306945709267527e-05\n",
      "            test  score: 0.9532268119941225 with variance: 0.0003849901267776258\n",
      "          Refitted train score: 0.9486552567237164,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9539523949456361 using:1.0,2\n",
      "            train score: 0.9466058763931106 with variance: 2.384828963230186e-05\n",
      "            test  score: 0.9539523949456361 with variance: 0.0003722545550852303\n",
      "          Refitted train score: 0.9490291262135923,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9532268119941225 using:1.0,2\n",
      "            train score: 0.9460075593697139 with variance: 2.5306945709267527e-05\n",
      "            test  score: 0.9532268119941225 with variance: 0.0003849901267776258\n",
      "          Refitted train score: 0.9486552567237164,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9539523949456361 using:1.0,2\n",
      "            train score: 0.9466058763931106 with variance: 2.384828963230186e-05\n",
      "            test  score: 0.9539523949456361 with variance: 0.0003722545550852303\n",
      "          Refitted train score: 0.9490291262135923,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9532268119941225 using:1.0,2\n",
      "            train score: 0.9460075593697139 with variance: 2.5306945709267527e-05\n",
      "            test  score: 0.9532268119941225 with variance: 0.0003849901267776258\n",
      "          Refitted train score: 0.9486552567237164,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9539523949456361 using:1.0,2\n",
      "            train score: 0.9466058763931106 with variance: 2.384828963230186e-05\n",
      "            test  score: 0.9539523949456361 with variance: 0.0003722545550852303\n",
      "          Refitted train score: 0.9490291262135923,  RMSE: 0.22576730008220358, Log-Loss:1.7604890792961077\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9574592039042246 using:1.0,3\n",
      "            train score: 0.95875542817651 with variance: 6.40719117768366e-05\n",
      "            test  score: 0.9574592039042246 with variance: 0.0008186054232509069\n",
      "          Refitted train score: 0.9582309582309582,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9586835145459889 using:1.0,3\n",
      "            train score: 0.95934051763839 with variance: 6.138411217515021e-05\n",
      "            test  score: 0.9586835145459889 with variance: 0.0007496056486433241\n",
      "          Refitted train score: 0.9587378640776699,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9574592039042246 using:1.0,3\n",
      "            train score: 0.95875542817651 with variance: 6.40719117768366e-05\n",
      "            test  score: 0.9574592039042246 with variance: 0.0008186054232509069\n",
      "          Refitted train score: 0.9582309582309582,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9586835145459889 using:1.0,3\n",
      "            train score: 0.95934051763839 with variance: 6.138411217515021e-05\n",
      "            test  score: 0.9586835145459889 with variance: 0.0007496056486433241\n",
      "          Refitted train score: 0.9587378640776699,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9574592039042246 using:1.0,3\n",
      "            train score: 0.95875542817651 with variance: 6.40719117768366e-05\n",
      "            test  score: 0.9574592039042246 with variance: 0.0008186054232509069\n",
      "          Refitted train score: 0.9582309582309582,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9586835145459889 using:1.0,3\n",
      "            train score: 0.95934051763839 with variance: 6.138411217515021e-05\n",
      "            test  score: 0.9586835145459889 with variance: 0.0007496056486433241\n",
      "          Refitted train score: 0.9587378640776699,  RMSE: 0.2031308344942493, Log-Loss:1.4251553308205416\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9506464193119676 using:1.0,5\n",
      "            train score: 0.9612642942561707 with variance: 2.974103065316712e-05\n",
      "            test  score: 0.9506464193119676 with variance: 0.0004148176876172519\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9515133705553922 using:1.0,5\n",
      "            train score: 0.9617666021921341 with variance: 2.8357154823264557e-05\n",
      "            test  score: 0.9515133705553922 with variance: 0.0004079562302160487\n",
      "          Refitted train score: 0.9611650485436893,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9506464193119676 using:1.0,5\n",
      "            train score: 0.9612642942561707 with variance: 2.974103065316712e-05\n",
      "            test  score: 0.9506464193119676 with variance: 0.0004148176876172519\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9515133705553922 using:1.0,5\n",
      "            train score: 0.9617666021921341 with variance: 2.8357154823264557e-05\n",
      "            test  score: 0.9515133705553922 with variance: 0.0004079562302160487\n",
      "          Refitted train score: 0.9611650485436893,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9506464193119676 using:1.0,5\n",
      "            train score: 0.9612642942561707 with variance: 2.974103065316712e-05\n",
      "            test  score: 0.9506464193119676 with variance: 0.0004148176876172519\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9515133705553922 using:1.0,5\n",
      "            train score: 0.9617666021921341 with variance: 2.8357154823264557e-05\n",
      "            test  score: 0.9515133705553922 with variance: 0.0004079562302160487\n",
      "          Refitted train score: 0.9611650485436893,  RMSE: 0.1970658556328586, Log-Loss:1.3413214085090344\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.961679573095061 using:1.0,10\n",
      "            train score: 0.9752774999177136 with variance: 6.632807421759444e-05\n",
      "            test  score: 0.961679573095061 with variance: 0.0009363173702003225\n",
      "          Refitted train score: 0.9727047146401985,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9635909491625035 using:1.0,10\n",
      "            train score: 0.9757281016855485 with variance: 6.24662737553922e-05\n",
      "            test  score: 0.9635909491625035 with variance: 0.0007733958273839889\n",
      "          Refitted train score: 0.9733009708737864,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.961679573095061 using:1.0,10\n",
      "            train score: 0.9752774999177136 with variance: 6.632807421759444e-05\n",
      "            test  score: 0.961679573095061 with variance: 0.0009363173702003225\n",
      "          Refitted train score: 0.9727047146401985,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9635909491625035 using:1.0,10\n",
      "            train score: 0.9757281016855485 with variance: 6.24662737553922e-05\n",
      "            test  score: 0.9635909491625035 with variance: 0.0007733958273839889\n",
      "          Refitted train score: 0.9733009708737864,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.961679573095061 using:1.0,10\n",
      "            train score: 0.9752774999177136 with variance: 6.632807421759444e-05\n",
      "            test  score: 0.961679573095061 with variance: 0.0009363173702003225\n",
      "          Refitted train score: 0.9727047146401985,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9635909491625035 using:1.0,10\n",
      "            train score: 0.9757281016855485 with variance: 6.24662737553922e-05\n",
      "            test  score: 0.9635909491625035 with variance: 0.0007733958273839889\n",
      "          Refitted train score: 0.9733009708737864,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9642745098039217 using:1.0,15\n",
      "            train score: 0.9827384214769299 with variance: 2.9423065651923025e-05\n",
      "            test  score: 0.9642745098039217 with variance: 0.0009650465205690102\n",
      "          Refitted train score: 0.9827160493827161,  RMSE: 0.13034681147667526, Log-Loss:0.5868238707873183\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9660005877167205 using:1.0,15\n",
      "            train score: 0.9830063553467809 with variance: 2.8097319038157538e-05\n",
      "            test  score: 0.9660005877167205 with variance: 0.000797895825613758\n",
      "          Refitted train score: 0.9830097087378641,  RMSE: 0.13034681147667526, Log-Loss:0.5868238707873183\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9642745098039217 using:1.0,15\n",
      "            train score: 0.9827384214769299 with variance: 2.9423065651923025e-05\n",
      "            test  score: 0.9642745098039217 with variance: 0.0009650465205690102\n",
      "          Refitted train score: 0.9827160493827161,  RMSE: 0.13034681147667526, Log-Loss:0.5868238707873183\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9660005877167205 using:1.0,15\n",
      "            train score: 0.9830063553467809 with variance: 2.8097319038157538e-05\n",
      "            test  score: 0.9660005877167205 with variance: 0.000797895825613758\n",
      "          Refitted train score: 0.9830097087378641,  RMSE: 0.13034681147667526, Log-Loss:0.5868238707873183\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9668053740014525 using:1.5,15\n",
      "            train score: 0.9858572710560477 with variance: 9.98435929497412e-06\n",
      "            test  score: 0.9668053740014525 with variance: 0.0010449571331908303\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9684102262709373 using:1.5,15\n",
      "            train score: 0.9860421847655891 with variance: 9.61757539159313e-06\n",
      "            test  score: 0.9684102262709373 with variance: 0.0008688466875392733\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9694486215538849 using:1.0,25\n",
      "            train score: 0.9864840516828284 with variance: 6.070454846990563e-06\n",
      "            test  score: 0.9694486215538849 with variance: 0.0006765293559713802\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9708492506611813 using:1.0,25\n",
      "            train score: 0.9866500875011515 with variance: 5.893002307904794e-06\n",
      "            test  score: 0.9708492506611813 with variance: 0.0005722561267050233\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9694486215538849 using:1.0,25\n",
      "            train score: 0.9864840516828284 with variance: 6.070454846990563e-06\n",
      "            test  score: 0.9694486215538849 with variance: 0.0006765293559713802\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9708492506611813 using:1.0,25\n",
      "            train score: 0.9866500875011515 with variance: 5.893002307904794e-06\n",
      "            test  score: 0.9708492506611813 with variance: 0.0005722561267050233\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9699541634835753 using:1.5,25\n",
      "            train score: 0.9871069870296901 with variance: 5.29453109681518e-06\n",
      "            test  score: 0.9699541634835753 with variance: 0.00043969518774938135\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9708786364972084 using:1.5,25\n",
      "            train score: 0.9872579902367136 with variance: 5.124795111449521e-06\n",
      "            test  score: 0.9708786364972084 with variance: 0.00039194125181589076\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9669794857514156 using:1.0,50\n",
      "            train score: 0.989568514156965 with variance: 6.157468790240892e-06\n",
      "            test  score: 0.9669794857514156 with variance: 0.0005500448777433452\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9684102262709373 using:1.0,50\n",
      "            train score: 0.9896840747904576 with variance: 5.890606538487277e-06\n",
      "            test  score: 0.9684102262709373 with variance: 0.0004538527093473117\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9669794857514156 using:1.0,50\n",
      "            train score: 0.989568514156965 with variance: 6.157468790240892e-06\n",
      "            test  score: 0.9669794857514156 with variance: 0.0005500448777433452\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9684102262709373 using:1.0,50\n",
      "            train score: 0.9896840747904576 with variance: 5.890606538487277e-06\n",
      "            test  score: 0.9684102262709373 with variance: 0.0004538527093473117\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9669794857514156 using:1.0,50\n",
      "            train score: 0.989568514156965 with variance: 6.157468790240892e-06\n",
      "            test  score: 0.9669794857514156 with variance: 0.0005500448777433452\n",
      "          Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9684102262709373 using:1.0,50\n",
      "            train score: 0.9896840747904576 with variance: 5.890606538487277e-06\n",
      "            test  score: 0.9684102262709373 with variance: 0.0004538527093473117\n",
      "          Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9694486215538849 using:1.0,100\n",
      "            train score: 0.9981725850693157 with variance: 5.944333320888543e-06\n",
      "            test  score: 0.9694486215538849 with variance: 0.0006765293559713802\n",
      "          Refitted train score: 0.9975669099756691,  RMSE: 0.04926646390821465, Log-Loss:0.08383198154104635\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9708492506611813 using:1.0,100\n",
      "            train score: 0.9981799760523165 with variance: 5.881430673750222e-06\n",
      "            test  score: 0.9708492506611813 with variance: 0.0005722561267050233\n",
      "          Refitted train score: 0.9975728155339806,  RMSE: 0.04926646390821465, Log-Loss:0.08383198154104635\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9694486215538849 using:1.0,100\n",
      "            train score: 0.9981725850693157 with variance: 5.944333320888543e-06\n",
      "            test  score: 0.9694486215538849 with variance: 0.0006765293559713802\n",
      "          Refitted train score: 0.9975669099756691,  RMSE: 0.04926646390821465, Log-Loss:0.08383198154104635\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9708492506611813 using:1.0,100\n",
      "            train score: 0.9981799760523165 with variance: 5.881430673750222e-06\n",
      "            test  score: 0.9708492506611813 with variance: 0.0005722561267050233\n",
      "          Refitted train score: 0.9975728155339806,  RMSE: 0.04926646390821465, Log-Loss:0.08383198154104635\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        f1\n",
      "          CV score: 0.9745103499489464 using:1.5,100\n",
      "            train score: 0.9993920972644377 with variance: 1.4781829436165328e-06\n",
      "            test  score: 0.9745103499489464 with variance: 0.0007711601373143116\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9756979136056421 using:1.5,100\n",
      "            train score: 0.9993939393939394 with variance: 1.4692378328742156e-06\n",
      "            test  score: 0.9756979136056421 with variance: 0.0006551029415282298\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.941076052744859 using:1.0,2\n",
      "            train score: 0.9445712601525041 with variance: 8.87222275984091e-05\n",
      "            test  score: 0.941076052744859 with variance: 0.0006947470907731484\n",
      "          Refitted train score: 0.9438775510204082,  RMSE: 0.23510929779476553, Log-Loss:1.9091946670037105\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.9421835443037974 using:1.0,2\n",
      "            train score: 0.9453480806766429 with variance: 8.926841670891104e-05\n",
      "            test  score: 0.9421835443037974 with variance: 0.00061764540938952\n",
      "          Refitted train score: 0.9447236180904522,  RMSE: 0.23510929779476553, Log-Loss:1.9091946670037105\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        f1\n",
      "          CV score: 0.941076052744859 using:1.0,2\n",
      "            train score: 0.9445712601525041 with variance: 8.87222275984091e-05\n",
      "            test  score: 0.941076052744859 with variance: 0.0006947470907731484\n",
      "          Refitted train score: 0.9438775510204082,  RMSE: 0.23510929779476553, Log-Loss:1.9091946670037105\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.9422151898734178 using:0.001,2\n",
      "            train score: 0.9434691745036574 with variance: 5.4852822694995356e-05\n",
      "            test  score: 0.9422151898734178 with variance: 0.0009314152379426378\n",
      "          Refitted train score: 0.9422110552763819,  RMSE: 0.24039331256010033, Log-Loss:1.9959654670232072\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        f1\n",
      "          CV score: 0.941076052744859 using:1.0,2\n",
      "            train score: 0.9445712601525041 with variance: 8.87222275984091e-05\n",
      "            test  score: 0.941076052744859 with variance: 0.0006947470907731484\n",
      "          Refitted train score: 0.9438775510204082,  RMSE: 0.23510929779476553, Log-Loss:1.9091946670037105\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.9422151898734178 using:0.001,2\n",
      "            train score: 0.9434691745036574 with variance: 5.4852822694995356e-05\n",
      "            test  score: 0.9422151898734178 with variance: 0.0009314152379426378\n",
      "          Refitted train score: 0.9422110552763819,  RMSE: 0.24039331256010033, Log-Loss:1.9959654670232072\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9610936172339681 using:1.0,3\n",
      "            train score: 0.963828557258393 with variance: 4.8592766613048336e-05\n",
      "            test  score: 0.9610936172339681 with variance: 0.001390305216036384\n",
      "          Refitted train score: 0.9644670050761421,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9621835443037975 using:1.0,3\n",
      "            train score: 0.9641903747954496 with variance: 4.613474486532176e-05\n",
      "            test  score: 0.9621835443037975 with variance: 0.0012803036372376225\n",
      "          Refitted train score: 0.964824120603015,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9610936172339681 using:1.0,3\n",
      "            train score: 0.963828557258393 with variance: 4.8592766613048336e-05\n",
      "            test  score: 0.9610936172339681 with variance: 0.001390305216036384\n",
      "          Refitted train score: 0.9644670050761421,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9621835443037975 using:1.0,3\n",
      "            train score: 0.9641903747954496 with variance: 4.613474486532176e-05\n",
      "            test  score: 0.9621835443037975 with variance: 0.0012803036372376225\n",
      "          Refitted train score: 0.964824120603015,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9610936172339681 using:1.0,3\n",
      "            train score: 0.963828557258393 with variance: 4.8592766613048336e-05\n",
      "            test  score: 0.9610936172339681 with variance: 0.001390305216036384\n",
      "          Refitted train score: 0.9644670050761421,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9621835443037975 using:1.0,3\n",
      "            train score: 0.9641903747954496 with variance: 4.613474486532176e-05\n",
      "            test  score: 0.9621835443037975 with variance: 0.0012803036372376225\n",
      "          Refitted train score: 0.964824120603015,  RMSE: 0.18755233775398517, Log-Loss:1.2149418781806554\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9664110978878911 using:1.0,5\n",
      "            train score: 0.9656685148877427 with variance: 6.355573837462626e-05\n",
      "            test  score: 0.9664110978878911 with variance: 0.0007238038023042103\n",
      "          Refitted train score: 0.9669211195928753,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9672784810126582 using:1.0,5\n",
      "            train score: 0.9660732241083576 with variance: 6.109610813656163e-05\n",
      "            test  score: 0.9672784810126582 with variance: 0.0006711404422368214\n",
      "          Refitted train score: 0.9673366834170855,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        f1\n",
      "          CV score: 0.9664110978878911 using:1.0,5\n",
      "            train score: 0.9656685148877427 with variance: 6.355573837462626e-05\n",
      "            test  score: 0.9664110978878911 with variance: 0.0007238038023042103\n",
      "          Refitted train score: 0.9669211195928753,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9672784810126582 using:1.0,5\n",
      "            train score: 0.9660732241083576 with variance: 6.109610813656163e-05\n",
      "            test  score: 0.9672784810126582 with variance: 0.0006711404422368214\n",
      "          Refitted train score: 0.9673366834170855,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        f1\n",
      "          CV score: 0.9664110978878911 using:1.0,5\n",
      "            train score: 0.9656685148877427 with variance: 6.355573837462626e-05\n",
      "            test  score: 0.9664110978878911 with variance: 0.0007238038023042103\n",
      "          Refitted train score: 0.9669211195928753,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9672784810126582 using:1.0,5\n",
      "            train score: 0.9660732241083576 with variance: 6.109610813656163e-05\n",
      "            test  score: 0.9672784810126582 with variance: 0.0006711404422368214\n",
      "          Refitted train score: 0.9673366834170855,  RMSE: 0.1807299548578336, Log-Loss:1.1281590239285428\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9665352743833756 using:1.0,10\n",
      "            train score: 0.9795967960120947 with variance: 4.793986336603844e-05\n",
      "            test  score: 0.9665352743833756 with variance: 0.00039754341656336544\n",
      "          Refitted train score: 0.9795918367346939,  RMSE: 0.1417762410016672, Log-Loss:0.6942487707455177\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9673101265822786 using:1.0,10\n",
      "            train score: 0.979899844245973 with variance: 4.571437183438897e-05\n",
      "            test  score: 0.9673101265822786 with variance: 0.000358321983656466\n",
      "          Refitted train score: 0.9798994974874372,  RMSE: 0.1417762410016672, Log-Loss:0.6942487707455177\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        f1\n",
      "          CV score: 0.9665352743833756 using:1.0,10\n",
      "            train score: 0.9795967960120947 with variance: 4.793986336603844e-05\n",
      "            test  score: 0.9665352743833756 with variance: 0.00039754341656336544\n",
      "          Refitted train score: 0.9795918367346939,  RMSE: 0.1417762410016672, Log-Loss:0.6942487707455177\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9673101265822786 using:1.0,10\n",
      "            train score: 0.979899844245973 with variance: 4.571437183438897e-05\n",
      "            test  score: 0.9673101265822786 with variance: 0.000358321983656466\n",
      "          Refitted train score: 0.9798994974874372,  RMSE: 0.1417762410016672, Log-Loss:0.6942487707455177\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        f1\n",
      "          CV score: 0.9665352743833756 using:1.0,10\n",
      "            train score: 0.9795967960120947 with variance: 4.793986336603844e-05\n",
      "            test  score: 0.9665352743833756 with variance: 0.00039754341656336544\n",
      "          Refitted train score: 0.9795918367346939,  RMSE: 0.1417762410016672, Log-Loss:0.6942487707455177\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9673101265822786 using:1.0,10\n",
      "            train score: 0.979899844245973 with variance: 4.571437183438897e-05\n",
      "            test  score: 0.9673101265822786 with variance: 0.000358321983656466\n",
      "          Refitted train score: 0.9798994974874372,  RMSE: 0.1417762410016672, Log-Loss:0.6942487707455177\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9740832924488265 using:1.0,15\n",
      "            train score: 0.9872852695914158 with variance: 1.227607037557156e-05\n",
      "            test  score: 0.9740832924488265 with variance: 0.0002821952073613134\n",
      "          Refitted train score: 0.9872773536895675,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9748417721518987 using:1.0,15\n",
      "            train score: 0.9874391277774492 with variance: 1.1805102143733292e-05\n",
      "            test  score: 0.9748417721518987 with variance: 0.00025559806120814077\n",
      "          Refitted train score: 0.9874371859296482,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9740832924488265 using:1.0,15\n",
      "            train score: 0.9872852695914158 with variance: 1.227607037557156e-05\n",
      "            test  score: 0.9740832924488265 with variance: 0.0002821952073613134\n",
      "          Refitted train score: 0.9872773536895675,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9748417721518987 using:1.0,15\n",
      "            train score: 0.9874391277774492 with variance: 1.1805102143733292e-05\n",
      "            test  score: 0.9748417721518987 with variance: 0.00025559806120814077\n",
      "          Refitted train score: 0.9874371859296482,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9794814031100951 using:1.5,15\n",
      "            train score: 0.9879201775497275 with variance: 2.199706028719544e-05\n",
      "            test  score: 0.9794814031100951 with variance: 0.00011033393801008274\n",
      "          Refitted train score: 0.9872773536895675,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9702970297029702,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.9799050632911392 using:1.5,15\n",
      "            train score: 0.9880680585950593 with variance: 2.1276077843947503e-05\n",
      "            test  score: 0.9799050632911392 with variance: 0.000100174250921327\n",
      "          Refitted train score: 0.9874371859296482,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9768174004460924 using:1.0,25\n",
      "            train score: 0.9885470100236937 with variance: 1.881334245404874e-05\n",
      "            test  score: 0.9768174004460924 with variance: 0.00016601390646363463\n",
      "          Refitted train score: 0.9872773536895675,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9702970297029702,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.977373417721519 using:1.0,25\n",
      "            train score: 0.9886950178427082 with variance: 1.815617653863841e-05\n",
      "            test  score: 0.977373417721519 with variance: 0.00015224923890402208\n",
      "          Refitted train score: 0.9874371859296482,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        f1\n",
      "          CV score: 0.9768174004460924 using:1.0,25\n",
      "            train score: 0.9885470100236937 with variance: 1.881334245404874e-05\n",
      "            test  score: 0.9768174004460924 with variance: 0.00016601390646363463\n",
      "          Refitted train score: 0.9872773536895675,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9702970297029702,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.977373417721519 using:1.0,25\n",
      "            train score: 0.9886950178427082 with variance: 1.815617653863841e-05\n",
      "            test  score: 0.977373417721519 with variance: 0.00015224923890402208\n",
      "          Refitted train score: 0.9874371859296482,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        f1\n",
      "          CV score: 0.9768174004460924 using:1.0,25\n",
      "            train score: 0.9885470100236937 with variance: 1.881334245404874e-05\n",
      "            test  score: 0.9768174004460924 with variance: 0.00016601390646363463\n",
      "          Refitted train score: 0.9872773536895675,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9702970297029702,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.977373417721519 using:1.0,25\n",
      "            train score: 0.9886950178427082 with variance: 1.815617653863841e-05\n",
      "            test  score: 0.977373417721519 with variance: 0.00015224923890402208\n",
      "          Refitted train score: 0.9874371859296482,  RMSE: 0.11208395991555509, Log-Loss:0.4339042260667181\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9820130486797154 using:1.0,50\n",
      "            train score: 0.9891941275019704 with variance: 1.4636566744057532e-05\n",
      "            test  score: 0.9820130486797154 with variance: 0.00017577019209131934\n",
      "          Refitted train score: 0.9898477157360407,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9824050632911392 using:1.0,50\n",
      "            train score: 0.9893239486603183 with variance: 1.4180797107519403e-05\n",
      "            test  score: 0.9824050632911392 with variance: 0.00016314893446563058\n",
      "          Refitted train score: 0.9899497487437185,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        f1\n",
      "          CV score: 0.9820130486797154 using:1.0,50\n",
      "            train score: 0.9891941275019704 with variance: 1.4636566744057532e-05\n",
      "            test  score: 0.9820130486797154 with variance: 0.00017577019209131934\n",
      "          Refitted train score: 0.9898477157360407,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9824050632911392 using:1.0,50\n",
      "            train score: 0.9893239486603183 with variance: 1.4180797107519403e-05\n",
      "            test  score: 0.9824050632911392 with variance: 0.00016314893446563058\n",
      "          Refitted train score: 0.9899497487437185,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        f1\n",
      "          CV score: 0.9820130486797154 using:1.0,50\n",
      "            train score: 0.9891941275019704 with variance: 1.4636566744057532e-05\n",
      "            test  score: 0.9820130486797154 with variance: 0.00017577019209131934\n",
      "          Refitted train score: 0.9898477157360407,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9824050632911392 using:1.0,50\n",
      "            train score: 0.9893239486603183 with variance: 1.4180797107519403e-05\n",
      "            test  score: 0.9824050632911392 with variance: 0.00016314893446563058\n",
      "          Refitted train score: 0.9899497487437185,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9844821844821844 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9844821844821844 with variance: 0.00022801485338947886\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9849050632911392 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9849050632911392 with variance: 0.00021362361800993427\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        f1\n",
      "          CV score: 0.9844821844821844 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9844821844821844 with variance: 0.00022801485338947886\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9849050632911392 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9849050632911392 with variance: 0.00021362361800993427\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        f1\n",
      "          CV score: 0.9844821844821844 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9844821844821844 with variance: 0.00022801485338947886\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9849050632911392 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9849050632911392 with variance: 0.00021362361800993427\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9526934951433252 using:1.0,2\n",
      "            train score: 0.9520945802132312 with variance: 4.7791429422661455e-05\n",
      "            test  score: 0.9526934951433252 with variance: 0.0006492710911722321\n",
      "          Refitted train score: 0.9502487562189055,  RMSE: 0.2224970797449924, Log-Loss:1.7098582284036774\n",
      "          Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        accuracy\n",
      "          CV score: 0.9529012345679012 using:1.0,2\n",
      "            train score: 0.9523468256698392 with variance: 4.86803870563705e-05\n",
      "            test  score: 0.9529012345679012 with variance: 0.0006442463039170845\n",
      "          Refitted train score: 0.9504950495049505,  RMSE: 0.2224970797449924, Log-Loss:1.7098582284036774\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        f1\n",
      "          CV score: 0.9526934951433252 using:1.0,2\n",
      "            train score: 0.9520945802132312 with variance: 4.7791429422661455e-05\n",
      "            test  score: 0.9526934951433252 with variance: 0.0006492710911722321\n",
      "          Refitted train score: 0.9502487562189055,  RMSE: 0.2224970797449924, Log-Loss:1.7098582284036774\n",
      "          Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        accuracy\n",
      "          CV score: 0.9529012345679012 using:1.0,2\n",
      "            train score: 0.9523468256698392 with variance: 4.86803870563705e-05\n",
      "            test  score: 0.9529012345679012 with variance: 0.0006442463039170845\n",
      "          Refitted train score: 0.9504950495049505,  RMSE: 0.2224970797449924, Log-Loss:1.7098582284036774\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        f1\n",
      "          CV score: 0.9526934951433252 using:1.0,2\n",
      "            train score: 0.9520945802132312 with variance: 4.7791429422661455e-05\n",
      "            test  score: 0.9526934951433252 with variance: 0.0006492710911722321\n",
      "          Refitted train score: 0.9502487562189055,  RMSE: 0.2224970797449924, Log-Loss:1.7098582284036774\n",
      "          Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        accuracy\n",
      "          CV score: 0.9529012345679012 using:1.0,2\n",
      "            train score: 0.9523468256698392 with variance: 4.86803870563705e-05\n",
      "            test  score: 0.9529012345679012 with variance: 0.0006442463039170845\n",
      "          Refitted train score: 0.9504950495049505,  RMSE: 0.2224970797449924, Log-Loss:1.7098582284036774\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9543524150486176 using:1.0,3\n",
      "            train score: 0.9608988402017495 with variance: 4.6853830825520286e-05\n",
      "            test  score: 0.9543524150486176 with variance: 0.0007612662647715773\n",
      "          Refitted train score: 0.9595959595959594,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9555555555555556,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        accuracy\n",
      "          CV score: 0.9554012345679013 using:1.0,3\n",
      "            train score: 0.9616309291747888 with variance: 4.465869287336433e-05\n",
      "            test  score: 0.9554012345679013 with variance: 0.0007126390794086267\n",
      "          Refitted train score: 0.9603960396039604,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        f1\n",
      "          CV score: 0.9543524150486176 using:1.0,3\n",
      "            train score: 0.9608988402017495 with variance: 4.6853830825520286e-05\n",
      "            test  score: 0.9543524150486176 with variance: 0.0007612662647715773\n",
      "          Refitted train score: 0.9595959595959594,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9555555555555556,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        accuracy\n",
      "          CV score: 0.9554012345679013 using:1.0,3\n",
      "            train score: 0.9616309291747888 with variance: 4.465869287336433e-05\n",
      "            test  score: 0.9554012345679013 with variance: 0.0007126390794086267\n",
      "          Refitted train score: 0.9603960396039604,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        f1\n",
      "          CV score: 0.9543524150486176 using:1.0,3\n",
      "            train score: 0.9608988402017495 with variance: 4.6853830825520286e-05\n",
      "            test  score: 0.9543524150486176 with variance: 0.0007612662647715773\n",
      "          Refitted train score: 0.9595959595959594,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9555555555555556,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        accuracy\n",
      "          CV score: 0.9554012345679013 using:1.0,3\n",
      "            train score: 0.9616309291747888 with variance: 4.465869287336433e-05\n",
      "            test  score: 0.9554012345679013 with variance: 0.0007126390794086267\n",
      "          Refitted train score: 0.9603960396039604,  RMSE: 0.19900743804199783, Log-Loss:1.3678802492779505\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9645986616039102 using:1.0,5\n",
      "            train score: 0.971540709907082 with variance: 2.3791760350037157e-05\n",
      "            test  score: 0.9645986616039102 with variance: 0.0004184725804459048\n",
      "          Refitted train score: 0.9721518987341773,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758615\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n",
      "        accuracy\n",
      "          CV score: 0.9653395061728395 using:1.0,5\n",
      "            train score: 0.9721553338684401 with variance: 2.2887277140372693e-05\n",
      "            test  score: 0.9653395061728395 with variance: 0.000390675964029873\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758615\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n",
      "        f1\n",
      "          CV score: 0.9645986616039102 using:1.0,5\n",
      "            train score: 0.971540709907082 with variance: 2.3791760350037157e-05\n",
      "            test  score: 0.9645986616039102 with variance: 0.0004184725804459048\n",
      "          Refitted train score: 0.9721518987341773,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758615\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n",
      "        accuracy\n",
      "          CV score: 0.9653395061728395 using:1.0,5\n",
      "            train score: 0.9721553338684401 with variance: 2.2887277140372693e-05\n",
      "            test  score: 0.9653395061728395 with variance: 0.000390675964029873\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758615\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n",
      "        f1\n",
      "          CV score: 0.9645986616039102 using:1.0,5\n",
      "            train score: 0.971540709907082 with variance: 2.3791760350037157e-05\n",
      "            test  score: 0.9645986616039102 with variance: 0.0004184725804459048\n",
      "          Refitted train score: 0.9721518987341773,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758615\n",
      "          Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n",
      "        accuracy\n",
      "          CV score: 0.9653395061728395 using:1.0,5\n",
      "            train score: 0.9721553338684401 with variance: 2.2887277140372693e-05\n",
      "            test  score: 0.9653395061728395 with variance: 0.000390675964029873\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404142077758615\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9747412456273216 using:1.0,10\n",
      "            train score: 0.9798977611921268 with variance: 3.388022014406608e-05\n",
      "            test  score: 0.9747412456273216 with variance: 0.00025845194612892313\n",
      "          Refitted train score: 0.9774436090225563,  RMSE: 0.14925557853149837, Log-Loss:0.7694321454184577\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9752777777777778 using:1.0,10\n",
      "            train score: 0.980197225088866 with variance: 3.300154159100009e-05\n",
      "            test  score: 0.9752777777777778 with variance: 0.00024310699588477356\n",
      "          Refitted train score: 0.9777227722772277,  RMSE: 0.14925557853149837, Log-Loss:0.7694321454184577\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9747412456273216 using:1.0,10\n",
      "            train score: 0.9798977611921268 with variance: 3.388022014406608e-05\n",
      "            test  score: 0.9747412456273216 with variance: 0.00025845194612892313\n",
      "          Refitted train score: 0.9774436090225563,  RMSE: 0.14925557853149837, Log-Loss:0.7694321454184577\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9752777777777778 using:1.0,10\n",
      "            train score: 0.980197225088866 with variance: 3.300154159100009e-05\n",
      "            test  score: 0.9752777777777778 with variance: 0.00024310699588477356\n",
      "          Refitted train score: 0.9777227722772277,  RMSE: 0.14925557853149837, Log-Loss:0.7694321454184577\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9747412456273216 using:1.0,10\n",
      "            train score: 0.9798977611921268 with variance: 3.388022014406608e-05\n",
      "            test  score: 0.9747412456273216 with variance: 0.00025845194612892313\n",
      "          Refitted train score: 0.9774436090225563,  RMSE: 0.14925557853149837, Log-Loss:0.7694321454184577\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9752777777777778 using:1.0,10\n",
      "            train score: 0.980197225088866 with variance: 3.300154159100009e-05\n",
      "            test  score: 0.9752777777777778 with variance: 0.00024310699588477356\n",
      "          Refitted train score: 0.9777227722772277,  RMSE: 0.14925557853149837, Log-Loss:0.7694321454184577\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.974676331638357 using:1.0,15\n",
      "            train score: 0.9855560200313424 with variance: 2.2493314561348533e-05\n",
      "            test  score: 0.974676331638357 with variance: 0.0003225685855807126\n",
      "          Refitted train score: 0.9874686716791979,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9565217391304347,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.975246913580247 using:1.0,15\n",
      "            train score: 0.9857623361235334 with variance: 2.1532132482032933e-05\n",
      "            test  score: 0.975246913580247 with variance: 0.0003048468221307727\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        f1\n",
      "          CV score: 0.974676331638357 using:1.0,15\n",
      "            train score: 0.9855560200313424 with variance: 2.2493314561348533e-05\n",
      "            test  score: 0.974676331638357 with variance: 0.0003225685855807126\n",
      "          Refitted train score: 0.9874686716791979,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9565217391304347,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.975246913580247 using:1.0,15\n",
      "            train score: 0.9857623361235334 with variance: 2.1532132482032933e-05\n",
      "            test  score: 0.975246913580247 with variance: 0.0003048468221307727\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        f1\n",
      "          CV score: 0.974676331638357 using:1.0,15\n",
      "            train score: 0.9855560200313424 with variance: 2.2493314561348533e-05\n",
      "            test  score: 0.974676331638357 with variance: 0.0003225685855807126\n",
      "          Refitted train score: 0.9874686716791979,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9565217391304347,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.975246913580247 using:1.0,15\n",
      "            train score: 0.9857623361235334 with variance: 2.1532132482032933e-05\n",
      "            test  score: 0.975246913580247 with variance: 0.0003048468221307727\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9797452125933139 using:1.0,25\n",
      "            train score: 0.9880994931591129 with variance: 9.493196887705894e-06\n",
      "            test  score: 0.9797452125933139 with variance: 0.00016669749080358714\n",
      "          Refitted train score: 0.9874686716791979,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.980185185185185 using:1.0,25\n",
      "            train score: 0.9882410274051141 with variance: 9.230191800784737e-06\n",
      "            test  score: 0.980185185185185 with variance: 0.0001591373266270388\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9797452125933139 using:1.0,25\n",
      "            train score: 0.9880994931591129 with variance: 9.493196887705894e-06\n",
      "            test  score: 0.9797452125933139 with variance: 0.00016669749080358714\n",
      "          Refitted train score: 0.9874686716791979,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.980185185185185 using:1.0,25\n",
      "            train score: 0.9882410274051141 with variance: 9.230191800784737e-06\n",
      "            test  score: 0.980185185185185 with variance: 0.0001591373266270388\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9797452125933139 using:1.0,25\n",
      "            train score: 0.9880994931591129 with variance: 9.493196887705894e-06\n",
      "            test  score: 0.9797452125933139 with variance: 0.00016669749080358714\n",
      "          Refitted train score: 0.9874686716791979,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.980185185185185 using:1.0,25\n",
      "            train score: 0.9882410274051141 with variance: 9.230191800784737e-06\n",
      "            test  score: 0.980185185185185 with variance: 0.0001591373266270388\n",
      "          Refitted train score: 0.9876237623762376,  RMSE: 0.1112485398724962, Log-Loss:0.42746010389741035\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9723276414847888 using:1.0,50\n",
      "            train score: 0.992519446218146 with variance: 2.3196159548272084e-06\n",
      "            test  score: 0.9723276414847888 with variance: 0.00039965611467660965\n",
      "          Refitted train score: 0.9925187032418953,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9727777777777777 using:1.0,50\n",
      "            train score: 0.9925734816343692 with variance: 2.309940198339874e-06\n",
      "            test  score: 0.9727777777777777 with variance: 0.00038989483310470925\n",
      "          Refitted train score: 0.9925742574257426,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9723276414847888 using:1.0,50\n",
      "            train score: 0.992519446218146 with variance: 2.3196159548272084e-06\n",
      "            test  score: 0.9723276414847888 with variance: 0.00039965611467660965\n",
      "          Refitted train score: 0.9925187032418953,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9727777777777777 using:1.0,50\n",
      "            train score: 0.9925734816343692 with variance: 2.309940198339874e-06\n",
      "            test  score: 0.9727777777777777 with variance: 0.00038989483310470925\n",
      "          Refitted train score: 0.9925742574257426,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9749891150323382 using:1.5,50\n",
      "            train score: 0.9943963570907094 with variance: 5.45419989712651e-06\n",
      "            test  score: 0.9749891150323382 with variance: 0.0003023167349244018\n",
      "          Refitted train score: 0.9950248756218906,  RMSE: 0.07035975447302918, Log-Loss:0.17098404155896477\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.975246913580247 using:1.5,50\n",
      "            train score: 0.9944291556778657 with variance: 5.377116415175863e-06\n",
      "            test  score: 0.975246913580247 with variance: 0.0003048468221307727\n",
      "          Refitted train score: 0.995049504950495,  RMSE: 0.07035975447302918, Log-Loss:0.17098404155896477\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9768847818847819 using:1.0,100\n",
      "            train score: 0.9981385569476192 with variance: 2.310029769815272e-06\n",
      "            test  score: 0.9768847818847819 with variance: 0.0005654916622948576\n",
      "          Refitted train score: 0.9975186104218362,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9777160493827161 using:1.0,100\n",
      "            train score: 0.9981424148606811 with variance: 2.300415033212295e-06\n",
      "            test  score: 0.9777160493827161 with variance: 0.000512437128486512\n",
      "          Refitted train score: 0.9975247524752475,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9768847818847819 using:1.0,100\n",
      "            train score: 0.9981385569476192 with variance: 2.310029769815272e-06\n",
      "            test  score: 0.9768847818847819 with variance: 0.0005654916622948576\n",
      "          Refitted train score: 0.9975186104218362,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9777160493827161 using:1.0,100\n",
      "            train score: 0.9981424148606811 with variance: 2.300415033212295e-06\n",
      "            test  score: 0.9777160493827161 with variance: 0.000512437128486512\n",
      "          Refitted train score: 0.9975247524752475,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9768847818847819 using:1.0,100\n",
      "            train score: 0.9981385569476192 with variance: 2.310029769815272e-06\n",
      "            test  score: 0.9768847818847819 with variance: 0.0005654916622948576\n",
      "          Refitted train score: 0.9975186104218362,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9777160493827161 using:1.0,100\n",
      "            train score: 0.9981424148606811 with variance: 2.300415033212295e-06\n",
      "            test  score: 0.9777160493827161 with variance: 0.000512437128486512\n",
      "          Refitted train score: 0.9975247524752475,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "    random state: 850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9370774279635039 using:1.0,2\n",
      "            train score: 0.935998674119201 with variance: 7.463477908637086e-05\n",
      "            test  score: 0.9370774279635039 with variance: 0.0012256063827604498\n",
      "          Refitted train score: 0.93734335839599,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9375 using:1.0,2\n",
      "            train score: 0.93625 with variance: 7.26562499999999e-05\n",
      "            test  score: 0.9375 with variance: 0.0011875000000000006\n",
      "          Refitted train score: 0.9375,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9370774279635039 using:1.0,2\n",
      "            train score: 0.935998674119201 with variance: 7.463477908637086e-05\n",
      "            test  score: 0.9370774279635039 with variance: 0.0012256063827604498\n",
      "          Refitted train score: 0.93734335839599,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9375 using:1.0,2\n",
      "            train score: 0.93625 with variance: 7.26562499999999e-05\n",
      "            test  score: 0.9375 with variance: 0.0011875000000000006\n",
      "          Refitted train score: 0.9375,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9370774279635039 using:1.0,2\n",
      "            train score: 0.935998674119201 with variance: 7.463477908637086e-05\n",
      "            test  score: 0.9370774279635039 with variance: 0.0012256063827604498\n",
      "          Refitted train score: 0.93734335839599,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9375 using:1.0,2\n",
      "            train score: 0.93625 with variance: 7.26562499999999e-05\n",
      "            test  score: 0.9375 with variance: 0.0011875000000000006\n",
      "          Refitted train score: 0.9375,  RMSE: 0.25, Log-Loss:2.158697512604824\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9516283716283717 using:1.0,3\n",
      "            train score: 0.953726428658231 with variance: 2.4894620221238736e-05\n",
      "            test  score: 0.9516283716283717 with variance: 0.0004109602962250306\n",
      "          Refitted train score: 0.9543147208121826,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9524999999999999 using:1.0,3\n",
      "            train score: 0.9543750000000001 with variance: 2.5781249999999952e-05\n",
      "            test  score: 0.9524999999999999 with variance: 0.00039999999999999915\n",
      "          Refitted train score: 0.955,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9516283716283717 using:1.0,3\n",
      "            train score: 0.953726428658231 with variance: 2.4894620221238736e-05\n",
      "            test  score: 0.9516283716283717 with variance: 0.0004109602962250306\n",
      "          Refitted train score: 0.9543147208121826,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9524999999999999 using:1.0,3\n",
      "            train score: 0.9543750000000001 with variance: 2.5781249999999952e-05\n",
      "            test  score: 0.9524999999999999 with variance: 0.00039999999999999915\n",
      "          Refitted train score: 0.955,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9516283716283717 using:1.0,3\n",
      "            train score: 0.953726428658231 with variance: 2.4894620221238736e-05\n",
      "            test  score: 0.9516283716283717 with variance: 0.0004109602962250306\n",
      "          Refitted train score: 0.9543147208121826,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9524999999999999 using:1.0,3\n",
      "            train score: 0.9543750000000001 with variance: 2.5781249999999952e-05\n",
      "            test  score: 0.9524999999999999 with variance: 0.00039999999999999915\n",
      "          Refitted train score: 0.955,  RMSE: 0.21213203435596426, Log-Loss:1.5542569317324344\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9696170074651087 using:1.0,5\n",
      "            train score: 0.97575503535157 with variance: 1.1109882680085407e-05\n",
      "            test  score: 0.9696170074651087 with variance: 0.00016032010750312683\n",
      "          Refitted train score: 0.9770992366412213,  RMSE: 0.15, Log-Loss:0.7771244678790669\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9700000000000001 using:1.0,5\n",
      "            train score: 0.97625 with variance: 1.0156249999999874e-05\n",
      "            test  score: 0.9700000000000001 with variance: 0.0001625000000000005\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771244678790669\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9696170074651087 using:1.0,5\n",
      "            train score: 0.97575503535157 with variance: 1.1109882680085407e-05\n",
      "            test  score: 0.9696170074651087 with variance: 0.00016032010750312683\n",
      "          Refitted train score: 0.9770992366412213,  RMSE: 0.15, Log-Loss:0.7771244678790669\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9700000000000001 using:1.0,5\n",
      "            train score: 0.97625 with variance: 1.0156249999999874e-05\n",
      "            test  score: 0.9700000000000001 with variance: 0.0001625000000000005\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771244678790669\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.9696170074651087 using:1.0,5\n",
      "            train score: 0.97575503535157 with variance: 1.1109882680085407e-05\n",
      "            test  score: 0.9696170074651087 with variance: 0.00016032010750312683\n",
      "          Refitted train score: 0.9770992366412213,  RMSE: 0.15, Log-Loss:0.7771244678790669\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9700000000000001 using:1.0,5\n",
      "            train score: 0.97625 with variance: 1.0156249999999874e-05\n",
      "            test  score: 0.9700000000000001 with variance: 0.0001625000000000005\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771244678790669\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9693580680922453 using:1.0,10\n",
      "            train score: 0.97967033065477 with variance: 2.3897877436849046e-06\n",
      "            test  score: 0.9693580680922453 with variance: 0.00010503374209688665\n",
      "          Refitted train score: 0.9796954314720813,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        accuracy\n",
      "          CV score: 0.9700000000000001 using:1.0,10\n",
      "            train score: 0.9799999999999999 with variance: 2.3437499999999003e-06\n",
      "            test  score: 0.9700000000000001 with variance: 0.00010000000000000007\n",
      "          Refitted train score: 0.98,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        f1\n",
      "          CV score: 0.9693580680922453 using:1.0,10\n",
      "            train score: 0.97967033065477 with variance: 2.3897877436849046e-06\n",
      "            test  score: 0.9693580680922453 with variance: 0.00010503374209688665\n",
      "          Refitted train score: 0.9796954314720813,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        accuracy\n",
      "          CV score: 0.9700000000000001 using:1.0,10\n",
      "            train score: 0.9799999999999999 with variance: 2.3437499999999003e-06\n",
      "            test  score: 0.9700000000000001 with variance: 0.00010000000000000007\n",
      "          Refitted train score: 0.98,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        f1\n",
      "          CV score: 0.9693580680922453 using:1.0,10\n",
      "            train score: 0.97967033065477 with variance: 2.3897877436849046e-06\n",
      "            test  score: 0.9693580680922453 with variance: 0.00010503374209688665\n",
      "          Refitted train score: 0.9796954314720813,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        accuracy\n",
      "          CV score: 0.9700000000000001 using:1.0,10\n",
      "            train score: 0.9799999999999999 with variance: 2.3437499999999003e-06\n",
      "            test  score: 0.9700000000000001 with variance: 0.00010000000000000007\n",
      "          Refitted train score: 0.98,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9770853618954884 using:1.0,15\n",
      "            train score: 0.9841470765521398 with variance: 4.00637386468402e-06\n",
      "            test  score: 0.9770853618954884 with variance: 9.041184986854381e-05\n",
      "          Refitted train score: 0.9822784810126582,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045135\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:1.0,15\n",
      "            train score: 0.984375 with variance: 3.906250000000111e-06\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.9825,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045135\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9770853618954884 using:1.0,15\n",
      "            train score: 0.9841470765521398 with variance: 4.00637386468402e-06\n",
      "            test  score: 0.9770853618954884 with variance: 9.041184986854381e-05\n",
      "          Refitted train score: 0.9822784810126582,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045135\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:1.0,15\n",
      "            train score: 0.984375 with variance: 3.906250000000111e-06\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.9825,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045135\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9770853618954884 using:1.0,15\n",
      "            train score: 0.9841470765521398 with variance: 4.00637386468402e-06\n",
      "            test  score: 0.9770853618954884 with variance: 9.041184986854381e-05\n",
      "          Refitted train score: 0.9822784810126582,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045135\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:1.0,15\n",
      "            train score: 0.984375 with variance: 3.906250000000111e-06\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.9825,  RMSE: 0.13228756555322954, Log-Loss:0.6044305859045135\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9796802986043491 using:1.0,25\n",
      "            train score: 0.9873377156370408 with variance: 4.107928968528555e-06\n",
      "            test  score: 0.9796802986043491 with variance: 3.9186906462860475e-05\n",
      "          Refitted train score: 0.9873417721518987,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,25\n",
      "            train score: 0.9875 with variance: 3.906249999999972e-06\n",
      "            test  score: 0.9800000000000001 with variance: 3.75000000000004e-05\n",
      "          Refitted train score: 0.9875,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9796802986043491 using:1.0,25\n",
      "            train score: 0.9873377156370408 with variance: 4.107928968528555e-06\n",
      "            test  score: 0.9796802986043491 with variance: 3.9186906462860475e-05\n",
      "          Refitted train score: 0.9873417721518987,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,25\n",
      "            train score: 0.9875 with variance: 3.906249999999972e-06\n",
      "            test  score: 0.9800000000000001 with variance: 3.75000000000004e-05\n",
      "          Refitted train score: 0.9875,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9822111628018801 using:1.5,25\n",
      "            train score: 0.9879766167271657 with variance: 5.745890803909827e-06\n",
      "            test  score: 0.9822111628018801 with variance: 4.111760046523236e-05\n",
      "          Refitted train score: 0.9873417721518987,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9825000000000002 using:1.5,25\n",
      "            train score: 0.9881249999999999 with variance: 5.468749999999933e-06\n",
      "            test  score: 0.9825000000000002 with variance: 3.75000000000004e-05\n",
      "          Refitted train score: 0.9875,  RMSE: 0.11180339887498948, Log-Loss:0.4317347049363845\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9770162959403464 using:1.0,50\n",
      "            train score: 0.9886155178172906 with variance: 6.5674634333653025e-06\n",
      "            test  score: 0.9770162959403464 with variance: 9.592659116951477e-05\n",
      "          Refitted train score: 0.98989898989899,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:1.0,50\n",
      "            train score: 0.9887499999999999 with variance: 6.249999999999927e-06\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.99,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9770162959403464 using:1.0,50\n",
      "            train score: 0.9886155178172906 with variance: 6.5674634333653025e-06\n",
      "            test  score: 0.9770162959403464 with variance: 9.592659116951477e-05\n",
      "          Refitted train score: 0.98989898989899,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:1.0,50\n",
      "            train score: 0.9887499999999999 with variance: 6.249999999999927e-06\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.99,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9770162959403464 using:1.0,50\n",
      "            train score: 0.9886155178172906 with variance: 6.5674634333653025e-06\n",
      "            test  score: 0.9770162959403464 with variance: 9.592659116951477e-05\n",
      "          Refitted train score: 0.98989898989899,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9775 using:1.0,50\n",
      "            train score: 0.9887499999999999 with variance: 6.249999999999927e-06\n",
      "            test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "          Refitted train score: 0.99,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9796802986043491 using:1.0,100\n",
      "            train score: 0.998115179117131 with variance: 6.323919197356401e-06\n",
      "            test  score: 0.9796802986043491 with variance: 3.9186906462860475e-05\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,100\n",
      "            train score: 0.9981249999999999 with variance: 6.2499999999999825e-06\n",
      "            test  score: 0.9800000000000001 with variance: 3.75000000000004e-05\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9796802986043491 using:1.0,100\n",
      "            train score: 0.998115179117131 with variance: 6.323919197356401e-06\n",
      "            test  score: 0.9796802986043491 with variance: 3.9186906462860475e-05\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,100\n",
      "            train score: 0.9981249999999999 with variance: 6.2499999999999825e-06\n",
      "            test  score: 0.9800000000000001 with variance: 3.75000000000004e-05\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9796802986043491 using:1.0,100\n",
      "            train score: 0.998115179117131 with variance: 6.323919197356401e-06\n",
      "            test  score: 0.9796802986043491 with variance: 3.9186906462860475e-05\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:1.0,100\n",
      "            train score: 0.9981249999999999 with variance: 6.2499999999999825e-06\n",
      "            test  score: 0.9800000000000001 with variance: 3.75000000000004e-05\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9501525221145475 using:1.0,2\n",
      "            train score: 0.9516129971332464 with variance: 1.371606397969043e-05\n",
      "            test  score: 0.9501525221145475 with variance: 0.0005835702092985239\n",
      "          Refitted train score: 0.9502487562189056,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9507377295995182 using:1.0,2\n",
      "            train score: 0.95197150997151 with variance: 1.3531188870220063e-05\n",
      "            test  score: 0.9507377295995182 with variance: 0.0005487548736104968\n",
      "          Refitted train score: 0.9507389162561576,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        f1\n",
      "          CV score: 0.9501525221145475 using:1.0,2\n",
      "            train score: 0.9516129971332464 with variance: 1.371606397969043e-05\n",
      "            test  score: 0.9501525221145475 with variance: 0.0005835702092985239\n",
      "          Refitted train score: 0.9502487562189056,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9507377295995182 using:1.0,2\n",
      "            train score: 0.95197150997151 with variance: 1.3531188870220063e-05\n",
      "            test  score: 0.9507377295995182 with variance: 0.0005487548736104968\n",
      "          Refitted train score: 0.9507389162561576,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        f1\n",
      "          CV score: 0.9501525221145475 using:1.0,2\n",
      "            train score: 0.9516129971332464 with variance: 1.371606397969043e-05\n",
      "            test  score: 0.9501525221145475 with variance: 0.0005835702092985239\n",
      "          Refitted train score: 0.9502487562189056,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9507377295995182 using:1.0,2\n",
      "            train score: 0.95197150997151 with variance: 1.3531188870220063e-05\n",
      "            test  score: 0.9507377295995182 with variance: 0.0005487548736104968\n",
      "          Refitted train score: 0.9507389162561576,  RMSE: 0.22194838080923765, Log-Loss:1.7014333120139298\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9545400015236385 using:1.0,3\n",
      "            train score: 0.9606501528335236 with variance: 1.791488564527411e-05\n",
      "            test  score: 0.9545400015236385 with variance: 0.00043409318773552144\n",
      "          Refitted train score: 0.96,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.955615778380006 using:1.0,3\n",
      "            train score: 0.9612060778727447 with variance: 1.748333572328516e-05\n",
      "            test  score: 0.955615778380006 with variance: 0.0004047713667942662\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        f1\n",
      "          CV score: 0.9545400015236385 using:1.0,3\n",
      "            train score: 0.9606501528335236 with variance: 1.791488564527411e-05\n",
      "            test  score: 0.9545400015236385 with variance: 0.00043409318773552144\n",
      "          Refitted train score: 0.96,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.955615778380006 using:1.0,3\n",
      "            train score: 0.9612060778727447 with variance: 1.748333572328516e-05\n",
      "            test  score: 0.955615778380006 with variance: 0.0004047713667942662\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        f1\n",
      "          CV score: 0.9572706042542413 using:1.5,3\n",
      "            train score: 0.9606501528335236 with variance: 1.791488564527411e-05\n",
      "            test  score: 0.9572706042542413 with variance: 0.0003575606135234121\n",
      "          Refitted train score: 0.96,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.989010989010989,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9580849141824752 using:1.5,3\n",
      "            train score: 0.9612060778727447 with variance: 1.748333572328516e-05\n",
      "            test  score: 0.9580849141824752 with variance: 0.00034350765401996395\n",
      "          Refitted train score: 0.9605911330049262,  RMSE: 0.19851666679418606, Log-Loss:1.361143892378626\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.947980390756908 using:1.0,5\n",
      "            train score: 0.9639430891156712 with variance: 9.114407028042121e-06\n",
      "            test  score: 0.947980390756908 with variance: 0.0006527516422112885\n",
      "          Refitted train score: 0.9627791563275433,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        accuracy\n",
      "          CV score: 0.9483288166214996 using:1.0,5\n",
      "            train score: 0.964286799620133 with variance: 9.770757632739326e-06\n",
      "            test  score: 0.9483288166214996 with variance: 0.0006261505420099539\n",
      "          Refitted train score: 0.9630541871921182,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        f1\n",
      "          CV score: 0.947980390756908 using:1.0,5\n",
      "            train score: 0.9639430891156712 with variance: 9.114407028042121e-06\n",
      "            test  score: 0.947980390756908 with variance: 0.0006527516422112885\n",
      "          Refitted train score: 0.9627791563275433,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        accuracy\n",
      "          CV score: 0.9483288166214996 using:1.0,5\n",
      "            train score: 0.964286799620133 with variance: 9.770757632739326e-06\n",
      "            test  score: 0.9483288166214996 with variance: 0.0006261505420099539\n",
      "          Refitted train score: 0.9630541871921182,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        f1\n",
      "          CV score: 0.947980390756908 using:1.0,5\n",
      "            train score: 0.9639430891156712 with variance: 9.114407028042121e-06\n",
      "            test  score: 0.947980390756908 with variance: 0.0006527516422112885\n",
      "          Refitted train score: 0.9627791563275433,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        accuracy\n",
      "          CV score: 0.9483288166214996 using:1.0,5\n",
      "            train score: 0.964286799620133 with variance: 9.770757632739326e-06\n",
      "            test  score: 0.9483288166214996 with variance: 0.0006261505420099539\n",
      "          Refitted train score: 0.9630541871921182,  RMSE: 0.1922129361096224, Log-Loss:1.2760749840104475\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9701128564892482 using:1.0,10\n",
      "            train score: 0.9793569623229296 with variance: 2.590970080796993e-05\n",
      "            test  score: 0.9701128564892482 with variance: 0.0002205523720160787\n",
      "          Refitted train score: 0.975,  RMSE: 0.15694120514358612, Log-Loss:0.8507127171033685\n",
      "          Refitted test  score: 0.9662921348314606,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        accuracy\n",
      "          CV score: 0.970460704607046 using:1.0,10\n",
      "            train score: 0.9796828110161444 with variance: 2.4900937853138078e-05\n",
      "            test  score: 0.970460704607046 with variance: 0.00021817309410673098\n",
      "          Refitted train score: 0.9753694581280788,  RMSE: 0.15694120514358612, Log-Loss:0.8507127171033685\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        f1\n",
      "          CV score: 0.9701128564892482 using:1.0,10\n",
      "            train score: 0.9793569623229296 with variance: 2.590970080796993e-05\n",
      "            test  score: 0.9701128564892482 with variance: 0.0002205523720160787\n",
      "          Refitted train score: 0.975,  RMSE: 0.15694120514358612, Log-Loss:0.8507127171033685\n",
      "          Refitted test  score: 0.9662921348314606,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        accuracy\n",
      "          CV score: 0.970460704607046 using:1.0,10\n",
      "            train score: 0.9796828110161444 with variance: 2.4900937853138078e-05\n",
      "            test  score: 0.970460704607046 with variance: 0.00021817309410673098\n",
      "          Refitted train score: 0.9753694581280788,  RMSE: 0.15694120514358612, Log-Loss:0.8507127171033685\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        f1\n",
      "          CV score: 0.9726445020588684 using:1.5,10\n",
      "            train score: 0.9799954948590646 with variance: 1.809753563579583e-05\n",
      "            test  score: 0.9726445020588684 with variance: 0.00033342430519021124\n",
      "          Refitted train score: 0.975,  RMSE: 0.15694120514358612, Log-Loss:0.8507127171033685\n",
      "          Refitted test  score: 0.9662921348314606,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        accuracy\n",
      "          CV score: 0.9729298404095152 using:1.5,10\n",
      "            train score: 0.9802981956315291 with variance: 1.7338661572913025e-05\n",
      "            test  score: 0.9729298404095152 with variance: 0.00032746636810943036\n",
      "          Refitted train score: 0.9753694581280788,  RMSE: 0.15694120514358612, Log-Loss:0.8507127171033685\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9750495653500078 using:1.0,15\n",
      "            train score: 0.9831503115264798 with variance: 2.5918020496695783e-05\n",
      "            test  score: 0.9750495653500078 with variance: 0.0002476387016319305\n",
      "          Refitted train score: 0.98,  RMSE: 0.1403724812687193, Log-Loss:0.680568992011616\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9753989762119843 using:1.0,15\n",
      "            train score: 0.9833751187084522 with variance: 2.4971067154036298e-05\n",
      "            test  score: 0.9753989762119843 with variance: 0.00024166743055901275\n",
      "          Refitted train score: 0.9802955665024631,  RMSE: 0.1403724812687193, Log-Loss:0.680568992011616\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        f1\n",
      "          CV score: 0.9750495653500078 using:1.0,15\n",
      "            train score: 0.9831503115264798 with variance: 2.5918020496695783e-05\n",
      "            test  score: 0.9750495653500078 with variance: 0.0002476387016319305\n",
      "          Refitted train score: 0.98,  RMSE: 0.1403724812687193, Log-Loss:0.680568992011616\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9753989762119843 using:1.0,15\n",
      "            train score: 0.9833751187084522 with variance: 2.4971067154036298e-05\n",
      "            test  score: 0.9753989762119843 with variance: 0.00024166743055901275\n",
      "          Refitted train score: 0.9802955665024631,  RMSE: 0.1403724812687193, Log-Loss:0.680568992011616\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        f1\n",
      "          CV score: 0.9750495653500078 using:1.0,15\n",
      "            train score: 0.9831503115264798 with variance: 2.5918020496695783e-05\n",
      "            test  score: 0.9750495653500078 with variance: 0.0002476387016319305\n",
      "          Refitted train score: 0.98,  RMSE: 0.1403724812687193, Log-Loss:0.680568992011616\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9753989762119843 using:1.0,15\n",
      "            train score: 0.9833751187084522 with variance: 2.4971067154036298e-05\n",
      "            test  score: 0.9753989762119843 with variance: 0.00024166743055901275\n",
      "          Refitted train score: 0.9802955665024631,  RMSE: 0.1403724812687193, Log-Loss:0.680568992011616\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9725179197803875 using:1.0,25\n",
      "            train score: 0.9888043602564744 with variance: 6.235693234610002e-06\n",
      "            test  score: 0.9725179197803875 with variance: 0.00014694430410913607\n",
      "          Refitted train score: 0.9900497512437811,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.972929840409515 using:1.0,25\n",
      "            train score: 0.9889173789173789 with variance: 6.038262676439163e-06\n",
      "            test  score: 0.972929840409515 with variance: 0.00014456741977838318\n",
      "          Refitted train score: 0.9901477832512315,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        f1\n",
      "          CV score: 0.9725179197803875 using:1.0,25\n",
      "            train score: 0.9888043602564744 with variance: 6.235693234610002e-06\n",
      "            test  score: 0.9725179197803875 with variance: 0.00014694430410913607\n",
      "          Refitted train score: 0.9900497512437811,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.972929840409515 using:1.0,25\n",
      "            train score: 0.9889173789173789 with variance: 6.038262676439163e-06\n",
      "            test  score: 0.972929840409515 with variance: 0.00014456741977838318\n",
      "          Refitted train score: 0.9901477832512315,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        f1\n",
      "          CV score: 0.9725179197803875 using:1.0,25\n",
      "            train score: 0.9888043602564744 with variance: 6.235693234610002e-06\n",
      "            test  score: 0.9725179197803875 with variance: 0.00014694430410913607\n",
      "          Refitted train score: 0.9900497512437811,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.972929840409515 using:1.0,25\n",
      "            train score: 0.9889173789173789 with variance: 6.038262676439163e-06\n",
      "            test  score: 0.972929840409515 with variance: 0.00014456741977838318\n",
      "          Refitted train score: 0.9901477832512315,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.977463723371411 using:1.0,50\n",
      "            train score: 0.9919311987931682 with variance: 2.3009505624963445e-06\n",
      "            test  score: 0.977463723371411 with variance: 8.860064620358362e-05\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        accuracy\n",
      "          CV score: 0.9778380006022281 using:1.0,50\n",
      "            train score: 0.9919962013295345 with variance: 2.25822120852195e-06\n",
      "            test  score: 0.9778380006022281 with variance: 8.506995304487478e-05\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        f1\n",
      "          CV score: 0.977463723371411 using:1.0,50\n",
      "            train score: 0.9919311987931682 with variance: 2.3009505624963445e-06\n",
      "            test  score: 0.977463723371411 with variance: 8.860064620358362e-05\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        accuracy\n",
      "          CV score: 0.9778380006022281 using:1.0,50\n",
      "            train score: 0.9919962013295345 with variance: 2.25822120852195e-06\n",
      "            test  score: 0.9778380006022281 with variance: 8.506995304487478e-05\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        f1\n",
      "          CV score: 0.9798726363494297 using:1.5,50\n",
      "            train score: 0.9938042036036382 with variance: 7.66810927547838e-06\n",
      "            test  score: 0.9798726363494297 with variance: 0.00010288000149265246\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        accuracy\n",
      "          CV score: 0.9802770249924719 using:1.5,50\n",
      "            train score: 0.9938423551756885 with variance: 7.574022216630692e-06\n",
      "            test  score: 0.9802770249924719 with variance: 9.799582756107265e-05\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9799945875689418 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9799945875689418 with variance: 0.00010175104200230972\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9803071364046974 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9803071364046974 with variance: 9.69658196029917e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        f1\n",
      "          CV score: 0.9799945875689418 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9799945875689418 with variance: 0.00010175104200230972\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9803071364046974 using:1.0,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9803071364046974 with variance: 9.69658196029917e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        f1\n",
      "          CV score: 0.982526233138562 using:1.5,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.982526233138562 with variance: 0.0001645888937602717\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "        accuracy\n",
      "          CV score: 0.9827762722071665 using:1.5,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9827762722071665 with variance: 0.00015763473904938815\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9477519422256264 using:1.0,2\n",
      "            train score: 0.9494762871958304 with variance: 2.4053030972056122e-05\n",
      "            test  score: 0.9477519422256264 with variance: 0.0008530372886596353\n",
      "          Refitted train score: 0.9509043927648579,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9490425186627718 using:1.0,2\n",
      "            train score: 0.9502574225188744 with variance: 2.2595115154233516e-05\n",
      "            test  score: 0.9490425186627718 with variance: 0.0007659050070892347\n",
      "          Refitted train score: 0.951530612244898,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        f1\n",
      "          CV score: 0.9477519422256264 using:1.0,2\n",
      "            train score: 0.9494762871958304 with variance: 2.4053030972056122e-05\n",
      "            test  score: 0.9477519422256264 with variance: 0.0008530372886596353\n",
      "          Refitted train score: 0.9509043927648579,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9490425186627718 using:1.0,2\n",
      "            train score: 0.9502574225188744 with variance: 2.2595115154233516e-05\n",
      "            test  score: 0.9490425186627718 with variance: 0.0007659050070892347\n",
      "          Refitted train score: 0.951530612244898,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        f1\n",
      "          CV score: 0.9477519422256264 using:1.0,2\n",
      "            train score: 0.9494762871958304 with variance: 2.4053030972056122e-05\n",
      "            test  score: 0.9477519422256264 with variance: 0.0008530372886596353\n",
      "          Refitted train score: 0.9509043927648579,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9490425186627718 using:1.0,2\n",
      "            train score: 0.9502574225188744 with variance: 2.2595115154233516e-05\n",
      "            test  score: 0.9490425186627718 with variance: 0.0007659050070892347\n",
      "          Refitted train score: 0.951530612244898,  RMSE: 0.22015764296317772, Log-Loss:1.6740876241972313\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.953089273817455 using:1.0,3\n",
      "            train score: 0.9568866149757234 with variance: 2.4970808956541517e-05\n",
      "            test  score: 0.953089273817455 with variance: 0.00033335310370479247\n",
      "          Refitted train score: 0.9538461538461539,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9541058098020123 using:1.0,3\n",
      "            train score: 0.95727193178812 with variance: 2.6749191118888054e-05\n",
      "            test  score: 0.9541058098020123 with variance: 0.00029325489717685197\n",
      "          Refitted train score: 0.9540816326530612,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.953089273817455 using:1.0,3\n",
      "            train score: 0.9568866149757234 with variance: 2.4970808956541517e-05\n",
      "            test  score: 0.953089273817455 with variance: 0.00033335310370479247\n",
      "          Refitted train score: 0.9538461538461539,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9541058098020123 using:1.0,3\n",
      "            train score: 0.95727193178812 with variance: 2.6749191118888054e-05\n",
      "            test  score: 0.9541058098020123 with variance: 0.00029325489717685197\n",
      "          Refitted train score: 0.9540816326530612,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9534310373171133 using:1.5,3\n",
      "            train score: 0.9588994393122233 with variance: 4.48191613924577e-05\n",
      "            test  score: 0.9534310373171133 with variance: 0.0005212321060660976\n",
      "          Refitted train score: 0.9538461538461539,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9541382667964946 using:1.5,3\n",
      "            train score: 0.959188864695468 with variance: 4.60273548276343e-05\n",
      "            test  score: 0.9541382667964946 with variance: 0.0004827211539646683\n",
      "          Refitted train score: 0.9540816326530612,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.958942038640906 using:1.0,5\n",
      "            train score: 0.9616110635810736 with variance: 6.798188234739344e-05\n",
      "            test  score: 0.958942038640906 with variance: 0.0004703065759846522\n",
      "          Refitted train score: 0.9616368286445012,  RMSE: 0.1956151991089879, Log-Loss:1.321651130371612\n",
      "          Refitted test  score: 0.9714285714285713,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9592015579357351 using:1.0,5\n",
      "            train score: 0.9617346004354816 with variance: 6.938732463920627e-05\n",
      "            test  score: 0.9592015579357351 with variance: 0.00047451472790114294\n",
      "          Refitted train score: 0.9617346938775511,  RMSE: 0.1956151991089879, Log-Loss:1.321651130371612\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.958942038640906 using:1.0,5\n",
      "            train score: 0.9616110635810736 with variance: 6.798188234739344e-05\n",
      "            test  score: 0.958942038640906 with variance: 0.0004703065759846522\n",
      "          Refitted train score: 0.9616368286445012,  RMSE: 0.1956151991089879, Log-Loss:1.321651130371612\n",
      "          Refitted test  score: 0.9714285714285713,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9592015579357351 using:1.0,5\n",
      "            train score: 0.9617346004354816 with variance: 6.938732463920627e-05\n",
      "            test  score: 0.9592015579357351 with variance: 0.00047451472790114294\n",
      "          Refitted train score: 0.9617346938775511,  RMSE: 0.1956151991089879, Log-Loss:1.321651130371612\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.958942038640906 using:1.0,5\n",
      "            train score: 0.9616110635810736 with variance: 6.798188234739344e-05\n",
      "            test  score: 0.958942038640906 with variance: 0.0004703065759846522\n",
      "          Refitted train score: 0.9616368286445012,  RMSE: 0.1956151991089879, Log-Loss:1.321651130371612\n",
      "          Refitted test  score: 0.9714285714285713,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9592015579357351 using:1.0,5\n",
      "            train score: 0.9617346004354816 with variance: 6.938732463920627e-05\n",
      "            test  score: 0.9592015579357351 with variance: 0.00047451472790114294\n",
      "          Refitted train score: 0.9617346938775511,  RMSE: 0.1956151991089879, Log-Loss:1.321651130371612\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9688435101768436 using:1.0,10\n",
      "            train score: 0.973949428970385 with variance: 4.717022626879345e-05\n",
      "            test  score: 0.9688435101768436 with variance: 0.0006957202452146278\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9693930542031808 using:1.0,10\n",
      "            train score: 0.9744917685842779 with variance: 4.469302094735523e-05\n",
      "            test  score: 0.9693930542031808 with variance: 0.000686196275167471\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9688435101768436 using:1.0,10\n",
      "            train score: 0.973949428970385 with variance: 4.717022626879345e-05\n",
      "            test  score: 0.9688435101768436 with variance: 0.0006957202452146278\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9693930542031808 using:1.0,10\n",
      "            train score: 0.9744917685842779 with variance: 4.469302094735523e-05\n",
      "            test  score: 0.9693930542031808 with variance: 0.000686196275167471\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9688435101768436 using:1.0,10\n",
      "            train score: 0.973949428970385 with variance: 4.717022626879345e-05\n",
      "            test  score: 0.9688435101768436 with variance: 0.0006957202452146278\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9693930542031808 using:1.0,10\n",
      "            train score: 0.9744917685842779 with variance: 4.469302094735523e-05\n",
      "            test  score: 0.9693930542031808 with variance: 0.000686196275167471\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810932743534118\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9660951303585286 using:1.0,15\n",
      "            train score: 0.9766189006958156 with variance: 3.9908485967925025e-05\n",
      "            test  score: 0.9660951303585286 with variance: 0.0007230377605135606\n",
      "          Refitted train score: 0.9766233766233766,  RMSE: 0.15152288168283162, Log-Loss:0.7929841508970068\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:1.0,15\n",
      "            train score: 0.9770415742455384 with variance: 3.8204204400585306e-05\n",
      "            test  score: 0.9668614086335605 with variance: 0.0006883537540606801\n",
      "          Refitted train score: 0.9770408163265306,  RMSE: 0.15152288168283162, Log-Loss:0.7929841508970068\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9660951303585286 using:1.0,15\n",
      "            train score: 0.9766189006958156 with variance: 3.9908485967925025e-05\n",
      "            test  score: 0.9660951303585286 with variance: 0.0007230377605135606\n",
      "          Refitted train score: 0.9766233766233766,  RMSE: 0.15152288168283162, Log-Loss:0.7929841508970068\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:1.0,15\n",
      "            train score: 0.9770415742455384 with variance: 3.8204204400585306e-05\n",
      "            test  score: 0.9668614086335605 with variance: 0.0006883537540606801\n",
      "          Refitted train score: 0.9770408163265306,  RMSE: 0.15152288168283162, Log-Loss:0.7929841508970068\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        f1\n",
      "          CV score: 0.9660951303585286 using:1.0,15\n",
      "            train score: 0.9766189006958156 with variance: 3.9908485967925025e-05\n",
      "            test  score: 0.9660951303585286 with variance: 0.0007230377605135606\n",
      "          Refitted train score: 0.9766233766233766,  RMSE: 0.15152288168283162, Log-Loss:0.7929841508970068\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:1.0,15\n",
      "            train score: 0.9770415742455384 with variance: 3.8204204400585306e-05\n",
      "            test  score: 0.9668614086335605 with variance: 0.0006883537540606801\n",
      "          Refitted train score: 0.9770408163265306,  RMSE: 0.15152288168283162, Log-Loss:0.7929841508970068\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9658483385505555 using:1.0,25\n",
      "            train score: 0.9870839121357031 with variance: 8.623442618520725e-06\n",
      "            test  score: 0.9658483385505555 with variance: 0.0007436303212400358\n",
      "          Refitted train score: 0.9870801033591732,  RMSE: 0.11293848786315641, Log-Loss:0.44054561728202496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:1.0,25\n",
      "            train score: 0.9872428318512038 with variance: 8.17924058397689e-06\n",
      "            test  score: 0.9668614086335605 with variance: 0.0006883537540606801\n",
      "          Refitted train score: 0.9872448979591837,  RMSE: 0.11293848786315641, Log-Loss:0.44054561728202496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9658483385505555 using:1.0,25\n",
      "            train score: 0.9870839121357031 with variance: 8.623442618520725e-06\n",
      "            test  score: 0.9658483385505555 with variance: 0.0007436303212400358\n",
      "          Refitted train score: 0.9870801033591732,  RMSE: 0.11293848786315641, Log-Loss:0.44054561728202496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:1.0,25\n",
      "            train score: 0.9872428318512038 with variance: 8.17924058397689e-06\n",
      "            test  score: 0.9668614086335605 with variance: 0.0006883537540606801\n",
      "          Refitted train score: 0.9872448979591837,  RMSE: 0.11293848786315641, Log-Loss:0.44054561728202496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9658483385505555 using:1.0,25\n",
      "            train score: 0.9870839121357031 with variance: 8.623442618520725e-06\n",
      "            test  score: 0.9658483385505555 with variance: 0.0007436303212400358\n",
      "          Refitted train score: 0.9870801033591732,  RMSE: 0.11293848786315641, Log-Loss:0.44054561728202496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:1.0,25\n",
      "            train score: 0.9872428318512038 with variance: 8.17924058397689e-06\n",
      "            test  score: 0.9668614086335605 with variance: 0.0006883537540606801\n",
      "          Refitted train score: 0.9872448979591837,  RMSE: 0.11293848786315641, Log-Loss:0.44054561728202496\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9707818017118667 using:1.0,50\n",
      "            train score: 0.9922787026090288 with variance: 6.71368317260257e-06\n",
      "            test  score: 0.9707818017118667 with variance: 0.000749033138808704\n",
      "          Refitted train score: 0.9922879177377892,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.971924699772801 using:1.0,50\n",
      "            train score: 0.992344478134348 with variance: 6.5380206780018005e-06\n",
      "            test  score: 0.971924699772801 with variance: 0.0006778360444562856\n",
      "          Refitted train score: 0.9923469387755102,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9707818017118667 using:1.0,50\n",
      "            train score: 0.9922787026090288 with variance: 6.71368317260257e-06\n",
      "            test  score: 0.9707818017118667 with variance: 0.000749033138808704\n",
      "          Refitted train score: 0.9922879177377892,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.971924699772801 using:1.0,50\n",
      "            train score: 0.992344478134348 with variance: 6.5380206780018005e-06\n",
      "            test  score: 0.971924699772801 with variance: 0.0006778360444562856\n",
      "          Refitted train score: 0.9923469387755102,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9707818017118667 using:1.0,50\n",
      "            train score: 0.9922787026090288 with variance: 6.71368317260257e-06\n",
      "            test  score: 0.9707818017118667 with variance: 0.000749033138808704\n",
      "          Refitted train score: 0.9922879177377892,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.971924699772801 using:1.0,50\n",
      "            train score: 0.992344478134348 with variance: 6.5380206780018005e-06\n",
      "            test  score: 0.971924699772801 with variance: 0.0006778360444562856\n",
      "          Refitted train score: 0.9923469387755102,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9736696210380422 using:1.0,100\n",
      "            train score: 0.9993610223642172 with variance: 1.6331696761220812e-06\n",
      "            test  score: 0.9736696210380422 with variance: 0.000555553207519042\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9744888023369036 using:1.0,100\n",
      "            train score: 0.9993630573248407 with variance: 1.6227838857560136e-06\n",
      "            test  score: 0.9744888023369036 with variance: 0.0005193793329323887\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9736696210380422 using:1.0,100\n",
      "            train score: 0.9993610223642172 with variance: 1.6331696761220812e-06\n",
      "            test  score: 0.9736696210380422 with variance: 0.000555553207519042\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9744888023369036 using:1.0,100\n",
      "            train score: 0.9993630573248407 with variance: 1.6227838857560136e-06\n",
      "            test  score: 0.9744888023369036 with variance: 0.0005193793329323887\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9736696210380422 using:1.0,100\n",
      "            train score: 0.9993610223642172 with variance: 1.6331696761220812e-06\n",
      "            test  score: 0.9736696210380422 with variance: 0.000555553207519042\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9744888023369036 using:1.0,100\n",
      "            train score: 0.9993630573248407 with variance: 1.6227838857560136e-06\n",
      "            test  score: 0.9744888023369036 with variance: 0.0005193793329323887\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9453397316437002 using:1.0,2\n",
      "            train score: 0.9464611189764565 with variance: 2.889949727413883e-05\n",
      "            test  score: 0.9453397316437002 with variance: 0.0004291647389163624\n",
      "          Refitted train score: 0.9484029484029484,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9523809523809523,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        accuracy\n",
      "          CV score: 0.9463414634146341 using:1.0,2\n",
      "            train score: 0.9469512195121951 with variance: 2.8256989886972093e-05\n",
      "            test  score: 0.9463414634146341 with variance: 0.0003926234384295056\n",
      "          Refitted train score: 0.948780487804878,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        f1\n",
      "          CV score: 0.9453397316437002 using:1.0,2\n",
      "            train score: 0.9464611189764565 with variance: 2.889949727413883e-05\n",
      "            test  score: 0.9453397316437002 with variance: 0.0004291647389163624\n",
      "          Refitted train score: 0.9484029484029484,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9523809523809523,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        accuracy\n",
      "          CV score: 0.9463414634146341 using:1.0,2\n",
      "            train score: 0.9469512195121951 with variance: 2.8256989886972093e-05\n",
      "            test  score: 0.9463414634146341 with variance: 0.0003926234384295056\n",
      "          Refitted train score: 0.948780487804878,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        f1\n",
      "          CV score: 0.9507227241785916 using:1.5,2\n",
      "            train score: 0.9458837210657253 with variance: 3.9690267254509695e-05\n",
      "            test  score: 0.9507227241785916 with variance: 0.0003058441485453415\n",
      "          Refitted train score: 0.9484029484029484,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9523809523809523,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        accuracy\n",
      "          CV score: 0.9512195121951219 using:1.5,2\n",
      "            train score: 0.9463414634146343 with variance: 3.9411064842355355e-05\n",
      "            test  score: 0.9512195121951219 with variance: 0.0002974419988102314\n",
      "          Refitted train score: 0.948780487804878,  RMSE: 0.22631728213974722, Log-Loss:1.7690768309024303\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.965287989565098 using:1.0,3\n",
      "            train score: 0.9647054918429262 with variance: 4.0867613974201206e-05\n",
      "            test  score: 0.965287989565098 with variance: 0.0004461892560488574\n",
      "          Refitted train score: 0.9653465346534654,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "          Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9658536585365853 using:1.0,3\n",
      "            train score: 0.9652439024390244 with variance: 3.9411064842355815e-05\n",
      "            test  score: 0.9658536585365853 with variance: 0.00044021415823914414\n",
      "          Refitted train score: 0.9658536585365853,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.965287989565098 using:1.0,3\n",
      "            train score: 0.9647054918429262 with variance: 4.0867613974201206e-05\n",
      "            test  score: 0.965287989565098 with variance: 0.0004461892560488574\n",
      "          Refitted train score: 0.9653465346534654,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "          Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9658536585365853 using:1.0,3\n",
      "            train score: 0.9652439024390244 with variance: 3.9411064842355815e-05\n",
      "            test  score: 0.9658536585365853 with variance: 0.00044021415823914414\n",
      "          Refitted train score: 0.9658536585365853,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        f1\n",
      "          CV score: 0.965287989565098 using:1.0,3\n",
      "            train score: 0.9647054918429262 with variance: 4.0867613974201206e-05\n",
      "            test  score: 0.965287989565098 with variance: 0.0004461892560488574\n",
      "          Refitted train score: 0.9653465346534654,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "          Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9658536585365853 using:1.0,3\n",
      "            train score: 0.9652439024390244 with variance: 3.9411064842355815e-05\n",
      "            test  score: 0.9658536585365853 with variance: 0.00044021415823914414\n",
      "          Refitted train score: 0.9658536585365853,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9673361823361823 using:1.0,5\n",
      "            train score: 0.9756969437510884 with variance: 1.344930217858272e-05\n",
      "            test  score: 0.9673361823361823 with variance: 0.0003583931948604304\n",
      "          Refitted train score: 0.9751243781094527,  RMSE: 0.15617376188860607, Log-Loss:0.8424111306013107\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:1.0,5\n",
      "            train score: 0.9762195121951219 with variance: 1.2641284949434882e-05\n",
      "            test  score: 0.9682926829268294 with variance: 0.00033313503866746043\n",
      "          Refitted train score: 0.975609756097561,  RMSE: 0.15617376188860607, Log-Loss:0.8424111306013107\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "        f1\n",
      "          CV score: 0.9673361823361823 using:1.0,5\n",
      "            train score: 0.9756969437510884 with variance: 1.344930217858272e-05\n",
      "            test  score: 0.9673361823361823 with variance: 0.0003583931948604304\n",
      "          Refitted train score: 0.9751243781094527,  RMSE: 0.15617376188860607, Log-Loss:0.8424111306013107\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:1.0,5\n",
      "            train score: 0.9762195121951219 with variance: 1.2641284949434882e-05\n",
      "            test  score: 0.9682926829268294 with variance: 0.00033313503866746043\n",
      "          Refitted train score: 0.975609756097561,  RMSE: 0.15617376188860607, Log-Loss:0.8424111306013107\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "        f1\n",
      "          CV score: 0.9673361823361823 using:1.0,5\n",
      "            train score: 0.9756969437510884 with variance: 1.344930217858272e-05\n",
      "            test  score: 0.9673361823361823 with variance: 0.0003583931948604304\n",
      "          Refitted train score: 0.9751243781094527,  RMSE: 0.15617376188860607, Log-Loss:0.8424111306013107\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:1.0,5\n",
      "            train score: 0.9762195121951219 with variance: 1.2641284949434882e-05\n",
      "            test  score: 0.9682926829268294 with variance: 0.00033313503866746043\n",
      "          Refitted train score: 0.975609756097561,  RMSE: 0.15617376188860607, Log-Loss:0.8424111306013107\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9675213675213674 using:1.0,10\n",
      "            train score: 0.9807893433010376 with variance: 2.909883101119439e-05\n",
      "            test  score: 0.9675213675213674 with variance: 0.00029415345654661867\n",
      "          Refitted train score: 0.9800995024875622,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.942528735632184,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:1.0,10\n",
      "            train score: 0.9810975609756097 with variance: 2.751338488994651e-05\n",
      "            test  score: 0.9682926829268294 with variance: 0.00027364663890541393\n",
      "          Refitted train score: 0.9804878048780488,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "        f1\n",
      "          CV score: 0.9675213675213674 using:1.0,10\n",
      "            train score: 0.9807893433010376 with variance: 2.909883101119439e-05\n",
      "            test  score: 0.9675213675213674 with variance: 0.00029415345654661867\n",
      "          Refitted train score: 0.9800995024875622,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.942528735632184,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:1.0,10\n",
      "            train score: 0.9810975609756097 with variance: 2.751338488994651e-05\n",
      "            test  score: 0.9682926829268294 with variance: 0.00027364663890541393\n",
      "          Refitted train score: 0.9804878048780488,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "        f1\n",
      "          CV score: 0.9675213675213674 using:1.0,10\n",
      "            train score: 0.9807893433010376 with variance: 2.909883101119439e-05\n",
      "            test  score: 0.9675213675213674 with variance: 0.00029415345654661867\n",
      "          Refitted train score: 0.9800995024875622,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.942528735632184,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "        accuracy\n",
      "          CV score: 0.9682926829268294 using:1.0,10\n",
      "            train score: 0.9810975609756097 with variance: 2.751338488994651e-05\n",
      "            test  score: 0.9682926829268294 with variance: 0.00027364663890541393\n",
      "          Refitted train score: 0.9804878048780488,  RMSE: 0.13968605915391563, Log-Loss:0.673927344290941\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9773409907798094 using:1.0,15\n",
      "            train score: 0.9876427840656348 with variance: 1.1643726569777301e-05\n",
      "            test  score: 0.9773409907798094 with variance: 0.00021888309533049465\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:1.0,15\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.00020226055919095814\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        f1\n",
      "          CV score: 0.9773409907798094 using:1.0,15\n",
      "            train score: 0.9876427840656348 with variance: 1.1643726569777301e-05\n",
      "            test  score: 0.9773409907798094 with variance: 0.00021888309533049465\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:1.0,15\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.00020226055919095814\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        f1\n",
      "          CV score: 0.9773409907798094 using:1.0,15\n",
      "            train score: 0.9876427840656348 with variance: 1.1643726569777301e-05\n",
      "            test  score: 0.9773409907798094 with variance: 0.00021888309533049465\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:1.0,15\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.00020226055919095814\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9774050632911393 using:1.0,25\n",
      "            train score: 0.9876427840656348 with variance: 1.1643726569777301e-05\n",
      "            test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "          Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:1.0,25\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "          Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        f1\n",
      "          CV score: 0.9774050632911393 using:1.0,25\n",
      "            train score: 0.9876427840656348 with variance: 1.1643726569777301e-05\n",
      "            test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "          Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:1.0,25\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "          Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        f1\n",
      "          CV score: 0.9799359274886701 using:1.5,25\n",
      "            train score: 0.9876427840656348 with variance: 1.1643726569777301e-05\n",
      "            test  score: 0.9799359274886701 with variance: 0.0001663314703732731\n",
      "          Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "        accuracy\n",
      "          CV score: 0.9804878048780488 using:1.5,25\n",
      "            train score: 0.9878048780487804 with variance: 1.1154074955383719e-05\n",
      "            test  score: 0.9804878048780488 with variance: 0.0001546698393813209\n",
      "          Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594121975070654\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.975 using:1.0,50\n",
      "            train score: 0.9895155874079944 with variance: 1.0095973808490853e-05\n",
      "            test  score: 0.975 with variance: 0.00024999999999999935\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.975609756097561 using:1.0,50\n",
      "            train score: 0.9896341463414634 with variance: 9.666864961332556e-06\n",
      "            test  score: 0.975609756097561 with variance: 0.000237953599048186\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        f1\n",
      "          CV score: 0.975 using:1.0,50\n",
      "            train score: 0.9895155874079944 with variance: 1.0095973808490853e-05\n",
      "            test  score: 0.975 with variance: 0.00024999999999999935\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.975609756097561 using:1.0,50\n",
      "            train score: 0.9896341463414634 with variance: 9.666864961332556e-06\n",
      "            test  score: 0.975609756097561 with variance: 0.000237953599048186\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        f1\n",
      "          CV score: 0.975 using:1.0,50\n",
      "            train score: 0.9895155874079944 with variance: 1.0095973808490853e-05\n",
      "            test  score: 0.975 with variance: 0.00024999999999999935\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.975609756097561 using:1.0,50\n",
      "            train score: 0.9896341463414634 with variance: 9.666864961332556e-06\n",
      "            test  score: 0.975609756097561 with variance: 0.000237953599048186\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.975 using:1.0,100\n",
      "            train score: 0.998165137614679 with variance: 2.2444799820441875e-06\n",
      "            test  score: 0.975 with variance: 0.00024999999999999935\n",
      "          Refitted train score: 0.9975550122249389,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9438202247191012,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "        accuracy\n",
      "          CV score: 0.975609756097561 using:1.0,100\n",
      "            train score: 0.9981707317073172 with variance: 2.2308149910767443e-06\n",
      "            test  score: 0.975609756097561 with variance: 0.000237953599048186\n",
      "          Refitted train score: 0.9975609756097561,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "        f1\n",
      "          CV score: 0.975 using:1.0,100\n",
      "            train score: 0.998165137614679 with variance: 2.2444799820441875e-06\n",
      "            test  score: 0.975 with variance: 0.00024999999999999935\n",
      "          Refitted train score: 0.9975550122249389,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9438202247191012,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "        accuracy\n",
      "          CV score: 0.975609756097561 using:1.0,100\n",
      "            train score: 0.9981707317073172 with variance: 2.2308149910767443e-06\n",
      "            test  score: 0.975609756097561 with variance: 0.000237953599048186\n",
      "          Refitted train score: 0.9975609756097561,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "        f1\n",
      "          CV score: 0.975 using:1.0,100\n",
      "            train score: 0.998165137614679 with variance: 2.2444799820441875e-06\n",
      "            test  score: 0.975 with variance: 0.00024999999999999935\n",
      "          Refitted train score: 0.9975550122249389,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9438202247191012,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "        accuracy\n",
      "          CV score: 0.975609756097561 using:1.0,100\n",
      "            train score: 0.9981707317073172 with variance: 2.2308149910767443e-06\n",
      "            test  score: 0.975609756097561 with variance: 0.000237953599048186\n",
      "          Refitted train score: 0.9975609756097561,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9340923772848655 using:1.0,2\n",
      "            train score: 0.9342971280937027 with variance: 3.423324056587348e-05\n",
      "            test  score: 0.9340923772848655 with variance: 0.0006872772946334778\n",
      "          Refitted train score: 0.9315789473684212,  RMSE: 0.2602082499332666, Log-Loss:2.3385858902067973\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.934894053315106 using:1.0,2\n",
      "            train score: 0.934891492871949 with variance: 3.445447392835741e-05\n",
      "            test  score: 0.934894053315106 with variance: 0.0006073018250591373\n",
      "          Refitted train score: 0.9322916666666666,  RMSE: 0.2602082499332666, Log-Loss:2.3385858902067973\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9340923772848655 using:1.0,2\n",
      "            train score: 0.9342971280937027 with variance: 3.423324056587348e-05\n",
      "            test  score: 0.9340923772848655 with variance: 0.0006872772946334778\n",
      "          Refitted train score: 0.9315789473684212,  RMSE: 0.2602082499332666, Log-Loss:2.3385858902067973\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.934894053315106 using:1.0,2\n",
      "            train score: 0.934891492871949 with variance: 3.445447392835741e-05\n",
      "            test  score: 0.934894053315106 with variance: 0.0006073018250591373\n",
      "          Refitted train score: 0.9322916666666666,  RMSE: 0.2602082499332666, Log-Loss:2.3385858902067973\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9340923772848655 using:1.0,2\n",
      "            train score: 0.9342971280937027 with variance: 3.423324056587348e-05\n",
      "            test  score: 0.9340923772848655 with variance: 0.0006872772946334778\n",
      "          Refitted train score: 0.9315789473684212,  RMSE: 0.2602082499332666, Log-Loss:2.3385858902067973\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.934894053315106 using:1.0,2\n",
      "            train score: 0.934891492871949 with variance: 3.445447392835741e-05\n",
      "            test  score: 0.934894053315106 with variance: 0.0006073018250591373\n",
      "          Refitted train score: 0.9322916666666666,  RMSE: 0.2602082499332666, Log-Loss:2.3385858902067973\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.952725619540025 using:1.0,3\n",
      "            train score: 0.95501719128777 with variance: 4.208568240104094e-05\n",
      "            test  score: 0.952725619540025 with variance: 0.0001538302813579821\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190238840762092\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.95311004784689 using:1.0,3\n",
      "            train score: 0.9550784720165828 with variance: 3.9859247470806426e-05\n",
      "            test  score: 0.95311004784689 with variance: 0.00010943907335604297\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190238840762092\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.952725619540025 using:1.0,3\n",
      "            train score: 0.95501719128777 with variance: 4.208568240104094e-05\n",
      "            test  score: 0.952725619540025 with variance: 0.0001538302813579821\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190238840762092\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.95311004784689 using:1.0,3\n",
      "            train score: 0.9550784720165828 with variance: 3.9859247470806426e-05\n",
      "            test  score: 0.95311004784689 with variance: 0.00010943907335604297\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190238840762092\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.952725619540025 using:1.0,3\n",
      "            train score: 0.95501719128777 with variance: 4.208568240104094e-05\n",
      "            test  score: 0.952725619540025 with variance: 0.0001538302813579821\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190238840762092\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.95311004784689 using:1.0,3\n",
      "            train score: 0.9550784720165828 with variance: 3.9859247470806426e-05\n",
      "            test  score: 0.95311004784689 with variance: 0.00010943907335604297\n",
      "          Refitted train score: 0.953125,  RMSE: 0.21650635094610965, Log-Loss:1.6190238840762092\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9446020133361905 using:1.0,5\n",
      "            train score: 0.9578673588178239 with variance: 5.966680181925201e-05\n",
      "            test  score: 0.9446020133361905 with variance: 0.0007482964819606841\n",
      "          Refitted train score: 0.9578947368421052,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9453178400546822 using:1.0,5\n",
      "            train score: 0.9583400313042005 with variance: 5.616970227294387e-05\n",
      "            test  score: 0.9453178400546822 with variance: 0.0007010006218553909\n",
      "          Refitted train score: 0.9583333333333334,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.9446020133361905 using:1.0,5\n",
      "            train score: 0.9578673588178239 with variance: 5.966680181925201e-05\n",
      "            test  score: 0.9446020133361905 with variance: 0.0007482964819606841\n",
      "          Refitted train score: 0.9578947368421052,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9453178400546822 using:1.0,5\n",
      "            train score: 0.9583400313042005 with variance: 5.616970227294387e-05\n",
      "            test  score: 0.9453178400546822 with variance: 0.0007010006218553909\n",
      "          Refitted train score: 0.9583333333333334,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.9473235323235324 using:1.5,5\n",
      "            train score: 0.9585576090335269 with variance: 4.7078795146208885e-05\n",
      "            test  score: 0.9473235323235324 with variance: 0.000597161985400775\n",
      "          Refitted train score: 0.9578947368421052,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9479152426520848 using:1.5,5\n",
      "            train score: 0.9589893819535513 with variance: 4.4495180255344654e-05\n",
      "            test  score: 0.9479152426520848 with variance: 0.0005397947737049082\n",
      "          Refitted train score: 0.9583333333333334,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9624343786295005 using:1.0,10\n",
      "            train score: 0.9734913522470439 with variance: 5.798819515265316e-05\n",
      "            test  score: 0.9624343786295005 with variance: 0.0008896745998022441\n",
      "          Refitted train score: 0.9735449735449735,  RMSE: 0.1613743060919757, Log-Loss:0.8994514665207488\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:1.0,10\n",
      "            train score: 0.9739646347138203 with variance: 5.4720442007612855e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.0007691010288412891\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.1613743060919757, Log-Loss:0.8994514665207488\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9624343786295005 using:1.0,10\n",
      "            train score: 0.9734913522470439 with variance: 5.798819515265316e-05\n",
      "            test  score: 0.9624343786295005 with variance: 0.0008896745998022441\n",
      "          Refitted train score: 0.9735449735449735,  RMSE: 0.1613743060919757, Log-Loss:0.8994514665207488\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:1.0,10\n",
      "            train score: 0.9739646347138203 with variance: 5.4720442007612855e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.0007691010288412891\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.1613743060919757, Log-Loss:0.8994514665207488\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        f1\n",
      "          CV score: 0.9624343786295005 using:1.0,10\n",
      "            train score: 0.9734913522470439 with variance: 5.798819515265316e-05\n",
      "            test  score: 0.9624343786295005 with variance: 0.0008896745998022441\n",
      "          Refitted train score: 0.9735449735449735,  RMSE: 0.1613743060919757, Log-Loss:0.8994514665207488\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:1.0,10\n",
      "            train score: 0.9739646347138203 with variance: 5.4720442007612855e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.0007691010288412891\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.1613743060919757, Log-Loss:0.8994514665207488\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,15\n",
      "            train score: 0.981477772138606 with variance: 2.0677355781346142e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9815303430079155,  RMSE: 0.13501543121683043, Log-Loss:0.6296151936505348\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,15\n",
      "            train score: 0.9817737636955878 with variance: 1.938859162326203e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9817708333333334,  RMSE: 0.13501543121683043, Log-Loss:0.6296151936505348\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,15\n",
      "            train score: 0.981477772138606 with variance: 2.0677355781346142e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9815303430079155,  RMSE: 0.13501543121683043, Log-Loss:0.6296151936505348\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,15\n",
      "            train score: 0.9817737636955878 with variance: 1.938859162326203e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9817708333333334,  RMSE: 0.13501543121683043, Log-Loss:0.6296151936505348\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,15\n",
      "            train score: 0.981477772138606 with variance: 2.0677355781346142e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9815303430079155,  RMSE: 0.13501543121683043, Log-Loss:0.6296151936505348\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,15\n",
      "            train score: 0.9817737636955878 with variance: 1.938859162326203e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9817708333333334,  RMSE: 0.13501543121683043, Log-Loss:0.6296151936505348\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9656399893839973 using:1.0,25\n",
      "            train score: 0.9867766083772187 with variance: 2.645894495953125e-05\n",
      "            test  score: 0.9656399893839973 with variance: 0.0007473950256441988\n",
      "          Refitted train score: 0.9868073878627968,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9662337662337663 using:1.0,25\n",
      "            train score: 0.9869812597825627 with variance: 2.5396011195164725e-05\n",
      "            test  score: 0.9662337662337663 with variance: 0.0007151290268173389\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9656399893839973 using:1.0,25\n",
      "            train score: 0.9867766083772187 with variance: 2.645894495953125e-05\n",
      "            test  score: 0.9656399893839973 with variance: 0.0007473950256441988\n",
      "          Refitted train score: 0.9868073878627968,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9662337662337663 using:1.0,25\n",
      "            train score: 0.9869812597825627 with variance: 2.5396011195164725e-05\n",
      "            test  score: 0.9662337662337663 with variance: 0.0007151290268173389\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.5,25\n",
      "            train score: 0.9867766083772187 with variance: 2.645894495953125e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9868073878627968,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.5,25\n",
      "            train score: 0.9869812597825627 with variance: 2.5396011195164725e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,50\n",
      "            train score: 0.9881186694936293 with variance: 2.4569908514757167e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9868073878627968,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,50\n",
      "            train score: 0.9882841913786539 with variance: 2.3670821510421103e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,50\n",
      "            train score: 0.9881186694936293 with variance: 2.4569908514757167e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9868073878627968,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,50\n",
      "            train score: 0.9882841913786539 with variance: 2.3670821510421103e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,50\n",
      "            train score: 0.9881186694936293 with variance: 2.4569908514757167e-05\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 0.9868073878627968,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,50\n",
      "            train score: 0.9882841913786539 with variance: 2.3670821510421103e-05\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 0.9869791666666666,  RMSE: 0.11410886614690961, Log-Loss:0.4497236509754004\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,100\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440926614e-06\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,100\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440927772e-06\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,100\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440926614e-06\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,100\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440927772e-06\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        f1\n",
      "          CV score: 0.9686133853151396 using:1.0,100\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440926614e-06\n",
      "            test  score: 0.9686133853151396 with variance: 0.0005683030313009683\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311689 using:1.0,100\n",
      "            train score: 0.9993485342019544 with variance: 1.6976307440927772e-06\n",
      "            test  score: 0.9688311688311689 with variance: 0.0005801990217574637\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#logisticregression\n",
    "C = [1.0, 0.001, 1.5]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "    print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        \n",
    "    for ncomponents in ncomponentss:\n",
    "        print(tab * 3 + f\"ncomponents: {ncomponents}\")\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "                     \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        pca = PCA(n_components = ncomponents)        \n",
    "        pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for c in C:            \n",
    "            \n",
    "            lr = LogisticRegression(C = c, solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "            cv_results = cross_validate(lr, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "\n",
    "            for score in scores:\n",
    "                avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                var_score_test = np.var(cv_results['test_' + score])\n",
    "                avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                    best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, c, ncomponents]\n",
    "\n",
    "            \n",
    "            for score in scores: \n",
    "            \n",
    "                print(tab * 4 + str(score))\n",
    "                print(tab * 5 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "                print(tab * 6 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "                print(tab * 6 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "                lr = LogisticRegression(C = best_avg_scores[score][4], solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "                    \n",
    "                lr.fit(X_train, y_train)            \n",
    "                y_train_pred, y_test_pred = lr.predict(X_train), lr.predict(X_test)                          \n",
    "                rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "                log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "                score_train, score_test = get_scorer(score)(lr, X_train, y_train), get_scorer(score)(lr, X_test, y_test)\n",
    "\n",
    "                print(tab * 5 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "                print(tab * 5 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\") \n",
    "\n",
    "                n = len(results)\n",
    "                results.at[n, 'score'] = score\n",
    "                results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "                results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "                results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "                results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "                results.at[n, 'test rmse'] = rmse_test\n",
    "                results.at[n, 'train rmse'] = rmse_train\n",
    "                results.at[n, 'test log_loss'] = log_loss_test\n",
    "                results.at[n, 'train log_loss'] = log_loss_train\n",
    "                results.at[n, 'test size'] = testsize\n",
    "                results.at[n, 'random state'] = randomstate\n",
    "                results.at[n, 'estimator'] = \"Smote/pca/LogisticRegression\"\n",
    "                results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "262b0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000580199</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/LogisticRegression</td>\n",
       "      <td>1.0,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.968613</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000568303</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/LogisticRegression</td>\n",
       "      <td>1.0,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000580199</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/LogisticRegression</td>\n",
       "      <td>1.0,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.968613</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000568303</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/LogisticRegression</td>\n",
       "      <td>1.0,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.999349</td>\n",
       "      <td>0.000580199</td>\n",
       "      <td>1.69763e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/LogisticRegression</td>\n",
       "      <td>1.0,100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score test score train score test variance train variance test rmse  \\\n",
       "2235  accuracy   0.968831    0.999349   0.000580199    1.69763e-06  0.124035   \n",
       "2236        f1   0.968613    0.999349   0.000568303    1.69763e-06  0.124035   \n",
       "2237  accuracy   0.968831    0.999349   0.000580199    1.69763e-06  0.124035   \n",
       "2238        f1   0.968613    0.999349   0.000568303    1.69763e-06  0.124035   \n",
       "2239  accuracy   0.968831    0.999349   0.000580199    1.69763e-06  0.124035   \n",
       "\n",
       "     train rmse test log_loss train log_loss test size random state  \\\n",
       "2235          0      0.531366    9.99201e-16       0.2         2050   \n",
       "2236          0      0.531366    9.99201e-16       0.2         2050   \n",
       "2237          0      0.531366    9.99201e-16       0.2         2050   \n",
       "2238          0      0.531366    9.99201e-16       0.2         2050   \n",
       "2239          0      0.531366    9.99201e-16       0.2         2050   \n",
       "\n",
       "                         estimator estimator params  \n",
       "2235  Smote/pca/LogisticRegression          1.0,100  \n",
       "2236  Smote/pca/LogisticRegression          1.0,100  \n",
       "2237  Smote/pca/LogisticRegression          1.0,100  \n",
       "2238  Smote/pca/LogisticRegression          1.0,100  \n",
       "2239  Smote/pca/LogisticRegression          1.0,100  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d31163d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9523987869225913 using:rbf,1.5,2\n",
      "            train score: 0.9559961575115761 with variance: 4.853054281615784e-05\n",
      "            test  score: 0.9523987869225913 with variance: 0.00041240037273207534\n",
      "          Refitted train score: 0.9571106094808127,  RMSE: 0.20367797170338584, Log-Loss:1.4328348268518858\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9541328236980411 using:rbf,1.5,2\n",
      "            train score: 0.9574202290019505 with variance: 4.365968240347512e-05\n",
      "            test  score: 0.9541328236980411 with variance: 0.0003577152609122519\n",
      "          Refitted train score: 0.9585152838427947,  RMSE: 0.20367797170338584, Log-Loss:1.4328348268518858\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9609236066002065 using:rbf,1,3\n",
      "            train score: 0.9651253415536489 with variance: 3.289287098285491e-05\n",
      "            test  score: 0.9609236066002065 with variance: 0.0008602521363842679\n",
      "          Refitted train score: 0.9641255605381167,  RMSE: 0.1869077254063991, Log-Loss:1.2065983002476675\n",
      "          Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "        accuracy\n",
      "          CV score: 0.9627806975633062 using:rbf,1,3\n",
      "            train score: 0.9661529756852936 with variance: 2.8853337090279274e-05\n",
      "            test  score: 0.9627806975633062 with variance: 0.0007086084733106898\n",
      "          Refitted train score: 0.9650655021834061,  RMSE: 0.1869077254063991, Log-Loss:1.2065983002476675\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9587718990015033 using:rbf,1,5\n",
      "            train score: 0.9657129445309748 with variance: 6.160666723730465e-05\n",
      "            test  score: 0.9587718990015033 with variance: 0.0008470759710936242\n",
      "          Refitted train score: 0.9617977528089887,  RMSE: 0.19266007352363126, Log-Loss:1.282010475782407\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9606306736741519 using:rbf,1,5\n",
      "            train score: 0.9666964458539926 with variance: 5.5156490124898e-05\n",
      "            test  score: 0.9606306736741519 with variance: 0.0007067366045533431\n",
      "          Refitted train score: 0.962882096069869,  RMSE: 0.19266007352363126, Log-Loss:1.282010475782407\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9752684833859977 using:linear,1.5,10\n",
      "            train score: 0.9771517476625917 with variance: 2.303603472246088e-05\n",
      "            test  score: 0.9752684833859977 with variance: 0.0002916257317974914\n",
      "          Refitted train score: 0.9778761061946903,  RMSE: 0.1477635311413854, Log-Loss:0.7541252470392306\n",
      "          Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "        accuracy\n",
      "          CV score: 0.9759436215957955 using:linear,1.5,10\n",
      "            train score: 0.9776179628057949 with variance: 2.2081421927112244e-05\n",
      "            test  score: 0.9759436215957955 with variance: 0.00026189954958728747\n",
      "          Refitted train score: 0.9781659388646288,  RMSE: 0.1477635311413854, Log-Loss:0.7541252470392306\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9796163094729542 using:linear,1,15\n",
      "            train score: 0.9862069705567474 with variance: 3.909648194382393e-05\n",
      "            test  score: 0.9796163094729542 with variance: 0.0003932608479116895\n",
      "          Refitted train score: 0.9776785714285714,  RMSE: 0.1477635311413854, Log-Loss:0.7541217553473957\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9802914476827521 using:linear,1,15\n",
      "            train score: 0.9863521984485043 with variance: 3.865652974191127e-05\n",
      "            test  score: 0.9802914476827521 with variance: 0.00035766389865976513\n",
      "          Refitted train score: 0.9781659388646288,  RMSE: 0.1477635311413854, Log-Loss:0.7541217553473957\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9797730110089662 using:linear,1,25\n",
      "            train score: 0.9933974202073914 with variance: 7.996736322349453e-06\n",
      "            test  score: 0.9797730110089662 with variance: 0.00022687225825488967\n",
      "          Refitted train score: 0.9934065934065934,  RMSE: 0.08093341918275387, Log-Loss:0.2262365266042194\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.980315336837076 using:linear,1,25\n",
      "            train score: 0.9934470898289185 with variance: 7.781678848657059e-06\n",
      "            test  score: 0.980315336837076 with variance: 0.00021212838554287246\n",
      "          Refitted train score: 0.9934497816593887,  RMSE: 0.08093341918275387, Log-Loss:0.2262365266042194\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9844650939250432 using:linear,1,50\n",
      "            train score: 0.9972602493620746 with variance: 3.0190263062057347e-06\n",
      "            test  score: 0.9844650939250432 with variance: 8.258747088293463e-05\n",
      "          Refitted train score: 0.9956140350877193,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9846870520783565 using:linear,1,50\n",
      "            train score: 0.9972692485222078 with variance: 2.986063990577547e-06\n",
      "            test  score: 0.9846870520783565 with variance: 7.79188197913138e-05\n",
      "          Refitted train score: 0.9956331877729258,  RMSE: 0.06608186004550898, Log-Loss:0.15082435106947994\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9799621363044743 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9799621363044743 with variance: 0.0002262606336155812\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.980315336837076 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.980315336837076 with variance: 0.00021212838554287246\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9537812008779751 using:rbf,1,2\n",
      "            train score: 0.9588664284721116 with variance: 4.160085857567049e-05\n",
      "            test  score: 0.9537812008779751 with variance: 0.000748329743612227\n",
      "          Refitted train score: 0.9582417582417582,  RMSE: 0.20279433208435863, Log-Loss:1.4204362534369792\n",
      "          Refitted test  score: 0.9411764705882353,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        accuracy\n",
      "          CV score: 0.9546283309957925 using:rbf,1,2\n",
      "            train score: 0.9594199077125906 with variance: 3.776469900988207e-05\n",
      "            test  score: 0.9546283309957925 with variance: 0.0007078323029138289\n",
      "          Refitted train score: 0.9588744588744589,  RMSE: 0.20279433208435863, Log-Loss:1.4204362534369792\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9644717806754013 using:linear,1,3\n",
      "            train score: 0.9673703481750676 with variance: 4.908982084469518e-05\n",
      "            test  score: 0.9644717806754013 with variance: 0.00034238399519818604\n",
      "          Refitted train score: 0.956896551724138,  RMSE: 0.20806259464411975, Log-Loss:1.495204163354862\n",
      "          Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "        accuracy\n",
      "          CV score: 0.9653810191678355 using:linear,1,3\n",
      "            train score: 0.9675368050977807 with variance: 5.2380808224337374e-05\n",
      "            test  score: 0.9653810191678355 with variance: 0.0002951126270703199\n",
      "          Refitted train score: 0.9567099567099567,  RMSE: 0.20806259464411975, Log-Loss:1.495204163354862\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9645816673586658 using:rbf,1.5,5\n",
      "            train score: 0.9702345300434047 with variance: 3.0233397432373205e-05\n",
      "            test  score: 0.9645816673586658 with variance: 0.0005586042571623029\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156719\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "        accuracy\n",
      "          CV score: 0.9654043945769051 using:rbf,1.5,5\n",
      "            train score: 0.9707800483410238 with variance: 2.75159500116759e-05\n",
      "            test  score: 0.9654043945769051 with variance: 0.0005264548651340538\n",
      "          Refitted train score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466347799156719\n",
      "          Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9777734584693629 using:linear,1.5,10\n",
      "            train score: 0.9874505214512255 with variance: 1.6543657808101627e-05\n",
      "            test  score: 0.9777734584693629 with variance: 0.00030740711939976486\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416274\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9784011220196354 using:linear,1.5,10\n",
      "            train score: 0.9875558485314583 with variance: 1.6340364567235022e-05\n",
      "            test  score: 0.9784011220196354 with variance: 0.0002764909828184723\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416274\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9843593833067518 using:linear,1.5,15\n",
      "            train score: 0.993457447673376 with variance: 4.810449113900845e-06\n",
      "            test  score: 0.9843593833067518 with variance: 0.00028952034686946233\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9411764705882353,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "        accuracy\n",
      "          CV score: 0.9848994857410005 using:linear,1.5,15\n",
      "            train score: 0.9935076539954588 with variance: 4.67818548219003e-06\n",
      "            test  score: 0.9848994857410005 with variance: 0.0002596014574715081\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9868080457554141 using:linear,1,25\n",
      "            train score: 0.993457447673376 with variance: 4.810449113900845e-06\n",
      "            test  score: 0.9868080457554141 with variance: 6.981554472955074e-05\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9870266479663394 using:linear,1,25\n",
      "            train score: 0.9935076539954588 with variance: 4.67818548219003e-06\n",
      "            test  score: 0.9870266479663394 with variance: 6.545988795103105e-05\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.988913308913309 using:linear,1,50\n",
      "            train score: 0.9972781418833432 with variance: 5.939820415541892e-06\n",
      "            test  score: 0.988913308913309 with variance: 9.876781744913641e-05\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9891771856007481 using:linear,1,50\n",
      "            train score: 0.9972943675382699 with variance: 5.859552388591811e-06\n",
      "            test  score: 0.9891771856007481 with variance: 9.351037883462151e-05\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9821163066324357 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9821163066324357 with variance: 0.00023943781721792913\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9827255726975223 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9827255726975223 with variance: 0.0002128506393321906\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9420191438659604 using:rbf,1,2\n",
      "            train score: 0.9428015776856347 with variance: 2.7578816788524195e-05\n",
      "            test  score: 0.9420191438659604 with variance: 0.0006336801740956929\n",
      "          Refitted train score: 0.9424778761061947,  RMSE: 0.23722785729558887, Log-Loss:1.943754508759999\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9437120149602618 using:rbf,1,2\n",
      "            train score: 0.9437207939646965 with variance: 2.7713559071448743e-05\n",
      "            test  score: 0.9437120149602618 with variance: 0.0004925916673387505\n",
      "          Refitted train score: 0.9437229437229437,  RMSE: 0.23722785729558887, Log-Loss:1.943754508759999\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9594849299017246 using:rbf,1,3\n",
      "            train score: 0.9608240391281466 with variance: 2.3820883284552883e-05\n",
      "            test  score: 0.9594849299017246 with variance: 0.0004976127255558909\n",
      "          Refitted train score: 0.9601769911504424,  RMSE: 0.19738550848793068, Log-Loss:1.345673535710202\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9610331930808789 using:rbf,1,3\n",
      "            train score: 0.9615835347542665 with variance: 2.1392605579409966e-05\n",
      "            test  score: 0.9610331930808789 with variance: 0.0004065703805263065\n",
      "          Refitted train score: 0.961038961038961,  RMSE: 0.19738550848793068, Log-Loss:1.345673535710202\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9640636581355274 using:rbf,1,5\n",
      "            train score: 0.967878787878788 with variance: 1.4549535761657214e-05\n",
      "            test  score: 0.9640636581355274 with variance: 0.0004060640215583248\n",
      "          Refitted train score: 0.9667405764966741,  RMSE: 0.1801874925391118, Log-Loss:1.1213923054513444\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9653810191678355 using:rbf,1,5\n",
      "            train score: 0.9686178861788617 with variance: 1.326293950482659e-05\n",
      "            test  score: 0.9653810191678355 with variance: 0.0003484367544921975\n",
      "          Refitted train score: 0.9675324675324676,  RMSE: 0.1801874925391118, Log-Loss:1.1213923054513444\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9728198559566745 using:rbf,1,10\n",
      "            train score: 0.9755951503201181 with variance: 1.4228905063413575e-05\n",
      "            test  score: 0.9728198559566745 with variance: 0.0004569416485708396\n",
      "          Refitted train score: 0.975609756097561,  RMSE: 0.1543033499620919, Log-Loss:0.8223518189264457\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9740299205236091 using:rbf,1,10\n",
      "            train score: 0.9761913132644839 with variance: 1.282061091162281e-05\n",
      "            test  score: 0.9740299205236091 with variance: 0.00040391920042331464\n",
      "          Refitted train score: 0.9761904761904762,  RMSE: 0.1543033499620919, Log-Loss:0.8223518189264457\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9758559464059168 using:linear,1.5,15\n",
      "            train score: 0.984267911574606 with variance: 0.00010381007987555907\n",
      "            test  score: 0.9758559464059168 with variance: 0.00026296809516800844\n",
      "          Refitted train score: 0.9869565217391305,  RMSE: 0.11396057645963795, Log-Loss:0.4485589990569804\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9762505843852267 using:linear,1,15\n",
      "            train score: 0.9886339998535121 with variance: 1.0013784598839482e-05\n",
      "            test  score: 0.9762505843852267 with variance: 0.0002503616686129777\n",
      "          Refitted train score: 0.987012987012987,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962436\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9821717358796012 using:linear,1,25\n",
      "            train score: 0.9940053685358331 with variance: 4.223085763309022e-06\n",
      "            test  score: 0.9821717358796012 with variance: 0.0003286104341957623\n",
      "          Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:linear,1,25\n",
      "            train score: 0.9940467296564858 with variance: 4.106499433712534e-06\n",
      "            test  score: 0.9827021972884525 with variance: 0.00030706588674324673\n",
      "          Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9821717358796012 using:linear,1.5,50\n",
      "            train score: 0.9983710300318261 with variance: 1.7690578527781255e-06\n",
      "            test  score: 0.9821717358796012 with variance: 0.0003286104341957623\n",
      "          Refitted train score: 0.9978308026030369,  RMSE: 0.046524210519923545, Log-Loss:0.07475925626604142\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:linear,1.5,50\n",
      "            train score: 0.9983769134988648 with variance: 1.7562803463516615e-06\n",
      "            test  score: 0.9827021972884525 with variance: 0.00030706588674324673\n",
      "          Refitted train score: 0.9978354978354979,  RMSE: 0.046524210519923545, Log-Loss:0.07475925626604142\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9821717358796012 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9821717358796012 with variance: 0.0003286104341957623\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9827021972884525 with variance: 0.00030706588674324673\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9415748317875978 using:linear,0.001,2\n",
      "            train score: 0.9477720253609434 with variance: 1.0883002069884182e-05\n",
      "            test  score: 0.9415748317875978 with variance: 0.0005585722310423324\n",
      "          Refitted train score: 0.9492273730684326,  RMSE: 0.2231222754086866, Log-Loss:1.7194750092315094\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9437353903693315 using:linear,0.001,2\n",
      "            train score: 0.9491335237676701 with variance: 1.0014943369713938e-05\n",
      "            test  score: 0.9437353903693315 with variance: 0.0004403822158051871\n",
      "          Refitted train score: 0.9502164502164502,  RMSE: 0.2231222754086866, Log-Loss:1.7194750092315094\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9594932577986782 using:rbf,1,3\n",
      "            train score: 0.9701350444497934 with variance: 7.211751779291373e-06\n",
      "            test  score: 0.9594932577986782 with variance: 0.0004993244634299689\n",
      "          Refitted train score: 0.9690265486725663,  RMSE: 0.17407765595569785, Log-Loss:1.0466330491853038\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9610331930808789 using:linear,0.001,3\n",
      "            train score: 0.9615776752362117 with variance: 1.3064892687168208e-05\n",
      "            test  score: 0.9610331930808789 with variance: 0.0004990666228664613\n",
      "          Refitted train score: 0.9632034632034632,  RMSE: 0.1918242341221171, Log-Loss:1.2709090872530568\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9642800211615803 using:rbf,1.5,5\n",
      "            train score: 0.9707043653968249 with variance: 7.818287320121304e-06\n",
      "            test  score: 0.9642800211615803 with variance: 0.000280512992582587\n",
      "          Refitted train score: 0.9713024282560706,  RMSE: 0.16774542658006547, Log-Loss:0.9718737929192635\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9653810191678355 using:rbf,1.5,5\n",
      "            train score: 0.9713220537610783 with variance: 7.518912280663956e-06\n",
      "            test  score: 0.9653810191678355 with variance: 0.00025189708000815684\n",
      "          Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718737929192635\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9710736583299105 using:rbf,1.5,10\n",
      "            train score: 0.9744626041575826 with variance: 1.0984095640897442e-05\n",
      "            test  score: 0.9710736583299105 with variance: 0.00013476758279263806\n",
      "          Refitted train score: 0.9733333333333333,  RMSE: 0.16116459280507606, Log-Loss:0.8971110751924861\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9718793828892005 using:rbf,1.5,10\n",
      "            train score: 0.9751102321834029 with variance: 9.844925931982645e-06\n",
      "            test  score: 0.9718793828892005 with variance: 0.0001216832655020265\n",
      "          Refitted train score: 0.974025974025974,  RMSE: 0.16116459280507606, Log-Loss:0.8971110751924861\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9822678404918346 using:linear,1.5,15\n",
      "            train score: 0.9901697435375268 with variance: 4.831474350347549e-06\n",
      "            test  score: 0.9822678404918346 with variance: 8.300739171151472e-05\n",
      "          Refitted train score: 0.9780701754385964,  RMSE: 0.14712247158412492, Log-Loss:0.747596024121142\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9827021972884525 using:linear,1.5,15\n",
      "            train score: 0.9902614809931883 with variance: 4.662413323066765e-06\n",
      "            test  score: 0.9827021972884525 with variance: 7.380356482091597e-05\n",
      "          Refitted train score: 0.9783549783549783,  RMSE: 0.14712247158412492, Log-Loss:0.747596024121142\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9799678582287278 using:linear,1.5,25\n",
      "            train score: 0.9923526235062192 with variance: 1.6284899291731677e-05\n",
      "            test  score: 0.9799678582287278 with variance: 0.0003238194474935057\n",
      "          Refitted train score: 0.9912663755458515,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9805516596540439 using:linear,1.5,25\n",
      "            train score: 0.9924265729143779 with variance: 1.5752653146739616e-05\n",
      "            test  score: 0.9805516596540439 with variance: 0.0003004466790417542\n",
      "          Refitted train score: 0.9913419913419913,  RMSE: 0.09304842103984709, Log-Loss:0.29903702506416263\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9824165206773902 using:linear,1.5,50\n",
      "            train score: 0.9983710380582066 with variance: 4.722704769785739e-06\n",
      "            test  score: 0.9824165206773902 with variance: 0.00012562137045542748\n",
      "          Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208184\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9827255726975223 using:linear,1.5,50\n",
      "            train score: 0.9983783783783784 with variance: 4.67494521548566e-06\n",
      "            test  score: 0.9827255726975223 with variance: 0.00012035439699203582\n",
      "          Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208184\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9777745559985502 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9777745559985502 with variance: 0.0002502248948613693\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9783777466105658 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9783777466105658 with variance: 0.00023277055314807407\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9462982417488975 using:rbf,1,2\n",
      "            train score: 0.9539723691333082 with variance: 1.5563394078501087e-05\n",
      "            test  score: 0.9462982417488975 with variance: 0.0003293956889913488\n",
      "          Refitted train score: 0.9528089887640451,  RMSE: 0.215070933898399, Log-Loss:1.5976191671315108\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9472039072039072 using:linear,0.001,2\n",
      "            train score: 0.9504450095359187 with variance: 2.9834800105851452e-05\n",
      "            test  score: 0.9472039072039072 with variance: 0.000692572168030043\n",
      "          Refitted train score: 0.9515418502202643,  RMSE: 0.22013211891892487, Log-Loss:1.673694005892481\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9597179972555276 using:rbf,1.5,3\n",
      "            train score: 0.9647084494351773 with variance: 7.946671469860403e-06\n",
      "            test  score: 0.9597179972555276 with variance: 0.0002216622817275343\n",
      "          Refitted train score: 0.9642857142857142,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604151404151405 using:rbf,1.5,3\n",
      "            train score: 0.9653104471286289 with variance: 7.730939939227551e-06\n",
      "            test  score: 0.9604151404151405 with variance: 0.0002208023424140644\n",
      "          Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9599443696380969 using:rbf,1,5\n",
      "            train score: 0.9643384597445019 with variance: 1.6007171838508593e-05\n",
      "            test  score: 0.9599443696380969 with variance: 0.00021576360901645088\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604151404151405 using:rbf,1,5\n",
      "            train score: 0.9647594829413013 with variance: 1.625401382668916e-05\n",
      "            test  score: 0.9604151404151405 with variance: 0.0002208023424140644\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411578059709506\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9707118429249805 using:rbf,1,10\n",
      "            train score: 0.9723907719713839 with variance: 1.1020154377550385e-05\n",
      "            test  score: 0.9707118429249805 with variance: 0.00013878586369869456\n",
      "          Refitted train score: 0.972972972972973,  RMSE: 0.16257834438102145, Log-Loss:0.9129209610933012\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:rbf,1,10\n",
      "            train score: 0.9730209184754639 with variance: 1.0102246378366852e-05\n",
      "            test  score: 0.9714041514041515 with variance: 0.0001247323562341876\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129209610933012\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9707118429249805 using:rbf,1,15\n",
      "            train score: 0.9735526260200853 with variance: 8.167535274833147e-06\n",
      "            test  score: 0.9707118429249805 with variance: 0.00013878586369869456\n",
      "          Refitted train score: 0.972972972972973,  RMSE: 0.16257834438102145, Log-Loss:0.9129209610933012\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714041514041515 using:rbf,1,15\n",
      "            train score: 0.9741213332122423 with variance: 7.746931814599629e-06\n",
      "            test  score: 0.9714041514041515 with variance: 0.0001247323562341876\n",
      "          Refitted train score: 0.973568281938326,  RMSE: 0.16257834438102145, Log-Loss:0.9129209610933012\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9722767205007147 using:linear,1,25\n",
      "            train score: 0.9916866388127925 with variance: 1.2328664785876006e-05\n",
      "            test  score: 0.9722767205007147 with variance: 0.0006055018176229044\n",
      "          Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.380384761171771\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:linear,1,25\n",
      "            train score: 0.991743105379469 with variance: 1.2059294512378695e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.000512015457070402\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.380384761171771\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9776619363827374 using:linear,1,50\n",
      "            train score: 0.9972390741970193 with variance: 5.590408957329665e-11\n",
      "            test  score: 0.9776619363827374 with variance: 0.00014901080473775325\n",
      "          Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9780219780219781 using:linear,1,50\n",
      "            train score: 0.997246692701238 with variance: 9.164398494168121e-12\n",
      "            test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9797667849391989 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9797667849391989 with variance: 0.00017325164687908944\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9802197802197803 with variance: 0.0001642313730225819\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9485448709174866 using:rbf,1.5,2\n",
      "            train score: 0.9481392797181535 with variance: 4.446025906063489e-05\n",
      "            test  score: 0.9485448709174866 with variance: 0.000328602577518116\n",
      "          Refitted train score: 0.950892857142857,  RMSE: 0.22013211891892487, Log-Loss:1.6736992895759402\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9494017094017094 using:rbf,1.5,2\n",
      "            train score: 0.9487936306118124 with variance: 4.3700617506976506e-05\n",
      "            test  score: 0.9494017094017094 with variance: 0.00031602075851160034\n",
      "          Refitted train score: 0.9515418502202643,  RMSE: 0.22013211891892487, Log-Loss:1.6736992895759402\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9640347641509981 using:rbf,1,3\n",
      "            train score: 0.963338697002186 with variance: 2.2369028248848202e-05\n",
      "            test  score: 0.9640347641509981 with variance: 0.00021382226387209612\n",
      "          Refitted train score: 0.9662921348314607,  RMSE: 0.18176811485266747, Log-Loss:1.141154283515311\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:rbf,1,3\n",
      "            train score: 0.9642115460297278 with variance: 2.0851352660039752e-05\n",
      "            test  score: 0.9648107448107449 with variance: 0.000211356354946099\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.141154283515311\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9640926115083419 using:rbf,1.5,5\n",
      "            train score: 0.9674051951382434 with variance: 3.4486765688758526e-05\n",
      "            test  score: 0.9640926115083419 with variance: 0.00046264267817331734\n",
      "          Refitted train score: 0.968609865470852,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:rbf,1.5,5\n",
      "            train score: 0.9680667817031454 with variance: 3.175426504163871e-05\n",
      "            test  score: 0.9648107448107449 with variance: 0.0004528730799793072\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.065077683526521\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9726168663377965 using:rbf,1,10\n",
      "            train score: 0.9745742015106609 with variance: 2.327906953135628e-05\n",
      "            test  score: 0.9726168663377965 with variance: 0.0002981246546679134\n",
      "          Refitted train score: 0.9751693002257337,  RMSE: 0.15565691404453527, Log-Loss:0.8368425998766914\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9736263736263737 using:rbf,1,10\n",
      "            train score: 0.9752247752247752 with variance: 2.0950401478963865e-05\n",
      "            test  score: 0.9736263736263737 with variance: 0.00027049873203719284\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368425998766914\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9800222249660452 using:linear,1.5,15\n",
      "            train score: 0.9905632245104773 with variance: 7.956688654956475e-06\n",
      "            test  score: 0.9800222249660452 with variance: 0.0004571736893246977\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:linear,1.5,15\n",
      "            train score: 0.9906411770048134 with variance: 7.826112217588533e-06\n",
      "            test  score: 0.9802197802197803 with variance: 0.0004540514430624326\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.975022640195054 using:rbf,1,25\n",
      "            train score: 0.9786165847028204 with variance: 1.5085889450546376e-05\n",
      "            test  score: 0.975022640195054 with variance: 0.0002292379833114172\n",
      "          Refitted train score: 0.9774774774774774,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:rbf,1,25\n",
      "            train score: 0.9790784972603154 with variance: 1.3764596619758157e-05\n",
      "            test  score: 0.9758241758241759 with variance: 0.00021253471802922308\n",
      "          Refitted train score: 0.9779735682819384,  RMSE: 0.14841304429888122, Log-Loss:0.7607659998879014\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9779677576941866 using:linear,1,50\n",
      "            train score: 0.9961279969549871 with variance: 7.976940642631985e-06\n",
      "            test  score: 0.9779677576941866 with variance: 0.0006177352967357948\n",
      "          Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "        accuracy\n",
      "          CV score: 0.9780219780219781 using:linear,1,50\n",
      "            train score: 0.9961477916023371 with variance: 7.852652315627243e-06\n",
      "            test  score: 0.9780219780219781 with variance: 0.0006279434850863421\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9802522717009927 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9802522717009927 with variance: 0.00019950260264227408\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "        accuracy\n",
      "          CV score: 0.9802197802197803 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9802197802197803 with variance: 0.0002125347180292233\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9472488106152122 using:linear,0.001,2\n",
      "            train score: 0.9496251150078885 with variance: 3.0856158166602026e-05\n",
      "            test  score: 0.9472488106152122 with variance: 0.0002526587305498381\n",
      "          Refitted train score: 0.9521640091116175,  RMSE: 0.215070933898399, Log-Loss:1.5976138834480513\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9493772893772894 using:linear,0.001,2\n",
      "            train score: 0.951545424272697 with variance: 2.5709656904908017e-05\n",
      "            test  score: 0.9493772893772894 with variance: 0.00021964067678353376\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976138834480513\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9602782089990098 using:linear,1,3\n",
      "            train score: 0.9607518345239641 with variance: 9.670944541473157e-05\n",
      "            test  score: 0.9602782089990098 with variance: 0.0006553317586033018\n",
      "          Refitted train score: 0.9220489977728284,  RMSE: 0.2776553817472585, Log-Loss:2.6627074180249495\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9604395604395604 using:linear,1,3\n",
      "            train score: 0.9609133290951473 with variance: 0.00010323831453115419\n",
      "            test  score: 0.9604395604395604 with variance: 0.0006569254920903266\n",
      "          Refitted train score: 0.9229074889867841,  RMSE: 0.2776553817472585, Log-Loss:2.6627074180249495\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9639359865241307 using:rbf,1,5\n",
      "            train score: 0.967328805608177 with variance: 2.517667842371798e-05\n",
      "            test  score: 0.9639359865241307 with variance: 0.00022427002078397696\n",
      "          Refitted train score: 0.9661399548532731,  RMSE: 0.18176811485266747, Log-Loss:1.1411525222874914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:rbf,1,5\n",
      "            train score: 0.9680667817031454 with variance: 2.2647418970104566e-05\n",
      "            test  score: 0.9648107448107449 with variance: 0.000211356354946099\n",
      "          Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411525222874914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9703059497165448 using:rbf,1.5,10\n",
      "            train score: 0.97460245742383 with variance: 1.3598774684176369e-05\n",
      "            test  score: 0.9703059497165448 with variance: 0.0003053579832426476\n",
      "          Refitted train score: 0.9751693002257337,  RMSE: 0.15565691404453527, Log-Loss:0.8368425998766914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:rbf,1.5,10\n",
      "            train score: 0.975223261586898 with variance: 1.1960099063078674e-05\n",
      "            test  score: 0.9714285714285715 with variance: 0.00027049873203719295\n",
      "          Refitted train score: 0.9757709251101322,  RMSE: 0.15565691404453527, Log-Loss:0.8368425998766914\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9865134865134866 using:linear,1.5,15\n",
      "            train score: 0.9894273102506366 with variance: 1.0694065665088233e-05\n",
      "            test  score: 0.9865134865134866 with variance: 7.302886923266536e-05\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9868131868131869 using:linear,1.5,15\n",
      "            train score: 0.9895392486301577 with variance: 1.027128370859031e-05\n",
      "            test  score: 0.9868131868131869 with variance: 6.762468300929868e-05\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9753711805435945 using:linear,1.5,25\n",
      "            train score: 0.9927885075980061 with variance: 1.862506098006828e-06\n",
      "            test  score: 0.9753711805435945 with variance: 0.00016926927078606533\n",
      "          Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:linear,1.5,25\n",
      "            train score: 0.9928420064783701 with variance: 1.8114441707378058e-06\n",
      "            test  score: 0.9758241758241759 with variance: 0.00016423137302258172\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.3803829999439512\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9845117022693964 using:linear,1.5,50\n",
      "            train score: 0.9983410025716749 with variance: 1.8348793692870552e-06\n",
      "            test  score: 0.9845117022693964 with variance: 7.770367256124285e-05\n",
      "          Refitted train score: 0.9977924944812362,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9846153846153847 using:linear,1,50\n",
      "            train score: 0.9966972421517877 with variance: 4.236554793435851e-06\n",
      "            test  score: 0.9846153846153847 with variance: 7.728535201062706e-05\n",
      "          Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9753739617823307 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9753739617823307 with variance: 0.0002690464882502832\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        accuracy\n",
      "          CV score: 0.9758241758241759 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9758241758241759 with variance: 0.00026083806303586505\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9532603579954294 using:linear,0.001,2\n",
      "            train score: 0.948075504400246 with variance: 7.14235047349619e-05\n",
      "            test  score: 0.9532603579954294 with variance: 0.0006930264280261998\n",
      "          Refitted train score: 0.9473684210526317,  RMSE: 0.22658174179374144, Log-Loss:1.7732068184543017\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9553058676654181 using:linear,0.001,2\n",
      "            train score: 0.9497782480820405 with variance: 6.503356651811027e-05\n",
      "            test  score: 0.9553058676654181 with variance: 0.0005588956376314871\n",
      "          Refitted train score: 0.9486607142857143,  RMSE: 0.22658174179374144, Log-Loss:1.7732068184543017\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9579852539200042 using:rbf,1.5,3\n",
      "            train score: 0.9610818528221392 with variance: 7.758076092789239e-05\n",
      "            test  score: 0.9579852539200042 with variance: 0.0012268797813541565\n",
      "          Refitted train score: 0.9610983981693364,  RMSE: 0.1947984306184949, Log-Loss:1.3106285658610994\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "        accuracy\n",
      "          CV score: 0.959725343320849 using:rbf,1.5,3\n",
      "            train score: 0.9620469647219931 with variance: 7.07437533091378e-05\n",
      "            test  score: 0.959725343320849 with variance: 0.0010426642103113933\n",
      "          Refitted train score: 0.9620535714285714,  RMSE: 0.1947984306184949, Log-Loss:1.3106285658610994\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.955399007123145 using:rbf,1.5,5\n",
      "            train score: 0.9618032420766877 with variance: 0.00011777485681271099\n",
      "            test  score: 0.955399007123145 with variance: 0.0015233257597710413\n",
      "          Refitted train score: 0.958904109589041,  RMSE: 0.2004459314343183, Log-Loss:1.3877258337011462\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9575280898876404 using:linear,0.001,5\n",
      "            train score: 0.9570252563763402 with variance: 6.452855814927688e-05\n",
      "            test  score: 0.9575280898876404 with variance: 0.0009826318849253664\n",
      "          Refitted train score: 0.9575892857142857,  RMSE: 0.2059386177619785, Log-Loss:1.4648177470941157\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9695466519666069 using:rbf,1.5,10\n",
      "            train score: 0.9742440886590862 with variance: 4.0174843097192685e-05\n",
      "            test  score: 0.9695466519666069 with variance: 0.0008521246840316147\n",
      "          Refitted train score: 0.9748283752860412,  RMSE: 0.15669579263200217, Log-Loss:0.848050313267897\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9709113607990012 using:rbf,1.5,10\n",
      "            train score: 0.9748852336564948 with variance: 3.7435775258234043e-05\n",
      "            test  score: 0.9709113607990012 with variance: 0.0007373055840000241\n",
      "          Refitted train score: 0.9754464285714286,  RMSE: 0.15669579263200217, Log-Loss:0.848050313267897\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9794599973769756 using:linear,1.5,15\n",
      "            train score: 0.9881432808154405 with variance: 3.034968794672687e-05\n",
      "            test  score: 0.9794599973769756 with variance: 0.00018646227469040953\n",
      "          Refitted train score: 0.9841269841269841,  RMSE: 0.125, Log-Loss:0.5396683811704804\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9798751560549313 using:linear,1.5,15\n",
      "            train score: 0.9882774933474424 with variance: 2.9330684196006636e-05\n",
      "            test  score: 0.9798751560549313 with variance: 0.00017237753681805377\n",
      "          Refitted train score: 0.984375,  RMSE: 0.125, Log-Loss:0.5396683811704804\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9772111226561909 using:linear,1,25\n",
      "            train score: 0.9932520256245709 with variance: 2.0942176955389205e-05\n",
      "            test  score: 0.9772111226561909 with variance: 0.00016597983507056867\n",
      "          Refitted train score: 0.9909909909909909,  RMSE: 0.0944911182523068, Log-Loss:0.3083819320974178\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9776529338327091 using:linear,1,25\n",
      "            train score: 0.9933007578469055 with variance: 2.0583046737516085e-05\n",
      "            test  score: 0.9776529338327091 with variance: 0.00015206958842021756\n",
      "          Refitted train score: 0.9910714285714286,  RMSE: 0.0944911182523068, Log-Loss:0.3083819320974178\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9752039541974096 using:linear,1.5,50\n",
      "            train score: 0.9983224487566614 with variance: 1.8761512520198148e-06\n",
      "            test  score: 0.9752039541974096 with variance: 0.00017981999138416317\n",
      "          Refitted train score: 0.9977628635346756,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9754307116104869 using:linear,1.5,50\n",
      "            train score: 0.998325578500179 with variance: 1.8691329780909068e-06\n",
      "            test  score: 0.9754307116104869 with variance: 0.00017126781286188768\n",
      "          Refitted train score: 0.9977678571428571,  RMSE: 0.0472455591261534, Log-Loss:0.0770954830243552\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9861522198731502 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9861522198731502 with variance: 0.00034421107679379916\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.96,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.9865667915106118 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9865667915106118 with variance: 0.0003223037370577665\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9482221188870806 using:rbf,1.5,2\n",
      "            train score: 0.9518330583486392 with variance: 1.3627250681230697e-05\n",
      "            test  score: 0.9482221188870806 with variance: 0.0002671719901653342\n",
      "          Refitted train score: 0.9525959367945823,  RMSE: 0.21602468994692867, Log-Loss:1.6118220032780801\n",
      "          Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "        accuracy\n",
      "          CV score: 0.9488888888888889 using:linear,0.001,2\n",
      "            train score: 0.9505555555555555 with variance: 1.0493827160493751e-05\n",
      "            test  score: 0.9488888888888889 with variance: 0.00022716049382716014\n",
      "          Refitted train score: 0.9511111111111111,  RMSE: 0.22110831935702666, Log-Loss:1.6885730628280367\n",
      "          Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9582599541203918 using:linear,1,3\n",
      "            train score: 0.9599323615288956 with variance: 0.0001799338848568256\n",
      "            test  score: 0.9582599541203918 with variance: 0.0002993038052212756\n",
      "          Refitted train score: 0.9665924276169264,  RMSE: 0.18257418583505536, Log-Loss:1.1513049846792711\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.139912993398857\n",
      "        accuracy\n",
      "          CV score: 0.9577777777777777 using:linear,1,3\n",
      "            train score: 0.9594444444444445 with variance: 0.00020555555555555526\n",
      "            test  score: 0.9577777777777777 with variance: 0.0003160493827160503\n",
      "          Refitted train score: 0.9666666666666667,  RMSE: 0.18257418583505536, Log-Loss:1.1513049846792711\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.139912993398857\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9595230227829659 using:linear,1,5\n",
      "            train score: 0.9665207420119144 with variance: 6.526745826956892e-05\n",
      "            test  score: 0.9595230227829659 with variance: 0.0007942440005972312\n",
      "          Refitted train score: 0.957871396895787,  RMSE: 0.20548046676563256, Log-Loss:1.4583216610613448\n",
      "          Refitted test  score: 0.9130434782608695,  RMSE: 0.3481553119113957, Log-Loss:4.1865425811234225\n",
      "        accuracy\n",
      "          CV score: 0.96 using:linear,1,5\n",
      "            train score: 0.9666666666666666 with variance: 6.481481481481437e-05\n",
      "            test  score: 0.96 with variance: 0.0007703703703703703\n",
      "          Refitted train score: 0.9577777777777777,  RMSE: 0.20548046676563256, Log-Loss:1.4583216610613448\n",
      "          Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865425811234225\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9748141197710052 using:rbf,1,10\n",
      "            train score: 0.9755437359250918 with variance: 1.5238508689721246e-05\n",
      "            test  score: 0.9748141197710052 with variance: 0.0001335044357789322\n",
      "          Refitted train score: 0.9749430523917996,  RMSE: 0.15634719199411432, Log-Loss:0.8442812007644842\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9755555555555555 using:rbf,1,10\n",
      "            train score: 0.9761111111111112 with variance: 1.419753086419743e-05\n",
      "            test  score: 0.9755555555555555 with variance: 0.00011851851851851826\n",
      "          Refitted train score: 0.9755555555555555,  RMSE: 0.15634719199411432, Log-Loss:0.8442812007644842\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9864640977000528 using:linear,1,15\n",
      "            train score: 0.9932835616934563 with variance: 5.0531671608599956e-06\n",
      "            test  score: 0.9864640977000528 with variance: 7.27919288824359e-05\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "        accuracy\n",
      "          CV score: 0.9866666666666667 using:linear,1,15\n",
      "            train score: 0.9933333333333334 with variance: 4.938271604938237e-06\n",
      "            test  score: 0.9866666666666667 with variance: 6.91358024691361e-05\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9751236502960641 using:linear,1,25\n",
      "            train score: 0.9938469155266096 with variance: 4.4219682067969625e-06\n",
      "            test  score: 0.9751236502960641 with variance: 0.0002206526524690322\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9755555555555555 using:linear,1,25\n",
      "            train score: 0.993888888888889 with variance: 4.320987654320958e-06\n",
      "            test  score: 0.9755555555555555 with variance: 0.0002172839506172835\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "      ncomponents: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9795692296854638 using:linear,1,50\n",
      "            train score: 0.9966449062312714 with variance: 1.0660463734757408e-05\n",
      "            test  score: 0.9795692296854638 with variance: 0.00017619490994616132\n",
      "          Refitted train score: 0.9932885906040269,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:linear,1,50\n",
      "            train score: 0.9966666666666667 with variance: 1.0493827160493751e-05\n",
      "            test  score: 0.9800000000000001 with variance: 0.00016790123456790132\n",
      "          Refitted train score: 0.9933333333333333,  RMSE: 0.08164965809277261, Log-Loss:0.23025850929940553\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9794106468394423 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9794106468394423 with variance: 0.00033929466250929305\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9800000000000001 with variance: 0.00031604938271604895\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093283405674291\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9472557644863857 using:linear,0.001,2\n",
      "            train score: 0.9476092211978703 with variance: 8.187661998584043e-06\n",
      "            test  score: 0.9472557644863857 with variance: 0.00044353613453929276\n",
      "          Refitted train score: 0.95,  RMSE: 0.22013211891892487, Log-Loss:1.6736922446646612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9494017094017094 using:linear,0.001,2\n",
      "            train score: 0.9493415675233857 with variance: 7.629398403913175e-06\n",
      "            test  score: 0.9494017094017094 with variance: 0.000364324103518242\n",
      "          Refitted train score: 0.9515418502202643,  RMSE: 0.22013211891892487, Log-Loss:1.6736922446646612\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9494042215475245 using:rbf,1.5,3\n",
      "            train score: 0.9557354227558061 with variance: 1.4357057829702413e-05\n",
      "            test  score: 0.9494042215475245 with variance: 0.0006579771517370379\n",
      "          Refitted train score: 0.9590909090909091,  RMSE: 0.1991169934799916, Log-Loss:1.3693823222538613\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9515750915750916 using:linear,0.001,3\n",
      "            train score: 0.9564995610450155 with variance: 1.0153612831926353e-05\n",
      "            test  score: 0.9515750915750916 with variance: 0.00026826604409021956\n",
      "          Refitted train score: 0.9537444933920705,  RMSE: 0.215070933898399, Log-Loss:1.5976121222202313\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9638119396942928 using:rbf,1.5,5\n",
      "            train score: 0.9741093359724211 with variance: 4.0495857576524765e-05\n",
      "            test  score: 0.9638119396942928 with variance: 0.00048462513990388647\n",
      "          Refitted train score: 0.9706546275395034,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820912\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9647863247863249 using:rbf,1,5\n",
      "            train score: 0.9724669270123816 with variance: 2.1250223940096113e-05\n",
      "            test  score: 0.9647863247863249 with variance: 0.00025955951523717104\n",
      "          Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820912\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9723776223776225 using:rbf,1.5,10\n",
      "            train score: 0.9792774350271184 with variance: 2.1278350638362985e-05\n",
      "            test  score: 0.9723776223776225 with variance: 0.0006022349279092533\n",
      "          Refitted train score: 0.9798657718120806,  RMSE: 0.14079697633917962, Log-Loss:0.6846911611269312\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9735775335775336 using:rbf,1.5,10\n",
      "            train score: 0.9796264341718887 with variance: 1.9995617786256712e-05\n",
      "            test  score: 0.9735775335775336 with variance: 0.0005115956354051591\n",
      "          Refitted train score: 0.9801762114537445,  RMSE: 0.14079697633917962, Log-Loss:0.6846911611269312\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9748986307809838 using:rbf,1.5,15\n",
      "            train score: 0.9798469873216671 with variance: 2.0726227608729957e-05\n",
      "            test  score: 0.9748986307809838 with variance: 0.0004067852959791475\n",
      "          Refitted train score: 0.9798657718120806,  RMSE: 0.14079697633917962, Log-Loss:0.6846911611269312\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9757753357753358 using:rbf,1.5,15\n",
      "            train score: 0.9801758847213392 with variance: 1.944006278514722e-05\n",
      "            test  score: 0.9757753357753358 with variance: 0.00035723961291726916\n",
      "          Refitted train score: 0.9801762114537445,  RMSE: 0.14079697633917962, Log-Loss:0.6846911611269312\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.979970639467464 using:linear,1,25\n",
      "            train score: 0.9927945444435528 with variance: 1.4332624270407533e-05\n",
      "            test  score: 0.979970639467464 with variance: 0.00021695952579371645\n",
      "          Refitted train score: 0.9933774834437086,  RMSE: 0.08128917219051073, Log-Loss:0.22823156119419089\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9801953601953602 using:linear,1,25\n",
      "            train score: 0.9928404928404928 with variance: 1.3973874823768793e-05\n",
      "            test  score: 0.9801953601953602 with variance: 0.00021210774031286825\n",
      "          Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22823156119419089\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9755157554725115 using:linear,1,50\n",
      "            train score: 0.9977869605142333 with variance: 4.310911097788119e-06\n",
      "            test  score: 0.9755157554725115 with variance: 0.0002667615092020018\n",
      "          Refitted train score: 0.9977924944812362,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9757997557997559 using:linear,1,50\n",
      "            train score: 0.997797656888566 with variance: 4.2482027439218325e-06\n",
      "            test  score: 0.9757997557997559 with variance: 0.0002601964037861472\n",
      "          Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9796148105393085 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9796148105393085 with variance: 0.00028385271735606357\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9801953601953602 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9801953601953602 with variance: 0.0002604110853195101\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9576264461299852 using:rbf,1.5,2\n",
      "            train score: 0.9554800852200918 with variance: 2.581584685409488e-05\n",
      "            test  score: 0.9576264461299852 with variance: 0.00020354243029415396\n",
      "          Refitted train score: 0.9598214285714285,  RMSE: 0.1991169934799916, Log-Loss:1.3693893671651405\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9581684981684981 using:rbf,1.5,2\n",
      "            train score: 0.955950110495565 with variance: 2.702328178504886e-05\n",
      "            test  score: 0.9581684981684981 with variance: 0.00021126809698238225\n",
      "          Refitted train score: 0.960352422907489,  RMSE: 0.1991169934799916, Log-Loss:1.3693893671651405\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9627921571003201 using:linear,1,3\n",
      "            train score: 0.9629382287759457 with variance: 5.744479605230575e-05\n",
      "            test  score: 0.9627921571003201 with variance: 0.0003748935397947487\n",
      "          Refitted train score: 0.9684684684684685,  RMSE: 0.17560468218497577, Log-Loss:1.0650759222987012\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9625885225885226 using:linear,1,3\n",
      "            train score: 0.9631050767414404 with variance: 6.257859107488807e-05\n",
      "            test  score: 0.9625885225885226 with variance: 0.0004139155377250618\n",
      "          Refitted train score: 0.9691629955947136,  RMSE: 0.17560468218497577, Log-Loss:1.0650759222987012\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9645143312996485 using:rbf,1,5\n",
      "            train score: 0.9708299045509765 with variance: 7.5625718758419134e-06\n",
      "            test  score: 0.9645143312996485 with variance: 0.0004170354163210266\n",
      "          Refitted train score: 0.9707865168539326,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9648107448107449 using:linear,0.001,5\n",
      "            train score: 0.9598023188932279 with variance: 4.809008945368548e-06\n",
      "            test  score: 0.9648107448107449 with variance: 0.0003562663899660236\n",
      "          Refitted train score: 0.960352422907489,  RMSE: 0.1991169934799916, Log-Loss:1.3693823222538613\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9659252308821161 using:linear,0.001,10\n",
      "            train score: 0.9617772553117382 with variance: 1.5116660849077418e-05\n",
      "            test  score: 0.9659252308821161 with variance: 0.00020841640689411622\n",
      "          Refitted train score: 0.9612756264236901,  RMSE: 0.19350693507134273, Log-Loss:1.2933039610372516\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9670085470085471 using:linear,0.001,10\n",
      "            train score: 0.9631065903793177 with variance: 1.3895574203035297e-05\n",
      "            test  score: 0.9670085470085471 with variance: 0.0001921423577101229\n",
      "          Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933039610372516\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9780096730622283 using:linear,1,15\n",
      "            train score: 0.9883624963646304 with variance: 1.638470246654927e-05\n",
      "            test  score: 0.9780096730622283 with variance: 0.0002724831678329675\n",
      "          Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.977997557997558 using:linear,1,15\n",
      "            train score: 0.9884388338933793 with variance: 1.6302585138708016e-05\n",
      "            test  score: 0.977997557997558 with variance: 0.0002892857515568147\n",
      "          Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177095\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9755218032794974 using:linear,1,25\n",
      "            train score: 0.9933516990857711 with variance: 8.048931399993042e-06\n",
      "            test  score: 0.9755218032794974 with variance: 0.00010951605851236951\n",
      "          Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9757753357753357 using:linear,1,25\n",
      "            train score: 0.9933929706656979 with variance: 7.877671123516174e-06\n",
      "            test  score: 0.9757753357753357 with variance: 0.00011572288788405981\n",
      "          Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516107\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9754222530665769 using:linear,1,50\n",
      "            train score: 0.9983471074380166 with variance: 1.8213692143068916e-06\n",
      "            test  score: 0.9754222530665769 with variance: 0.0003121886435913033\n",
      "          Refitted train score: 0.9977924944812362,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879103\n",
      "          Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9757997557997559 using:linear,1,50\n",
      "            train score: 0.9983486210758938 with variance: 1.8180425376535258e-06\n",
      "            test  score: 0.9757997557997559 with variance: 0.00030849974879279004\n",
      "          Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879103\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9690583444435242 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9690583444435242 with variance: 0.0003496784987360046\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9691819291819291 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9691819291819291 with variance: 0.00035659556831718\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9474621568708246 using:rbf,1,2\n",
      "            train score: 0.9513918287831331 with variance: 2.3551133884810656e-05\n",
      "            test  score: 0.9474621568708246 with variance: 0.0005210208864238912\n",
      "          Refitted train score: 0.9519450800915331,  RMSE: 0.21699124819614724, Log-Loss:1.6262760131787126\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9484144818976279 using:rbf,1,2\n",
      "            train score: 0.9523542001070092 with variance: 2.1972434879227283e-05\n",
      "            test  score: 0.9484144818976279 with variance: 0.0004861738058388319\n",
      "          Refitted train score: 0.952914798206278,  RMSE: 0.21699124819614724, Log-Loss:1.6262760131787126\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9581320731252332 using:linear,0.001,3\n",
      "            train score: 0.9575323001725785 with variance: 8.846111878260348e-06\n",
      "            test  score: 0.9581320731252332 with variance: 0.00014230919293254648\n",
      "          Refitted train score: 0.958139534883721,  RMSE: 0.2008948590547275, Log-Loss:1.393943441044446\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9596504369538078 using:linear,0.001,3\n",
      "            train score: 0.9590816101721588 with variance: 8.088013568230496e-06\n",
      "            test  score: 0.9596504369538078 with variance: 0.00013043869944092957\n",
      "          Refitted train score: 0.9596412556053812,  RMSE: 0.2008948590547275, Log-Loss:1.393943441044446\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.961048663744074 using:rbf,1.5,5\n",
      "            train score: 0.9691522054758395 with variance: 2.3658344723965383e-05\n",
      "            test  score: 0.961048663744074 with variance: 0.00022747634660479104\n",
      "          Refitted train score: 0.9702517162471396,  RMSE: 0.1707278010834213, Log-Loss:1.0067392204679364\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9619225967540574 using:rbf,1.5,5\n",
      "            train score: 0.9697353098542788 with variance: 2.3028130927297843e-05\n",
      "            test  score: 0.9619225967540574 with variance: 0.0002278674752688976\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067392204679364\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9723037679021452 using:rbf,1,10\n",
      "            train score: 0.9747057916081072 with variance: 1.1604468467788935e-05\n",
      "            test  score: 0.9723037679021452 with variance: 8.74072874639912e-05\n",
      "          Refitted train score: 0.9723502304147466,  RMSE: 0.16402996554414245, Log-Loss:0.9292944321500641\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.973083645443196 using:rbf,1,10\n",
      "            train score: 0.9753359770874642 with variance: 1.0687606271730511e-05\n",
      "            test  score: 0.973083645443196 with variance: 8.125673120833619e-05\n",
      "          Refitted train score: 0.9730941704035875,  RMSE: 0.16402996554414245, Log-Loss:0.9292944321500641\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9840601259205911 using:linear,1.5,15\n",
      "            train score: 0.9903648981205538 with variance: 1.8189462171344484e-05\n",
      "            test  score: 0.9840601259205911 with variance: 8.485023361169365e-05\n",
      "          Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9842946317103621 using:linear,1.5,15\n",
      "            train score: 0.9904683221603248 with variance: 1.764643367712921e-05\n",
      "            test  score: 0.9842946317103621 with variance: 8.102481137030699e-05\n",
      "          Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9816524651818771 using:linear,1.5,25\n",
      "            train score: 0.9966164548251571 with variance: 7.722303602099615e-06\n",
      "            test  score: 0.9816524651818771 with variance: 0.00014326615694590275\n",
      "          Refitted train score: 0.9954954954954954,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834483\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9820474406991261 using:linear,1.5,25\n",
      "            train score: 0.9966370817990118 with variance: 7.530671432225681e-06\n",
      "            test  score: 0.9820474406991261 with variance: 0.00013163570505656956\n",
      "          Refitted train score: 0.9955156950672646,  RMSE: 0.0669649530182425, Log-Loss:0.15488240535834483\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9862579281183933 using:linear,1.5,50\n",
      "            train score: 0.9988763956286739 with variance: 1.893755078765027e-06\n",
      "            test  score: 0.9862579281183933 with variance: 0.00012593360717653908\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9865168539325844 using:linear,1.5,50\n",
      "            train score: 0.9988795518207283 with variance: 1.883106183649917e-06\n",
      "            test  score: 0.9865168539325844 with variance: 0.00012119681858351278\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9816596399284739 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9816596399284739 with variance: 0.00013816501972203796\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9820474406991261 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9820474406991261 with variance: 0.00013163570505656956\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.954013350119961 using:rbf,1,2\n",
      "            train score: 0.9531850079242629 with variance: 3.886351719947388e-05\n",
      "            test  score: 0.954013350119961 with variance: 0.0007142760759126235\n",
      "          Refitted train score: 0.9543378995433789,  RMSE: 0.21176177494381335, Log-Loss:1.5488348104995409\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9552559300873907 using:rbf,1,2\n",
      "            train score: 0.9540411670286092 with variance: 3.601872463142971e-05\n",
      "            test  score: 0.9552559300873907 with variance: 0.0006386872838415153\n",
      "          Refitted train score: 0.9551569506726457,  RMSE: 0.21176177494381335, Log-Loss:1.5488348104995409\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9638310568923915 using:linear,1,3\n",
      "            train score: 0.9628854543211176 with variance: 9.662254825290725e-05\n",
      "            test  score: 0.9638310568923915 with variance: 0.00028475975886814485\n",
      "          Refitted train score: 0.9705215419501134,  RMSE: 0.1707278010834213, Log-Loss:1.0067428061066368\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.964194756554307 using:rbf,1,3\n",
      "            train score: 0.9663708179901175 with variance: 2.807126251734933e-05\n",
      "            test  score: 0.964194756554307 with variance: 0.0003643535468305061\n",
      "          Refitted train score: 0.9708520179372198,  RMSE: 0.1707278010834213, Log-Loss:1.0067410132872867\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9631619120482279 using:rbf,1.5,5\n",
      "            train score: 0.9685618786052312 with variance: 2.4847817530869215e-05\n",
      "            test  score: 0.9631619120482279 with variance: 0.0006070982024155183\n",
      "          Refitted train score: 0.965675057208238,  RMSE: 0.18339107665182539, Log-Loss:1.1616234186456305\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9642197253433208 using:rbf,1.5,5\n",
      "            train score: 0.9691735121014698 with variance: 2.1811685777954638e-05\n",
      "            test  score: 0.9642197253433208 with variance: 0.0005608819188249377\n",
      "          Refitted train score: 0.9663677130044843,  RMSE: 0.18339107665182539, Log-Loss:1.1616234186456305\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9722503062608728 using:rbf,1,10\n",
      "            train score: 0.9759309206684748 with variance: 2.242001049171199e-05\n",
      "            test  score: 0.9722503062608728 with variance: 0.0003511510527404323\n",
      "          Refitted train score: 0.9748283752860412,  RMSE: 0.15704673549630008, Log-Loss:0.8518550222902423\n",
      "          Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "        accuracy\n",
      "          CV score: 0.973158551810237 using:rbf,1,10\n",
      "            train score: 0.9764611462562552 with variance: 2.0587573645348767e-05\n",
      "            test  score: 0.973158551810237 with variance: 0.0003260593421768358\n",
      "          Refitted train score: 0.9753363228699552,  RMSE: 0.15704673549630008, Log-Loss:0.8518550222902423\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      ncomponents: 15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9722503062608728 using:rbf,1,15\n",
      "            train score: 0.9776794783826486 with variance: 3.188445581902901e-05\n",
      "            test  score: 0.9722503062608728 with variance: 0.0003511510527404323\n",
      "          Refitted train score: 0.9771689497716896,  RMSE: 0.14973818705886996, Log-Loss:0.7744138196110705\n",
      "          Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.973158551810237 using:rbf,1,15\n",
      "            train score: 0.978143392188336 with variance: 2.9378819956161768e-05\n",
      "            test  score: 0.973158551810237 with variance: 0.0003260593421768358\n",
      "          Refitted train score: 0.9775784753363229,  RMSE: 0.14973818705886996, Log-Loss:0.7744138196110705\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9746542780403346 using:linear,1,25\n",
      "            train score: 0.9926568867187247 with variance: 1.948132692805265e-06\n",
      "            test  score: 0.9746542780403346 with variance: 0.0003958736943761639\n",
      "          Refitted train score: 0.9932279909706546,  RMSE: 0.08201498277207123, Log-Loss:0.2323236080375168\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9754057428214731 using:linear,1,25\n",
      "            train score: 0.9927139395083877 with variance: 1.8725665580796619e-06\n",
      "            test  score: 0.9754057428214731 with variance: 0.0003658971853223421\n",
      "          Refitted train score: 0.9932735426008968,  RMSE: 0.08201498277207123, Log-Loss:0.2323236080375168\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9771123833052237 using:linear,1,50\n",
      "            train score: 0.9966260395596758 with variance: 1.2589405283520192e-06\n",
      "            test  score: 0.9771123833052237 with variance: 0.00037254512305007117\n",
      "          Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "        accuracy\n",
      "          CV score: 0.9776279650436953 using:linear,1,50\n",
      "            train score: 0.9966370817990118 with variance: 1.253650820059291e-06\n",
      "            test  score: 0.9776279650436953 with variance: 0.00034904184999711595\n",
      "          Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9751711987558018 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9751711987558018 with variance: 0.0005103154491410939\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "        accuracy\n",
      "          CV score: 0.9754307116104869 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9754307116104869 with variance: 0.00051248299176591\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9491470818795248 using:rbf,1,2\n",
      "            train score: 0.9494430336018483 with variance: 9.2650787001347e-06\n",
      "            test  score: 0.9491470818795248 with variance: 0.00034951405088078986\n",
      "          Refitted train score: 0.9468822170900693,  RMSE: 0.22863229709016894, Log-Loss:1.8054505769599718\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.95 using:rbf,1,2\n",
      "            train score: 0.9505681818181818 with variance: 8.393595041322311e-06\n",
      "            test  score: 0.95 with variance: 0.0003409090909090919\n",
      "          Refitted train score: 0.9477272727272728,  RMSE: 0.22863229709016894, Log-Loss:1.8054505769599718\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9625164709027155 using:rbf,1,3\n",
      "            train score: 0.9607753793688124 with variance: 3.431287504043939e-05\n",
      "            test  score: 0.9625164709027155 with variance: 0.0002443863410338461\n",
      "          Refitted train score: 0.9601873536299766,  RMSE: 0.1965613482767241, Log-Loss:1.3344563588825964\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:rbf,1,3\n",
      "            train score: 0.9619318181818184 with variance: 3.099173553718985e-05\n",
      "            test  score: 0.9636363636363636 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9613636363636363,  RMSE: 0.1965613482767241, Log-Loss:1.3344563588825964\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9626787427079894 using:rbf,1,5\n",
      "            train score: 0.9645527046572484 with variance: 1.5276137214161576e-06\n",
      "            test  score: 0.9626787427079894 with variance: 0.00024520222908602405\n",
      "          Refitted train score: 0.9651972157772621,  RMSE: 0.1846372364689991, Log-Loss:1.1774637379907982\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9636363636363636 using:rbf,1,5\n",
      "            train score: 0.9653409090909092 with variance: 1.2913223140496604e-06\n",
      "            test  score: 0.9636363636363636 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9659090909090909,  RMSE: 0.1846372364689991, Log-Loss:1.1774637379907982\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9693475158370207 using:rbf,1,10\n",
      "            train score: 0.9749369092729895 with variance: 1.9833692797915717e-05\n",
      "            test  score: 0.9693475158370207 with variance: 0.00026826254822241437\n",
      "          Refitted train score: 0.9743589743589743,  RMSE: 0.15811388300841897, Log-Loss:0.863469409872768\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9704545454545455 using:rbf,1,10\n",
      "            train score: 0.9755681818181818 with variance: 1.8078512396694182e-05\n",
      "            test  score: 0.9704545454545455 with variance: 0.00023760330578512356\n",
      "          Refitted train score: 0.975,  RMSE: 0.15811388300841897, Log-Loss:0.863469409872768\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9745380001063303 using:linear,1.5,15\n",
      "            train score: 0.9879325486710296 with variance: 4.751111346869876e-06\n",
      "            test  score: 0.9745380001063303 with variance: 0.000243917697139699\n",
      "          Refitted train score: 0.9885583524027459,  RMSE: 0.10660035817780522, Log-Loss:0.39248791266360006\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.975 using:linear,1.5,15\n",
      "            train score: 0.9880681818181818 with variance: 4.5196280991734565e-06\n",
      "            test  score: 0.975 with variance: 0.00022727272727272684\n",
      "          Refitted train score: 0.9886363636363636,  RMSE: 0.10660035817780522, Log-Loss:0.39248791266360006\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9840600876446907 using:linear,1.5,25\n",
      "            train score: 0.9931264368620362 with variance: 8.640491340658725e-06\n",
      "            test  score: 0.9840600876446907 with variance: 8.258055767992604e-05\n",
      "          Refitted train score: 0.9908256880733944,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9840909090909091 using:linear,1.5,25\n",
      "            train score: 0.9931818181818182 with variance: 8.393595041322311e-06\n",
      "            test  score: 0.9840909090909091 with variance: 8.26446280991734e-05\n",
      "          Refitted train score: 0.990909090909091,  RMSE: 0.09534625892455922, Log-Loss:0.3139888763173708\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.988504532089135 using:linear,1.5,50\n",
      "            train score: 0.9982905982905983 with variance: 1.9480361360702597e-06\n",
      "            test  score: 0.988504532089135 with variance: 0.00010575014898637888\n",
      "          Refitted train score: 0.9977220956719818,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9886363636363636 using:linear,1.5,50\n",
      "            train score: 0.9982954545454545 with variance: 1.936983471074339e-06\n",
      "            test  score: 0.9886363636363636 with variance: 0.00010330578512396675\n",
      "          Refitted train score: 0.9977272727272727,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9861534349104517 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9861534349104517 with variance: 0.0001806749099915886\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "        accuracy\n",
      "          CV score: 0.9863636363636363 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9863636363636363 with variance: 0.0001756198347107435\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9416052269330437 using:rbf,1,2\n",
      "            train score: 0.948630383746573 with variance: 3.121461477230711e-05\n",
      "            test  score: 0.9416052269330437 with variance: 0.0005436794802106596\n",
      "          Refitted train score: 0.9451073985680192,  RMSE: 0.23290616784204735, Log-Loss:1.8735826732542873\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9434173669467786 using:rbf,1,2\n",
      "            train score: 0.9492920353982301 with variance: 2.5795111424369646e-05\n",
      "            test  score: 0.9434173669467786 with variance: 0.0004076297185540881\n",
      "          Refitted train score: 0.9457547169811321,  RMSE: 0.23290616784204735, Log-Loss:1.8735826732542873\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9580299218853435 using:rbf,1,3\n",
      "            train score: 0.9625979210410349 with variance: 6.721166197215231e-05\n",
      "            test  score: 0.9580299218853435 with variance: 0.0010516954686589678\n",
      "          Refitted train score: 0.961352657004831,  RMSE: 0.19425717247145283, Log-Loss:1.3033557101671271\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9599439775910363 using:rbf,1,3\n",
      "            train score: 0.9634426513968419 with variance: 6.131034681896268e-05\n",
      "            test  score: 0.9599439775910363 with variance: 0.0008618349300504518\n",
      "          Refitted train score: 0.9622641509433962,  RMSE: 0.19425717247145283, Log-Loss:1.3033557101671271\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9576311050159385 using:rbf,1,5\n",
      "            train score: 0.9637995561593685 with variance: 6.801980150808381e-05\n",
      "            test  score: 0.9576311050159385 with variance: 0.0014421334478132784\n",
      "          Refitted train score: 0.9638554216867471,  RMSE: 0.1880886984658197, Log-Loss:1.2218963318772436\n",
      "          Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9599439775910363 using:rbf,1,5\n",
      "            train score: 0.9646243276071491 with variance: 6.25206863183191e-05\n",
      "            test  score: 0.9599439775910363 with variance: 0.0011386515390469903\n",
      "          Refitted train score: 0.964622641509434,  RMSE: 0.1880886984658197, Log-Loss:1.2218963318772436\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9726972991423197 using:rbf,1.5,10\n",
      "            train score: 0.9751969268079813 with variance: 4.253912586801513e-05\n",
      "            test  score: 0.9726972991423197 with variance: 0.00099626596639654\n",
      "          Refitted train score: 0.9758454106280194,  RMSE: 0.1535737792084878, Log-Loss:0.8145937828988379\n",
      "          Refitted test  score: 0.9863013698630138,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9740896358543416 using:rbf,1.5,10\n",
      "            train score: 0.9758268263057435 with variance: 3.9606699580505925e-05\n",
      "            test  score: 0.9740896358543416 with variance: 0.000851807389622517\n",
      "          Refitted train score: 0.9764150943396226,  RMSE: 0.1535737792084878, Log-Loss:0.8145937828988379\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9807194179464321 using:linear,1.5,15\n",
      "            train score: 0.992281292092979 with variance: 1.971200650168552e-05\n",
      "            test  score: 0.9807194179464321 with variance: 0.0002742584892887603\n",
      "          Refitted train score: 0.9904761904761905,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9487179487179488,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "        accuracy\n",
      "          CV score: 0.9811764705882353 using:linear,1.5,15\n",
      "            train score: 0.9923373243102551 with variance: 1.943451510197969e-05\n",
      "            test  score: 0.9811764705882353 with variance: 0.0002546712802768175\n",
      "          Refitted train score: 0.9905660377358491,  RMSE: 0.09712858623572641, Log-Loss:0.32583751315953585\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9783671517387443 using:linear,1.5,25\n",
      "            train score: 0.992267171982394 with variance: 1.6286040045596874e-05\n",
      "            test  score: 0.9783671517387443 with variance: 0.0002623661047160219\n",
      "          Refitted train score: 0.9928741092636578,  RMSE: 0.08411582311380664, Log-Loss:0.24437813486965207\n",
      "          Refitted test  score: 0.961038961038961,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "        accuracy\n",
      "          CV score: 0.9788235294117648 using:linear,1.5,25\n",
      "            train score: 0.9923355891028978 with variance: 1.599882260023436e-05\n",
      "            test  score: 0.9788235294117648 with variance: 0.0002435986159169558\n",
      "          Refitted train score: 0.9929245283018868,  RMSE: 0.08411582311380664, Log-Loss:0.24437813486965207\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9831290565006491 using:linear,1,50\n",
      "            train score: 0.9958562323319228 with variance: 5.5979012585964615e-06\n",
      "            test  score: 0.9831290565006491 with variance: 0.0003323388092449881\n",
      "          Refitted train score: 0.9952606635071091,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "          Refitted test  score: 0.9487179487179488,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "        accuracy\n",
      "          CV score: 0.983529411764706 using:linear,1,50\n",
      "            train score: 0.9958736769043901 with variance: 5.556806603025463e-06\n",
      "            test  score: 0.983529411764706 with variance: 0.00031003460207612544\n",
      "          Refitted train score: 0.9952830188679245,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9831283815318663 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9831283815318663 with variance: 0.00027565079997125114\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9487179487179488,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "        accuracy\n",
      "          CV score: 0.983529411764706 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.983529411764706 with variance: 0.00025467128027681753\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195572238645625\n",
      "    random state: 650\n",
      "      ncomponents: 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.962170789192605 using:rbf,1,2\n",
      "            train score: 0.9621437284200285 with variance: 3.87011600806441e-05\n",
      "            test  score: 0.962170789192605 with variance: 0.00040469051097130084\n",
      "          Refitted train score: 0.9598108747044917,  RMSE: 0.19929783282370206, Log-Loss:1.371878496023512\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.9626538987688098 using:rbf,1,2\n",
      "            train score: 0.962619132866179 with variance: 3.8676643734082296e-05\n",
      "            test  score: 0.9626538987688098 with variance: 0.0004008975205900137\n",
      "          Refitted train score: 0.9602803738317757,  RMSE: 0.19929783282370206, Log-Loss:1.371878496023512\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9714225898086696 using:linear,1,3\n",
      "            train score: 0.9728043114924974 with variance: 2.4713723570950154e-05\n",
      "            test  score: 0.9714225898086696 with variance: 0.00032709536454075794\n",
      "          Refitted train score: 0.9738717339667458,  RMSE: 0.16031511026549947, Log-Loss:0.8876825690160709\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "        accuracy\n",
      "          CV score: 0.9720109439124487 using:linear,1,3\n",
      "            train score: 0.9731352189998808 with variance: 2.5031684374697424e-05\n",
      "            test  score: 0.9720109439124487 with variance: 0.00030147858844489013\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876825690160709\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9640624164235853 using:rbf,1,5\n",
      "            train score: 0.9726185309035265 with variance: 4.977309751266166e-06\n",
      "            test  score: 0.9640624164235853 with variance: 0.0003043063803322383\n",
      "          Refitted train score: 0.9714285714285714,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051144\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "        accuracy\n",
      "          CV score: 0.9649521203830369 using:rbf,1,5\n",
      "            train score: 0.9731318091146232 with variance: 4.727562636781466e-06\n",
      "            test  score: 0.9649521203830369 with variance: 0.00027557699757280207\n",
      "          Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051144\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114618962953716\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9808936586682865 using:linear,1,10\n",
      "            train score: 0.984007585335019 with variance: 1.6240748524851558e-05\n",
      "            test  score: 0.9808936586682865 with variance: 9.400762562104122e-05\n",
      "          Refitted train score: 0.988179669030733,  RMSE: 0.10808442529177922, Log-Loss:0.4034903784452192\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9813406292749658 using:linear,1,10\n",
      "            train score: 0.9842326905699623 with variance: 1.5584517999941943e-05\n",
      "            test  score: 0.9813406292749658 with variance: 8.57742237925297e-05\n",
      "          Refitted train score: 0.9883177570093458,  RMSE: 0.10808442529177922, Log-Loss:0.4034903784452192\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9857142857142858 using:linear,1,15\n",
      "            train score: 0.9929376653471966 with variance: 5.569426296418176e-06\n",
      "            test  score: 0.9857142857142858 with variance: 0.00013605442176870653\n",
      "          Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.9859917920656635 using:linear,1,15\n",
      "            train score: 0.9929909808534945 with variance: 5.461914939789973e-06\n",
      "            test  score: 0.9859917920656635 with variance: 0.00013082990712271332\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9858263305322129 using:linear,1.5,25\n",
      "            train score: 0.9947075768516214 with variance: 1.1773320595635897e-05\n",
      "            test  score: 0.9858263305322129 with variance: 0.00018930238762171486\n",
      "          Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9859917920656635 using:linear,1.5,25\n",
      "            train score: 0.9947419569331493 with variance: 1.1591720435939119e-05\n",
      "            test  score: 0.9859917920656635 with variance: 0.00018491319538663906\n",
      "          Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209422706713196\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9904761904761905 using:linear,1,50\n",
      "            train score: 0.9982404390327559 with variance: 5.524332377927671e-06\n",
      "            test  score: 0.9904761904761905 with variance: 0.00013605442176870653\n",
      "          Refitted train score: 0.9976580796252927,  RMSE: 0.04833682445228318, Log-Loss:0.08069807568904462\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9906429548563611 using:linear,1,50\n",
      "            train score: 0.9982473189777163 with variance: 5.467792548770248e-06\n",
      "            test  score: 0.9906429548563611 with variance: 0.00013133892630637378\n",
      "          Refitted train score: 0.9976635514018691,  RMSE: 0.04833682445228318, Log-Loss:0.08069807568904462\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9785381107158276 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9785381107158276 with variance: 0.000432665969131166\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9790150478796169 with variance: 0.0004004828196668542\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.938921555647282 using:linear,0.001,2\n",
      "            train score: 0.9399507338161035 with variance: 2.8218939643280078e-05\n",
      "            test  score: 0.938921555647282 with variance: 0.0005059397776628852\n",
      "          Refitted train score: 0.9371980676328503,  RMSE: 0.2470483026652182, Log-Loss:2.10801357617298\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "        accuracy\n",
      "          CV score: 0.941313269493844 using:linear,0.001,2\n",
      "            train score: 0.9419027082973953 with variance: 2.530608870785496e-05\n",
      "            test  score: 0.941313269493844 with variance: 0.0003876181083574586\n",
      "          Refitted train score: 0.9389671361502347,  RMSE: 0.2470483026652182, Log-Loss:2.10801357617298\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9513160578823229 using:rbf,1.5,3\n",
      "            train score: 0.9577722823783367 with variance: 1.5195551649344046e-05\n",
      "            test  score: 0.9513160578823229 with variance: 0.00019753778912586623\n",
      "          Refitted train score: 0.9565217391304348,  RMSE: 0.2055566129482595, Log-Loss:1.4593905490626367\n",
      "          Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "        accuracy\n",
      "          CV score: 0.9530506155950753 using:rbf,1.5,3\n",
      "            train score: 0.9589235811626704 with variance: 1.3518666109173667e-05\n",
      "            test  score: 0.9530506155950753 with variance: 0.00016613787308579765\n",
      "          Refitted train score: 0.9577464788732394,  RMSE: 0.2055566129482595, Log-Loss:1.4593905490626367\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.97107588834992 using:rbf,1.5,5\n",
      "            train score: 0.9747564993580514 with variance: 5.929829386595541e-06\n",
      "            test  score: 0.97107588834992 with variance: 0.00015129607221029908\n",
      "          Refitted train score: 0.9734939759036145,  RMSE: 0.16069099615140686, Log-Loss:0.8918463388357226\n",
      "          Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "        accuracy\n",
      "          CV score: 0.97187414500684 using:rbf,1.5,5\n",
      "            train score: 0.9753544937036398 with variance: 5.40534058276491e-06\n",
      "            test  score: 0.97187414500684 with variance: 0.00013987248320891676\n",
      "          Refitted train score: 0.9741784037558685,  RMSE: 0.16069099615140686, Log-Loss:0.8918463388357226\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9732452005192321 using:rbf,1.5,10\n",
      "            train score: 0.9759637899365996 with variance: 1.9309029264696282e-05\n",
      "            test  score: 0.9732452005192321 with variance: 0.0001575965347821592\n",
      "          Refitted train score: 0.9759615384615384,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415663\n",
      "          Refitted test  score: 0.9714285714285714,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "        accuracy\n",
      "          CV score: 0.9741723666210671 using:rbf,1.5,10\n",
      "            train score: 0.9765275142314991 with variance: 1.712947537389209e-05\n",
      "            test  score: 0.9741723666210671 with variance: 0.00013314145306263058\n",
      "          Refitted train score: 0.9765258215962441,  RMSE: 0.15321285325897388, Log-Loss:0.8107693989415663\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9783685510642695 using:linear,1,15\n",
      "            train score: 0.9875085054570876 with variance: 8.866639418725704e-06\n",
      "            test  score: 0.9783685510642695 with variance: 8.243546027029875e-05\n",
      "          Refitted train score: 0.9857142857142858,  RMSE: 0.11867816581938534, Log-Loss:0.48646163936494013\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.97890560875513 using:linear,1,15\n",
      "            train score: 0.9876763843367259 with variance: 8.247959416053616e-06\n",
      "            test  score: 0.97890560875513 with variance: 7.521806419255906e-05\n",
      "          Refitted train score: 0.9859154929577465,  RMSE: 0.11867816581938534, Log-Loss:0.48646163936494013\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9856569133677567 using:linear,1,25\n",
      "            train score: 0.9946832012634303 with variance: 4.964315285832857e-06\n",
      "            test  score: 0.9856569133677567 with variance: 7.909681509416004e-05\n",
      "          Refitted train score: 0.9929078014184397,  RMSE: 0.08391813582966891, Log-Loss:0.24323081968247054\n",
      "          Refitted test  score: 0.9295774647887323,  RMSE: 0.31943828249996997, Log-Loss:3.524397574885997\n",
      "        accuracy\n",
      "          CV score: 0.98593707250342 using:linear,1,25\n",
      "            train score: 0.9947162325340694 with variance: 4.852450106767632e-06\n",
      "            test  score: 0.98593707250342 with variance: 7.649061215171051e-05\n",
      "          Refitted train score: 0.9929577464788732,  RMSE: 0.08391813582966891, Log-Loss:0.24323081968247054\n",
      "          Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524397574885997\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9834160170092133 using:linear,1,50\n",
      "            train score: 0.9976470384691909 with variance: 1.3841668575862325e-06\n",
      "            test  score: 0.9834160170092133 with variance: 8.753335767717502e-05\n",
      "          Refitted train score: 0.9976470588235293,  RMSE: 0.048450158311150925, Log-Loss:0.08107693989415754\n",
      "          Refitted test  score: 0.9589041095890412,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "        accuracy\n",
      "          CV score: 0.9835567715458277 using:linear,1,50\n",
      "            train score: 0.9976522339140935 with variance: 1.3780125575174926e-06\n",
      "            test  score: 0.9835567715458277 with variance: 8.884181293170729e-05\n",
      "          Refitted train score: 0.9976525821596244,  RMSE: 0.048450158311150925, Log-Loss:0.08107693989415754\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9781225743309372 using:rbf,1.5,100\n",
      "            train score: 0.9887167821521647 with variance: 5.1095717606934915e-06\n",
      "            test  score: 0.9781225743309372 with variance: 0.0002191520425110363\n",
      "          Refitted train score: 0.98812351543943,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "        accuracy\n",
      "          CV score: 0.9788782489740082 using:rbf,1.5,100\n",
      "            train score: 0.9888511298947732 with variance: 4.791745232115666e-06\n",
      "            test  score: 0.9788782489740082 with variance: 0.00018798976721729426\n",
      "          Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053846994707836\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9546839906412092 using:linear,1.5,2\n",
      "            train score: 0.9414730318548037 with variance: 0.0002105894334899507\n",
      "            test  score: 0.9546839906412092 with variance: 0.0006398221601864521\n",
      "          Refitted train score: 0.928735632183908,  RMSE: 0.26787918780535985, Log-Loss:2.4785084754595945\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "        accuracy\n",
      "          CV score: 0.9538358727612938 using:linear,1.5,2\n",
      "            train score: 0.9409851721538075 with variance: 0.00020792468942583054\n",
      "            test  score: 0.9538358727612938 with variance: 0.0006827513181238462\n",
      "          Refitted train score: 0.9282407407407407,  RMSE: 0.26787918780535985, Log-Loss:2.4785084754595945\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114667917898422\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.964178325938472 using:rbf,1.5,3\n",
      "            train score: 0.9643591588723712 with variance: 1.8319741171018004e-05\n",
      "            test  score: 0.964178325938472 with variance: 0.0003017482187242114\n",
      "          Refitted train score: 0.9643705463182897,  RMSE: 0.18633899812498247, Log-Loss:1.1992667711076874\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9653033948142209 using:rbf,1.5,3\n",
      "            train score: 0.9652793834296725 with variance: 1.6601906876590393e-05\n",
      "            test  score: 0.9653033948142209 with variance: 0.0002679841581481377\n",
      "          Refitted train score: 0.9652777777777778,  RMSE: 0.18633899812498247, Log-Loss:1.1992667711076874\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9549889097065762 using:rbf,1,5\n",
      "            train score: 0.9680785184848147 with variance: 2.6358175557471498e-05\n",
      "            test  score: 0.9549889097065762 with variance: 0.0006115189610364548\n",
      "          Refitted train score: 0.9692671394799054,  RMSE: 0.17347216662217774, Log-Loss:1.0393650285386566\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9561347233360064 using:rbf,1,5\n",
      "            train score: 0.9687542933735445 with variance: 2.4531134102020774e-05\n",
      "            test  score: 0.9561347233360064 with variance: 0.0005990561969594886\n",
      "          Refitted train score: 0.9699074074074074,  RMSE: 0.17347216662217774, Log-Loss:1.0393650285386566\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9717040528736011 using:linear,1,10\n",
      "            train score: 0.9757791520812532 with variance: 5.121054661965571e-05\n",
      "            test  score: 0.9717040528736011 with variance: 0.00019779006051621846\n",
      "          Refitted train score: 0.9739952718676123,  RMSE: 0.15957118462605635, Log-Loss:0.8794614350496482\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9722801390002672 using:linear,1,10\n",
      "            train score: 0.9762804724805229 with variance: 4.79363886114872e-05\n",
      "            test  score: 0.9722801390002672 with variance: 0.00018965663721417532\n",
      "          Refitted train score: 0.9745370370370371,  RMSE: 0.15957118462605635, Log-Loss:0.8794614350496482\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9812298873037587 using:linear,1,15\n",
      "            train score: 0.9888802841784374 with variance: 4.848387763413503e-06\n",
      "            test  score: 0.9812298873037587 with variance: 0.0002490911820883765\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9815290029403902 using:linear,1,15\n",
      "            train score: 0.9890072882633827 with variance: 4.631402068701969e-06\n",
      "            test  score: 0.9815290029403902 with variance: 0.00024323117529652093\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.981226697575582 using:linear,1,25\n",
      "            train score: 0.9918332653338773 with variance: 8.303368905566273e-06\n",
      "            test  score: 0.981226697575582 with variance: 0.00013981427501405462\n",
      "          Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "        accuracy\n",
      "          CV score: 0.9815290029403902 using:linear,1,25\n",
      "            train score: 0.9919008125994806 with variance: 7.988054400455297e-06\n",
      "            test  score: 0.9815290029403902 with variance: 0.00013753689599938691\n",
      "          Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9788222265650447 using:linear,1,50\n",
      "            train score: 0.997098078867543 with variance: 3.3802225559685886e-06\n",
      "            test  score: 0.9788222265650447 with variance: 7.754544356900045e-05\n",
      "          Refitted train score: 0.9953488372093023,  RMSE: 0.06804138174397717, Log-Loss:0.1599017425690319\n",
      "          Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9792034215450414 using:linear,1,50\n",
      "            train score: 0.9971081511267489 with variance: 3.3412521655870206e-06\n",
      "            test  score: 0.9792034215450414 with variance: 7.325859707421449e-05\n",
      "          Refitted train score: 0.9953703703703703,  RMSE: 0.06804138174397717, Log-Loss:0.1599017425690319\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9787081568407693 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9787081568407693 with variance: 0.00019292670869569222\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9792034215450414 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9792034215450414 with variance: 0.00018142517360206716\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9464935640019332 using:rbf,1,2\n",
      "            train score: 0.9453802796460089 with variance: 2.2968110917231147e-05\n",
      "            test  score: 0.9464935640019332 with variance: 0.0002753516611795862\n",
      "          Refitted train score: 0.9443099273607748,  RMSE: 0.2340126166724879, Log-Loss:1.8914244139580658\n",
      "          Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "        accuracy\n",
      "          CV score: 0.9476190476190476 using:rbf,1,2\n",
      "            train score: 0.9464285714285714 with variance: 2.1258503401360394e-05\n",
      "            test  score: 0.9476190476190476 with variance: 0.0002607709750566888\n",
      "          Refitted train score: 0.9452380952380952,  RMSE: 0.2340126166724879, Log-Loss:1.8914244139580658\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9489773729062592 using:rbf,1.5,3\n",
      "            train score: 0.9488349680742223 with variance: 1.342416639673341e-05\n",
      "            test  score: 0.9489773729062592 with variance: 0.0001930525597152923\n",
      "          Refitted train score: 0.9486552567237164,  RMSE: 0.22360679774997896, Log-Loss:1.7269483387625613\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.95 using:rbf,1.5,3\n",
      "            train score: 0.95 with variance: 1.2046485260770888e-05\n",
      "            test  score: 0.95 with variance: 0.00019274376417233538\n",
      "          Refitted train score: 0.95,  RMSE: 0.22360679774997896, Log-Loss:1.7269483387625613\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9589060530340715 using:rbf,1.5,5\n",
      "            train score: 0.9641405805159398 with variance: 3.8109829624639946e-05\n",
      "            test  score: 0.9589060530340715 with variance: 0.0002585236537519655\n",
      "          Refitted train score: 0.9683698296836983,  RMSE: 0.1759328876372492, Log-Loss:1.0690611722111896\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9595238095238094 using:rbf,1.5,5\n",
      "            train score: 0.9648809523809524 with variance: 3.6848072562358015e-05\n",
      "            test  score: 0.9595238095238094 with variance: 0.00026077097505669024\n",
      "          Refitted train score: 0.969047619047619,  RMSE: 0.1759328876372492, Log-Loss:1.0690611722111896\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9657167231015565 using:rbf,1,10\n",
      "            train score: 0.9744675455256097 with variance: 1.791490696481931e-05\n",
      "            test  score: 0.9657167231015565 with variance: 0.00015152050800452187\n",
      "          Refitted train score: 0.97323600973236,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9666666666666666 using:rbf,1,10\n",
      "            train score: 0.975 with variance: 1.6298185941042967e-05\n",
      "            test  score: 0.9666666666666666 with variance: 0.0001360544217687081\n",
      "          Refitted train score: 0.9738095238095238,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.968309315694149 using:rbf,1,15\n",
      "            train score: 0.9744675455256097 with variance: 1.791490696481931e-05\n",
      "            test  score: 0.968309315694149 with variance: 9.691253362333718e-05\n",
      "          Refitted train score: 0.97323600973236,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9690476190476189 using:rbf,1,15\n",
      "            train score: 0.975 with variance: 1.6298185941042967e-05\n",
      "            test  score: 0.9690476190476189 with variance: 9.07029478458052e-05\n",
      "          Refitted train score: 0.9738095238095238,  RMSE: 0.1618347187425374, Log-Loss:0.9045889046224954\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9855380200860833 using:linear,1,25\n",
      "            train score: 0.99401912592725 with variance: 1.790691723269402e-05\n",
      "            test  score: 0.9855380200860833 with variance: 8.416805781696101e-05\n",
      "          Refitted train score: 0.9952153110047847,  RMSE: 0.06900655593423542, Log-Loss:0.16447036378528998\n",
      "          Refitted test  score: 0.975,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9857142857142858 using:linear,1,25\n",
      "            train score: 0.9940476190476192 with variance: 1.7715419501133662e-05\n",
      "            test  score: 0.9857142857142858 with variance: 7.936507936507965e-05\n",
      "          Refitted train score: 0.9952380952380953,  RMSE: 0.06900655593423542, Log-Loss:0.16447036378528998\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9853658536585366 using:linear,1.5,50\n",
      "            train score: 0.9958029886173598 with variance: 1.296011645921972e-05\n",
      "            test  score: 0.9853658536585366 with variance: 0.00014277215942891164\n",
      "          Refitted train score: 0.9928057553956835,  RMSE: 0.08451542547285165, Log-Loss:0.24670554567793443\n",
      "          Refitted test  score: 0.975,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9857142857142858 using:linear,1.5,50\n",
      "            train score: 0.9958333333333333 with variance: 1.2755102040816236e-05\n",
      "            test  score: 0.9857142857142858 with variance: 0.0001360544217687078\n",
      "          Refitted train score: 0.9928571428571429,  RMSE: 0.08451542547285165, Log-Loss:0.24670554567793443\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9878909612625538 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9878909612625538 with variance: 0.00011900644080286718\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.975,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9880952380952381 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9880952380952381 with variance: 0.00011337868480725647\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.954901285815531 using:rbf,1,2\n",
      "            train score: 0.9542950409058669 with variance: 3.435861661435817e-05\n",
      "            test  score: 0.954901285815531 with variance: 0.000534223991441802\n",
      "          Refitted train score: 0.957345971563981,  RMSE: 0.20507577810739896, Log-Loss:1.4525765717125556\n",
      "          Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "        accuracy\n",
      "          CV score: 0.9557045143638853 using:rbf,1,2\n",
      "            train score: 0.9550287282832933 with variance: 3.2213616760265796e-05\n",
      "            test  score: 0.9557045143638853 with variance: 0.0005050997359462995\n",
      "          Refitted train score: 0.9579439252336449,  RMSE: 0.20507577810739896, Log-Loss:1.4525765717125556\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9692997198879553 using:linear,1,3\n",
      "            train score: 0.9652052435293175 with variance: 2.4633293019174306e-05\n",
      "            test  score: 0.9692997198879553 with variance: 0.0002584123845616673\n",
      "          Refitted train score: 0.9694117647058823,  RMSE: 0.17428089905580857, Log-Loss:1.0490843250490427\n",
      "          Refitted test  score: 0.9565217391304348,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "        accuracy\n",
      "          CV score: 0.9696853625170998 using:linear,1,3\n",
      "            train score: 0.9655414045317375 with variance: 2.4919155196238784e-05\n",
      "            test  score: 0.9696853625170998 with variance: 0.00024957360286398107\n",
      "          Refitted train score: 0.969626168224299,  RMSE: 0.17428089905580857, Log-Loss:1.0490843250490427\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9711990820424556 using:rbf,1,5\n",
      "            train score: 0.9717968166564951 with variance: 2.0721907265095286e-05\n",
      "            test  score: 0.9711990820424556 with variance: 0.0003843453479519257\n",
      "          Refitted train score: 0.973621103117506,  RMSE: 0.16031511026549947, Log-Loss:0.8876788325794811\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9720383036935705 using:rbf,1,5\n",
      "            train score: 0.9725521286208718 with variance: 1.8782431446195787e-05\n",
      "            test  score: 0.9720383036935705 with variance: 0.00035645266028022215\n",
      "          Refitted train score: 0.9742990654205608,  RMSE: 0.16031511026549947, Log-Loss:0.8876788325794811\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:rbf,1.5,10\n",
      "            train score: 0.9791257995735607 with variance: 1.0820781865876242e-05\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.9785202863961814,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "        accuracy\n",
      "          CV score: 0.9790150478796169 using:rbf,1.5,10\n",
      "            train score: 0.9795594428247488 with variance: 1.008124469191688e-05\n",
      "            test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "          Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9785994397759105 using:linear,1,15\n",
      "            train score: 0.9899634061759993 with variance: 9.220826542845812e-06\n",
      "            test  score: 0.9785994397759105 with variance: 0.00024996979183830294\n",
      "          Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "        accuracy\n",
      "          CV score: 0.9790424076607387 using:linear,1,15\n",
      "            train score: 0.9900704141305645 with variance: 8.879881182791335e-06\n",
      "            test  score: 0.9790424076607387 with variance: 0.0002374604434081079\n",
      "          Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "          Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.978485370051635 using:rbf,1,25\n",
      "            train score: 0.9803375450007277 with variance: 1.6642416207931317e-05\n",
      "            test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "          Refitted train score: 0.9785202863961814,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "          Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "        accuracy\n",
      "          CV score: 0.9790424076607387 using:linear,1,25\n",
      "            train score: 0.9912365948885821 with variance: 1.7079511970754694e-05\n",
      "            test  score: 0.9790424076607387 with variance: 0.0001833771551441812\n",
      "          Refitted train score: 0.9883177570093458,  RMSE: 0.10808442529177922, Log-Loss:0.4034903784452193\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9810084033613446 using:linear,1,50\n",
      "            train score: 0.9976539287688263 with variance: 4.836308402109701e-06\n",
      "            test  score: 0.9810084033613446 with variance: 0.0002615760029501984\n",
      "          Refitted train score: 0.9976580796252927,  RMSE: 0.04833682445228318, Log-Loss:0.08069807568904465\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9813679890560876 using:linear,1,50\n",
      "            train score: 0.9976625236560789 with variance: 4.785815497298013e-06\n",
      "            test  score: 0.9813679890560876 with variance: 0.00024840435585680824\n",
      "          Refitted train score: 0.9976635514018691,  RMSE: 0.04833682445228318, Log-Loss:0.08069807568904465\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      ncomponents: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9810644257703082 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9810644257703082 with variance: 0.0001450180072028805\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "        accuracy\n",
      "          CV score: 0.9813679890560876 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9813679890560876 with variance: 0.00014023777932895546\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9455110058279761 using:rbf,1,2\n",
      "            train score: 0.9461282470390022 with variance: 3.301182293541291e-05\n",
      "            test  score: 0.9455110058279761 with variance: 0.00040426069901063224\n",
      "          Refitted train score: 0.9455445544554456,  RMSE: 0.23108019874586222, Log-Loss:1.8443171792962298\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9466647076109315 using:rbf,1,2\n",
      "            train score: 0.947211936999171 with variance: 3.1268163976741066e-05\n",
      "            test  score: 0.9466647076109315 with variance: 0.00038375155834305944\n",
      "          Refitted train score: 0.9466019417475728,  RMSE: 0.23108019874586222, Log-Loss:1.8443171792962298\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9527413208161517 using:rbf,1,3\n",
      "            train score: 0.9554246274441317 with variance: 5.775995878647002e-05\n",
      "            test  score: 0.9527413208161517 with variance: 0.00048308999293706755\n",
      "          Refitted train score: 0.9554455445544554,  RMSE: 0.2090199042874853, Log-Loss:1.5089853715911252\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.953923009109609 using:rbf,1,3\n",
      "            train score: 0.9563083724785854 with variance: 5.385508440425471e-05\n",
      "            test  score: 0.953923009109609 with variance: 0.00043544748721741945\n",
      "          Refitted train score: 0.9563106796116505,  RMSE: 0.2090199042874853, Log-Loss:1.5089853715911252\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9497481197274107 using:rbf,1.5,5\n",
      "            train score: 0.9632112333420502 with variance: 6.231933473880055e-05\n",
      "            test  score: 0.9497481197274107 with variance: 0.0009322589439314792\n",
      "          Refitted train score: 0.9600000000000001,  RMSE: 0.1970658556328586, Log-Loss:1.3413155861976498\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9515427563914194 using:rbf,1.5,5\n",
      "            train score: 0.9642037395228884 with variance: 5.6268703321786225e-05\n",
      "            test  score: 0.9515427563914194 with variance: 0.000877450874144428\n",
      "          Refitted train score: 0.9611650485436893,  RMSE: 0.1970658556328586, Log-Loss:1.3413155861976498\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9696825669839086 using:linear,1,10\n",
      "            train score: 0.9795585187657665 with variance: 3.37507271556593e-05\n",
      "            test  score: 0.9696825669839086 with variance: 0.0007320087575887512\n",
      "          Refitted train score: 0.9776674937965261,  RMSE: 0.14779939172464399, Log-Loss:0.7544878338694092\n",
      "          Refitted test  score: 0.9767441860465116,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9708786364972084 using:linear,1,10\n",
      "            train score: 0.9799723680574743 with variance: 3.174606907388419e-05\n",
      "            test  score: 0.9708786364972084 with variance: 0.0006298948508640749\n",
      "          Refitted train score: 0.9781553398058253,  RMSE: 0.14779939172464399, Log-Loss:0.7544878338694092\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9672736540058899 using:linear,1,15\n",
      "            train score: 0.9859138568517013 with variance: 1.7255527221763344e-05\n",
      "            test  score: 0.9672736540058899 with variance: 0.0006686354216166545\n",
      "          Refitted train score: 0.9901960784313726,  RMSE: 0.0985329278164293, Log-Loss:0.3353279261641823\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9684396121069645 using:linear,1,15\n",
      "            train score: 0.9860440268950909 with variance: 1.6892190096260995e-05\n",
      "            test  score: 0.9684396121069645 with variance: 0.0005711231788100051\n",
      "          Refitted train score: 0.9902912621359223,  RMSE: 0.0985329278164293, Log-Loss:0.3353279261641823\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9699206622220039 using:linear,1.5,25\n",
      "            train score: 0.9926567064525196 with variance: 6.06843837431636e-06\n",
      "            test  score: 0.9699206622220039 with variance: 0.0007347676259184095\n",
      "          Refitted train score: 0.9926650366748166,  RMSE: 0.08533201859828615, Log-Loss:0.251495944623137\n",
      "          Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "        accuracy\n",
      "          CV score: 0.9708786364972084 using:linear,1.5,25\n",
      "            train score: 0.9927162199502625 with variance: 5.917326493717009e-06\n",
      "            test  score: 0.9708786364972084 with variance: 0.0006298948508640749\n",
      "          Refitted train score: 0.9927184466019418,  RMSE: 0.08533201859828615, Log-Loss:0.251495944623137\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9804079681567892 using:linear,1.5,50\n",
      "            train score: 0.9987841945288753 with variance: 2.2172744154247993e-06\n",
      "            test  score: 0.9804079681567892 with variance: 0.0002146688705198512\n",
      "          Refitted train score: 0.9951219512195122,  RMSE: 0.06967330142916177, Log-Loss:0.16766396308209167\n",
      "          Refitted test  score: 0.9885057471264368,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "        accuracy\n",
      "          CV score: 0.9806053482221568 using:linear,1.5,50\n",
      "            train score: 0.9987860366583771 with variance: 2.2105689758091624e-06\n",
      "            test  score: 0.9806053482221568 with variance: 0.00021160737932485814\n",
      "          Refitted train score: 0.9951456310679612,  RMSE: 0.06967330142916177, Log-Loss:0.16766396308209167\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9830029048656499 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9830029048656499 with variance: 0.00014620002120108893\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9767441860465116,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "        accuracy\n",
      "          CV score: 0.9830443726124007 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9830443726124007 with variance: 0.00015154559739643047\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.950624034834561 using:linear,0.001,2\n",
      "            train score: 0.9442132540758774 with variance: 5.7868459045619315e-05\n",
      "            test  score: 0.950624034834561 with variance: 0.0009437706016207005\n",
      "          Refitted train score: 0.9430051813471502,  RMSE: 0.23510929779476553, Log-Loss:1.909188639887403\n",
      "          Refitted test  score: 0.9583333333333334,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "        accuracy\n",
      "          CV score: 0.9522151898734178 using:linear,0.001,2\n",
      "            train score: 0.945977011494253 with variance: 5.2993698418731905e-05\n",
      "            test  score: 0.9522151898734178 with variance: 0.0008621114404742834\n",
      "          Refitted train score: 0.9447236180904522,  RMSE: 0.23510929779476553, Log-Loss:1.909188639887403\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254631627637353\n",
      "      ncomponents: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9532348093751603 using:rbf,1,3\n",
      "            train score: 0.9571326779352711 with variance: 7.708289837283803e-05\n",
      "            test  score: 0.9532348093751603 with variance: 0.0011658639958657476\n",
      "          Refitted train score: 0.9538461538461539,  RMSE: 0.2126643615025008, Log-Loss:1.562065259034029\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "        accuracy\n",
      "          CV score: 0.9546835443037974 using:rbf,1,3\n",
      "            train score: 0.9579050097592713 with variance: 7.025027060731565e-05\n",
      "            test  score: 0.9546835443037974 with variance: 0.001063056801794584\n",
      "          Refitted train score: 0.9547738693467337,  RMSE: 0.2126643615025008, Log-Loss:1.562065259034029\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728016\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9704323074186089 using:rbf,1.5,5\n",
      "            train score: 0.9728592140717573 with variance: 6.875812771275104e-05\n",
      "            test  score: 0.9704323074186089 with variance: 0.001302070750835535\n",
      "          Refitted train score: 0.9768637532133677,  RMSE: 0.15037641213512565, Log-Loss:0.7810276069200918\n",
      "          Refitted test  score: 0.9591836734693877,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.9722468354430379 using:rbf,1.5,5\n",
      "            train score: 0.9736125076398336 with variance: 6.185155593690388e-05\n",
      "            test  score: 0.9722468354430379 with variance: 0.0011133191796186518\n",
      "          Refitted train score: 0.9773869346733668,  RMSE: 0.15037641213512565, Log-Loss:0.7810276069200918\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9763499658236501 using:rbf,1.5,10\n",
      "            train score: 0.9788020345501899 with variance: 2.860649301920269e-05\n",
      "            test  score: 0.9763499658236501 with variance: 0.0005824416257196755\n",
      "          Refitted train score: 0.9794871794871796,  RMSE: 0.1417762410016672, Log-Loss:0.6942467617067484\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9773417721518987 using:rbf,1.5,10\n",
      "            train score: 0.9792669702884407 with variance: 2.625111527311746e-05\n",
      "            test  score: 0.9773417721518987 with variance: 0.0005313892004486472\n",
      "          Refitted train score: 0.9798994974874372,  RMSE: 0.1417762410016672, Log-Loss:0.6942467617067484\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9790840738209159 using:rbf,1.5,15\n",
      "            train score: 0.9814324696354102 with variance: 1.4409041494297187e-05\n",
      "            test  score: 0.9790840738209159 with variance: 0.00045386566521940736\n",
      "          Refitted train score: 0.9820971867007673,  RMSE: 0.13261952985323264, Log-Loss:0.6074659164934049\n",
      "          Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "        accuracy\n",
      "          CV score: 0.9798417721518987 using:rbf,1.5,15\n",
      "            train score: 0.981782693558881 with variance: 1.3484269788775235e-05\n",
      "            test  score: 0.9798417721518987 with variance: 0.0004196803396891529\n",
      "          Refitted train score: 0.9824120603015075,  RMSE: 0.13261952985323264, Log-Loss:0.6074659164934049\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9896761466381718 using:linear,1.5,25\n",
      "            train score: 0.9955795779686613 with variance: 6.384289348570161e-06\n",
      "            test  score: 0.9896761466381718 with variance: 0.00022905670959908045\n",
      "          Refitted train score: 0.9949494949494949,  RMSE: 0.0708881205008336, Log-Loss:0.17356169042668781\n",
      "          Refitted test  score: 0.9523809523809523,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "        accuracy\n",
      "          CV score: 0.9899683544303798 using:linear,1.5,25\n",
      "            train score: 0.995603398986613 with variance: 6.319005917983215e-06\n",
      "            test  score: 0.9899683544303798 with variance: 0.00021266223361640735\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.0708881205008336, Log-Loss:0.17356169042668781\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9896761466381718 using:linear,1,50\n",
      "            train score: 0.9987421259258527 with variance: 2.3734098961279883e-06\n",
      "            test  score: 0.9896761466381718 with variance: 0.00022905670959908045\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9423076923076924,  RMSE: 0.3038218101251, Log-Loss:3.1882562516402326\n",
      "        accuracy\n",
      "          CV score: 0.9899683544303798 using:linear,1,50\n",
      "            train score: 0.998744109934741 with variance: 2.365899501744545e-06\n",
      "            test  score: 0.9899683544303798 with variance: 0.00021266223361640735\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1882562516402326\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.987079587079587 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.987079587079587 with variance: 0.0002681478805354932\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9514563106796116,  RMSE: 0.2773500981126146, Log-Loss:2.656878159450373\n",
      "        accuracy\n",
      "          CV score: 0.9874367088607595 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9874367088607595 with variance: 0.000251598301554238\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656878159450373\n",
      "    random state: 650\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9500969355847404 using:rbf,1,2\n",
      "            train score: 0.9530207793800315 with variance: 4.473592049754177e-05\n",
      "            test  score: 0.9500969355847404 with variance: 0.0004963069476271311\n",
      "          Refitted train score: 0.949748743718593,  RMSE: 0.2224970797449924, Log-Loss:1.709854270000558\n",
      "          Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "        accuracy\n",
      "          CV score: 0.9504320987654321 using:rbf,1,2\n",
      "            train score: 0.9535852157627183 with variance: 4.248441323234847e-05\n",
      "            test  score: 0.9504320987654321 with variance: 0.0004970126505105925\n",
      "          Refitted train score: 0.9504950495049505,  RMSE: 0.2224970797449924, Log-Loss:1.709854270000558\n",
      "          Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.188194744145602\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9516749137801769 using:rbf,1,3\n",
      "            train score: 0.9568248478555617 with variance: 6.911345730433123e-05\n",
      "            test  score: 0.9516749137801769 with variance: 0.0005670642996498688\n",
      "          Refitted train score: 0.9543147208121827,  RMSE: 0.21107926341908756, Log-Loss:1.5388642908369146\n",
      "          Refitted test  score: 0.9555555555555556,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        accuracy\n",
      "          CV score: 0.9529012345679012 using:rbf,1,3\n",
      "            train score: 0.9579157588961509 with variance: 6.39850191709067e-05\n",
      "            test  score: 0.9529012345679012 with variance: 0.000522313671696387\n",
      "          Refitted train score: 0.9554455445544554,  RMSE: 0.21107926341908756, Log-Loss:1.5388642908369146\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9671319932511657 using:rbf,1,5\n",
      "            train score: 0.9733773199551831 with variance: 1.8842438153596535e-05\n",
      "            test  score: 0.9671319932511657 with variance: 0.00028925589148044695\n",
      "          Refitted train score: 0.9720101781170484,  RMSE: 0.16500825061880156, Log-Loss:0.9404122285743017\n",
      "          Refitted test  score: 0.9555555555555556,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "        accuracy\n",
      "          CV score: 0.9678086419753086 using:rbf,1,5\n",
      "            train score: 0.9740090968161145 with variance: 1.767531715428814e-05\n",
      "            test  score: 0.9678086419753086 with variance: 0.0002813938424020719\n",
      "          Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404122285743017\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "      ncomponents: 10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9776489657301637 using:linear,1.5,10\n",
      "            train score: 0.9837809824302559 with variance: 1.684062355959514e-05\n",
      "            test  score: 0.9776489657301637 with variance: 0.00038975378322297455\n",
      "          Refitted train score: 0.9850746268656716,  RMSE: 0.12186666955535813, Log-Loss:0.5129560830800121\n",
      "          Refitted test  score: 0.9574468085106385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9777160493827161 using:linear,1.5,10\n",
      "            train score: 0.9839104842716815 with variance: 1.6881908882945423e-05\n",
      "            test  score: 0.9777160493827161 with variance: 0.00039050449626581345\n",
      "          Refitted train score: 0.9851485148514851,  RMSE: 0.12186666955535813, Log-Loss:0.5129560830800121\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9802354718017368 using:linear,1,15\n",
      "            train score: 0.9918963932586445 with variance: 1.0175833571212242e-05\n",
      "            test  score: 0.9802354718017368 with variance: 0.0002764903950699552\n",
      "          Refitted train score: 0.9925187032418953,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        accuracy\n",
      "          CV score: 0.980185185185185 using:linear,1,15\n",
      "            train score: 0.9919542865879294 with variance: 9.982723673313157e-06\n",
      "            test  score: 0.980185185185185 with variance: 0.0002810699588477374\n",
      "          Refitted train score: 0.9925742574257426,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9848717948717949 using:linear,1,25\n",
      "            train score: 0.9931463932586444 with variance: 5.434850424601141e-06\n",
      "            test  score: 0.9848717948717949 with variance: 0.0001526298487836952\n",
      "          Refitted train score: 0.9925187032418953,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9787234042553191,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9851234567901234 using:linear,1,25\n",
      "            train score: 0.9931926766808086 with variance: 5.3724268783569176e-06\n",
      "            test  score: 0.9851234567901234 with variance: 0.00014755372656607234\n",
      "          Refitted train score: 0.9925742574257426,  RMSE: 0.0861727484432139, Log-Loss:0.2564760623384466\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9824643874643874 using:linear,1,50\n",
      "            train score: 0.9981385569476192 with variance: 2.310029769815272e-06\n",
      "            test  score: 0.9824643874643874 with variance: 0.00022334315468218658\n",
      "          Refitted train score: 0.9975186104218362,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.9583333333333333,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "        accuracy\n",
      "          CV score: 0.9826543209876542 using:linear,1,50\n",
      "            train score: 0.9981424148606811 with variance: 2.300415033212295e-06\n",
      "            test  score: 0.9826543209876542 with variance: 0.00022040847431793986\n",
      "          Refitted train score: 0.9975247524752475,  RMSE: 0.04975185951049946, Log-Loss:0.0854920207794829\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.984807722360465 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.984807722360465 with variance: 0.00021958561542120787\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.968421052631579,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "        accuracy\n",
      "          CV score: 0.9851234567901234 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9851234567901234 with variance: 0.00020852004267642174\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706537\n",
      "    random state: 850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9393984439780467 using:rbf,1.5,2\n",
      "            train score: 0.9398373592917519 with variance: 8.061723828131452e-05\n",
      "            test  score: 0.9393984439780467 with variance: 0.0009402948176251193\n",
      "          Refitted train score: 0.9417721518987343,  RMSE: 0.23979157616563598, Log-Loss:1.9859976336495446\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9400000000000001 using:rbf,1.5,2\n",
      "            train score: 0.940625 with variance: 7.812500000000029e-05\n",
      "            test  score: 0.9400000000000001 with variance: 0.0009000000000000012\n",
      "          Refitted train score: 0.9425,  RMSE: 0.23979157616563598, Log-Loss:1.9859976336495446\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9490309058030577 using:rbf,1,3\n",
      "            train score: 0.9508758940129894 with variance: 5.4046170024539163e-05\n",
      "            test  score: 0.9490309058030577 with variance: 0.000507256287475282\n",
      "          Refitted train score: 0.9540816326530612,  RMSE: 0.21213203435596426, Log-Loss:1.554254932738859\n",
      "          Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.95 using:rbf,1,3\n",
      "            train score: 0.9518749999999999 with variance: 5.3125000000000316e-05\n",
      "            test  score: 0.95 with variance: 0.0005000000000000002\n",
      "          Refitted train score: 0.955,  RMSE: 0.21213203435596426, Log-Loss:1.554254932738859\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.972632105833265 using:linear,1.5,5\n",
      "            train score: 0.9704567669762236 with variance: 5.152962076925323e-05\n",
      "            test  score: 0.972632105833265 with variance: 0.0003038702853957024\n",
      "          Refitted train score: 0.9773299748110831,  RMSE: 0.15, Log-Loss:0.7771284658662178\n",
      "          Refitted test  score: 0.98989898989899,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898605\n",
      "        accuracy\n",
      "          CV score: 0.9725000000000001 using:linear,1.5,5\n",
      "            train score: 0.9706250000000001 with variance: 5.312500000000035e-05\n",
      "            test  score: 0.9725000000000001 with variance: 0.00033750000000000045\n",
      "          Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771284658662178\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898605\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9746186303148328 using:linear,1,10\n",
      "            train score: 0.9822698835873176 with variance: 1.0780995608677637e-05\n",
      "            test  score: 0.9746186303148328 with variance: 0.00012820144110740943\n",
      "          Refitted train score: 0.9796954314720813,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.9791666666666666,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "        accuracy\n",
      "          CV score: 0.975 using:linear,1,10\n",
      "            train score: 0.9824999999999999 with variance: 1.0156250000000094e-05\n",
      "            test  score: 0.975 with variance: 0.00012500000000000022\n",
      "          Refitted train score: 0.98,  RMSE: 0.1414213562373095, Log-Loss:0.6907775268917901\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9799319605226777 using:linear,1,15\n",
      "            train score: 0.9880244348050053 with variance: 5.6339061082986495e-06\n",
      "            test  score: 0.9799319605226777 with variance: 9.769010417490906e-05\n",
      "          Refitted train score: 0.9874055415617129,  RMSE: 0.11180339887498948, Log-Loss:0.43173670392996\n",
      "          Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:linear,1,15\n",
      "            train score: 0.9881249999999999 with variance: 5.468749999999933e-06\n",
      "            test  score: 0.9800000000000001 with variance: 0.00010000000000000029\n",
      "          Refitted train score: 0.9875,  RMSE: 0.11180339887498948, Log-Loss:0.43173670392996\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9872768581629341 using:linear,1,25\n",
      "            train score: 0.9943376137547666 with variance: 5.602728248803051e-06\n",
      "            test  score: 0.9872768581629341 with variance: 6.575254033131848e-05\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "        accuracy\n",
      "          CV score: 0.9875 using:linear,1,25\n",
      "            train score: 0.994375 with variance: 5.468749999999933e-06\n",
      "            test  score: 0.9875 with variance: 6.250000000000011e-05\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717275\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9798694507555267 using:linear,1,50\n",
      "            train score: 0.9968652037617556 with variance: 0.0\n",
      "            test  score: 0.9798694507555267 with variance: 9.67402881498208e-05\n",
      "          Refitted train score: 0.9949748743718593,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "        accuracy\n",
      "          CV score: 0.9800000000000001 using:linear,1,50\n",
      "            train score: 0.996875 with variance: 0.0\n",
      "            test  score: 0.9800000000000001 with variance: 0.00010000000000000029\n",
      "          Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.1726938819745544\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9823988093824463 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9823988093824463 with variance: 3.680576690604711e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.96,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "        accuracy\n",
      "          CV score: 0.9824999999999999 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9824999999999999 with variance: 3.7500000000000397e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "    random state: 1050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9505659467436584 using:rbf,1,2\n",
      "            train score: 0.9503734911210353 with variance: 2.6612678588409814e-05\n",
      "            test  score: 0.9505659467436584 with variance: 0.0005002213741300704\n",
      "          Refitted train score: 0.9554455445544553,  RMSE: 0.21055872190307892, Log-Loss:1.531291556373976\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9507678410117434 using:rbf,1,2\n",
      "            train score: 0.9507407407407408 with variance: 2.6336799214291965e-05\n",
      "            test  score: 0.9507678410117434 with variance: 0.0004841037402979999\n",
      "          Refitted train score: 0.9556650246305419,  RMSE: 0.21055872190307892, Log-Loss:1.531291556373976\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9538394419206397 using:linear,1.5,3\n",
      "            train score: 0.9377011240095816 with variance: 0.0011242037960393515\n",
      "            test  score: 0.9538394419206397 with variance: 0.0002324482964507226\n",
      "          Refitted train score: 0.9489051094890512,  RMSE: 0.227429413073671, Log-Loss:1.7865140370928996\n",
      "          Refitted test  score: 0.9574468085106383,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "        accuracy\n",
      "          CV score: 0.9532068654019874 using:linear,1.5,3\n",
      "            train score: 0.9365887939221272 with variance: 0.0012281772748958576\n",
      "            test  score: 0.9532068654019874 with variance: 0.00026771502617498635\n",
      "          Refitted train score: 0.9482758620689655,  RMSE: 0.227429413073671, Log-Loss:1.7865140370928996\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605133\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9652214030695043 using:rbf,1.5,5\n",
      "            train score: 0.966860893486025 with variance: 9.739093217119194e-06\n",
      "            test  score: 0.9652214030695043 with variance: 0.00019591783846878061\n",
      "          Refitted train score: 0.9674185463659147,  RMSE: 0.17894050529015934, Log-Loss:1.1059273200150979\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9655525444143329 using:rbf,1.5,5\n",
      "            train score: 0.9673656220322886 with variance: 9.777467534985792e-06\n",
      "            test  score: 0.9655525444143329 with variance: 0.0002037747434251081\n",
      "          Refitted train score: 0.9679802955665024,  RMSE: 0.17894050529015934, Log-Loss:1.1059273200150979\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9728812537673297 using:linear,1,10\n",
      "            train score: 0.9825384828199674 with variance: 4.1966425852254425e-05\n",
      "            test  score: 0.9728812537673297 with variance: 0.0005065036600550581\n",
      "          Refitted train score: 0.9850746268656716,  RMSE: 0.12156613477096616, Log-Loss:0.5104272363716618\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9729599518217406 using:linear,1,10\n",
      "            train score: 0.9827616334283 with variance: 4.0067438125051e-05\n",
      "            test  score: 0.9729599518217406 with variance: 0.0005068219439931364\n",
      "          Refitted train score: 0.9852216748768473,  RMSE: 0.12156613477096616, Log-Loss:0.5104272363716618\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9802394387677292 using:linear,1,15\n",
      "            train score: 0.9900736495971387 with variance: 5.415558541788043e-06\n",
      "            test  score: 0.9802394387677292 with variance: 0.00015285247452513935\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "        accuracy\n",
      "          CV score: 0.9803372478169227 using:linear,1,15\n",
      "            train score: 0.9901481481481481 with variance: 5.294892086914916e-06\n",
      "            test  score: 0.9803372478169227 with variance: 0.00015542239801266498\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9849351461165806 using:linear,1,25\n",
      "            train score: 0.9931811626252331 with variance: 5.3581982965636474e-06\n",
      "            test  score: 0.9849351461165806 with variance: 0.00015447795809046737\n",
      "          Refitted train score: 0.9925558312655086,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9462365591397849,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "        accuracy\n",
      "          CV score: 0.9852152965974103 using:linear,1,25\n",
      "            train score: 0.9932269705603038 with variance: 5.29715758079168e-06\n",
      "            test  score: 0.9852152965974103 with variance: 0.0001464714837853993\n",
      "          Refitted train score: 0.9926108374384236,  RMSE: 0.08596023825918792, Log-Loss:0.25521263345993206\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656865857951447\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.977465228942022 using:linear,1,50\n",
      "            train score: 0.9987692307692309 with variance: 2.2721893491124426e-06\n",
      "            test  score: 0.977465228942022 with variance: 0.00014952328487605166\n",
      "          Refitted train score: 0.9975308641975309,  RMSE: 0.049629166698546515, Log-Loss:0.08507087781997805\n",
      "          Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "        accuracy\n",
      "          CV score: 0.977807889190003 using:linear,1,50\n",
      "            train score: 0.9987692307692309 with variance: 2.2721893491124426e-06\n",
      "            test  score: 0.977807889190003 with variance: 0.00014691757878132846\n",
      "          Refitted train score: 0.9975369458128078,  RMSE: 0.049629166698546515, Log-Loss:0.08507087781997805\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "      ncomponents: 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9851211698474227 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9851211698474227 with variance: 8.512651732091637e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706541\n",
      "        accuracy\n",
      "          CV score: 0.9852152965974103 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9852152965974103 with variance: 8.550516767504983e-05\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706541\n",
      "    random state: 1250\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9433527003147256 using:linear,1,2\n",
      "            train score: 0.9413540472569686 with variance: 0.00029991826824178874\n",
      "            test  score: 0.9433527003147256 with variance: 0.0009691571388685642\n",
      "          Refitted train score: 0.9538461538461539,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "        accuracy\n",
      "          CV score: 0.9439467705290492 using:linear,1,2\n",
      "            train score: 0.941332085224151 with variance: 0.00030331166566622224\n",
      "            test  score: 0.9439467705290492 with variance: 0.000939678975989725\n",
      "          Refitted train score: 0.9540816326530612,  RMSE: 0.2142857142857143, Log-Loss:1.5859805405301892\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627561843797202\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9571804368471035 using:linear,1,3\n",
      "            train score: 0.9502460036737623 with variance: 0.0001056776229020726\n",
      "            test  score: 0.9571804368471035 with variance: 0.0005110006177799791\n",
      "          Refitted train score: 0.8977556109725686,  RMSE: 0.3234066120763363, Log-Loss:3.612525056446666\n",
      "          Refitted test  score: 0.9622641509433962,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9567023693605972 using:linear,1,3\n",
      "            train score: 0.9496225148043385 with variance: 0.00011526001069883025\n",
      "            test  score: 0.9567023693605972 with variance: 0.0005469693584270886\n",
      "          Refitted train score: 0.8954081632653061,  RMSE: 0.3234066120763363, Log-Loss:3.612525056446666\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9639420386409061 using:rbf,1,5\n",
      "            train score: 0.9652932638406698 with variance: 3.0835813105193966e-05\n",
      "            test  score: 0.9639420386409061 with variance: 0.0007308861895755916\n",
      "          Refitted train score: 0.9665809768637533,  RMSE: 0.1821078397711709, Log-Loss:1.145428803880077\n",
      "          Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "        accuracy\n",
      "          CV score: 0.9643297630639402 using:rbf,1,5\n",
      "            train score: 0.9655623613683076 with variance: 3.0104861519687206e-05\n",
      "            test  score: 0.9643297630639402 with variance: 0.0007351693605129323\n",
      "          Refitted train score: 0.9668367346938775,  RMSE: 0.1821078397711709, Log-Loss:1.145428803880077\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.968530961341088 using:rbf,1.5,10\n",
      "            train score: 0.9758308559688338 with variance: 3.836475405585222e-05\n",
      "            test  score: 0.968530961341088 with variance: 0.0007152214190918476\n",
      "          Refitted train score: 0.9738219895287958,  RMSE: 0.15971914124998499, Log-Loss:0.8810912345640489\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9693930542031808 using:rbf,1.5,10\n",
      "            train score: 0.9764046315703793 with variance: 3.4922344337698534e-05\n",
      "            test  score: 0.9693930542031808 with variance: 0.000686196275167471\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810912345640489\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9661891891891893 using:rbf,1.5,15\n",
      "            train score: 0.976486389627168 with variance: 4.639552992415514e-05\n",
      "            test  score: 0.9661891891891893 with variance: 0.0008861972242512766\n",
      "          Refitted train score: 0.9765013054830287,  RMSE: 0.15152288168283162, Log-Loss:0.7929821111076442\n",
      "          Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "        accuracy\n",
      "          CV score: 0.9668614086335605 using:rbf,1,15\n",
      "            train score: 0.9751287112594372 with variance: 3.824077000223266e-05\n",
      "            test  score: 0.9668614086335605 with variance: 0.0008773227793848251\n",
      "          Refitted train score: 0.9744897959183674,  RMSE: 0.15971914124998499, Log-Loss:0.8810912345640489\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9714804318488529 using:linear,1.5,25\n",
      "            train score: 0.9948593880513601 with variance: 1.0768739571085928e-05\n",
      "            test  score: 0.9714804318488529 with variance: 0.0002961081443357153\n",
      "          Refitted train score: 0.9948717948717948,  RMSE: 0.07142857142857142, Log-Loss:0.1762182469128106\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "        accuracy\n",
      "          CV score: 0.9719896137617656 using:linear,1.5,25\n",
      "            train score: 0.9948942837956085 with variance: 1.0613068563172843e-05\n",
      "            test  score: 0.9719896137617656 with variance: 0.00028369161915314556\n",
      "          Refitted train score: 0.9948979591836735,  RMSE: 0.07142857142857142, Log-Loss:0.1762182469128106\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9766856283844959 using:linear,1,50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9766856283844959 with variance: 0.00029146428961335425\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "        accuracy\n",
      "          CV score: 0.9770853618954884 using:linear,1,50\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9770853618954884 with variance: 0.0002826887285738809\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9763310945855916 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9763310945855916 with variance: 0.00045107054160216343\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9814814814814815,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "        accuracy\n",
      "          CV score: 0.9770204479065239 using:linear,1,100\n",
      "            train score: 1.0 with variance: 0.0\n",
      "            test  score: 0.9770204479065239 with variance: 0.00041781769956495443\n",
      "          Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "    random state: 1850\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9500855482244454 using:rbf,1.5,2\n",
      "            train score: 0.9489239996372285 with variance: 6.668801590273789e-05\n",
      "            test  score: 0.9500855482244454 with variance: 0.0004501343147451216\n",
      "          Refitted train score: 0.9523809523809524,  RMSE: 0.21527067476698758, Log-Loss:1.6005852436415222\n",
      "          Refitted test  score: 0.9397590361445783,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "        accuracy\n",
      "          CV score: 0.9512195121951219 using:rbf,1.5,2\n",
      "            train score: 0.95 with variance: 6.171921475312263e-05\n",
      "            test  score: 0.9512195121951219 with variance: 0.00041641879833432453\n",
      "          Refitted train score: 0.9536585365853658,  RMSE: 0.21527067476698758, Log-Loss:1.6005852436415222\n",
      "          Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "      ncomponents: 3\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9628188537626288 using:linear,1,3\n",
      "            train score: 0.9666738643532454 with variance: 3.9296799788045224e-05\n",
      "            test  score: 0.9628188537626288 with variance: 0.000299158447011999\n",
      "          Refitted train score: 0.9516908212560385,  RMSE: 0.2208630521496931, Log-Loss:1.6848417635789668\n",
      "          Refitted test  score: 0.9545454545454546,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "        accuracy\n",
      "          CV score: 0.9634146341463413 using:linear,1,3\n",
      "            train score: 0.9670731707317073 with variance: 3.8667459845330225e-05\n",
      "            test  score: 0.9634146341463413 with variance: 0.00029744199881023256\n",
      "          Refitted train score: 0.9512195121951219,  RMSE: 0.2208630521496931, Log-Loss:1.6848417635789668\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125487765761587\n",
      "      ncomponents: 5\n",
      "        f1\n",
      "          CV score: 0.9694871794871794 using:rbf,1,5\n",
      "            train score: 0.971119796833459 with variance: 2.2742280669424954e-05\n",
      "            test  score: 0.9694871794871794 with variance: 0.0003709072978303735\n",
      "          Refitted train score: 0.9724310776942355,  RMSE: 0.16379642332078845, Log-Loss:0.9266500984000436\n",
      "          Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        accuracy\n",
      "          CV score: 0.9707317073170731 using:rbf,1,5\n",
      "            train score: 0.9719512195121951 with variance: 2.0077334919690696e-05\n",
      "            test  score: 0.9707317073170731 with variance: 0.00033313503866746043\n",
      "          Refitted train score: 0.973170731707317,  RMSE: 0.16379642332078845, Log-Loss:0.9266500984000436\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.9774050632911393 using:rbf,1.5,10\n",
      "            train score: 0.9788158718310465 with variance: 1.3862331223569873e-05\n",
      "            test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "          Refitted train score: 0.9775561097256857,  RMSE: 0.14815943949743843, Log-Loss:0.7581682623273086\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:rbf,1.5,10\n",
      "            train score: 0.9792682926829268 with variance: 1.2641284949434882e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "          Refitted train score: 0.9780487804878049,  RMSE: 0.14815943949743843, Log-Loss:0.7581682623273086\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9849359274886702 using:linear,1,15\n",
      "            train score: 0.9901347473891174 with variance: 1.3181821737145392e-05\n",
      "            test  score: 0.9849359274886702 with variance: 0.0002169721954865719\n",
      "          Refitted train score: 0.9876543209876543,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9662921348314608,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706541\n",
      "        accuracy\n",
      "          CV score: 0.9853658536585366 using:linear,1,15\n",
      "            train score: 0.9902439024390244 with variance: 1.2641284949434882e-05\n",
      "            test  score: 0.9853658536585366 with variance: 0.00020226055919095814\n",
      "          Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818384\n",
      "          Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941219750706541\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.9774050632911393 using:rbf,1,25\n",
      "            train score: 0.9813546333865354 with variance: 1.208446096132382e-05\n",
      "            test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "          Refitted train score: 0.9826302729528535,  RMSE: 0.13066434376564756, Log-Loss:0.5896864262545735\n",
      "          Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:linear,1.5,25\n",
      "            train score: 0.9920731707317074 with variance: 2.4538964901844183e-05\n",
      "            test  score: 0.978048780487805 with variance: 0.0004402141582391441\n",
      "          Refitted train score: 0.9926829268292683,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "          Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.06275618437972\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9800617283950617 using:linear,1,50\n",
      "            train score: 0.998165137614679 with variance: 2.2444799820441875e-06\n",
      "            test  score: 0.9800617283950617 with variance: 0.0002884316415180602\n",
      "          Refitted train score: 0.9975550122249389,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "        accuracy\n",
      "          CV score: 0.9804878048780488 using:linear,1,50\n",
      "            train score: 0.9981707317073172 with variance: 2.2308149910767443e-06\n",
      "            test  score: 0.9804878048780488 with variance: 0.00027364663890541393\n",
      "          Refitted train score: 0.9975609756097561,  RMSE: 0.04938647983247948, Log-Loss:0.08424091803636853\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.9774050632911393 using:rbf,1,100\n",
      "            train score: 0.9832508349420894 with variance: 1.0348792300072985e-05\n",
      "            test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "          Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "        accuracy\n",
      "          CV score: 0.978048780487805 using:rbf,1,100\n",
      "            train score: 0.9835365853658538 with variance: 9.666864961332556e-06\n",
      "            test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "          Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "          Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "    random state: 2050\n",
      "      ncomponents: 2\n",
      "        f1\n",
      "          CV score: 0.9382244203258248 using:linear,0.001,2\n",
      "            train score: 0.9379787631972972 with variance: 4.551216727989476e-05\n",
      "            test  score: 0.9382244203258248 with variance: 0.0005417105804073533\n",
      "          Refitted train score: 0.9414893617021277,  RMSE: 0.23935677693908453, Log-Loss:1.9787986402865798\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "        accuracy\n",
      "          CV score: 0.9401230348598769 using:linear,0.001,2\n",
      "            train score: 0.939453868606963 with variance: 3.640079726869998e-05\n",
      "            test  score: 0.9401230348598769 with variance: 0.00044321329639889217\n",
      "          Refitted train score: 0.9427083333333334,  RMSE: 0.23935677693908453, Log-Loss:1.9787986402865798\n",
      "          Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      ncomponents: 3\n",
      "        f1\n",
      "          CV score: 0.9547142336656254 using:rbf,1,3\n",
      "            train score: 0.9558595468616952 with variance: 4.4017440560356936e-05\n",
      "            test  score: 0.9547142336656254 with variance: 0.00015926364985950384\n",
      "          Refitted train score: 0.9578947368421052,  RMSE: 0.2041241452319315, Log-Loss:1.439128176831126\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9557758031442243 using:linear,0.001,3\n",
      "            train score: 0.956381403612674 with variance: 3.6386820948798443e-05\n",
      "            test  score: 0.9557758031442243 with variance: 0.000307872147279278\n",
      "          Refitted train score: 0.9583333333333334,  RMSE: 0.2041241452319315, Log-Loss:1.4391219299762028\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        f1\n",
      "          CV score: 0.9596476968269366 using:rbf,1.5,5\n",
      "            train score: 0.9648522009515874 with variance: 1.2949996292395139e-05\n",
      "            test  score: 0.9596476968269366 with variance: 0.0002679101532337484\n",
      "          Refitted train score: 0.962962962962963,  RMSE: 0.19094065395649334, Log-Loss:1.2592345518710173\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9609706083390293 using:rbf,1.5,5\n",
      "            train score: 0.9654955793392276 with variance: 1.0976135512508002e-05\n",
      "            test  score: 0.9609706083390293 with variance: 0.00020063830115274548\n",
      "          Refitted train score: 0.9635416666666666,  RMSE: 0.19094065395649334, Log-Loss:1.2592345518710173\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 10\n",
      "        f1\n",
      "          CV score: 0.967062271062271 using:rbf,1,10\n",
      "            train score: 0.9725833388707998 with variance: 3.850018969861137e-05\n",
      "            test  score: 0.967062271062271 with variance: 0.0008715417622670366\n",
      "          Refitted train score: 0.9732620320855615,  RMSE: 0.1613743060919757, Log-Loss:0.8994473019507999\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311687 using:rbf,1,10\n",
      "            train score: 0.9733110537670798 with variance: 3.540400470169117e-05\n",
      "            test  score: 0.9688311688311687 with variance: 0.000715129026817339\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.1613743060919757, Log-Loss:0.8994473019507999\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 15\n",
      "        f1\n",
      "          CV score: 0.9697991131675343 using:rbf,1.5,15\n",
      "            train score: 0.977407846067582 with variance: 2.414698420779353e-05\n",
      "            test  score: 0.9697991131675343 with variance: 0.0008628463394995921\n",
      "          Refitted train score: 0.9788359788359788,  RMSE: 0.14433756729740643, Log-Loss:0.7195599238456145\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285713 using:rbf,1.5,15\n",
      "            train score: 0.9778670840560091 with variance: 2.2786877436752824e-05\n",
      "            test  score: 0.9714285714285713 with variance: 0.0007016360263113515\n",
      "          Refitted train score: 0.9791666666666666,  RMSE: 0.14433756729740643, Log-Loss:0.7195599238456145\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 25\n",
      "        f1\n",
      "          CV score: 0.967062271062271 using:rbf,1,25\n",
      "            train score: 0.9732299386478344 with variance: 3.252111692929779e-05\n",
      "            test  score: 0.967062271062271 with variance: 0.0008715417622670366\n",
      "          Refitted train score: 0.9732620320855615,  RMSE: 0.1613743060919757, Log-Loss:0.8994473019507999\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311687 using:rbf,1,25\n",
      "            train score: 0.9739625195651254 with variance: 2.9434738156715585e-05\n",
      "            test  score: 0.9688311688311687 with variance: 0.000715129026817339\n",
      "          Refitted train score: 0.9739583333333334,  RMSE: 0.1613743060919757, Log-Loss:0.8994473019507999\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      ncomponents: 50\n",
      "        f1\n",
      "          CV score: 0.9719377573518522 using:linear,1,50\n",
      "            train score: 0.9980413306989908 with variance: 2.5576511177716315e-06\n",
      "            test  score: 0.9719377573518522 with variance: 0.00044312771927672344\n",
      "          Refitted train score: 0.9973890339425587,  RMSE: 0.05103103630798288, Log-Loss:0.08994473019508088\n",
      "          Refitted test  score: 0.9913043478260869,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "        accuracy\n",
      "          CV score: 0.9714285714285715 using:linear,1,50\n",
      "            train score: 0.998047717754558 with variance: 2.5409522234250156e-06\n",
      "            test  score: 0.9714285714285715 with variance: 0.0004992410187215385\n",
      "          Refitted train score: 0.9973958333333334,  RMSE: 0.05103103630798288, Log-Loss:0.08994473019508088\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898607\n",
      "      ncomponents: 100\n",
      "        f1\n",
      "          CV score: 0.967062271062271 using:rbf,1,100\n",
      "            train score: 0.9786927616934535 with variance: 3.924291237038885e-05\n",
      "            test  score: 0.967062271062271 with variance: 0.0008715417622670366\n",
      "          Refitted train score: 0.9787234042553191,  RMSE: 0.14433756729740643, Log-Loss:0.71955784156064\n",
      "          Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "        accuracy\n",
      "          CV score: 0.9688311688311687 using:rbf,1,100\n",
      "            train score: 0.9791700156521003 with variance: 3.632382908445367e-05\n",
      "            test  score: 0.9688311688311687 with variance: 0.000715129026817339\n",
      "          Refitted train score: 0.9791666666666666,  RMSE: 0.14433756729740643, Log-Loss:0.71955784156064\n",
      "          Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#svc\n",
    "kernels = ['linear', 'rbf']\n",
    "C = [0.001, 1, 1.5]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "    print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        \n",
    "    for ncomponents in ncomponentss:\n",
    "        print(tab * 3 + f\"ncomponents: {ncomponents}\")\n",
    "\n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "                     \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        pca = PCA(n_components = ncomponents)        \n",
    "        pca.fit(X_train)\n",
    "        X_train = pca.transform(X_train)\n",
    "        X_test  = pca.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for kernel in kernels:\n",
    "            for c in C:\n",
    "                    \n",
    "                svc = SVC(kernel = kernel, C = c, max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "                cv_results = cross_validate(svc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "\n",
    "                for score in scores:\n",
    "                    avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                    var_score_test = np.var(cv_results['test_' + score])\n",
    "                    avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                    var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                    if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                        best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, kernel, c, ncomponents]\n",
    "\n",
    "\n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 4 + str(score))\n",
    "            print(tab * 5 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 6 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 6 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            svc = SVC(kernel = best_avg_scores[score][4], C = best_avg_scores[score][5], max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "            \n",
    "            svc.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = svc.predict(X_train), svc.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(svc, X_train, y_train), get_scorer(score)(svc, X_test, y_test)\n",
    "            \n",
    "            print(tab * 5 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 5 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")            \n",
    "            \n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/pca/SVC\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "945c51ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2683</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.973963</td>\n",
       "      <td>0.000715129</td>\n",
       "      <td>2.94347e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.161374</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.899447</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/SVC</td>\n",
       "      <td>rbf,1,25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2684</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.971938</td>\n",
       "      <td>0.998041</td>\n",
       "      <td>0.000443128</td>\n",
       "      <td>2.55765e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>0.531378</td>\n",
       "      <td>0.0899447</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/SVC</td>\n",
       "      <td>linear,1,50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2685</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.971429</td>\n",
       "      <td>0.998048</td>\n",
       "      <td>0.000499241</td>\n",
       "      <td>2.54095e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.051031</td>\n",
       "      <td>0.531378</td>\n",
       "      <td>0.0899447</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/SVC</td>\n",
       "      <td>linear,1,50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.967062</td>\n",
       "      <td>0.978693</td>\n",
       "      <td>0.000871542</td>\n",
       "      <td>3.92429e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.719558</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/SVC</td>\n",
       "      <td>rbf,1,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.968831</td>\n",
       "      <td>0.97917</td>\n",
       "      <td>0.000715129</td>\n",
       "      <td>3.63238e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.719558</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/pca/SVC</td>\n",
       "      <td>rbf,1,100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         score test score train score test variance train variance test rmse  \\\n",
       "2683  accuracy   0.968831    0.973963   0.000715129    2.94347e-05  0.124035   \n",
       "2684        f1   0.971938    0.998041   0.000443128    2.55765e-06  0.124035   \n",
       "2685  accuracy   0.971429    0.998048   0.000499241    2.54095e-06  0.124035   \n",
       "2686        f1   0.967062    0.978693   0.000871542    3.92429e-05  0.124035   \n",
       "2687  accuracy   0.968831     0.97917   0.000715129    3.63238e-05  0.124035   \n",
       "\n",
       "     train rmse test log_loss train log_loss test size random state  \\\n",
       "2683   0.161374      0.531366       0.899447       0.2         2050   \n",
       "2684   0.051031      0.531378      0.0899447       0.2         2050   \n",
       "2685   0.051031      0.531378      0.0899447       0.2         2050   \n",
       "2686   0.144338      0.531366       0.719558       0.2         2050   \n",
       "2687   0.144338      0.531366       0.719558       0.2         2050   \n",
       "\n",
       "          estimator estimator params  \n",
       "2683  Smote/pca/SVC         rbf,1,25  \n",
       "2684  Smote/pca/SVC      linear,1,50  \n",
       "2685  Smote/pca/SVC      linear,1,50  \n",
       "2686  Smote/pca/SVC        rbf,1,100  \n",
       "2687  Smote/pca/SVC        rbf,1,100  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c1a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(path + \"classification-results-3-pca.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "classification-7 (17.6.22).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
