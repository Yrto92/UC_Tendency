{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32e90fa",
   "metadata": {
    "id": "c32e90fa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import random\n",
    "import math\n",
    "\n",
    "from numpy import mean, std\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,  cross_val_score, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import get_scorer, make_scorer, confusion_matrix, classification_report, recall_score, precision_score, accuracy_score, fbeta_score, roc_curve, roc_auc_score, f1_score, confusion_matrix, mean_squared_error, log_loss\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from warnings import simplefilter\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "simplefilter(\"ignore\", category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vxMsA1bZQENI",
   "metadata": {
    "id": "vxMsA1bZQENI"
   },
   "outputs": [],
   "source": [
    "class KidronClassifier:\n",
    "    \n",
    "    def __init__(self, min_rows = None, min_columns = None, max_estimators = None, estimators = None, base_estimator = None, random_state = None):\n",
    "\n",
    "        self.min_rows = min_rows\n",
    "        self.min_columns = min_columns\n",
    "        self.max_estimators = max_estimators\n",
    "        self.estimators = estimators\n",
    "        self.base_estimator = base_estimator \n",
    "        self.random_state = random_state \n",
    "        #self.fitted_estimators = None\n",
    "        #self.fitted_columns = None        \n",
    "        return\n",
    "             \n",
    "    def get_params(self, deep = True):\n",
    "        return {\"min_rows\": self.min_rows, \n",
    "                \"min_columns\": self.min_columns,\n",
    "                \"max_estimators\": self.max_estimators,\n",
    "                \"estimators\": self.estimators,\n",
    "                \"base_estimator\": self.base_estimator,\n",
    "                \"random_state\": self.random_state}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    #build training data for a single model\n",
    "    def even_data(self, dict_X, length, width, seed):     \n",
    "        \n",
    "        labels = dict_X.keys()          \n",
    "        X = pd.concat([dict_X[label].sample(n = length, random_state = seed) for label in labels]) #length\n",
    "        \n",
    "        random.seed(seed)\n",
    "        columns = random.sample(range(len(X.columns)), width)\n",
    "        X = X.iloc[:, columns]\n",
    "        \n",
    "        y = []\n",
    "        for label in labels:\n",
    "            y.extend([label] * length)\n",
    "        \n",
    "        return X, y, columns\n",
    "\n",
    "    #fit \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #label encoding\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(y)\n",
    "        \n",
    "        #X = pd.DataFrame(X)\n",
    "        \n",
    "        length = X.shape[0] #len(X);\n",
    "        width  = X.shape[1] #len(X.columns)\n",
    "        col = min([int(width  ** 0.5) + 1, width])\n",
    "        row = min([int(length ** 0.5) + 1, length])            \n",
    "        estimators = row * col\n",
    "        \n",
    "        if(self.max_estimators):\n",
    "            estimators = min([estimators, self.max_estimators])\n",
    "            \n",
    "        if(self.estimators is None):\n",
    "            if(self.base_estimator):\n",
    "                self.estimators = [clone(self.base_estimator) for i in range(estimators)]\n",
    "            else:\n",
    "                self.estimators = [LogisticRegression() for i in range(estimators)]  #default\n",
    "                                \n",
    "        dict_X = {}\n",
    "        for label in self.le.classes_:\n",
    "            dict_X[label] = X[y == label]\n",
    "            \n",
    "        rows = min([len(dict_X[label]) for label in dict_X.keys()])  #maximal length available  \n",
    "        rows = min(row, length)\n",
    "        if(self.min_rows):\n",
    "            rows = max([self.min_rows, rows])\n",
    "            \n",
    "        cols = col\n",
    "        if(self.min_columns):\n",
    "            cols = max([self.min_columns, cols])\n",
    "        \n",
    "        seed, self.fitted_estimators, self.fitted_columns = 0, [], []\n",
    "        #print(len(self.estimators))\n",
    "        \n",
    "        for estimator in self.estimators:\n",
    "\n",
    "            #get a balanced data\n",
    "            X_train, y_train, fitted_columns = self.even_data(dict_X, rows, cols, seed)\n",
    "            \n",
    "            #fit\n",
    "            fitted_estimator = estimator.fit(X_train, y_train)\n",
    "            \n",
    "            #save fitted\n",
    "            self.fitted_estimators.append(fitted_estimator)\n",
    "            self.fitted_columns.append(fitted_columns)\n",
    "            \n",
    "            seed += 1\n",
    "        return\n",
    "    \n",
    "    #predict_proba\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        length = len(X)\n",
    "        labels = len(self.le.classes_)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        # Predict 'soft' voting with probabilities\n",
    "        predict_proba = []\n",
    "        for fitted_estimator, fitted_columns in zip(self.fitted_estimators, self.fitted_columns):             \n",
    "            fitted_X = X.iloc[:, fitted_columns]\n",
    "            predict_proba.append(np.asarray(fitted_estimator.predict_proba(fitted_X)).reshape(length * labels, 1))\n",
    "            \n",
    "        predict_proba = np.concatenate(predict_proba, axis = 1)\n",
    "        predict_proba = np.average(predict_proba, axis = 1).reshape(length, labels)\n",
    "            \n",
    "        # Convert integer predictions to original labels:\n",
    "        return predict_proba\n",
    "    \n",
    "    #predict\n",
    "    def predict(self, X):\n",
    "            \n",
    "        proba = self.predict_proba(X)\n",
    "        \n",
    "        # Convert integer predictions to original labels:\n",
    "        return self.le.inverse_transform(np.argmax(proba, axis = 1))\n",
    "    \n",
    "    #predict, old slow version\n",
    "    def predict_slow(self, X):\n",
    "\n",
    "        pred = []\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            # Predict 'soft' voting with probabilities\n",
    "            x = X[i : i + 1]\n",
    "            predict_proba = np.asarray([estimator.predict_proba(x) for estimator in self.fitted_estimators])\n",
    "            predict_proba = np.average(predict_proba, axis = 0)\n",
    "        \n",
    "            #the indice of the average\n",
    "            pred.append(np.argmax(predict_proba, axis = 1)[0])        \n",
    "\n",
    "        # Convert integer predictions to original labels:\n",
    "        return self.le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e97763",
   "metadata": {
    "id": "b4e97763"
   },
   "outputs": [],
   "source": [
    "path = \"/Users/yaeerk/Documents/NAYA/classification/\"\n",
    "jobs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be32050a",
   "metadata": {
    "id": "be32050a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'PROTECT_and_RISK_shared_DEGs_NOT NORM.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40272eb6",
   "metadata": {
    "id": "40272eb6"
   },
   "outputs": [],
   "source": [
    "X = df.drop('Diagnosis', axis = 1)\n",
    "y = df.Diagnosis\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "numerical_cols = X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa04d5bd",
   "metadata": {
    "id": "aa04d5bd"
   },
   "outputs": [],
   "source": [
    "tab = \"  \"\n",
    "testsizes = [0.08, 0.1, 0.15, 0.2]\n",
    "#randomstates = [132, 400, 1440, 1600, 2500, 3333, 4567]\n",
    "randomstates = [250, 650, 850, 1050, 1250, 1850, 2050]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44b49851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score, test score, train score, test variance, train variance, test rmse, train rmse, test log_loss, train log_loss, test size, random state, estimator, estimator params]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging parameters\n",
    "n_estimators = [2, 10, 20, 30]\n",
    "max_samples = [0.6, 0.8, 1.0]\n",
    "bootstrap = [True, False]\n",
    "bootstrap_features = [True, False]\n",
    "\n",
    "#cross validation\n",
    "cv = 5\n",
    "\n",
    "#scores we want\n",
    "scores = ['f1', 'accuracy', 'f2']\n",
    "\n",
    "results = pd.DataFrame(columns = [\"score\", \"test score\", \"train score\", \"test variance\", \"train variance\", \"test rmse\", \"train rmse\", \"test log_loss\", \"train log_loss\", \"test size\", \"random state\", \"estimator\", \"estimator params\"])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9b845754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9773180459387356 using:10,3\n",
      "          train score: 0.9934004809337067 with variance: 4.900485401730748e-06\n",
      "          test  score: 0.9773180459387356 with variance: 0.0003723410952958266\n",
      "        Refitted train score: 0.9934065934065934,  RMSE: 0.08093341918275387, Log-Loss:0.22623652660421945\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9780936454849499 using:10,3\n",
      "          train score: 0.9934470898289185 with variance: 4.795623726079488e-06\n",
      "          test  score: 0.9780936454849499 with variance: 0.00033865758247236897\n",
      "        Refitted train score: 0.9934497816593887,  RMSE: 0.08093341918275387, Log-Loss:0.22623652660421945\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9752685184053371 using:10,3\n",
      "          train score: 0.9945533382166358 with variance: 5.971925030038383e-06\n",
      "          test  score: 0.9752685184053371 with variance: 0.00029374966102582256\n",
      "        Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "        Refitted test  score: 0.9714285714285714,  RMSE: 0.19611613513818404, Log-Loss:1.3284144767273351\n",
      "      accuracy\n",
      "        CV score: 0.9762272089761572 using:10,3\n",
      "          train score: 0.9945901999560535 with variance: 5.8357975856676976e-06\n",
      "          test  score: 0.9762272089761572 with variance: 0.00024874538857492113\n",
      "        Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284144767273351\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9777207022368313 using:10,3\n",
      "          train score: 0.9929124965716911 with variance: 1.8212582381385604e-06\n",
      "          test  score: 0.9777207022368313 with variance: 0.0002561105768896251\n",
      "        Refitted train score: 0.9934640522875817,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.978354371201496 using:10,3\n",
      "          train score: 0.9929656485754046 with variance: 1.7531902906868005e-06\n",
      "          test  score: 0.978354371201496 with variance: 0.0002352971518282539\n",
      "        Refitted train score: 0.9935064935064936,  RMSE: 0.08058229640253803, Log-Loss:0.2242777687981223\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9779215898903246 using:10,10\n",
      "          train score: 0.9829382236715236 with variance: 1.2355319620891538e-06\n",
      "          test  score: 0.9779215898903246 with variance: 9.99741978216979e-05\n",
      "        Refitted train score: 0.9868421052631579,  RMSE: 0.11396057645963795, Log-Loss:0.44855553759624356\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9783777466105656 using:10,10\n",
      "          train score: 0.9832256646890795 with variance: 1.1501959698818652e-06\n",
      "          test  score: 0.9783777466105656 with variance: 9.301533160186973e-05\n",
      "        Refitted train score: 0.987012987012987,  RMSE: 0.11396057645963795, Log-Loss:0.44855553759624356\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9750628207524856 using:10,3\n",
      "          train score: 0.9933425157863688 with variance: 4.959020630667379e-06\n",
      "          test  score: 0.9750628207524856 with variance: 0.00023587117566890528\n",
      "        Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9758241758241759 using:10,3\n",
      "          train score: 0.9933929706656979 with variance: 4.842055766338022e-06\n",
      "          test  score: 0.9758241758241759 with variance: 0.00021253471802922308\n",
      "        Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9775741112819765 using:10,3\n",
      "          train score: 0.9933487056790955 with variance: 1.834880045229328e-06\n",
      "          test  score: 0.9775741112819765 with variance: 0.00014830017282873136\n",
      "        Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637116\n",
      "        Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9780219780219781 using:10,3\n",
      "          train score: 0.9933929706656979 with variance: 1.8064404091600394e-06\n",
      "          test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "        Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637116\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9725032381690928 using:10,3\n",
      "          train score: 0.9933425157863688 with variance: 4.959020630667379e-06\n",
      "          test  score: 0.9725032381690928 with variance: 0.00035962879646631393\n",
      "        Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9736263736263737 using:10,3\n",
      "          train score: 0.9933929706656979 with variance: 4.842055766338021e-06\n",
      "          test  score: 0.9736263736263737 with variance: 0.0003188020770438349\n",
      "        Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.22822979996637113\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9718437805558704 using:10,3\n",
      "          train score: 0.9932520349393987 with variance: 5.124866270956944e-06\n",
      "          test  score: 0.9718437805558704 with variance: 0.000858279794343276\n",
      "        Refitted train score: 0.9932584269662922,  RMSE: 0.08183170883849714, Log-Loss:0.2312864490730636\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9731335830212234 using:10,3\n",
      "          train score: 0.9933007578469055 with variance: 5.012766606091223e-06\n",
      "          test  score: 0.9731335830212234 with variance: 0.0007381933631649568\n",
      "        Refitted train score: 0.9933035714285714,  RMSE: 0.08183170883849714, Log-Loss:0.2312864490730636\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9772198936282624 using:10,10\n",
      "          train score: 0.9847664160548895 with variance: 5.226188259606315e-06\n",
      "          test  score: 0.9772198936282624 with variance: 5.404557468767175e-05\n",
      "        Refitted train score: 0.9864864864864865,  RMSE: 0.11547005383792516, Log-Loss:0.46051701859881\n",
      "        Refitted test  score: 0.9787234042553191,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9777777777777779 using:10,3\n",
      "          train score: 0.9955555555555555 with variance: 1.8518518518518385e-06\n",
      "          test  score: 0.9777777777777779 with variance: 0.00014814814814814806\n",
      "        Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627068\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.977096432978786 using:10,3\n",
      "          train score: 0.9933455850838113 with variance: 1.8796619299333878e-06\n",
      "          test  score: 0.977096432978786 with variance: 0.0004881389778499591\n",
      "        Refitted train score: 0.9933481152993348,  RMSE: 0.08128917219051073, Log-Loss:0.2282297999663711\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.977973137973138 using:10,3\n",
      "          train score: 0.9933914570278206 with variance: 1.8280775540045403e-06\n",
      "          test  score: 0.977973137973138 with variance: 0.0004347396464612585\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9933920704845814,  RMSE: 0.08128917219051073, Log-Loss:0.2282297999663711\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9734119336369027 using:10,10\n",
      "          train score: 0.9860350146812433 with variance: 1.5780569271654763e-05\n",
      "          test  score: 0.9734119336369027 with variance: 0.0002582524766246141\n",
      "        Refitted train score: 0.9820627802690582,  RMSE: 0.1327446623199944, Log-Loss:0.6086127999103214\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9736019536019537 using:10,10\n",
      "          train score: 0.9862364907819453 with variance: 1.506177140460222e-05\n",
      "          test  score: 0.9736019536019537 with variance: 0.000269749732020795\n",
      "        Refitted train score: 0.9823788546255506,  RMSE: 0.1327446623199944, Log-Loss:0.6086127999103214\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9771112893165821 using:10,3\n",
      "          train score: 0.9926569046004069 with variance: 5.122066497680635e-06\n",
      "          test  score: 0.9771112893165821 with variance: 0.00015866318871450422\n",
      "        Refitted train score: 0.9932279909706546,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751675\n",
      "        Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9775780274656679 using:10,3\n",
      "          train score: 0.9927123658452146 with variance: 5.032284888924031e-06\n",
      "          test  score: 0.9775780274656679 with variance: 0.00015150599827618697\n",
      "        Refitted train score: 0.9932735426008968,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751675\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9792022065077399 using:10,3\n",
      "          train score: 0.9932266599297808 with variance: 1.929986708258804e-06\n",
      "          test  score: 0.9792022065077399 with variance: 0.0002380140234408131\n",
      "        Refitted train score: 0.9932279909706546,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751684\n",
      "        Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9798751560549313 using:10,3\n",
      "          train score: 0.9932741635980236 with variance: 1.8760929741539203e-06\n",
      "          test  score: 0.9798751560549313 with variance: 0.00021729641942577977\n",
      "        Refitted train score: 0.9932735426008968,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751684\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9738935574229692 using:10,3\n",
      "          train score: 0.9931297491641331 with variance: 5.288240518184503e-06\n",
      "          test  score: 0.9738935574229692 with variance: 0.0004746180825271294\n",
      "        Refitted train score: 0.9931350114416476,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802837\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.975 using:10,3\n",
      "          train score: 0.9931818181818182 with variance: 5.1652892561984136e-06\n",
      "          test  score: 0.975 with variance: 0.0004338842975206604\n",
      "        Refitted train score: 0.9931818181818182,  RMSE: 0.08257228238447704, Log-Loss:0.23549165723802837\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9754188181296615 using:10,3\n",
      "          train score: 0.9922742162202075 with variance: 2.138986714918764e-06\n",
      "          test  score: 0.9754188181296615 with variance: 0.0006922077622842827\n",
      "        Refitted train score: 0.9928741092636578,  RMSE: 0.08411582311380664, Log-Loss:0.24437813486965207\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9764425770308124 using:10,3\n",
      "          train score: 0.9923338538955406 with variance: 2.1007239846335178e-06\n",
      "          test  score: 0.9764425770308124 with variance: 0.000608340591138416\n",
      "        Refitted train score: 0.9929245283018868,  RMSE: 0.08411582311380664, Log-Loss:0.24437813486965207\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9784846950828523 using:10,10\n",
      "          train score: 0.9863710006467858 with variance: 9.42267874388448e-06\n",
      "          test  score: 0.9784846950828523 with variance: 8.184858293474876e-05\n",
      "        Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "      accuracy\n",
      "        CV score: 0.9789876880984952 using:10,10\n",
      "          train score: 0.986566757028626 with variance: 8.832267317758555e-06\n",
      "          test  score: 0.9789876880984952 with variance: 7.547407089963512e-05\n",
      "        Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9780071052811369 using:10,3\n",
      "          train score: 0.9929027960103325 with variance: 2.1718729551216582e-06\n",
      "          test  score: 0.9780071052811369 with variance: 0.0002763497271160031\n",
      "        Refitted train score: 0.9929078014184397,  RMSE: 0.08391813582966891, Log-Loss:0.24323081968247054\n",
      "        Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "      accuracy\n",
      "        CV score: 0.9788782489740082 using:10,3\n",
      "          train score: 0.9929584267724685 with variance: 2.0559193665482076e-06\n",
      "          test  score: 0.9788782489740082 with variance: 0.00024335308901660192\n",
      "        Refitted train score: 0.9929577464788732,  RMSE: 0.08391813582966891, Log-Loss:0.24323081968247054\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9738355101076575 using:10,10\n",
      "          train score: 0.9817247139731421 with variance: 1.5579922700874813e-05\n",
      "          test  score: 0.9738355101076575 with variance: 8.027955557313622e-05\n",
      "        Refitted train score: 0.9811320754716981,  RMSE: 0.13608276348795434, Log-Loss:0.6396069702761247\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9745522587543437 using:10,10\n",
      "          train score: 0.9820641702270253 with variance: 1.4605061707021445e-05\n",
      "          test  score: 0.9745522587543437 with variance: 7.450189105729317e-05\n",
      "        Refitted train score: 0.9814814814814815,  RMSE: 0.13608276348795434, Log-Loss:0.6396069702761247\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9755452316427926 using:10,3\n",
      "          train score: 0.9934041718901849 with variance: 5.084655321476595e-06\n",
      "          test  score: 0.9755452316427926 with variance: 0.00018301663391981831\n",
      "        Refitted train score: 0.9928057553956835,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9761904761904763 using:10,3\n",
      "          train score: 0.993452380952381 with variance: 4.960317460317425e-06\n",
      "          test  score: 0.9761904761904763 with variance: 0.0001700680272108842\n",
      "        Refitted train score: 0.9928571428571429,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9810644257703082 using:10,3\n",
      "          train score: 0.9929411459390804 with variance: 2.0765017251219157e-06\n",
      "          test  score: 0.9810644257703082 with variance: 0.0001450180072028805\n",
      "        Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.2420942270671319\n",
      "        Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      accuracy\n",
      "        CV score: 0.9813406292749658 using:10,3\n",
      "          train score: 0.9929909808534942 with variance: 2.0420592576996405e-06\n",
      "          test  score: 0.9813406292749658 with variance: 0.00014113754559183747\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.2420942270671319\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9716155896069288 using:10,3\n",
      "          train score: 0.9926604471831594 with variance: 2.3141343432462886e-06\n",
      "          test  score: 0.9716155896069288 with variance: 0.0008542779608175916\n",
      "        Refitted train score: 0.9926650366748166,  RMSE: 0.08533201859828615, Log-Loss:0.25149594462313707\n",
      "        Refitted test  score: 0.9885057471264368,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.973258889215398 using:10,3\n",
      "          train score: 0.9927180620797642 with variance: 2.215156908177756e-06\n",
      "          test  score: 0.973258889215398 with variance: 0.0007359670975351553\n",
      "        Refitted train score: 0.9927184466019418,  RMSE: 0.08533201859828615, Log-Loss:0.25149594462313707\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9763499658236501 using:10,3\n",
      "          train score: 0.9924009689856359 with variance: 2.4700594732909665e-06\n",
      "          test  score: 0.9763499658236501 with variance: 0.0005824416257196755\n",
      "        Refitted train score: 0.9924050632911393,  RMSE: 0.0868198620259849, Log-Loss:0.26034253564003124\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9773417721518987 using:10,3\n",
      "          train score: 0.992460716468524 with variance: 2.393256827874985e-06\n",
      "          test  score: 0.9773417721518987 with variance: 0.0005313892004486472\n",
      "        Refitted train score: 0.992462311557789,  RMSE: 0.0868198620259849, Log-Loss:0.26034253564003124\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9771486530347289 using:10,3\n",
      "          train score: 0.9950232799443693 with variance: 2.334248381499025e-06\n",
      "          test  score: 0.9771486530347289 with variance: 0.0002249241379644529\n",
      "        Refitted train score: 0.9950248756218906,  RMSE: 0.07035975447302918, Log-Loss:0.17098404155896477\n",
      "        Refitted test  score: 0.9782608695652174,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.977746913580247 using:10,3\n",
      "          train score: 0.9950483507243053 with variance: 2.3075296887599186e-06\n",
      "          test  score: 0.977746913580247 with variance: 0.0002066796220088398\n",
      "        Refitted train score: 0.995049504950495,  RMSE: 0.07035975447302918, Log-Loss:0.17098404155896477\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9768231768231768 using:10,10\n",
      "          train score: 0.9834758359792627 with variance: 5.8297527467023495e-06\n",
      "          test  score: 0.9768231768231768 with variance: 0.000160904696369232\n",
      "        Refitted train score: 0.9847715736040609,  RMSE: 0.1224744871391589, Log-Loss:0.5180816459236612\n",
      "        Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      accuracy\n",
      "        CV score: 0.9775 using:10,10\n",
      "          train score: 0.98375 with variance: 5.468750000000155e-06\n",
      "          test  score: 0.9775 with variance: 0.00014999999999999993\n",
      "        Refitted train score: 0.985,  RMSE: 0.1224744871391589, Log-Loss:0.5180816459236612\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9748687866625503 using:10,3\n",
      "          train score: 0.9950502380798069 with variance: 2.2912127234572236e-06\n",
      "          test  score: 0.9748687866625503 with variance: 0.00012832184472946016\n",
      "        Refitted train score: 0.995049504950495,  RMSE: 0.07018624063435965, Log-Loss:0.170141755639955\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.975368864799759 using:10,3\n",
      "          train score: 0.9950750237416905 with variance: 2.265190848919892e-06\n",
      "          test  score: 0.975368864799759 with variance: 0.00012194713937503723\n",
      "        Refitted train score: 0.9950738916256158,  RMSE: 0.07018624063435965, Log-Loss:0.170141755639955\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9734736842105264 using:10,3\n",
      "          train score: 0.9916398447868213 with variance: 2.4814323395388317e-06\n",
      "          test  score: 0.9734736842105264 with variance: 0.0004903711911357326\n",
      "        Refitted train score: 0.9922879177377892,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "        Refitted test  score: 0.9906542056074767,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898605\n",
      "      accuracy\n",
      "        CV score: 0.9744888023369036 using:10,3\n",
      "          train score: 0.9917095704198123 with variance: 2.4343414712236187e-06\n",
      "          test  score: 0.9744888023369036 with variance: 0.0004536331133400145\n",
      "        Refitted train score: 0.9923469387755102,  RMSE: 0.08748177652797065, Log-Loss:0.2643273703692154\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313780921898605\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9825308641975308 using:10,3\n",
      "          train score: 0.9926267107126003 with variance: 2.3001544933467783e-06\n",
      "          test  score: 0.9825308641975308 with variance: 0.00010031245237006564\n",
      "        Refitted train score: 0.9926289926289926,  RMSE: 0.08553989227683016, Log-Loss:0.25272275410910355\n",
      "        Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.9829268292682926 using:10,3\n",
      "          train score: 0.9926829268292684 with variance: 2.2308149910767443e-06\n",
      "          test  score: 0.9829268292682926 with variance: 9.518143961927441e-05\n",
      "        Refitted train score: 0.9926829268292683,  RMSE: 0.08553989227683016, Log-Loss:0.25272275410910355\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9723299156983367 using:10,10\n",
      "          train score: 0.9813812420949833 with variance: 3.9010309799581795e-05\n",
      "          test  score: 0.9723299156983367 with variance: 0.0009115464017860675\n",
      "        Refitted train score: 0.9787234042553191,  RMSE: 0.14433756729740643, Log-Loss:0.71955784156064\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.974025974025974 using:10,10\n",
      "          train score: 0.9817716485468928 with variance: 3.6466634504189905e-05\n",
      "          test  score: 0.974025974025974 with variance: 0.0007421150278293139\n",
      "        Refitted train score: 0.9791666666666666,  RMSE: 0.14433756729740643, Log-Loss:0.71955784156064\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "max_depths = [10, 20, 30]\n",
    "min_samples_leafs = [3, 10]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        random.seed(randomstate)\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "                     \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for max_depth in max_depths:\n",
    "            for min_samples_leaf in min_samples_leafs:\n",
    "                    \n",
    "                rf = RandomForestClassifier(max_depth = max_depth, min_samples_leaf = min_samples_leaf, random_state = randomstate)\n",
    "                cv_results = cross_validate(rf, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    " \n",
    "                for score in scores:\n",
    "                    avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                    var_score_test = np.var(cv_results['test_' + score])\n",
    "                    avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                    var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                    if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                        best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, max_depth, min_samples_leaf]\n",
    "\n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 3 + str(score))\n",
    "            print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            rf = RandomForestClassifier(max_depth = best_avg_scores[score][4], min_samples_leaf = best_avg_scores[score][5], random_state = randomstate)\n",
    "            \n",
    "            rf.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = rf.predict(X_train), rf.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(rf, X_train, y_train), get_scorer(score)(rf, X_test, y_test)\n",
    "            \n",
    "            print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")\n",
    "            \n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/RandomForestClassifier\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "66745011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.974489</td>\n",
       "      <td>0.99171</td>\n",
       "      <td>0.000453633</td>\n",
       "      <td>2.43434e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0874818</td>\n",
       "      <td>0.531378</td>\n",
       "      <td>0.264327</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1250</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.982531</td>\n",
       "      <td>0.992627</td>\n",
       "      <td>0.000100312</td>\n",
       "      <td>2.30015e-06</td>\n",
       "      <td>0.214834</td>\n",
       "      <td>0.0855399</td>\n",
       "      <td>1.5941</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.992683</td>\n",
       "      <td>9.51814e-05</td>\n",
       "      <td>2.23081e-06</td>\n",
       "      <td>0.214834</td>\n",
       "      <td>0.0855399</td>\n",
       "      <td>1.5941</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.97233</td>\n",
       "      <td>0.981381</td>\n",
       "      <td>0.000911546</td>\n",
       "      <td>3.90103e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.719558</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.981772</td>\n",
       "      <td>0.000742115</td>\n",
       "      <td>3.64666e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.144338</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.719558</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score test score train score test variance train variance test rmse  \\\n",
       "51  accuracy   0.974489     0.99171   0.000453633    2.43434e-06  0.124035   \n",
       "52        f1   0.982531    0.992627   0.000100312    2.30015e-06  0.214834   \n",
       "53  accuracy   0.982927    0.992683   9.51814e-05    2.23081e-06  0.214834   \n",
       "54        f1    0.97233    0.981381   0.000911546    3.90103e-05         0   \n",
       "55  accuracy   0.974026    0.981772   0.000742115    3.64666e-05         0   \n",
       "\n",
       "   train rmse test log_loss train log_loss test size random state  \\\n",
       "51  0.0874818      0.531378       0.264327       0.2         1250   \n",
       "52  0.0855399        1.5941       0.252723       0.2         1850   \n",
       "53  0.0855399        1.5941       0.252723       0.2         1850   \n",
       "54   0.144338   9.99201e-16       0.719558       0.2         2050   \n",
       "55   0.144338   9.99201e-16       0.719558       0.2         2050   \n",
       "\n",
       "                       estimator estimator params  \n",
       "51  Smote/RandomForestClassifier             10,3  \n",
       "52  Smote/RandomForestClassifier             10,3  \n",
       "53  Smote/RandomForestClassifier             10,3  \n",
       "54  Smote/RandomForestClassifier            10,10  \n",
       "55  Smote/RandomForestClassifier            10,10  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aue3SdsInJE4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aue3SdsInJE4",
    "outputId": "f3e519a4-4a17-455a-fe97-bc41381c149b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9733546481436166 using:10,KNeighborsClassifier(),32,500\n",
      "          train score: 0.9698470197837992 with variance: 3.468482372025526e-05\n",
      "          test  score: 0.9733546481436166 with variance: 0.0007747467626388868\n",
      "        Refitted train score: 0.9686098654708519,  RMSE: 0.21674839277792138, Log-Loss:1.6226297621683892\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9595480225988702 using:10,KNeighborsClassifier(),32,500\n",
      "          train score: 0.9546886537041595 with variance: 8.087072544002419e-05\n",
      "          test  score: 0.9595480225988702 with variance: 0.0017919307989402796\n",
      "        Refitted train score: 0.9530201342281879,  RMSE: 0.21674839277792138, Log-Loss:1.6226297621683892\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9776133941483485 using:8,DecisionTreeClassifier(),30,700\n",
      "          train score: 0.9789482705841337 with variance: 4.0590175963327537e-05\n",
      "          test  score: 0.9776133941483485 with variance: 6.994273641065436e-05\n",
      "        Refitted train score: 0.9801324503311257,  RMSE: 0.17378533390904768, Log-Loss:1.043117407899988\n",
      "        Refitted test  score: 0.9714285714285714,  RMSE: 0.19611613513818404, Log-Loss:1.3284144767273351\n",
      "      accuracy\n",
      "        CV score: 0.9664406779661017 using:8,DecisionTreeClassifier(),30,700\n",
      "          train score: 0.9681305158046483 with variance: 8.800232129323266e-05\n",
      "          test  score: 0.9664406779661017 with variance: 0.00011498611510102475\n",
      "        Refitted train score: 0.959731543624161,  RMSE: 0.20067001862719533, Log-Loss:1.390823210533317\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.3284144767273351\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9757633747375314 using:8,DecisionTreeClassifier(),32,700\n",
      "          train score: 0.9789967274525473 with variance: 6.102003772598816e-05\n",
      "          test  score: 0.9757633747375314 with variance: 0.0003952363102584706\n",
      "        Refitted train score: 0.9801324503311257,  RMSE: 0.17378533390904768, Log-Loss:1.0431174078999879\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9629378531073447 using:10,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9723075841215147 with variance: 0.00015993826486876485\n",
      "          test  score: 0.9629378531073447 with variance: 0.0007370295891985061\n",
      "        Refitted train score: 0.9697986577181208,  RMSE: 0.17378533390904768, Log-Loss:1.0431174078999879\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9744482322109966 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9739947608305739 with variance: 3.7497683474045125e-05\n",
      "          test  score: 0.9744482322109966 with variance: 0.00019755245619997123\n",
      "        Refitted train score: 0.9778761061946903,  RMSE: 0.18318582636182792, Log-Loss:1.1590193421110975\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9599435028248587 using:10,DecisionTreeClassifier(),32,700\n",
      "          train score: 0.9597306705108822 with variance: 8.867103975723517e-05\n",
      "          test  score: 0.9599435028248587 with variance: 0.0012862651217721613\n",
      "        Refitted train score: 0.9630872483221476,  RMSE: 0.19212691554764613, Log-Loss:1.2749212763222073\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.97713600037471 using:10,DecisionTreeClassifier(),28,500\n",
      "          train score: 0.9774447373193714 with variance: 1.730957289362841e-05\n",
      "          test  score: 0.97713600037471 with variance: 0.00015578844233355907\n",
      "        Refitted train score: 0.9820627802690582,  RMSE: 0.16384638410380808, Log-Loss:0.9272154736888781\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9664406779661017 using:10,DecisionTreeClassifier(),28,500\n",
      "          train score: 0.9664498435357405 with variance: 3.4723439896679785e-05\n",
      "          test  score: 0.9664406779661017 with variance: 0.00033340993967250843\n",
      "        Refitted train score: 0.9630872483221476,  RMSE: 0.19212691554764613, Log-Loss:1.2749212763222073\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9758999832561255 using:8,KNeighborsClassifier(),30,500\n",
      "          train score: 0.9729470677419544 with variance: 3.1940634003695554e-05\n",
      "          test  score: 0.9758999832561255 with variance: 0.00047025444661606843\n",
      "        Refitted train score: 0.9730941704035875,  RMSE: 0.20067001862719533, Log-Loss:1.390828576959023\n",
      "        Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9665536723163843 using:8,KNeighborsClassifier(),30,500\n",
      "          train score: 0.9597447347139691 with variance: 5.943405334745181e-05\n",
      "          test  score: 0.9665536723163843 with variance: 0.0008889399597816715\n",
      "        Refitted train score: 0.959731543624161,  RMSE: 0.20067001862719533, Log-Loss:1.390828576959023\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9782533256217467 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9728396267498303 with variance: 3.0731912580899406e-05\n",
      "          test  score: 0.9782533256217467 with variance: 0.0007101461443795006\n",
      "        Refitted train score: 0.9728506787330317,  RMSE: 0.20067001862719533, Log-Loss:1.390823210533317\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9698870056497174 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9597447347139691 with variance: 6.637776220783578e-05\n",
      "          test  score: 0.9698870056497174 with variance: 0.0013785821443391098\n",
      "        Refitted train score: 0.9496644295302014,  RMSE: 0.2243559013482789, Log-Loss:1.738529013166646\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9727328850924357 using:12,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.9789313866454398 with variance: 7.855037448215719e-06\n",
      "          test  score: 0.9727328850924357 with variance: 0.0007788501762700766\n",
      "        Refitted train score: 0.9771689497716896,  RMSE: 0.18537599944001618, Log-Loss:1.1868995324711582\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9586791350087667 using:12,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.9682144442800059 with variance: 1.9070494459683642e-05\n",
      "          test  score: 0.9586791350087667 with variance: 0.001857769764930807\n",
      "        Refitted train score: 0.9725085910652921,  RMSE: 0.16580533445793566, Log-Loss:0.9495196259769269\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9745425674554824 using:12,DecisionTreeClassifier(),30,600\n",
      "          train score: 0.9790443866716185 with variance: 7.966424409608367e-06\n",
      "          test  score: 0.9745425674554824 with variance: 0.00020680631146477685\n",
      "        Refitted train score: 0.9726027397260273,  RMSE: 0.2030692330267238, Log-Loss:1.4242794389653899\n",
      "        Refitted test  score: 0.9787234042553191,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9621858562244302 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9682144442800059 with variance: 4.334544267195191e-06\n",
      "          test  score: 0.9621858562244302 with variance: 0.0002862353506601662\n",
      "        Refitted train score: 0.9656357388316151,  RMSE: 0.18537599944001618, Log-Loss:1.1868995324711584\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9732103253286333 using:10,DecisionTreeClassifier(),28,600\n",
      "          train score: 0.9757537137601542 with variance: 3.5746349442639016e-05\n",
      "          test  score: 0.9732103253286333 with variance: 0.00044559184501957006\n",
      "        Refitted train score: 0.9751693002257337,  RMSE: 0.19442398845107403, Log-Loss:1.3055894857182742\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9587375803623612 using:10,DecisionTreeClassifier(),28,600\n",
      "          train score: 0.963053130087317 with variance: 8.591860590902434e-05\n",
      "          test  score: 0.9587375803623612 with variance: 0.0010242590915658665\n",
      "        Refitted train score: 0.9553264604810997,  RMSE: 0.211361158964698, Log-Loss:1.5429693922125056\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9734234932667182 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9764234541950367 with variance: 1.8755244618557682e-05\n",
      "          test  score: 0.9734234932667182 with variance: 0.00018529261039126562\n",
      "        Refitted train score: 0.9728506787330317,  RMSE: 0.2030692330267238, Log-Loss:1.4242794389653899\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9587375803623612 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9639225987864437 with variance: 5.56880603474828e-05\n",
      "          test  score: 0.9587375803623612 with variance: 0.0005486348347287678\n",
      "        Refitted train score: 0.9553264604810997,  RMSE: 0.211361158964698, Log-Loss:1.5429693922125054\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9768332809674994 using:10,DecisionTreeClassifier(),28,600\n",
      "          train score: 0.9788295117828483 with variance: 4.726438248718874e-06\n",
      "          test  score: 0.9768332809674994 with variance: 0.00011918584779397205\n",
      "        Refitted train score: 0.9770642201834863,  RMSE: 0.18537599944001618, Log-Loss:1.1868995324711582\n",
      "        Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9656341320864991 using:10,DecisionTreeClassifier(),28,600\n",
      "          train score: 0.9682144442800059 with variance: 1.1702519363439283e-05\n",
      "          test  score: 0.9656341320864991 with variance: 0.00023786678216825715\n",
      "        Refitted train score: 0.9725085910652921,  RMSE: 0.16580533445793566, Log-Loss:0.9495196259769269\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9785285446261056 using:8,KNeighborsClassifier(),32,500\n",
      "          train score: 0.9747585729215578 with variance: 4.799696799744356e-05\n",
      "          test  score: 0.9785285446261056 with variance: 0.00037531845618084107\n",
      "        Refitted train score: 0.9748283752860412,  RMSE: 0.19442398845107403, Log-Loss:1.3055922334757661\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      accuracy\n",
      "        CV score: 0.9691992986557569 using:8,KNeighborsClassifier(),32,500\n",
      "          train score: 0.9622132603226283 with variance: 9.07608483412935e-05\n",
      "          test  score: 0.9691992986557569 with variance: 0.0007434822841578256\n",
      "        Refitted train score: 0.9621993127147767,  RMSE: 0.19442398845107403, Log-Loss:1.3055922334757661\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9765826977010057 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9772403947901063 with variance: 3.6382638859850375e-05\n",
      "          test  score: 0.9765826977010057 with variance: 0.0003950128507176954\n",
      "        Refitted train score: 0.9719626168224299,  RMSE: 0.2030692330267238, Log-Loss:1.4242794389653899\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9656341320864993 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9664866064821667 with variance: 6.996312880405383e-05\n",
      "          test  score: 0.9656341320864993 with variance: 0.0008323971032146297\n",
      "        Refitted train score: 0.9518900343642611,  RMSE: 0.2193398405117931, Log-Loss:1.6616593454596214\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9790517658922196 using:12,DecisionTreeClassifier(),30,600\n",
      "          train score: 0.9783983669809846 with variance: 8.414894780376576e-05\n",
      "          test  score: 0.9790517658922196 with variance: 0.000267736900654525\n",
      "        Refitted train score: 0.973365617433414,  RMSE: 0.2, Log-Loss:1.3815510557964283\n",
      "        Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9672727272727272 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9618181818181817 with variance: 0.00012892561983471066\n",
      "          test  score: 0.9672727272727272 with variance: 0.00044958677685950443\n",
      "        Refitted train score: 0.9563636363636364,  RMSE: 0.2088931871468374, Log-Loss:1.507146606323376\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146352812686184\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.981024014744945 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9790724725070076 with variance: 3.440691392068278e-05\n",
      "          test  score: 0.981024014744945 with variance: 9.104336096435377e-05\n",
      "        Refitted train score: 0.9760765550239235,  RMSE: 0.19069251784911845, Log-Loss:1.2559555052694802\n",
      "        Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "      accuracy\n",
      "        CV score: 0.9709090909090909 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9681818181818181 with variance: 7.438016528925594e-05\n",
      "          test  score: 0.9709090909090909 with variance: 0.00021157024793388448\n",
      "        Refitted train score: 0.96,  RMSE: 0.2, Log-Loss:1.3815510557964283\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024777\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9779194822499286 using:12,KNeighborsClassifier(),32,600\n",
      "          train score: 0.9766978752006352 with variance: 1.1279313300687624e-05\n",
      "          test  score: 0.9779194822499286 with variance: 0.00024989446150060717\n",
      "        Refitted train score: 0.9686746987951806,  RMSE: 0.2174229226018436, Log-Loss:1.632745064477343\n",
      "        Refitted test  score: 0.9714285714285714,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "      accuracy\n",
      "        CV score: 0.9672727272727272 using:12,KNeighborsClassifier(),32,600\n",
      "          train score: 0.9645454545454546 with variance: 2.8099173553719047e-05\n",
      "          test  score: 0.9672727272727272 with variance: 0.0005818181818181823\n",
      "        Refitted train score: 0.9527272727272728,  RMSE: 0.2174229226018436, Log-Loss:1.632745064477343\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9737860639058462 using:8,KNeighborsClassifier(),30,500\n",
      "          train score: 0.9704838554137758 with variance: 2.26770437203548e-05\n",
      "          test  score: 0.9737860639058462 with variance: 0.00021166368836963217\n",
      "        Refitted train score: 0.9617224880382775,  RMSE: 0.2412090756622109, Log-Loss:2.0095317160581865\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.96 using:8,KNeighborsClassifier(),30,500\n",
      "          train score: 0.9545454545454545 with variance: 4.9586776859504164e-05\n",
      "          test  score: 0.96 with variance: 0.00044958677685950443\n",
      "        Refitted train score: 0.9418181818181818,  RMSE: 0.2412090756622109, Log-Loss:2.0095317160581865\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9775400943803909 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9786502052491347 with variance: 3.564571667975878e-05\n",
      "          test  score: 0.9775400943803909 with variance: 0.00022349720827057827\n",
      "        Refitted train score: 0.9705882352941176,  RMSE: 0.2088931871468374, Log-Loss:1.507146606323376\n",
      "        Refitted test  score: 0.9873417721518987,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      accuracy\n",
      "        CV score: 0.9672727272727272 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9681818181818181 with variance: 7.438016528925615e-05\n",
      "          test  score: 0.9672727272727272 with variance: 0.00044958677685950443\n",
      "        Refitted train score: 0.9636363636363636,  RMSE: 0.19069251784911845, Log-Loss:1.2559555052694804\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9783269963714158 using:10,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.9821826455671182 with variance: 2.8484564086894786e-06\n",
      "          test  score: 0.9783269963714158 with variance: 8.511591384713527e-05\n",
      "        Refitted train score: 0.9760765550239235,  RMSE: 0.19069251784911845, Log-Loss:1.2559555052694802\n",
      "        Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      accuracy\n",
      "        CV score: 0.9672727272727272 using:8,DecisionTreeClassifier(),28,700\n",
      "          train score: 0.9627272727272727 with variance: 1.1570247933884163e-05\n",
      "          test  score: 0.9672727272727272 with variance: 5.2892561983471106e-05\n",
      "        Refitted train score: 0.9709090909090909,  RMSE: 0.17056057308448835, Log-Loss:1.0047644042155843\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9738195138195138 using:8,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.975692453896318 with variance: 4.6174260682084306e-05\n",
      "          test  score: 0.9738195138195138 with variance: 0.00040876623653846494\n",
      "        Refitted train score: 0.9751243781094527,  RMSE: 0.19069251784911845, Log-Loss:1.2559555052694804\n",
      "        Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      accuracy\n",
      "        CV score: 0.9636363636363636 using:8,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.9645454545454546 with variance: 9.421487603305834e-05\n",
      "          test  score: 0.9636363636363636 with variance: 0.0006611570247933889\n",
      "        Refitted train score: 0.9636363636363636,  RMSE: 0.19069251784911845, Log-Loss:1.2559555052694802\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9799380636994506 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9795010035752387 with variance: 5.924795101818202e-06\n",
      "          test  score: 0.9799380636994506 with variance: 0.0003820492963641581\n",
      "        Refitted train score: 0.9742268041237113,  RMSE: 0.19649437297296482, Log-Loss:1.3335434901509926\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.9691553544494722 using:8,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.96911464139725 with variance: 1.4751902960181843e-05\n",
      "          test  score: 0.9691553544494722 with variance: 0.00097461376939684\n",
      "        Refitted train score: 0.9652509652509652,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9826818939695748 using:12,DecisionTreeClassifier(),30,600\n",
      "          train score: 0.9746448860146046 with variance: 2.2055726240504503e-05\n",
      "          test  score: 0.9826818939695748 with variance: 0.0003409181265642612\n",
      "        Refitted train score: 0.9746192893401014,  RMSE: 0.19649437297296482, Log-Loss:1.3335434901509924\n",
      "        Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.9729260935143287 using:12,DecisionTreeClassifier(),30,600\n",
      "          train score: 0.9613851727982163 with variance: 5.6329033384193036e-05\n",
      "          test  score: 0.9729260935143287 with variance: 0.0008319740473054276\n",
      "        Refitted train score: 0.9691119691119691,  RMSE: 0.17574991006549873, Log-Loss:1.0668347921207941\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9764624264624265 using:8,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.9730185269217747 with variance: 2.4713987487240848e-05\n",
      "          test  score: 0.9764624264624265 with variance: 0.0002914983168063409\n",
      "        Refitted train score: 0.9769820971867007,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9896907216494846,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      accuracy\n",
      "        CV score: 0.9653092006033184 using:8,DecisionTreeClassifier(),32,600\n",
      "          train score: 0.9594620958751394 with variance: 5.204123645425555e-05\n",
      "          test  score: 0.9653092006033184 with variance: 0.0006485898687123056\n",
      "        Refitted train score: 0.9575289575289575,  RMSE: 0.20608503698969138, Log-Loss:1.4668978391660914\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.977464427661576 using:8,KNeighborsClassifier(),28,500\n",
      "          train score: 0.9768241079006182 with variance: 3.4619654750220304e-05\n",
      "          test  score: 0.977464427661576 with variance: 0.0001503188829189645\n",
      "        Refitted train score: 0.9698492462311559,  RMSE: 0.21524880100025257, Log-Loss:1.6002583626787212\n",
      "        Refitted test  score: 0.9662921348314606,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.9653092006033182 using:8,KNeighborsClassifier(),28,500\n",
      "          train score: 0.9642930137495356 with variance: 7.964263456605065e-05\n",
      "          test  score: 0.9653092006033182 with variance: 0.00035273188054662586\n",
      "        Refitted train score: 0.9536679536679536,  RMSE: 0.21524880100025257, Log-Loss:1.6002583626787212\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.973665337263742 using:12,DecisionTreeClassifier(),28,600\n",
      "          train score: 0.9758218342855862 with variance: 2.894798218848763e-05\n",
      "          test  score: 0.973665337263742 with variance: 0.00027243135015153554\n",
      "        Refitted train score: 0.9765013054830287,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.9615384615384615 using:12,DecisionTreeClassifier(),28,600\n",
      "          train score: 0.9642837235228541 with variance: 6.174160023343281e-05\n",
      "          test  score: 0.9615384615384615 with variance: 0.0005917159763313611\n",
      "        Refitted train score: 0.9652509652509652,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9798014067850438 using:10,DecisionTreeClassifier(),32,500\n",
      "          train score: 0.9794488907859172 with variance: 2.2327013181872225e-05\n",
      "          test  score: 0.9798014067850438 with variance: 0.00016463389016853255\n",
      "        Refitted train score: 0.975,  RMSE: 0.19649437297296482, Log-Loss:1.3335434901509924\n",
      "        Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.9692307692307693 using:10,DecisionTreeClassifier(),30,500\n",
      "          train score: 0.9691239316239317 with variance: 4.1898283652197424e-05\n",
      "          test  score: 0.9692307692307693 with variance: 0.00038461538461538445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9652509652509652,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9706130699651101 using:12,DecisionTreeClassifier(),32,700\n",
      "          train score: 0.978609269573546 with variance: 3.6815558818623244e-05\n",
      "          test  score: 0.9706130699651101 with variance: 0.0009020769625173528\n",
      "        Refitted train score: 0.976,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.9615384615384617 using:10,DecisionTreeClassifier(),32,700\n",
      "          train score: 0.9720039018952062 with variance: 8.793168483076878e-05\n",
      "          test  score: 0.9615384615384617 with variance: 0.0010355029585798813\n",
      "        Refitted train score: 0.9652509652509652,  RMSE: 0.18641092980036, Log-Loss:1.2001891411358934\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n"
     ]
    }
   ],
   "source": [
    "#kidronclassifier\n",
    "max_estimators = [8, 10, 12]\n",
    "base_estimators = [LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), SVC()]\n",
    "min_rows = [28, 30, 32]\n",
    "min_columns = [500, 600, 700]\n",
    "    \n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        random.seed(randomstate)\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "           \n",
    "        #no need for treating imbalance here, the classifier does it on its own\n",
    "        #smote = SMOTE(random_state = randomstate)\n",
    "        #X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = pd.DataFrame(robustscaler.transform(X_train))\n",
    "        X_test  = pd.DataFrame(robustscaler.transform(X_test))\n",
    "\n",
    "        #best_scores = {score : [None] for score in scores}\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid\n",
    "        for max_estimator in max_estimators:\n",
    "            for base_estimator in base_estimators:\n",
    "                for min_row in min_rows:\n",
    "                    for min_column in min_columns:\n",
    "       \n",
    "                        kc = KidronClassifier(max_estimators = max_estimator, base_estimator = base_estimator, min_rows = min_row, min_columns = min_column, random_state = randomstate)                           \n",
    "                        cv_results = cross_validate(kc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    " \n",
    "                        for score in scores:\n",
    "                            avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                            var_score_test = np.var(cv_results['test_' + score])\n",
    "                            avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                            var_score_train = np.var(cv_results['train_' + score])\n",
    "                        \n",
    "                            if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                                best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, max_estimator, base_estimator, min_row, min_column]\n",
    "\n",
    "                    \n",
    "            \n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 3 + str(score))\n",
    "            print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            kc = KidronClassifier(max_estimators = best_avg_scores[score][4], base_estimator = best_avg_scores[score][5], min_rows = best_avg_scores[score][6], min_columns = best_avg_scores[score][7], random_state = randomstate)\n",
    "            \n",
    "            kc.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = kc.predict(X_train), kc.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(kc, X_train, y_train), get_scorer(score)(kc, X_test, y_test)\n",
    "            \n",
    "            print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")\n",
    "\n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"KidronClassifier\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "945d6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.964284</td>\n",
       "      <td>0.000591716</td>\n",
       "      <td>6.17416e-05</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>1.06274</td>\n",
       "      <td>1.20019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1250</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>12,DecisionTreeClassifier(),28,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.979801</td>\n",
       "      <td>0.979449</td>\n",
       "      <td>0.000164634</td>\n",
       "      <td>2.2327e-05</td>\n",
       "      <td>0.214834</td>\n",
       "      <td>0.196494</td>\n",
       "      <td>1.5941</td>\n",
       "      <td>1.33354</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>10,DecisionTreeClassifier(),32,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.969124</td>\n",
       "      <td>0.000384615</td>\n",
       "      <td>4.18983e-05</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>1.06273</td>\n",
       "      <td>1.20019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>10,DecisionTreeClassifier(),30,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.970613</td>\n",
       "      <td>0.978609</td>\n",
       "      <td>0.000902077</td>\n",
       "      <td>3.68156e-05</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>1.06274</td>\n",
       "      <td>1.20019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>12,DecisionTreeClassifier(),32,700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.961538</td>\n",
       "      <td>0.972004</td>\n",
       "      <td>0.0010355</td>\n",
       "      <td>8.79317e-05</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>1.06274</td>\n",
       "      <td>1.20019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>10,DecisionTreeClassifier(),32,700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "107  accuracy   0.961538    0.964284   0.000591716    6.17416e-05  0.175412   \n",
       "108        f1   0.979801    0.979449   0.000164634     2.2327e-05  0.214834   \n",
       "109  accuracy   0.969231    0.969124   0.000384615    4.18983e-05  0.175412   \n",
       "110        f1   0.970613    0.978609   0.000902077    3.68156e-05  0.175412   \n",
       "111  accuracy   0.961538    0.972004     0.0010355    8.79317e-05  0.175412   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "107   0.186411       1.06274        1.20019       0.2         1250   \n",
       "108   0.196494        1.5941        1.33354       0.2         1850   \n",
       "109   0.186411       1.06273        1.20019       0.2         1850   \n",
       "110   0.186411       1.06274        1.20019       0.2         2050   \n",
       "111   0.186411       1.06274        1.20019       0.2         2050   \n",
       "\n",
       "            estimator                    estimator params  \n",
       "107  KidronClassifier  12,DecisionTreeClassifier(),28,600  \n",
       "108  KidronClassifier  10,DecisionTreeClassifier(),32,500  \n",
       "109  KidronClassifier  10,DecisionTreeClassifier(),30,500  \n",
       "110  KidronClassifier  12,DecisionTreeClassifier(),32,700  \n",
       "111  KidronClassifier  10,DecisionTreeClassifier(),32,700  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74e2c8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9773180459387356 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9773180459387356 with variance: 0.0003723410952958266\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9780936454849499 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9780936454849499 with variance: 0.00033865758247236897\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      f1\n",
      "        CV score: 0.9773180459387356 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9773180459387356 with variance: 0.0003723410952958266\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9780936454849499 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9780936454849499 with variance: 0.00033865758247236897\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      f1\n",
      "        CV score: 0.9797213897213897 using:1.5,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9797213897213897 with variance: 0.00022822399539016344\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9802914476827521 using:1.5,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9802914476827521 with variance: 0.00021275386363983905\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9775151606519794 using:1.0,False,True,20,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9775151606519794 with variance: 0.0003252140827912302\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      accuracy\n",
      "        CV score: 0.9784011220196354 using:1.0,False,True,20,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9784011220196354 with variance: 0.0002764909828184723\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      f1\n",
      "        CV score: 0.9775151606519794 using:1.0,False,True,20,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9775151606519794 with variance: 0.0003252140827912302\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      accuracy\n",
      "        CV score: 0.9784011220196354 using:1.0,False,True,20,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9784011220196354 with variance: 0.0002764909828184723\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      f1\n",
      "        CV score: 0.9775151606519794 using:1.0,False,True,20,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9775151606519794 with variance: 0.0003252140827912302\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9142857142857143,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "      accuracy\n",
      "        CV score: 0.9784011220196354 using:1.0,False,True,20,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9784011220196354 with variance: 0.0002764909828184723\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852741839293175\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9774158342605181 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9879481503600076 with variance: 7.912536544072538e-06\n",
      "          test  score: 0.9774158342605181 with variance: 0.0004250644713911404\n",
      "        Refitted train score: 0.9868421052631579,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.978354371201496 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9880978539515125 with variance: 7.551023109115249e-06\n",
      "          test  score: 0.978354371201496 with variance: 0.00037707408944640165\n",
      "        Refitted train score: 0.987012987012987,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      f1\n",
      "        CV score: 0.9774158342605181 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9879481503600076 with variance: 7.912536544072538e-06\n",
      "          test  score: 0.9774158342605181 with variance: 0.0004250644713911404\n",
      "        Refitted train score: 0.9868421052631579,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.978354371201496 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9880978539515125 with variance: 7.551023109115249e-06\n",
      "          test  score: 0.978354371201496 with variance: 0.00037707408944640165\n",
      "        Refitted train score: 0.987012987012987,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      f1\n",
      "        CV score: 0.9774158342605181 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9879481503600076 with variance: 7.912536544072538e-06\n",
      "          test  score: 0.9774158342605181 with variance: 0.0004250644713911404\n",
      "        Refitted train score: 0.9868421052631579,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.978354371201496 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9880978539515125 with variance: 7.551023109115249e-06\n",
      "          test  score: 0.978354371201496 with variance: 0.00037707408944640165\n",
      "        Refitted train score: 0.987012987012987,  RMSE: 0.11396057645963795, Log-Loss:0.4485555375962435\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9732699520842003 using:1.0,True,True,10,1.0\n",
      "          train score: 0.9972811278284563 with variance: 5.907381172626802e-06\n",
      "          test  score: 0.9732699520842003 with variance: 0.00013942752365760298\n",
      "        Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9740532959326789 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9918816377352963 with variance: 2.9536769165154275e-06\n",
      "          test  score: 0.9740532959326789 with variance: 0.00012006261418597692\n",
      "        Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9732699520842003 using:1.0,True,True,10,1.0\n",
      "          train score: 0.9972811278284563 with variance: 5.907381172626802e-06\n",
      "          test  score: 0.9732699520842003 with variance: 0.00013942752365760298\n",
      "        Refitted train score: 0.9956521739130434,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208187\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9740532959326789 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9918816377352963 with variance: 2.9536769165154275e-06\n",
      "          test  score: 0.9740532959326789 with variance: 0.00012006261418597692\n",
      "        Refitted train score: 0.9891774891774892,  RMSE: 0.10403129732205987, Log-Loss:0.3737962813302032\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9753747335987277 using:1.5,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9753747335987277 with variance: 0.00018010459519345374\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9762038335670875 using:1.5,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9762038335670875 with variance: 0.0001576643474851269\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9774685946097431 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9911203190010897 with variance: 1.2451415934283064e-06\n",
      "          test  score: 0.9774685946097431 with variance: 0.00015521567793860407\n",
      "        Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9780219780219781 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9911891139163866 with variance: 1.2193323840354747e-06\n",
      "          test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9774685946097431 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9911203190010897 with variance: 1.2451415934283064e-06\n",
      "          test  score: 0.9774685946097431 with variance: 0.00015521567793860407\n",
      "        Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9780219780219781 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9911891139163866 with variance: 1.2193323840354747e-06\n",
      "          test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9774685946097431 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9911203190010897 with variance: 1.2451415934283064e-06\n",
      "          test  score: 0.9774685946097431 with variance: 0.00015521567793860407\n",
      "        Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9780219780219781 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9911891139163866 with variance: 1.2193323840354747e-06\n",
      "          test  score: 0.9780219780219781 with variance: 0.00014491003501992508\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9774259448416751 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9972298998926996 with variance: 6.138876735847741e-06\n",
      "          test  score: 0.9774259448416751 with variance: 0.00015151167364501383\n",
      "        Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9780219780219781 using:1.0,True,True,2,0.8\n",
      "          train score: 0.994491871764599 with variance: 1.2150810195740391e-05\n",
      "          test  score: 0.9780219780219781 with variance: 0.00019321338002656644\n",
      "        Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9774259448416751 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9972298998926996 with variance: 6.138876735847741e-06\n",
      "          test  score: 0.9774259448416751 with variance: 0.00015151167364501383\n",
      "        Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9780219780219781 using:1.0,True,True,2,0.8\n",
      "          train score: 0.994491871764599 with variance: 1.2150810195740391e-05\n",
      "          test  score: 0.9780219780219781 with variance: 0.00019321338002656644\n",
      "        Refitted train score: 0.9977973568281938,  RMSE: 0.04693232544639321, Log-Loss:0.07607659998879104\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9797230734309386 using:1.5,False,True,2,0.8\n",
      "          train score: 0.9972298998926996 with variance: 6.138876735847741e-06\n",
      "          test  score: 0.9797230734309386 with variance: 0.00012146728610367696\n",
      "        Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9802197802197803 using:1.5,False,True,2,0.8\n",
      "          train score: 0.9972482063391155 with variance: 6.054588166690858e-06\n",
      "          test  score: 0.9802197802197803 with variance: 0.00011592802801594017\n",
      "        Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9749662023949976 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9749662023949976 with variance: 0.00023529053565001526\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9758241758241759 using:1.0,False,True,2,0.6\n",
      "          train score: 0.9961432506887054 with variance: 2.6106292071731672e-05\n",
      "          test  score: 0.9758241758241759 with variance: 0.00026083806303586505\n",
      "        Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9749662023949976 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9749662023949976 with variance: 0.00023529053565001526\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9758241758241759 using:1.0,False,True,2,0.6\n",
      "          train score: 0.9961432506887054 with variance: 2.6106292071731672e-05\n",
      "          test  score: 0.9758241758241759 with variance: 0.00026083806303586505\n",
      "        Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9749662023949976 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9749662023949976 with variance: 0.00023529053565001526\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9758241758241759 using:1.0,False,True,2,0.6\n",
      "          train score: 0.9961432506887054 with variance: 2.6106292071731672e-05\n",
      "          test  score: 0.9758241758241759 with variance: 0.00026083806303586505\n",
      "        Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.1521531999775811\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9791437979862441 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9798501872659177 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      f1\n",
      "        CV score: 0.9791437979862441 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9798501872659177 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      f1\n",
      "        CV score: 0.9791437979862441 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9791437979862441 with variance: 0.0004120390522058947\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9798501872659177 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9798501872659177 with variance: 0.00037392460423222576\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9748141197710052 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9949704847314503 with variance: 4.414915649489256e-06\n",
      "          test  score: 0.9748141197710052 with variance: 0.0001335044357789322\n",
      "        Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627065\n",
      "        Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      accuracy\n",
      "        CV score: 0.9755555555555555 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9949999999999999 with variance: 4.320987654320957e-06\n",
      "          test  score: 0.9755555555555555 with variance: 0.00011851851851851826\n",
      "        Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627065\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      f1\n",
      "        CV score: 0.9748141197710052 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9949704847314503 with variance: 4.414915649489256e-06\n",
      "          test  score: 0.9748141197710052 with variance: 0.0001335044357789322\n",
      "        Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627065\n",
      "        Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      accuracy\n",
      "        CV score: 0.9755555555555555 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9949999999999999 with variance: 4.320987654320957e-06\n",
      "          test  score: 0.9755555555555555 with variance: 0.00011851851851851826\n",
      "        Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627065\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      f1\n",
      "        CV score: 0.9748141197710052 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9949704847314503 with variance: 4.414915649489256e-06\n",
      "          test  score: 0.9748141197710052 with variance: 0.0001335044357789322\n",
      "        Refitted train score: 0.9955357142857144,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627065\n",
      "        Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      accuracy\n",
      "        CV score: 0.9755555555555555 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9949999999999999 with variance: 4.320987654320957e-06\n",
      "          test  score: 0.9755555555555555 with variance: 0.00011851851851851826\n",
      "        Refitted train score: 0.9955555555555555,  RMSE: 0.06666666666666667, Log-Loss:0.15350567286627065\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9795111081758586 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9877435768274341 with variance: 5.105832574382752e-06\n",
      "          test  score: 0.9795111081758586 with variance: 0.0002895166624823494\n",
      "        Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9801953601953602 using:1.0,True,False,2,0.6\n",
      "          train score: 0.987884842430297 with variance: 4.870474566068345e-06\n",
      "          test  score: 0.9801953601953602 with variance: 0.00026041108531951\n",
      "        Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      f1\n",
      "        CV score: 0.9795111081758586 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9877435768274341 with variance: 5.105832574382752e-06\n",
      "          test  score: 0.9795111081758586 with variance: 0.0002895166624823494\n",
      "        Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9801953601953602 using:1.0,True,False,2,0.6\n",
      "          train score: 0.987884842430297 with variance: 4.870474566068345e-06\n",
      "          test  score: 0.9801953601953602 with variance: 0.00026041108531951\n",
      "        Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      f1\n",
      "        CV score: 0.9795111081758586 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9877435768274341 with variance: 5.105832574382752e-06\n",
      "          test  score: 0.9795111081758586 with variance: 0.0002895166624823494\n",
      "        Refitted train score: 0.9888641425389755,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9801953601953602 using:1.0,True,False,2,0.6\n",
      "          train score: 0.987884842430297 with variance: 4.870474566068345e-06\n",
      "          test  score: 0.9801953601953602 with variance: 0.00026041108531951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9775264061780915 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9933670202781203 with variance: 1.4120296003622557e-05\n",
      "          test  score: 0.9775264061780915 with variance: 0.00030412714288742337\n",
      "        Refitted train score: 0.9911504424778761,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.977997557997558 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9933929706656979 with variance: 1.3948901837872361e-05\n",
      "          test  score: 0.977997557997558 with variance: 0.0002892857515568147\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9775264061780915 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9933670202781203 with variance: 1.4120296003622557e-05\n",
      "          test  score: 0.9775264061780915 with variance: 0.00030412714288742337\n",
      "        Refitted train score: 0.9911504424778761,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.977997557997558 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9933929706656979 with variance: 1.3948901837872361e-05\n",
      "          test  score: 0.977997557997558 with variance: 0.0002892857515568147\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9775264061780915 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9933670202781203 with variance: 1.4120296003622557e-05\n",
      "          test  score: 0.9775264061780915 with variance: 0.00030412714288742337\n",
      "        Refitted train score: 0.9911504424778761,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.977997557997558 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9933929706656979 with variance: 1.3948901837872361e-05\n",
      "          test  score: 0.977997557997558 with variance: 0.0002892857515568147\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430816118298093\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9767869931953621 using:1.0,False,True,10,0.8\n",
      "          train score: 0.9983161715390381 with variance: 1.8902187291243681e-06\n",
      "          test  score: 0.9767869931953621 with variance: 0.0002810383050642718\n",
      "        Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9775530586766543 using:1.0,False,True,10,0.8\n",
      "          train score: 0.9983193277310924 with variance: 1.8831061836499175e-06\n",
      "          test  score: 0.9775530586766543 with variance: 0.0002530569621930141\n",
      "        Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9767869931953621 using:1.0,False,True,10,0.8\n",
      "          train score: 0.9983161715390381 with variance: 1.8902187291243681e-06\n",
      "          test  score: 0.9767869931953621 with variance: 0.0002810383050642718\n",
      "        Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9775530586766543 using:1.0,False,True,10,0.8\n",
      "          train score: 0.9983193277310924 with variance: 1.8831061836499175e-06\n",
      "          test  score: 0.9775530586766543 with variance: 0.0002530569621930141\n",
      "        Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9767869931953621 using:1.0,False,True,10,0.8\n",
      "          train score: 0.9983161715390381 with variance: 1.8902187291243681e-06\n",
      "          test  score: 0.9767869931953621 with variance: 0.0002810383050642718\n",
      "        Refitted train score: 0.9977528089887641,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9775530586766543 using:1.0,False,True,10,0.8\n",
      "          train score: 0.9983193277310924 with variance: 1.8831061836499175e-06\n",
      "          test  score: 0.9775530586766543 with variance: 0.0002530569621930141\n",
      "        Refitted train score: 0.9977578475336323,  RMSE: 0.047351372381037836, Log-Loss:0.07744120267917293\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9725086040782562 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9898080652882111 with variance: 1.9121749691366965e-06\n",
      "          test  score: 0.9725086040782562 with variance: 0.0003360638901450946\n",
      "        Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.973158551810237 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9899112453970353 with variance: 1.867326462283961e-06\n",
      "          test  score: 0.973158551810237 with variance: 0.0003260593421768358\n",
      "        Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9725086040782562 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9898080652882111 with variance: 1.9121749691366965e-06\n",
      "          test  score: 0.9725086040782562 with variance: 0.0003360638901450946\n",
      "        Refitted train score: 0.9909502262443438,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.973158551810237 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9899112453970353 with variance: 1.867326462283961e-06\n",
      "          test  score: 0.973158551810237 with variance: 0.0003260593421768358\n",
      "        Refitted train score: 0.9910313901345291,  RMSE: 0.09470274476207567, Log-Loss:0.3097648107166887\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9725158562367865 using:1.5,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9725158562367865 with variance: 0.0004940128458983852\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9731835205992511 using:1.5,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9731835205992511 with variance: 0.00047275736789686984\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9789839991392428 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9977175417175417 with variance: 4.567723327186159e-06\n",
      "          test  score: 0.9789839991392428 with variance: 0.00019001351774717692\n",
      "        Refitted train score: 0.9977220956719818,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9795454545454545 using:1.0,True,True,10,1.0\n",
      "          train score: 0.9948863636363636 with variance: 1.29132231404966e-06\n",
      "          test  score: 0.9795454545454545 with variance: 0.0001756198347107435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9977272727272727,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      f1\n",
      "        CV score: 0.9789839991392428 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9977175417175417 with variance: 4.567723327186159e-06\n",
      "          test  score: 0.9789839991392428 with variance: 0.00019001351774717692\n",
      "        Refitted train score: 0.9977220956719818,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9795454545454545 using:1.0,True,True,10,1.0\n",
      "          train score: 0.9948863636363636 with variance: 1.29132231404966e-06\n",
      "          test  score: 0.9795454545454545 with variance: 0.0001756198347107435\n",
      "        Refitted train score: 0.9977272727272727,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      f1\n",
      "        CV score: 0.9813916598779568 using:1.5,False,True,2,0.8\n",
      "          train score: 0.9977175417175417 with variance: 4.567723327186159e-06\n",
      "          test  score: 0.9813916598779568 with variance: 0.00014444711625985168\n",
      "        Refitted train score: 0.9977220956719818,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9818181818181818 using:1.5,False,True,2,0.8\n",
      "          train score: 0.9977272727272727 with variance: 4.519628099173608e-06\n",
      "          test  score: 0.9818181818181818 with variance: 0.00013429752066115679\n",
      "        Refitted train score: 0.9977272727272727,  RMSE: 0.04767312946227961, Log-Loss:0.07849721907934347\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9781298364950622 using:1.0,True,True,2,1.0\n",
      "          train score: 0.994690141543343 with variance: 1.5233973058341833e-05\n",
      "          test  score: 0.9781298364950622 with variance: 0.00045386703516339606\n",
      "        Refitted train score: 0.9952606635071091,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "        Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9787955182072829 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9946920006940829 with variance: 1.532307028788167e-05\n",
      "          test  score: 0.9787955182072829 with variance: 0.00040916445009376353\n",
      "        Refitted train score: 0.9952830188679245,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      f1\n",
      "        CV score: 0.9781298364950622 using:1.0,True,True,2,1.0\n",
      "          train score: 0.994690141543343 with variance: 1.5233973058341833e-05\n",
      "          test  score: 0.9781298364950622 with variance: 0.00045386703516339606\n",
      "        Refitted train score: 0.9952606635071091,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "        Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9787955182072829 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9946920006940829 with variance: 1.532307028788167e-05\n",
      "          test  score: 0.9787955182072829 with variance: 0.00040916445009376353\n",
      "        Refitted train score: 0.9952830188679245,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      f1\n",
      "        CV score: 0.9781298364950622 using:1.0,True,True,2,1.0\n",
      "          train score: 0.994690141543343 with variance: 1.5233973058341833e-05\n",
      "          test  score: 0.9781298364950622 with variance: 0.00045386703516339606\n",
      "        Refitted train score: 0.9952606635071091,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "        Refitted test  score: 0.9866666666666666,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9787955182072829 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9946920006940829 with variance: 1.532307028788167e-05\n",
      "          test  score: 0.9787955182072829 with variance: 0.00040916445009376353\n",
      "        Refitted train score: 0.9952830188679245,  RMSE: 0.06868028197434452, Log-Loss:0.16291875657976834\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9760757314974182 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9857740893158817 with variance: 8.622255497956095e-06\n",
      "          test  score: 0.9760757314974182 with variance: 5.8083329136560853e-05\n",
      "        Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9766621067031463 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9859836666496171 with variance: 8.12643101084122e-06\n",
      "          test  score: 0.9766621067031463 with variance: 5.345899120631929e-05\n",
      "        Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      f1\n",
      "        CV score: 0.9760757314974182 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9857740893158817 with variance: 8.622255497956095e-06\n",
      "          test  score: 0.9760757314974182 with variance: 5.8083329136560853e-05\n",
      "        Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9766621067031463 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9859836666496171 with variance: 8.12643101084122e-06\n",
      "          test  score: 0.9766621067031463 with variance: 5.345899120631929e-05\n",
      "        Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      f1\n",
      "        CV score: 0.9760757314974182 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9857740893158817 with variance: 8.622255497956095e-06\n",
      "          test  score: 0.9760757314974182 with variance: 5.8083329136560853e-05\n",
      "        Refitted train score: 0.985781990521327,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9766621067031463 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9859836666496171 with variance: 8.12643101084122e-06\n",
      "          test  score: 0.9766621067031463 with variance: 5.345899120631929e-05\n",
      "        Refitted train score: 0.985981308411215,  RMSE: 0.11840055569457876, Log-Loss:0.48418845413426287\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9781225743309372 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9916981573487321 with variance: 1.5805831610485575e-05\n",
      "          test  score: 0.9781225743309372 with variance: 0.0002191520425110363\n",
      "        Refitted train score: 0.990521327014218,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "        Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9788782489740082 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9917871312747973 with variance: 1.5117549187091787e-05\n",
      "          test  score: 0.9788782489740082 with variance: 0.00018798976721729426\n",
      "        Refitted train score: 0.9906103286384976,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9781225743309372 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9916981573487321 with variance: 1.5805831610485575e-05\n",
      "          test  score: 0.9781225743309372 with variance: 0.0002191520425110363\n",
      "        Refitted train score: 0.990521327014218,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "        Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9788782489740082 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9917871312747973 with variance: 1.5117549187091787e-05\n",
      "          test  score: 0.9788782489740082 with variance: 0.00018798976721729426\n",
      "        Refitted train score: 0.9906103286384976,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      f1\n",
      "        CV score: 0.9781225743309372 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9916981573487321 with variance: 1.5805831610485575e-05\n",
      "          test  score: 0.9781225743309372 with variance: 0.0002191520425110363\n",
      "        Refitted train score: 0.990521327014218,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "        Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9788782489740082 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9917871312747973 with variance: 1.5117549187091787e-05\n",
      "          test  score: 0.9788782489740082 with variance: 0.00018798976721729426\n",
      "        Refitted train score: 0.9906103286384976,  RMSE: 0.09690031662230185, Log-Loss:0.32430775957662705\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9786534372785258 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9970912789219426 with variance: 3.420010836223305e-06\n",
      "          test  score: 0.9786534372785258 with variance: 0.0001377902990625938\n",
      "        Refitted train score: 0.9976798143851509,  RMSE: 0.048112522432468816, Log-Loss:0.07995087128451644\n",
      "        Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9792034215450414 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9792034215450414 with variance: 0.00028711945289920107\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9786534372785258 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9970912789219426 with variance: 3.420010836223305e-06\n",
      "          test  score: 0.9786534372785258 with variance: 0.0001377902990625938\n",
      "        Refitted train score: 0.9976798143851509,  RMSE: 0.048112522432468816, Log-Loss:0.07995087128451644\n",
      "        Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9792034215450414 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9792034215450414 with variance: 0.00028711945289920107\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9786534372785258 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9970912789219426 with variance: 3.420010836223305e-06\n",
      "          test  score: 0.9786534372785258 with variance: 0.0001377902990625938\n",
      "        Refitted train score: 0.9976798143851509,  RMSE: 0.048112522432468816, Log-Loss:0.07995087128451644\n",
      "        Refitted test  score: 0.9850746268656716,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661414\n",
      "      accuracy\n",
      "        CV score: 0.9792034215450414 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9792034215450414 with variance: 0.00028711945289920107\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9753681392235609 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9940047617552308 with variance: 7.25757009957866e-06\n",
      "          test  score: 0.9753681392235609 with variance: 0.00024534849198967415\n",
      "        Refitted train score: 0.9928057553956835,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9761904761904763 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9940476190476192 with variance: 7.086167800453465e-06\n",
      "          test  score: 0.9761904761904763 with variance: 0.00022675736961451243\n",
      "        Refitted train score: 0.9928571428571429,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9753681392235609 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9940047617552308 with variance: 7.25757009957866e-06\n",
      "          test  score: 0.9753681392235609 with variance: 0.00024534849198967415\n",
      "        Refitted train score: 0.9928057553956835,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9761904761904763 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9940476190476192 with variance: 7.086167800453465e-06\n",
      "          test  score: 0.9761904761904763 with variance: 0.00022675736961451243\n",
      "        Refitted train score: 0.9928571428571429,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9753681392235609 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9940047617552308 with variance: 7.25757009957866e-06\n",
      "          test  score: 0.9753681392235609 with variance: 0.00024534849198967415\n",
      "        Refitted train score: 0.9928057553956835,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9761904761904763 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9940476190476192 with variance: 7.086167800453465e-06\n",
      "          test  score: 0.9761904761904763 with variance: 0.00022675736961451243\n",
      "        Refitted train score: 0.9928571428571429,  RMSE: 0.08451542547285165, Log-Loss:0.2467055456779344\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.978485370051635 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9905639013211192 with variance: 4.898208913603691e-06\n",
      "          test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "        Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9790150478796169 using:1.0,True,True,10,0.6\n",
      "          train score: 0.990655209452202 with variance: 4.762095769662352e-06\n",
      "          test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "        Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      f1\n",
      "        CV score: 0.978485370051635 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9905639013211192 with variance: 4.898208913603691e-06\n",
      "          test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "        Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9790150478796169 using:1.0,True,True,10,0.6\n",
      "          train score: 0.990655209452202 with variance: 4.762095769662352e-06\n",
      "          test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      f1\n",
      "        CV score: 0.978485370051635 using:1.0,True,True,10,0.6\n",
      "          train score: 0.9905639013211192 with variance: 4.898208913603691e-06\n",
      "          test  score: 0.978485370051635 with variance: 0.00013854286089526514\n",
      "        Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9790150478796169 using:1.0,True,True,10,0.6\n",
      "          train score: 0.990655209452202 with variance: 4.762095769662352e-06\n",
      "          test  score: 0.9790150478796169 with variance: 0.00013006637834722204\n",
      "        Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.3227923027561756\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.969205951052712 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9845846896847164 with variance: 7.954914771068628e-06\n",
      "          test  score: 0.969205951052712 with variance: 0.0007407110534217479\n",
      "        Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9708492506611812 using:1.0,True,True,2,0.6\n",
      "          train score: 0.984828221423966 with variance: 7.4138000848682875e-06\n",
      "          test  score: 0.9708492506611812 with variance: 0.0006303197063247064\n",
      "        Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.969205951052712 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9845846896847164 with variance: 7.954914771068628e-06\n",
      "          test  score: 0.969205951052712 with variance: 0.0007407110534217479\n",
      "        Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9708492506611812 using:1.0,True,True,2,0.6\n",
      "          train score: 0.984828221423966 with variance: 7.4138000848682875e-06\n",
      "          test  score: 0.9708492506611812 with variance: 0.0006303197063247064\n",
      "        Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.969205951052712 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9845846896847164 with variance: 7.954914771068628e-06\n",
      "          test  score: 0.969205951052712 with variance: 0.0007407110534217479\n",
      "        Refitted train score: 0.9877149877149877,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9708492506611812 using:1.0,True,True,2,0.6\n",
      "          train score: 0.984828221423966 with variance: 7.4138000848682875e-06\n",
      "          test  score: 0.9708492506611812 with variance: 0.0006303197063247064\n",
      "        Refitted train score: 0.9878640776699029,  RMSE: 0.11016316230980794, Log-Loss:0.41915990770522765\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9818181818181818 using:1.0,False,False,2,0.8\n",
      "          train score: 0.9968453883145442 with variance: 4.005886400725348e-06\n",
      "          test  score: 0.9818181818181818 with variance: 0.0003103390116377129\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.982373417721519 using:1.0,False,False,2,0.8\n",
      "          train score: 0.9968573174819108 with variance: 3.9555552817490666e-06\n",
      "          test  score: 0.982373417721519 with variance: 0.00029101506168883166\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      f1\n",
      "        CV score: 0.9818181818181818 using:1.0,False,False,2,0.8\n",
      "          train score: 0.9968453883145442 with variance: 4.005886400725348e-06\n",
      "          test  score: 0.9818181818181818 with variance: 0.0003103390116377129\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.982373417721519 using:1.0,False,False,2,0.8\n",
      "          train score: 0.9968573174819108 with variance: 3.9555552817490666e-06\n",
      "          test  score: 0.982373417721519 with variance: 0.00029101506168883166\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      f1\n",
      "        CV score: 0.9818181818181818 using:1.0,False,False,2,0.8\n",
      "          train score: 0.9968453883145442 with variance: 4.005886400725348e-06\n",
      "          test  score: 0.9818181818181818 with variance: 0.0003103390116377129\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.98,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.982373417721519 using:1.0,False,False,2,0.8\n",
      "          train score: 0.9968573174819108 with variance: 3.9555552817490666e-06\n",
      "          test  score: 0.982373417721519 with variance: 0.00029101506168883166\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9770837390457643 using:1.0,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9770837390457643 with variance: 0.00028935332625199775\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9777160493827161 using:1.0,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9777160493827161 with variance: 0.0002685718640451148\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      f1\n",
      "        CV score: 0.9770837390457643 using:1.0,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9770837390457643 with variance: 0.00028935332625199775\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9777160493827161 using:1.0,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9777160493827161 with variance: 0.0002685718640451148\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      f1\n",
      "        CV score: 0.9770837390457643 using:1.0,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9770837390457643 with variance: 0.00028935332625199775\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.967741935483871,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9777160493827161 using:1.0,False,True,20,0.8\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9777160493827161 with variance: 0.0002685718640451148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9744197363817616 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9860878653794838 with variance: 1.4528372829677859e-05\n",
      "          test  score: 0.9744197363817616 with variance: 6.927364942653582e-05\n",
      "        Refitted train score: 0.98989898989899,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "        Refitted test  score: 0.9791666666666666,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.975 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9862500000000001 with variance: 1.406250000000001e-05\n",
      "          test  score: 0.975 with variance: 6.250000000000011e-05\n",
      "        Refitted train score: 0.99,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      f1\n",
      "        CV score: 0.9744197363817616 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9860878653794838 with variance: 1.4528372829677859e-05\n",
      "          test  score: 0.9744197363817616 with variance: 6.927364942653582e-05\n",
      "        Refitted train score: 0.98989898989899,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "        Refitted test  score: 0.9791666666666666,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.975 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9862500000000001 with variance: 1.406250000000001e-05\n",
      "          test  score: 0.975 with variance: 6.250000000000011e-05\n",
      "        Refitted train score: 0.99,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      f1\n",
      "        CV score: 0.9770837390457643 using:1.5,True,False,2,0.8\n",
      "          train score: 0.9867507384154599 with variance: 5.573319679677349e-06\n",
      "          test  score: 0.9770837390457643 with variance: 2.6368447882504856e-05\n",
      "        Refitted train score: 0.98989898989899,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "        Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9775 using:1.5,True,False,2,0.8\n",
      "          train score: 0.9868750000000001 with variance: 5.468749999999989e-06\n",
      "          test  score: 0.9775 with variance: 2.5000000000000265e-05\n",
      "        Refitted train score: 0.99,  RMSE: 0.1, Log-Loss:0.34538776394910775\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9824035005469604 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9824035005469604 with variance: 0.00010383713406930883\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9827461607949413 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9827461607949413 with variance: 9.784712922909626e-05\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      f1\n",
      "        CV score: 0.9824035005469604 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9824035005469604 with variance: 0.00010383713406930883\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9827461607949413 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9827461607949413 with variance: 9.784712922909626e-05\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      f1\n",
      "        CV score: 0.9824035005469604 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9824035005469604 with variance: 0.00010383713406930883\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9827461607949413 using:1.0,False,True,2,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9827461607949413 with variance: 9.784712922909626e-05\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9761338235022446 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9761338235022446 with variance: 0.0004568704378230768\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      accuracy\n",
      "        CV score: 0.9770204479065239 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9770204479065239 with variance: 0.00041781769956495443\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      f1\n",
      "        CV score: 0.9761338235022446 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9761338235022446 with variance: 0.0004568704378230768\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      accuracy\n",
      "        CV score: 0.9770204479065239 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9770204479065239 with variance: 0.00041781769956495443\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      f1\n",
      "        CV score: 0.9761338235022446 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9761338235022446 with variance: 0.0004568704378230768\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9904761904761905,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "      accuracy\n",
      "        CV score: 0.9770204479065239 using:1.0,False,True,10,1.0\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9770204479065239 with variance: 0.00041781769956495443\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9774050632911393 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9895155874079944 with variance: 1.0095973808490853e-05\n",
      "          test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "        Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "        Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.978048780487805 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9896341463414634 with variance: 9.666864961332556e-06\n",
      "          test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "        Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9774050632911393 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9895155874079944 with variance: 1.0095973808490853e-05\n",
      "          test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "        Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "        Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.978048780487805 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9896341463414634 with variance: 9.666864961332556e-06\n",
      "          test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "        Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      f1\n",
      "        CV score: 0.9774050632911393 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9895155874079944 with variance: 1.0095973808490853e-05\n",
      "          test  score: 0.9774050632911393 with variance: 0.0001528841531805793\n",
      "        Refitted train score: 0.9851485148514851,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "        Refitted test  score: 0.9647058823529412,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.978048780487805 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9896341463414634 with variance: 9.666864961332556e-06\n",
      "          test  score: 0.978048780487805 with variance: 0.0001427721594289116\n",
      "        Refitted train score: 0.9853658536585366,  RMSE: 0.12097167578182678, Log-Loss:0.505445508218206\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9728592159014694 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9908366464161265 with variance: 5.999552955455369e-06\n",
      "          test  score: 0.9728592159014694 with variance: 0.0006281250998386371\n",
      "        Refitted train score: 0.9921671018276764,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702152\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.974025974025974 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9908879394221414 with variance: 5.875852473418774e-06\n",
      "          test  score: 0.974025974025974 with variance: 0.0005397200202395012\n",
      "        Refitted train score: 0.9921875,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702152\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      f1\n",
      "        CV score: 0.9728592159014694 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9908366464161265 with variance: 5.999552955455369e-06\n",
      "          test  score: 0.9728592159014694 with variance: 0.0006281250998386371\n",
      "        Refitted train score: 0.9921671018276764,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702152\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.974025974025974 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9908879394221414 with variance: 5.875852473418774e-06\n",
      "          test  score: 0.974025974025974 with variance: 0.0005397200202395012\n",
      "        Refitted train score: 0.9921875,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702152\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      f1\n",
      "        CV score: 0.9728592159014694 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9908366464161265 with variance: 5.999552955455369e-06\n",
      "          test  score: 0.9728592159014694 with variance: 0.0006281250998386371\n",
      "        Refitted train score: 0.9921671018276764,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702152\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.974025974025974 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9908879394221414 with variance: 5.875852473418774e-06\n",
      "          test  score: 0.974025974025974 with variance: 0.0005397200202395012\n",
      "        Refitted train score: 0.9921875,  RMSE: 0.08838834764831845, Log-Loss:0.2698362728702152\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#logistic parameters\n",
    "C = [1.0, 0.001, 1.5]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        random.seed(randomstate)\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "                     \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for c in C:            \n",
    "            lr = LogisticRegression(C = c, solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "\n",
    "            for b in bootstrap:\n",
    "                for bf in bootstrap_features:\n",
    "                    for n_estimator in n_estimators:\n",
    "                        for max_sample in max_samples:\n",
    "\n",
    "                            bc = BaggingClassifier(base_estimator = lr, bootstrap = b, bootstrap_features = bf, n_estimators = n_estimator, max_samples = max_sample, n_jobs = jobs, random_state = randomstate)\n",
    "                            cv_results = cross_validate(bc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "                                \n",
    "                            for score in scores:\n",
    "                                avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                                var_score_test = np.var(cv_results['test_' + score])\n",
    "                                avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                                var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                                if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                                    best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, c, b, bf, n_estimator, max_sample]\n",
    "\n",
    "            \n",
    "            for score in scores: \n",
    "            \n",
    "                print(tab * 3 + str(score))\n",
    "                print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "                print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "                print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "                lr = LogisticRegression(C = best_avg_scores[score][4], solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "                bc = BaggingClassifier(base_estimator = lr, bootstrap = best_avg_scores[score][5], bootstrap_features = best_avg_scores[score][6], n_estimators = best_avg_scores[score][7], max_samples = best_avg_scores[score][8], n_jobs = jobs, random_state = randomstate)\n",
    "                    \n",
    "                bc.fit(X_train, y_train)            \n",
    "                y_train_pred, y_test_pred = bc.predict(X_train), bc.predict(X_test)                          \n",
    "                rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "                log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "                score_train, score_test = get_scorer(score)(bc, X_train, y_train), get_scorer(score)(bc, X_test, y_test)\n",
    "\n",
    "                print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "                print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\") \n",
    "\n",
    "                n = len(results)\n",
    "                results.at[n, 'score'] = score\n",
    "                results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "                results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "                results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "                results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "                results.at[n, 'test rmse'] = rmse_test\n",
    "                results.at[n, 'train rmse'] = rmse_train\n",
    "                results.at[n, 'test log_loss'] = log_loss_test\n",
    "                results.at[n, 'train log_loss'] = log_loss_train\n",
    "                results.at[n, 'test size'] = testsize\n",
    "                results.at[n, 'random state'] = randomstate\n",
    "                results.at[n, 'estimator'] = \"Smote/Bagging/LogisticRegression\"\n",
    "                results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "262b0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.990888</td>\n",
       "      <td>0.00053972</td>\n",
       "      <td>5.87585e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.972859</td>\n",
       "      <td>0.990837</td>\n",
       "      <td>0.000628125</td>\n",
       "      <td>5.99955e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.990888</td>\n",
       "      <td>0.00053972</td>\n",
       "      <td>5.87585e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.972859</td>\n",
       "      <td>0.990837</td>\n",
       "      <td>0.000628125</td>\n",
       "      <td>5.99955e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.974026</td>\n",
       "      <td>0.990888</td>\n",
       "      <td>0.00053972</td>\n",
       "      <td>5.87585e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.269836</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "275  accuracy   0.974026    0.990888    0.00053972    5.87585e-06  0.124035   \n",
       "276        f1   0.972859    0.990837   0.000628125    5.99955e-06  0.124035   \n",
       "277  accuracy   0.974026    0.990888    0.00053972    5.87585e-06  0.124035   \n",
       "278        f1   0.972859    0.990837   0.000628125    5.99955e-06  0.124035   \n",
       "279  accuracy   0.974026    0.990888    0.00053972    5.87585e-06  0.124035   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "275  0.0883883      0.531366       0.269836       0.2         2050   \n",
       "276  0.0883883      0.531366       0.269836       0.2         2050   \n",
       "277  0.0883883      0.531366       0.269836       0.2         2050   \n",
       "278  0.0883883      0.531366       0.269836       0.2         2050   \n",
       "279  0.0883883      0.531366       0.269836       0.2         2050   \n",
       "\n",
       "                            estimator     estimator params  \n",
       "275  Smote/Bagging/LogisticRegression  1.0,True,True,2,0.8  \n",
       "276  Smote/Bagging/LogisticRegression  1.0,True,True,2,0.8  \n",
       "277  Smote/Bagging/LogisticRegression  1.0,True,True,2,0.8  \n",
       "278  Smote/Bagging/LogisticRegression  1.0,True,True,2,0.8  \n",
       "279  Smote/Bagging/LogisticRegression  1.0,True,True,2,0.8  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d31163d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9842174554534106 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9842174554534106 with variance: 0.0002881491974344508\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9846631629240324 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9846631629240324 with variance: 0.0002698778194737806\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9842668442668442 using:False,True,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9842668442668442 with variance: 0.00028860805577422393\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9444444444444444,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      accuracy\n",
      "        CV score: 0.9848761103319308 using:False,True,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9848761103319308 with variance: 0.000259400378683812\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.981969715677581 using:True,True,20,0.8,linear,1\n",
      "          train score: 0.9967331907816582 with variance: 7.114812577625485e-06\n",
      "          test  score: 0.981969715677581 with variance: 0.0003395276950960015\n",
      "        Refitted train score: 0.9978308026030369,  RMSE: 0.046524210519923545, Log-Loss:0.07475925626604142\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9826788218793828 using:True,True,20,0.8,linear,1\n",
      "          train score: 0.9967508972387021 with variance: 7.037807780608884e-06\n",
      "          test  score: 0.9826788218793828 with variance: 0.0003097946570306209\n",
      "        Refitted train score: 0.9978354978354979,  RMSE: 0.046524210519923545, Log-Loss:0.07475925626604142\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9800637325858459 using:False,True,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9800637325858459 with variance: 0.00017172368907934435\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9805516596540439 using:False,True,2,0.8,linear,1\n",
      "          train score: 0.9962103566981616 with variance: 1.772159799074355e-06\n",
      "          test  score: 0.9805516596540439 with variance: 0.00025116598376376183\n",
      "        Refitted train score: 0.9956709956709957,  RMSE: 0.0657951694959769, Log-Loss:0.14951851253208184\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9795572377942972 using:True,False,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9795572377942972 with variance: 0.00023995505732026583\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9802197802197803 using:True,False,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9802197802197803 with variance: 0.0002125347180292233\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9797230734309386 using:True,True,10,1.0,linear,1\n",
      "          train score: 0.9983286908077995 with variance: 1.1173097663735975e-05\n",
      "          test  score: 0.9797230734309386 with variance: 0.00012146728610367696\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9802197802197803 using:True,True,10,1.0,linear,1\n",
      "          train score: 0.9983471074380166 with variance: 1.0928215285841059e-05\n",
      "          test  score: 0.9802197802197803 with variance: 0.00011592802801594017\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.981915747088161 using:False,True,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.981915747088161 with variance: 0.00013699481476524077\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9824175824175825 using:False,True,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9824175824175825 with variance: 0.00012558869701726865\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9836898395721926 using:False,False,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9836898395721926 with variance: 0.0005293259744344992\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9843196004993757 using:False,False,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9843196004993757 with variance: 0.00048412393372204883\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9817653481737171 using:False,True,10,0.8,linear,1\n",
      "          train score: 0.9983286908077995 with variance: 1.8621829439559963e-06\n",
      "          test  score: 0.9817653481737171 with variance: 0.00013717050864561607\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9361702127659574,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "      accuracy\n",
      "        CV score: 0.9822222222222223 using:False,True,10,0.8,linear,1\n",
      "          train score: 0.9983333333333334 with variance: 1.8518518518518385e-06\n",
      "          test  score: 0.9822222222222223 with variance: 0.00012839506172839524\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1399129933988568\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9817089103736608 using:True,True,20,0.6,linear,1\n",
      "          train score: 0.9905383259002116 with variance: 8.282700625482116e-06\n",
      "          test  score: 0.9817089103736608 with variance: 0.000350595718441623\n",
      "        Refitted train score: 0.9889135254988914,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177106\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9823931623931624 using:True,True,20,0.6,linear,1\n",
      "          train score: 0.9906381497290588 with variance: 7.902689931405177e-06\n",
      "          test  score: 0.9823931623931624 with variance: 0.0003184824400941613\n",
      "        Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038476117177106\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 1050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9821178821178822 using:False,False,20,0.8,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9821178821178822 with variance: 0.0001283581553311823\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9823931623931624 using:True,True,30,0.6,linear,1\n",
      "          train score: 0.9873338782429691 with variance: 4.87714624817187e-06\n",
      "          test  score: 0.9823931623931624 with variance: 7.696571506095349e-05\n",
      "        Refitted train score: 0.9889867841409692,  RMSE: 0.10494387004027837, Log-Loss:0.38038299994395114\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9838502673796793 using:False,True,20,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9838502673796793 with variance: 0.00019493265463696395\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.962962962962963,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      accuracy\n",
      "        CV score: 0.9842696629213483 using:False,True,20,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9842696629213483 with variance: 0.00018179522787526835\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9794106468394423 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9794106468394423 with variance: 0.00012296150945358738\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9811320754716981,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "      accuracy\n",
      "        CV score: 0.9798501872659177 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9798501872659177 with variance: 0.00011919931546241366\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.0466538179497245\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.983743972093942 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.983743972093942 with variance: 0.00014471598837138234\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9840909090909091 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9840909090909091 with variance: 0.00013429752066115679\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9831283815318663 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9831283815318663 with variance: 0.00027565079997125114\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9473684210526315,  RMSE: 0.2857142857142857, Log-Loss:2.8195409055496605\n",
      "      accuracy\n",
      "        CV score: 0.983529411764706 using:False,True,10,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.983529411764706 with variance: 0.00025467128027681753\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195409055496605\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9784846950828523 using:False,True,2,0.6,linear,1\n",
      "          train score: 0.9899633756444917 with variance: 5.760814256403484e-06\n",
      "          test  score: 0.9784846950828523 with variance: 8.184858293474876e-05\n",
      "        Refitted train score: 0.9929411764705882,  RMSE: 0.08372183582789214, Log-Loss:0.2420942270671319\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9789876880984952 using:False,True,2,0.6,linear,1\n",
      "          train score: 0.9900687091879359 with variance: 5.4958550794800275e-06\n",
      "          test  score: 0.9789876880984952 with variance: 7.547407089963514e-05\n",
      "        Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.2420942270671319\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9807151669235298 using:True,False,20,0.6,linear,1\n",
      "          train score: 0.9863147172151112 with variance: 5.721333241453517e-06\n",
      "          test  score: 0.9807151669235298 with variance: 0.00010021743212565593\n",
      "        Refitted train score: 0.9857142857142858,  RMSE: 0.11867816581938534, Log-Loss:0.48646163936494013\n",
      "        Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9812311901504789 using:True,False,20,0.6,linear,1\n",
      "          train score: 0.9865050888390547 with variance: 5.4554518616444585e-06\n",
      "          test  score: 0.9812311901504789 with variance: 8.807828415621683e-05\n",
      "        Refitted train score: 0.9859154929577465,  RMSE: 0.11867816581938534, Log-Loss:0.48646163936494013\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9834733893557424 using:False,True,20,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9834733893557424 with variance: 0.00014474809531655734\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9705882352941176,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "      accuracy\n",
      "        CV score: 0.983827853515103 using:False,True,20,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.983827853515103 with variance: 0.00013790559697367933\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.409778611932282\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.982836495031617 using:False,True,10,0.8,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.982836495031617 with variance: 0.0002177161187450474\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.975,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      accuracy\n",
      "        CV score: 0.9833333333333334 using:False,True,10,0.8,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9833333333333334 with variance: 0.00020408163265306123\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.980952380952381 using:True,True,10,0.8,rbf,1\n",
      "          train score: 0.9845767562727161 with variance: 8.503226070069779e-06\n",
      "          test  score: 0.980952380952381 with variance: 9.070294784580434e-05\n",
      "        Refitted train score: 0.983372921615202,  RMSE: 0.12788721666732716, Log-Loss:0.5648865298233066\n",
      "        Refitted test  score: 0.9411764705882354,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9813406292749658 using:True,True,10,0.6,linear,1\n",
      "          train score: 0.9912382998312108 with variance: 3.4200126508759737e-06\n",
      "          test  score: 0.9813406292749658 with variance: 0.00014113754559183747\n",
      "        Refitted train score: 0.9953271028037384,  RMSE: 0.06835859270246632, Log-Loss:0.16139615137808827\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "    random state: 2050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9773128106461441 using:False,True,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9773128106461441 with variance: 0.0005029489717641053\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9767441860465116,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9781369379958861 using:False,True,30,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9781369379958861 with variance: 0.00044051466576007866\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.987079587079587 using:False,True,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.987079587079587 with variance: 0.0002681478805354932\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9607843137254902,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "      accuracy\n",
      "        CV score: 0.9874367088607595 using:False,True,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9874367088607595 with variance: 0.000251598301554238\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9772135670236937 using:True,False,2,0.6,rbf,1.5\n",
      "          train score: 0.9778459403823627 with variance: 3.258026756940686e-05\n",
      "          test  score: 0.9772135670236937 with variance: 8.977852236082419e-05\n",
      "        Refitted train score: 0.9746192893401014,  RMSE: 0.15732919388188815, Log-Loss:0.8549202077948196\n",
      "        Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "      accuracy\n",
      "        CV score: 0.977746913580247 using:True,False,2,0.6,rbf,1\n",
      "          train score: 0.9789645682834538 with variance: 3.964074238558482e-05\n",
      "          test  score: 0.977746913580247 with variance: 0.0002066796220088398\n",
      "        Refitted train score: 0.9727722772277227,  RMSE: 0.16500825061880156, Log-Loss:0.9404122285743016\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9796802986043491 using:True,False,10,1.0,linear,1\n",
      "          train score: 0.9949803828788866 with variance: 6.299197316965833e-06\n",
      "          test  score: 0.9796802986043491 with variance: 3.9186906462860475e-05\n",
      "        Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.17269588096812988\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.9800000000000001 using:True,False,10,1.0,linear,1\n",
      "          train score: 0.9949999999999999 with variance: 6.249999999999927e-06\n",
      "          test  score: 0.9800000000000001 with variance: 3.75000000000004e-05\n",
      "        Refitted train score: 0.995,  RMSE: 0.07071067811865475, Log-Loss:0.17269588096812988\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9849351461165806 using:True,False,2,1.0,linear,1\n",
      "          train score: 0.9937572675312808 with variance: 4.3659299690869184e-05\n",
      "          test  score: 0.9849351461165806 with variance: 0.00015447795809046737\n",
      "        Refitted train score: 0.9975308641975309,  RMSE: 0.049629166698546515, Log-Loss:0.08507087781997803\n",
      "        Refitted test  score: 0.9565217391304348,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "      accuracy\n",
      "        CV score: 0.9852152965974103 using:True,False,2,1.0,linear,1\n",
      "          train score: 0.9938347578347578 with variance: 4.193784141362472e-05\n",
      "          test  score: 0.9852152965974103 with variance: 0.0001464714837853993\n",
      "        Refitted train score: 0.9975369458128078,  RMSE: 0.049629166698546515, Log-Loss:0.08507087781997803\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254877657615876\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9789446343130553 using:True,False,10,1.0,linear,1\n",
      "          train score: 0.9967969198001146 with variance: 8.21829422634852e-06\n",
      "          test  score: 0.9789446343130553 with variance: 0.00031876824229840685\n",
      "        Refitted train score: 0.9948717948717948,  RMSE: 0.07142857142857142, Log-Loss:0.1762182469128106\n",
      "        Refitted test  score: 0.9811320754716981,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.9795845504706264 using:True,False,10,1.0,linear,1\n",
      "          train score: 0.9968112167029568 with variance: 8.13990875108353e-06\n",
      "          test  score: 0.9795845504706264 with variance: 0.00029897516592203066\n",
      "        Refitted train score: 0.9948979591836735,  RMSE: 0.07142857142857142, Log-Loss:0.1762182469128106\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9850617283950618 using:False,False,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9850617283950618 with variance: 8.781435756744405e-05\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9555555555555557,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "      accuracy\n",
      "        CV score: 0.9853658536585366 using:False,False,2,1.0,linear,1\n",
      "          train score: 1.0 with variance: 0.0\n",
      "          test  score: 0.9853658536585366 with variance: 8.328375966686511e-05\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1255000672605138\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9758308591992803 using:False,True,10,0.6,linear,1\n",
      "          train score: 0.9980284728213977 with variance: 6.919549967579294e-06\n",
      "          test  score: 0.9758308591992803 with variance: 0.000338688733437224\n",
      "        Refitted train score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.9766233766233766 using:True,False,10,0.8,linear,1\n",
      "          train score: 0.9921866407208426 with variance: 1.9533848714991336e-05\n",
      "          test  score: 0.9766233766233766 with variance: 0.0004992410187215385\n",
      "        Refitted train score: 0.9947916666666666,  RMSE: 0.07216878364870322, Log-Loss:0.17988946039016082\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#bagging svc\n",
    "kernels = ['linear', 'rbf']\n",
    "C = [0.001, 1, 1.5]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        random.seed(randomstate)\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "                     \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for kernel in kernels:\n",
    "            for c in C:\n",
    "                    \n",
    "                svc = SVC(kernel = kernel, C = c, max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "\n",
    "                for b in bootstrap:\n",
    "                    for bf in bootstrap_features:\n",
    "                        for n_estimator in n_estimators:\n",
    "                            for max_sample in max_samples:\n",
    "\n",
    "                                random.seed(randomstate)\n",
    "                                bc = BaggingClassifier(base_estimator = svc, bootstrap = b, bootstrap_features = bf, n_estimators = n_estimator, max_samples = max_sample, n_jobs = jobs, random_state = randomstate)\n",
    "                                cv_results = cross_validate(bc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "\n",
    "                                for score in scores:\n",
    "                                    avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                                    var_score_test = np.var(cv_results['test_' + score])\n",
    "                                    avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                                    var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                                    if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                                        best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, b, bf, n_estimator, max_sample, kernel, c]\n",
    "\n",
    "\n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 3 + str(score))\n",
    "            print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            svc = SVC(kernel = best_avg_scores[score][8], C = best_avg_scores[score][9], max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "            bc = BaggingClassifier(base_estimator = svc, bootstrap = best_avg_scores[score][4], bootstrap_features = best_avg_scores[score][5], n_estimators = best_avg_scores[score][6], max_samples = best_avg_scores[score][7], n_jobs = jobs, random_state = randomstate)\n",
    "            \n",
    "            bc.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = bc.predict(X_train), bc.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(bc, X_train, y_train), get_scorer(score)(bc, X_test, y_test)\n",
    "            \n",
    "            print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")            \n",
    "            \n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/Bagging/SVC\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "945c51ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.979585</td>\n",
       "      <td>0.996811</td>\n",
       "      <td>0.000298975</td>\n",
       "      <td>8.13991e-06</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.0714286</td>\n",
       "      <td>1.06274</td>\n",
       "      <td>0.176218</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1250</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>True,False,10,1.0,linear,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.985062</td>\n",
       "      <td>1</td>\n",
       "      <td>8.78144e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1255</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>False,False,2,1.0,linear,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.985366</td>\n",
       "      <td>1</td>\n",
       "      <td>8.32838e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0</td>\n",
       "      <td>2.1255</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>False,False,2,1.0,linear,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.975831</td>\n",
       "      <td>0.998028</td>\n",
       "      <td>0.000338689</td>\n",
       "      <td>6.91955e-06</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>False,True,10,0.6,linear,1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.976623</td>\n",
       "      <td>0.992187</td>\n",
       "      <td>0.000499241</td>\n",
       "      <td>1.95338e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.0721688</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>0.179889</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>True,False,10,0.8,linear,1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "331  accuracy   0.979585    0.996811   0.000298975    8.13991e-06  0.175412   \n",
       "332        f1   0.985062           1   8.78144e-05              0  0.248069   \n",
       "333  accuracy   0.985366           1   8.32838e-05              0  0.248069   \n",
       "334        f1   0.975831    0.998028   0.000338689    6.91955e-06  0.124035   \n",
       "335  accuracy   0.976623    0.992187   0.000499241    1.95338e-05  0.124035   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "331  0.0714286       1.06274       0.176218       0.2         1250   \n",
       "332          0        2.1255    9.99201e-16       0.2         1850   \n",
       "333          0        2.1255    9.99201e-16       0.2         1850   \n",
       "334          0      0.531366    9.99201e-16       0.2         2050   \n",
       "335  0.0721688      0.531366       0.179889       0.2         2050   \n",
       "\n",
       "             estimator            estimator params  \n",
       "331  Smote/Bagging/SVC  True,False,10,1.0,linear,1  \n",
       "332  Smote/Bagging/SVC  False,False,2,1.0,linear,1  \n",
       "333  Smote/Bagging/SVC  False,False,2,1.0,linear,1  \n",
       "334  Smote/Bagging/SVC  False,True,10,0.6,linear,1  \n",
       "335  Smote/Bagging/SVC  True,False,10,0.8,linear,1  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "53c1a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(path + \"classification-results-4.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "classification-7 (17.6.22).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
