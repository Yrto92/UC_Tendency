{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c32e90fa",
   "metadata": {
    "id": "c32e90fa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import random\n",
    "import math\n",
    "\n",
    "from numpy import mean, std\n",
    "from scipy import stats\n",
    "import scipy as sp\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV,  cross_val_score, RepeatedStratifiedKFold, cross_validate\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier, BaggingClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import get_scorer, make_scorer, confusion_matrix, classification_report, recall_score, precision_score, accuracy_score, fbeta_score, roc_curve, roc_auc_score, f1_score, confusion_matrix, mean_squared_error, log_loss\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler, LabelEncoder, RobustScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "\n",
    "from warnings import simplefilter\n",
    "import imblearn\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "\n",
    "\n",
    "simplefilter(\"ignore\", category = ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vxMsA1bZQENI",
   "metadata": {
    "id": "vxMsA1bZQENI"
   },
   "outputs": [],
   "source": [
    "class KidronClassifier:\n",
    "    \n",
    "    def __init__(self, min_rows = None, min_columns = None, max_estimators = None, estimators = None, base_estimator = None, random_state = None):\n",
    "\n",
    "        self.min_rows = min_rows\n",
    "        self.min_columns = min_columns\n",
    "        self.max_estimators = max_estimators\n",
    "        self.estimators = estimators\n",
    "        self.base_estimator = base_estimator \n",
    "        self.random_state = random_state \n",
    "        #self.fitted_estimators = None\n",
    "        #self.fitted_columns = None        \n",
    "        return\n",
    "             \n",
    "    def get_params(self, deep = True):\n",
    "        return {\"min_rows\": self.min_rows, \n",
    "                \"min_columns\": self.min_columns,\n",
    "                \"max_estimators\": self.max_estimators,\n",
    "                \"estimators\": self.estimators,\n",
    "                \"base_estimator\": self.base_estimator,\n",
    "                \"random_state\": self.random_state}\n",
    "    \n",
    "    def set_params(self, **parameters):\n",
    "        for parameter, value in parameters.items():\n",
    "            setattr(self, parameter, value)\n",
    "        return self\n",
    "\n",
    "    #build training data for a single model\n",
    "    def even_data(self, dict_X, length, width, seed):     \n",
    "        \n",
    "        labels = dict_X.keys()          \n",
    "        X = pd.concat([dict_X[label].sample(n = length, random_state = seed) for label in labels]) #length\n",
    "        \n",
    "        random.seed(seed)\n",
    "        columns = random.sample(range(len(X.columns)), width)\n",
    "        X = X.iloc[:, columns]\n",
    "        \n",
    "        y = []\n",
    "        for label in labels:\n",
    "            y.extend([label] * length)\n",
    "        \n",
    "        return X, y, columns\n",
    "\n",
    "    #fit \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #label encoding\n",
    "        self.le = LabelEncoder()\n",
    "        self.le.fit(y)\n",
    "        \n",
    "        #X = pd.DataFrame(X)\n",
    "        \n",
    "        length = X.shape[0] #len(X);\n",
    "        width  = X.shape[1] #len(X.columns)\n",
    "        col = min([int(width  ** 0.5) + 1, width])\n",
    "        row = min([int(length ** 0.5) + 1, length])            \n",
    "        estimators = row * col\n",
    "        \n",
    "        if(self.max_estimators):\n",
    "            estimators = min([estimators, self.max_estimators])\n",
    "            \n",
    "        if(self.estimators is None):\n",
    "            if(self.base_estimator):\n",
    "                self.estimators = [clone(self.base_estimator) for i in range(estimators)]\n",
    "            else:\n",
    "                self.estimators = [LogisticRegression() for i in range(estimators)]  #default\n",
    "                                \n",
    "        dict_X = {}\n",
    "        for label in self.le.classes_:\n",
    "            dict_X[label] = X[y == label]\n",
    "            \n",
    "        rows = min([len(dict_X[label]) for label in dict_X.keys()])  #maximal length available  \n",
    "        rows = min(row, length)\n",
    "        if(self.min_rows):\n",
    "            rows = max([self.min_rows, rows])\n",
    "            \n",
    "        cols = col\n",
    "        if(self.min_columns):\n",
    "            cols = max([self.min_columns, cols])\n",
    "        \n",
    "        seed, self.fitted_estimators, self.fitted_columns = 0, [], []\n",
    "        #print(len(self.estimators))\n",
    "        \n",
    "        for estimator in self.estimators:\n",
    "\n",
    "            #get a balanced data\n",
    "            X_train, y_train, fitted_columns = self.even_data(dict_X, rows, cols, seed)\n",
    "            \n",
    "            #fit\n",
    "            fitted_estimator = estimator.fit(X_train, y_train)\n",
    "            \n",
    "            #save fitted\n",
    "            self.fitted_estimators.append(fitted_estimator)\n",
    "            self.fitted_columns.append(fitted_columns)\n",
    "            \n",
    "            seed += 1\n",
    "        return\n",
    "    \n",
    "    #predict_proba\n",
    "    def predict_proba(self, X):\n",
    "\n",
    "        length = len(X)\n",
    "        labels = len(self.le.classes_)\n",
    "        \n",
    "        pred = []\n",
    "        \n",
    "        # Predict 'soft' voting with probabilities\n",
    "        predict_proba = []\n",
    "        for fitted_estimator, fitted_columns in zip(self.fitted_estimators, self.fitted_columns):             \n",
    "            fitted_X = X.iloc[:, fitted_columns]\n",
    "            predict_proba.append(np.asarray(fitted_estimator.predict_proba(fitted_X)).reshape(length * labels, 1))\n",
    "            \n",
    "        predict_proba = np.concatenate(predict_proba, axis = 1)\n",
    "        predict_proba = np.average(predict_proba, axis = 1).reshape(length, labels)\n",
    "            \n",
    "        # Convert integer predictions to original labels:\n",
    "        return predict_proba\n",
    "    \n",
    "    #predict\n",
    "    def predict(self, X):\n",
    "            \n",
    "        proba = self.predict_proba(X)\n",
    "        \n",
    "        # Convert integer predictions to original labels:\n",
    "        return self.le.inverse_transform(np.argmax(proba, axis = 1))\n",
    "    \n",
    "    #predict, old slow version\n",
    "    def predict_slow(self, X):\n",
    "\n",
    "        pred = []\n",
    "        for i in range(len(X)):\n",
    "\n",
    "            # Predict 'soft' voting with probabilities\n",
    "            x = X[i : i + 1]\n",
    "            predict_proba = np.asarray([estimator.predict_proba(x) for estimator in self.fitted_estimators])\n",
    "            predict_proba = np.average(predict_proba, axis = 0)\n",
    "        \n",
    "            #the indice of the average\n",
    "            pred.append(np.argmax(predict_proba, axis = 1)[0])        \n",
    "\n",
    "        # Convert integer predictions to original labels:\n",
    "        return self.le.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e97763",
   "metadata": {
    "id": "b4e97763"
   },
   "outputs": [],
   "source": [
    "path = \"/Users/yaeerk/Documents/NAYA/classification/\"\n",
    "jobs = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be32050a",
   "metadata": {
    "id": "be32050a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(path + 'PROTECT_and_RISK_shared_DEGs_NOT NORM.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40272eb6",
   "metadata": {
    "id": "40272eb6"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-0f7257603c88>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Diagnosis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDiagnosis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLabelEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnumerical_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "X = df.drop('Diagnosis', axis = 1)\n",
    "y = df.Diagnosis\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "numerical_cols = X.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa04d5bd",
   "metadata": {
    "id": "aa04d5bd"
   },
   "outputs": [],
   "source": [
    "tab = \"  \"\n",
    "testsizes = [0.08, 0.1, 0.15, 0.2]\n",
    "#randomstates = [132, 400, 1440, 1600, 2500, 3333, 4567]\n",
    "randomstates = [250, 650, 850, 1050, 1250, 1850, 2050]\n",
    "features = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e04e8150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dominant_features(X_train, X_test, y_train, t, n):\n",
    "    genes = {}\n",
    "    for r in randomstates:\n",
    "        #X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = t, random_state = r)\n",
    "\n",
    "        for depth in range(2, 6, 2):\n",
    "            dtc = DecisionTreeClassifier(max_depth = depth).fit(X_train, y_train)\n",
    "            sort_arr = np.argsort(dtc.feature_importances_)\n",
    "\n",
    "            for i in range(-3, -1, 1):\n",
    "                gene  = X.columns[sort_arr[i]]\n",
    "                value = dtc.feature_importances_[sort_arr[i]]\n",
    "                if(value <= 0):\n",
    "                    continue\n",
    "\n",
    "                if(gene in genes):\n",
    "                    genes[gene] += value\n",
    "                else:\n",
    "                    genes[gene] = value\n",
    "\n",
    "    features = [(k, v) for k, v in sorted(genes.items(), reverse = True, key = lambda item: item[1])]\n",
    "    feature_names = [k for k, v in features]\n",
    "    feature_names = feature_names[:n]\n",
    "    \n",
    "    return X_train.drop(X_train.columns.difference(feature_names), 1), X_test.drop(X_test.columns.difference(feature_names), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bb47e947",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop all features, except to 50\n",
    "#feature_names = [k for k, v in features]\n",
    "#feature_names = feature_names[:50]\n",
    "#X.drop(X.columns.difference(feature_names), 1, inplace = True)\n",
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44b49851",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [score, test score, train score, test variance, train variance, test rmse, train rmse, test log_loss, train log_loss, test size, random state, estimator, estimator params]\n",
       "Index: []"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bagging parameters\n",
    "n_estimators = [2, 10, 20, 30]\n",
    "max_samples = [0.6, 0.8, 1.0]\n",
    "bootstrap = [True, False]\n",
    "bootstrap_features = [True, False]\n",
    "\n",
    "#cross validation\n",
    "cv = 5\n",
    "\n",
    "#scores we want\n",
    "scores = ['f1', 'accuracy']\n",
    "\n",
    "results = pd.DataFrame(columns = [\"score\", \"test score\", \"train score\", \"test variance\", \"train variance\", \"test rmse\", \"train rmse\", \"test log_loss\", \"train log_loss\", \"test size\", \"random state\", \"estimator\", \"estimator params\"])\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b845754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9728516419814245 using:10,3\n",
      "          train score: 0.9911814199399192 with variance: 1.0487225559813789e-05\n",
      "          test  score: 0.9728516419814245 with variance: 0.0005720398485385564\n",
      "        Refitted train score: 0.9911894273127753,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "        Refitted test  score: 0.9500000000000001,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "      accuracy\n",
      "        CV score: 0.9737219302436694 using:10,3\n",
      "          train score: 0.9912657643572906 with variance: 1.0146220192779643e-05\n",
      "          test  score: 0.9737219302436694 with variance: 0.0005118248460445013\n",
      "        Refitted train score: 0.9912663755458515,  RMSE: 0.09345386270319955, Log-Loss:0.30164870213895895\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9596336205497238 using:10,10\n",
      "          train score: 0.9712388159525529 with variance: 0.00011306704222007347\n",
      "          test  score: 0.9596336205497238 with variance: 0.0013958881283503764\n",
      "        Refitted train score: 0.9713024282560706,  RMSE: 0.16774542658006547, Log-Loss:0.9718737929192632\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      accuracy\n",
      "        CV score: 0.9611266947171575 using:10,10\n",
      "          train score: 0.971869918699187 with variance: 0.0001069167757721862\n",
      "          test  score: 0.9611266947171575 with variance: 0.0012260975787272636\n",
      "        Refitted train score: 0.9718614718614719,  RMSE: 0.16774542658006547, Log-Loss:0.9718737929192632\n",
      "        Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.929255655425286 using:10,3\n",
      "          train score: 0.9632195219034483 with variance: 3.7788012697867475e-05\n",
      "          test  score: 0.929255655425286 with variance: 0.0005415005036251048\n",
      "        Refitted train score: 0.9667405764966741,  RMSE: 0.1801874925391118, Log-Loss:1.121392305451344\n",
      "        Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      accuracy\n",
      "        CV score: 0.9329125759700794 using:10,3\n",
      "          train score: 0.9642862374569692 with variance: 3.3285843576800675e-05\n",
      "          test  score: 0.9329125759700794 with variance: 0.0004421383767390305\n",
      "        Refitted train score: 0.9675324675324676,  RMSE: 0.1801874925391118, Log-Loss:1.121392305451344\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.976148509512354 using:10,3\n",
      "          train score: 0.9831416629730843 with variance: 4.1668809454718224e-06\n",
      "          test  score: 0.976148509512354 with variance: 0.00015569299565102972\n",
      "        Refitted train score: 0.9847494553376906,  RMSE: 0.12309149097933274, Log-Loss:0.5233182553230208\n",
      "        Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      accuracy\n",
      "        CV score: 0.9762505843852267 using:10,3\n",
      "          train score: 0.9832271295685932 with variance: 4.033960376978107e-06\n",
      "          test  score: 0.9762505843852267 with variance: 0.00015584371020087903\n",
      "        Refitted train score: 0.9848484848484849,  RMSE: 0.12309149097933274, Log-Loss:0.5233182553230208\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9728671778240632 using:10,3\n",
      "          train score: 0.9848987868649595 with variance: 8.37608790995123e-06\n",
      "          test  score: 0.9728671778240632 with variance: 0.00014116187383791706\n",
      "        Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327413\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9736019536019537 using:10,3\n",
      "          train score: 0.9851345624072897 with variance: 7.799645434737628e-06\n",
      "          test  score: 0.9736019536019537 with variance: 0.00012483969700086896\n",
      "        Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.4564595999327413\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9665867465867466 using:10,3\n",
      "          train score: 0.9905414464954957 with variance: 8.25543938031767e-06\n",
      "          test  score: 0.9665867465867466 with variance: 0.0005828467680615549\n",
      "        Refitted train score: 0.9911111111111112,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 0.9767441860465117,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9670329670329672 using:10,3\n",
      "          train score: 0.9906381497290588 with variance: 7.902689931405177e-06\n",
      "          test  score: 0.9670329670329672 with variance: 0.0005796401400797003\n",
      "        Refitted train score: 0.9911894273127754,  RMSE: 0.09386465089278642, Log-Loss:0.30430639995516123\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9796691048415187 using:10,3\n",
      "          train score: 0.9922190157463346 with variance: 1.0618347701680408e-05\n",
      "          test  score: 0.9796691048415187 with variance: 0.00032283434399241526\n",
      "        Refitted train score: 0.9955752212389382,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9802197802197803 using:10,3\n",
      "          train score: 0.9922910422910423 with variance: 1.0316170932414183e-05\n",
      "          test  score: 0.9802197802197803 with variance: 0.0003091414080425065\n",
      "        Refitted train score: 0.9955947136563876,  RMSE: 0.0663723311599972, Log-Loss:0.15215319997758112\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9744255361496741 using:10,3\n",
      "          train score: 0.9904064684403554 with variance: 1.4853109130988078e-05\n",
      "          test  score: 0.9744255361496741 with variance: 0.0005948497490806941\n",
      "        Refitted train score: 0.9887133182844243,  RMSE: 0.10564428184106457, Log-Loss:0.3854774151217719\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9753807740324595 using:10,3\n",
      "          train score: 0.9905090179113303 with variance: 1.4387984882114426e-05\n",
      "          test  score: 0.9753807740324595 with variance: 0.0005256500535379472\n",
      "        Refitted train score: 0.9888392857142857,  RMSE: 0.10564428184106457, Log-Loss:0.3854774151217719\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9679444956766143 using:10,3\n",
      "          train score: 0.991061426360121 with variance: 4.369591650932502e-06\n",
      "          test  score: 0.9679444956766143 with variance: 0.0006506845394961827\n",
      "        Refitted train score: 0.9910714285714286,  RMSE: 0.09428090415820634, Log-Loss:0.30701312261571856\n",
      "        Refitted test  score: 0.9333333333333333,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      accuracy\n",
      "        CV score: 0.9688888888888888 using:10,3\n",
      "          train score: 0.9911111111111112 with variance: 4.320987654320957e-06\n",
      "          test  score: 0.9688888888888888 with variance: 0.0005629629629629619\n",
      "        Refitted train score: 0.9911111111111112,  RMSE: 0.09428090415820634, Log-Loss:0.30701312261571856\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9290294533255536 using:10,3\n",
      "          train score: 0.9665384668723526 with variance: 3.225769278950376e-05\n",
      "          test  score: 0.9290294533255536 with variance: 0.0006370869618748853\n",
      "        Refitted train score: 0.9659863945578231,  RMSE: 0.18176811485266747, Log-Loss:1.1411507610596714\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.186566811348581\n",
      "      accuracy\n",
      "        CV score: 0.9317948717948716 using:10,3\n",
      "          train score: 0.9675097629643084 with variance: 2.8609281752832233e-05\n",
      "          test  score: 0.9317948717948716 with variance: 0.0005455272444283432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411507610596714\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.186566811348581\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.978017695272214 using:10,3\n",
      "          train score: 0.9854748167454529 with variance: 4.369961803331331e-06\n",
      "          test  score: 0.978017695272214 with variance: 0.0005167040110722067\n",
      "        Refitted train score: 0.9866071428571429,  RMSE: 0.11496024978590211, Log-Loss:0.45645959993274116\n",
      "        Refitted test  score: 0.9565217391304348,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "      accuracy\n",
      "        CV score: 0.977997557997558 using:10,3\n",
      "          train score: 0.9856840129567402 with variance: 4.21016132577297e-06\n",
      "          test  score: 0.977997557997558 with variance: 0.0005308024765900224\n",
      "        Refitted train score: 0.986784140969163,  RMSE: 0.11496024978590211, Log-Loss:0.45645959993274116\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093307635899448\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.8407489400484639 using:20,3\n",
      "          train score: 0.9312039733627963 with variance: 3.705237671479858e-05\n",
      "          test  score: 0.8407489400484639 with variance: 0.002429937883421133\n",
      "        Refitted train score: 0.9265033407572383,  RMSE: 0.27201292504242247, Log-Loss:2.5555919591609784\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.3481553119113957, Log-Loss:4.18656681134858\n",
      "      accuracy\n",
      "        CV score: 0.8453932584269663 using:10,3\n",
      "          train score: 0.92993264721619 with variance: 3.139129410028853e-05\n",
      "          test  score: 0.8453932584269663 with variance: 0.0018470395152127238\n",
      "        Refitted train score: 0.9237668161434978,  RMSE: 0.276103574508738, Log-Loss:2.6330277833821\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.18656681134858\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9727237504843084 using:10,3\n",
      "          train score: 0.9886780403265639 with variance: 3.121420368485307e-06\n",
      "          test  score: 0.9727237504843084 with variance: 0.0005995017951164561\n",
      "        Refitted train score: 0.9932279909706546,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751675\n",
      "        Refitted test  score: 0.9803921568627451,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.973158551810237 using:10,3\n",
      "          train score: 0.9887892235545903 with variance: 3.1386687966932745e-06\n",
      "          test  score: 0.973158551810237 with variance: 0.0005785527142258197\n",
      "        Refitted train score: 0.9932735426008968,  RMSE: 0.08201498277207123, Log-Loss:0.23232360803751675\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9813368983957218 using:10,3\n",
      "          train score: 0.993709373720835 with variance: 1.3286737869012383e-06\n",
      "          test  score: 0.9813368983957218 with variance: 0.0002532643198261315\n",
      "        Refitted train score: 0.995433789954338,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868588\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9818181818181818 using:10,3\n",
      "          train score: 0.99375 with variance: 1.291322314049559e-06\n",
      "          test  score: 0.9818181818181818 with variance: 0.00023760330578512356\n",
      "        Refitted train score: 0.9954545454545455,  RMSE: 0.06741998624632421, Log-Loss:0.15699443815868588\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9457642771153878 using:10,3\n",
      "          train score: 0.9759058137928058 with variance: 4.093874280217448e-05\n",
      "          test  score: 0.9457642771153878 with variance: 0.001453021680628812\n",
      "        Refitted train score: 0.9807692307692307,  RMSE: 0.13736056394868904, Log-Loss:0.6516750263190705\n",
      "        Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      accuracy\n",
      "        CV score: 0.9480112044817928 using:10,3\n",
      "          train score: 0.9764185320145758 with variance: 3.808363133404504e-05\n",
      "          test  score: 0.9480112044817928 with variance: 0.0012703936476551408\n",
      "        Refitted train score: 0.9811320754716981,  RMSE: 0.13736056394868904, Log-Loss:0.6516750263190705\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9713124274099885 using:10,3\n",
      "          train score: 0.9893700375893143 with variance: 9.115844579446632e-06\n",
      "          test  score: 0.9713124274099885 with variance: 8.965077206770077e-05\n",
      "        Refitted train score: 0.9905660377358491,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "        Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      accuracy\n",
      "        CV score: 0.9719835841313269 using:10,3\n",
      "          train score: 0.9894873237515558 with variance: 8.840086688756017e-06\n",
      "          test  score: 0.9719835841313269 with variance: 8.55331882379136e-05\n",
      "        Refitted train score: 0.9906542056074766,  RMSE: 0.09667364890456635, Log-Loss:0.32279230275617554\n",
      "        Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9834609757668996 using:10,3\n",
      "          train score: 0.9905464049541457 with variance: 1.335859986935917e-06\n",
      "          test  score: 0.9834609757668996 with variance: 3.3138373674127075e-05\n",
      "        Refitted train score: 0.9881796690307328,  RMSE: 0.10833784750435987, Log-Loss:0.4053865764600563\n",
      "        Refitted test  score: 0.9577464788732395,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "      accuracy\n",
      "        CV score: 0.9835567715458277 using:10,3\n",
      "          train score: 0.990610660686562 with variance: 1.3700137975633508e-06\n",
      "          test  score: 0.9835567715458277 with variance: 3.347849113239953e-05\n",
      "        Refitted train score: 0.9882629107981221,  RMSE: 0.10833784750435987, Log-Loss:0.4053865764600563\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.114635281268618\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9742773131706572 using:10,3\n",
      "          train score: 0.9900772339010793 with variance: 8.836063636911685e-06\n",
      "          test  score: 0.9742773131706572 with variance: 0.00023557918642402742\n",
      "        Refitted train score: 0.9906542056074767,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9746057203956161 using:10,3\n",
      "          train score: 0.990161682164698 with variance: 8.737856657731991e-06\n",
      "          test  score: 0.9746057203956161 with variance: 0.0002320529620371617\n",
      "        Refitted train score: 0.9907407407407407,  RMSE: 0.09622504486493763, Log-Loss:0.31980348513806284\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.8336143021274143 using:10,3\n",
      "          train score: 0.9318157026451743 with variance: 3.406904104759105e-05\n",
      "          test  score: 0.8336143021274143 with variance: 0.0007115725592704826\n",
      "        Refitted train score: 0.9304556354916068,  RMSE: 0.2627691364061218, Log-Loss:2.3848450243309585\n",
      "        Refitted test  score: 0.935064935064935,  RMSE: 0.31943828249996997, Log-Loss:3.5243975748859966\n",
      "      accuracy\n",
      "        CV score: 0.8404761904761905 using:10,10\n",
      "          train score: 0.875 with variance: 8.857709750566831e-05\n",
      "          test  score: 0.8404761904761905 with variance: 0.0006575963718820855\n",
      "        Refitted train score: 0.8738095238095238,  RMSE: 0.3552329886011098, Log-Loss:4.358510331591884\n",
      "        Refitted test  score: 0.8571428571428571,  RMSE: 0.3779644730092272, Log-Loss:4.934159868503376\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9694638785746857 using:10,3\n",
      "          train score: 0.992357852546019 with variance: 9.130170057570313e-06\n",
      "          test  score: 0.9694638785746857 with variance: 0.0005169367947605352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9929742388758782,  RMSE: 0.08372183582789214, Log-Loss:0.24209609528542675\n",
      "        Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      accuracy\n",
      "        CV score: 0.9697127222982216 using:10,3\n",
      "          train score: 0.9924061855318568 with variance: 8.89174104660931e-06\n",
      "          test  score: 0.9697127222982216 with variance: 0.0005184480154801715\n",
      "        Refitted train score: 0.9929906542056075,  RMSE: 0.08372183582789214, Log-Loss:0.24209609528542675\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9778771039592584 using:10,3\n",
      "          train score: 0.9920450969929601 with variance: 2.3002379381041806e-06\n",
      "          test  score: 0.9778771039592584 with variance: 0.00020361089498059979\n",
      "        Refitted train score: 0.9926650366748166,  RMSE: 0.08533201859828615, Log-Loss:0.251495944623137\n",
      "        Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      accuracy\n",
      "        CV score: 0.9781957096679401 using:10,3\n",
      "          train score: 0.9921120014737037 with variance: 2.2039924869553113e-06\n",
      "          test  score: 0.9781957096679401 with variance: 0.00019942818945341235\n",
      "        Refitted train score: 0.9927184466019418,  RMSE: 0.08533201859828615, Log-Loss:0.251495944623137\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9720603316238746 using:10,3\n",
      "          train score: 0.9936748160638993 with variance: 4.057058027370111e-06\n",
      "          test  score: 0.9720603316238746 with variance: 0.0002688712348226303\n",
      "        Refitted train score: 0.9898477157360407,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "        Refitted test  score: 0.9215686274509804,  RMSE: 0.35082320772281167, Log-Loss:4.250987833022099\n",
      "      accuracy\n",
      "        CV score: 0.9723417721518987 using:10,3\n",
      "          train score: 0.9937185781037441 with variance: 3.955633023511302e-06\n",
      "          test  score: 0.9723417721518987 with variance: 0.0002766223361640765\n",
      "        Refitted train score: 0.9899497487437185,  RMSE: 0.1002509414234171, Log-Loss:0.34712338085337463\n",
      "        Refitted test  score: 0.8769230769230769,  RMSE: 0.35082320772281167, Log-Loss:4.250987833022099\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9478889970704204 using:10,10\n",
      "          train score: 0.9573583020950889 with variance: 5.1449550620876776e-05\n",
      "          test  score: 0.9478889970704204 with variance: 0.0005603994618516743\n",
      "        Refitted train score: 0.9587628865979382,  RMSE: 0.19900743804199783, Log-Loss:1.367872332471711\n",
      "        Refitted test  score: 0.945054945054945,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "      accuracy\n",
      "        CV score: 0.9504012345679012 using:10,3\n",
      "          train score: 0.977097427665023 with variance: 5.6137933939587106e-05\n",
      "          test  score: 0.9504012345679012 with variance: 0.0003819882639841483\n",
      "        Refitted train score: 0.9752475247524752,  RMSE: 0.15732919388188815, Log-Loss:0.8549202077948199\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9775795880699037 using:10,3\n",
      "          train score: 0.9887106545071178 with variance: 2.2959099523732493e-06\n",
      "          test  score: 0.9775795880699037 with variance: 7.919596925989931e-05\n",
      "        Refitted train score: 0.9874686716791979,  RMSE: 0.11180339887498948, Log-Loss:0.4317387029235354\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "      accuracy\n",
      "        CV score: 0.9775 using:10,3\n",
      "          train score: 0.9887500000000001 with variance: 2.3437499999999003e-06\n",
      "          test  score: 0.9775 with variance: 8.750000000000027e-05\n",
      "        Refitted train score: 0.9875,  RMSE: 0.11180339887498948, Log-Loss:0.4317387029235354\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062743882880794\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9772760767908448 using:10,3\n",
      "          train score: 0.9925542160312524 with variance: 2.3344813333115038e-06\n",
      "          test  score: 0.9772760767908448 with variance: 9.106037573322708e-05\n",
      "        Refitted train score: 0.9900497512437811,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "        Refitted test  score: 0.9777777777777777,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.9778380006022281 using:10,3\n",
      "          train score: 0.9926115859449192 with variance: 2.2628964952485195e-06\n",
      "          test  score: 0.9778380006022281 with variance: 8.506995304487478e-05\n",
      "        Refitted train score: 0.9901477832512315,  RMSE: 0.09925833339709303, Log-Loss:0.34028351127990913\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.961299326922245 using:10,3\n",
      "          train score: 0.978657304306519 with variance: 2.807008666118298e-05\n",
      "          test  score: 0.961299326922245 with variance: 0.0005955867970780026\n",
      "        Refitted train score: 0.9819121447028423,  RMSE: 0.1336306209562122, Log-Loss:0.6167659039841973\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9617656604998377 using:10,3\n",
      "          train score: 0.9789544372316396 with variance: 2.6818553953270563e-05\n",
      "          test  score: 0.9617656604998377 with variance: 0.0005785435563700886\n",
      "        Refitted train score: 0.9821428571428571,  RMSE: 0.1336306209562122, Log-Loss:0.6167659039841973\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9725146740809393 using:10,3\n",
      "          train score: 0.9932382618073319 with variance: 9.215163826367412e-06\n",
      "          test  score: 0.9725146740809393 with variance: 0.00028181272415056416\n",
      "        Refitted train score: 0.9926289926289926,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "        Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "      accuracy\n",
      "        CV score: 0.9731707317073169 using:10,3\n",
      "          train score: 0.9932926829268294 with variance: 8.923259964306977e-06\n",
      "          test  score: 0.9731707317073169 with variance: 0.0002617489589530046\n",
      "        Refitted train score: 0.9926829268292683,  RMSE: 0.08553989227683016, Log-Loss:0.2527227541091035\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9807206877629412 using:10,3\n",
      "          train score: 0.9907849033301277 with variance: 1.059540760245065e-05\n",
      "          test  score: 0.9807206877629412 with variance: 0.0006876398153123806\n",
      "        Refitted train score: 0.9921259842519685,  RMSE: 0.08838834764831845, Log-Loss:0.26983419058524066\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9818181818181818 using:10,3\n",
      "          train score: 0.9908858242734464 with variance: 1.0177677841105461e-05\n",
      "          test  score: 0.9818181818181818 with variance: 0.0005801990217574637\n",
      "        Refitted train score: 0.9921875,  RMSE: 0.08838834764831845, Log-Loss:0.26983419058524066\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n"
     ]
    }
   ],
   "source": [
    "#random forest\n",
    "max_depths = [10, 20, 30]\n",
    "min_samples_leafs = [3, 10]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "\n",
    "\n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "        X_train, X_test = dominant_features(X_train, X_test, y_train, testsize, features)\n",
    "\n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for max_depth in max_depths:\n",
    "            for min_samples_leaf in min_samples_leafs:\n",
    "                    \n",
    "                rf = RandomForestClassifier(max_depth = max_depth, min_samples_leaf = min_samples_leaf, random_state = randomstate)\n",
    "                cv_results = cross_validate(rf, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    " \n",
    "                for score in scores:\n",
    "                    avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                    var_score_test = np.var(cv_results['test_' + score])\n",
    "                    avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                    var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                    if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                        best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, max_depth, min_samples_leaf]\n",
    "\n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 3 + str(score))\n",
    "            print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            rf = RandomForestClassifier(max_depth = best_avg_scores[score][4], min_samples_leaf = best_avg_scores[score][5], random_state = randomstate)\n",
    "            \n",
    "            rf.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = rf.predict(X_train), rf.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(rf, X_train, y_train), get_scorer(score)(rf, X_test, y_test)\n",
    "            \n",
    "            print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")\n",
    "            \n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/RandomForestClassifier\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66745011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.961766</td>\n",
       "      <td>0.978954</td>\n",
       "      <td>0.000578544</td>\n",
       "      <td>2.68186e-05</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.133631</td>\n",
       "      <td>2.12548</td>\n",
       "      <td>0.616766</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1250</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.972515</td>\n",
       "      <td>0.993238</td>\n",
       "      <td>0.000281813</td>\n",
       "      <td>9.21516e-06</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.0855399</td>\n",
       "      <td>2.12548</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.973171</td>\n",
       "      <td>0.993293</td>\n",
       "      <td>0.000261749</td>\n",
       "      <td>8.92326e-06</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.0855399</td>\n",
       "      <td>2.12548</td>\n",
       "      <td>0.252723</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.980721</td>\n",
       "      <td>0.990785</td>\n",
       "      <td>0.00068764</td>\n",
       "      <td>1.05954e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.269834</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.981818</td>\n",
       "      <td>0.990886</td>\n",
       "      <td>0.000580199</td>\n",
       "      <td>1.01777e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0883883</td>\n",
       "      <td>9.99201e-16</td>\n",
       "      <td>0.269834</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/RandomForestClassifier</td>\n",
       "      <td>10,3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       score test score train score test variance train variance test rmse  \\\n",
       "51  accuracy   0.961766    0.978954   0.000578544    2.68186e-05  0.248069   \n",
       "52        f1   0.972515    0.993238   0.000281813    9.21516e-06  0.248069   \n",
       "53  accuracy   0.973171    0.993293   0.000261749    8.92326e-06  0.248069   \n",
       "54        f1   0.980721    0.990785    0.00068764    1.05954e-05         0   \n",
       "55  accuracy   0.981818    0.990886   0.000580199    1.01777e-05         0   \n",
       "\n",
       "   train rmse test log_loss train log_loss test size random state  \\\n",
       "51   0.133631       2.12548       0.616766       0.2         1250   \n",
       "52  0.0855399       2.12548       0.252723       0.2         1850   \n",
       "53  0.0855399       2.12548       0.252723       0.2         1850   \n",
       "54  0.0883883   9.99201e-16       0.269834       0.2         2050   \n",
       "55  0.0883883   9.99201e-16       0.269834       0.2         2050   \n",
       "\n",
       "                       estimator estimator params  \n",
       "51  Smote/RandomForestClassifier             10,3  \n",
       "52  Smote/RandomForestClassifier             10,3  \n",
       "53  Smote/RandomForestClassifier             10,3  \n",
       "54  Smote/RandomForestClassifier             10,3  \n",
       "55  Smote/RandomForestClassifier             10,3  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aue3SdsInJE4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aue3SdsInJE4",
    "outputId": "f3e519a4-4a17-455a-fe97-bc41381c149b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9682853053469485 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9725439712940638 with variance: 9.551950487955732e-05\n",
      "          test  score: 0.9682853053469485 with variance: 0.0009517688028671496\n",
      "        Refitted train score: 0.9661399548532731,  RMSE: 0.2243559013482789, Log-Loss:1.738529013166646\n",
      "        Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9528248587570621 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9589008825287436 with variance: 0.00021949045534632735\n",
      "          test  score: 0.9528248587570621 with variance: 0.0021201761945800995\n",
      "        Refitted train score: 0.9496644295302014,  RMSE: 0.2243559013482789, Log-Loss:1.738529013166646\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9652823653798898 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9726759208113229 with variance: 6.376543450529514e-05\n",
      "          test  score: 0.9652823653798898 with variance: 0.0005290802292622675\n",
      "        Refitted train score: 0.9619686800894854,  RMSE: 0.2388450959634127, Log-Loss:1.970335564801718\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      accuracy\n",
      "        CV score: 0.9496045197740113 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9589008825287436 with variance: 0.00013598904002926415\n",
      "          test  score: 0.9496045197740113 with variance: 0.0010077755434262168\n",
      "        Refitted train score: 0.9530201342281879,  RMSE: 0.21674839277792138, Log-Loss:1.6226270789555362\n",
      "        Refitted test  score: 0.8846153846153846,  RMSE: 0.3396831102433787, Log-Loss:3.9852434301820026\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.920602572176245 using:12,LogisticRegression(),28,None\n",
      "          train score: 0.9211448438567084 with variance: 4.15658601843576e-05\n",
      "          test  score: 0.920602572176245 with variance: 0.0010476748215984503\n",
      "        Refitted train score: 0.9195402298850573,  RMSE: 0.342709300179511, Log-Loss:4.056578430240251\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.885819209039548 using:12,LogisticRegression(),28,None\n",
      "          train score: 0.8842234801870539 with variance: 9.651907376074056e-05\n",
      "          test  score: 0.885819209039548 with variance: 0.0017784927702767374\n",
      "        Refitted train score: 0.8825503355704698,  RMSE: 0.342709300179511, Log-Loss:4.056578430240251\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9696693830794029 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9740071315730544 with variance: 1.2311630823815025e-05\n",
      "          test  score: 0.9696693830794029 with variance: 9.865390387354576e-05\n",
      "        Refitted train score: 0.9710467706013363,  RMSE: 0.20886397744423404, Log-Loss:1.5067251447444265\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.3284452304746504\n",
      "      accuracy\n",
      "        CV score: 0.9530508474576271 using:8,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9530431419429697 with variance: 0.0002954077289976175\n",
      "          test  score: 0.9530508474576271 with variance: 0.0003760222158383611\n",
      "        Refitted train score: 0.9496644295302014,  RMSE: 0.2243559013482789, Log-Loss:1.738529013166646\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9348092439178661 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9471779285269417 with variance: 0.00010322201448714392\n",
      "          test  score: 0.9348092439178661 with variance: 0.0001443483047544636\n",
      "        Refitted train score: 0.9705215419501134,  RMSE: 0.20886397744423404, Log-Loss:1.5067251447444265\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9061016949152544 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9178193453113463 with variance: 0.0003926249195161439\n",
      "          test  score: 0.9061016949152544 with variance: 0.0005040888633534425\n",
      "        Refitted train score: 0.9429530201342282,  RMSE: 0.2388450959634127, Log-Loss:1.9703328815888652\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9626176134520165 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.968848314601888 with variance: 9.56456359995742e-06\n",
      "          test  score: 0.9626176134520165 with variance: 0.00048313422116589585\n",
      "        Refitted train score: 0.9681818181818181,  RMSE: 0.21674839277792138, Log-Loss:1.6226270789555364\n",
      "        Refitted test  score: 0.9268292682926829,  RMSE: 0.3396831102433787, Log-Loss:3.985243430182003\n",
      "      accuracy\n",
      "        CV score: 0.9465536723163842 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9538623817727927 with variance: 2.778393432472609e-05\n",
      "          test  score: 0.9465536723163842 with variance: 0.0010399757413259287\n",
      "        Refitted train score: 0.9563758389261745,  RMSE: 0.20886397744423404, Log-Loss:1.5067251447444268\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9725366325237076 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9734157757706772 with variance: 1.5029234411079856e-05\n",
      "          test  score: 0.9725366325237076 with variance: 0.00020048687376883508\n",
      "        Refitted train score: 0.9774774774774774,  RMSE: 0.18318582636182792, Log-Loss:1.1590193421110977\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9598305084745762 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.961421890932105 with variance: 5.1036155041611965e-05\n",
      "          test  score: 0.9598305084745762 with variance: 0.0005146158511283475\n",
      "        Refitted train score: 0.9563758389261745,  RMSE: 0.20886397744423404, Log-Loss:1.5067251447444268\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9653978205702345 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9719516860391654 with variance: 4.2835746029866226e-05\n",
      "          test  score: 0.9653978205702345 with variance: 0.0008731896533037142\n",
      "        Refitted train score: 0.9771689497716896,  RMSE: 0.18537599944001618, Log-Loss:1.1868995324711582\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.94833430742256 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9579103152286518 with variance: 0.00010564502318141482\n",
      "          test  score: 0.94833430742256 with variance: 0.0020254474690360913\n",
      "        Refitted train score: 0.9690721649484536,  RMSE: 0.17586311452816475, Log-Loss:1.0682095792240427\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9511236482746849 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9671064625494978 with variance: 0.0001031954403851847\n",
      "          test  score: 0.9511236482746849 with variance: 8.401437945873537e-05\n",
      "        Refitted train score: 0.9749430523917996,  RMSE: 0.19442398845107403, Log-Loss:1.3055894857182742\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      accuracy\n",
      "        CV score: 0.9278784336645238 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9510248631049283 with variance: 0.0002040259435076506\n",
      "          test  score: 0.9278784336645238 with variance: 0.00015874864774667683\n",
      "        Refitted train score: 0.9587628865979382,  RMSE: 0.2030692330267238, Log-Loss:1.4242794389653899\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "    random state: 850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9149190471099671 using:8,LogisticRegression(),30,None\n",
      "          train score: 0.9211640690227968 with variance: 3.4208106377020326e-05\n",
      "          test  score: 0.9149190471099671 with variance: 0.0010914707354357804\n",
      "        Refitted train score: 0.9223529411764706,  RMSE: 0.3367522262074448, Log-Loss:3.9167739526698053\n",
      "        Refitted test  score: 0.9545454545454546,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "      accuracy\n",
      "        CV score: 0.8761542957334892 using:8,LogisticRegression(),28,None\n",
      "          train score: 0.8848712446351932 with variance: 4.92272836117817e-05\n",
      "          test  score: 0.8761542957334892 with variance: 0.0023292881588210627\n",
      "        Refitted train score: 0.8831615120274914,  RMSE: 0.3418164536304661, Log-Loss:4.035466653674413\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932834056742906\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9718501633065951 using:8,LogisticRegression(),28,None\n",
      "          train score: 0.9662991829621568 with variance: 6.054023418176934e-05\n",
      "          test  score: 0.9718501633065951 with variance: 0.0003613429400048517\n",
      "        Refitted train score: 0.9638009049773755,  RMSE: 0.23448415270421966, Log-Loss:1.8990447474688368\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9555230859146697 using:8,LogisticRegression(),28,None\n",
      "          train score: 0.9484719550096197 with variance: 0.00016098658719708315\n",
      "          test  score: 0.9555230859146697 with variance: 0.0009819707527290136\n",
      "        Refitted train score: 0.9450171821305842,  RMSE: 0.23448415270421966, Log-Loss:1.8990447474688368\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.8618960740399174 using:10,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.8909959371843605 with variance: 0.0008165131258410247\n",
      "          test  score: 0.8618960740399174 with variance: 0.001143109430565606\n",
      "        Refitted train score: 0.8992628992628993,  RMSE: 0.37535779036857353, Log-Loss:4.8662908308892385\n",
      "        Refitted test  score: 0.875,  RMSE: 0.4264014327112209, Log-Loss:6.279801756572555\n",
      "      accuracy\n",
      "        CV score: 0.8075978959672707 using:10,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.849711410389226 with variance: 0.0013019939155506973\n",
      "          test  score: 0.8075978959672707 with variance: 0.0014570553037877435\n",
      "        Refitted train score: 0.8487972508591065,  RMSE: 0.38884797690214806, Log-Loss:5.222360690630586\n",
      "        Refitted test  score: 0.8484848484848485,  RMSE: 0.3892494720807615, Log-Loss:5.233172168847988\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9615098405659135 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9741020230433163 with variance: 4.035841597788345e-06\n",
      "          test  score: 0.9615098405659135 with variance: 0.00033248522139614587\n",
      "        Refitted train score: 0.9627906976744186,  RMSE: 0.23448415270421966, Log-Loss:1.8990392519538524\n",
      "        Refitted test  score: 0.9166666666666666,  RMSE: 0.3481553119113957, Log-Loss:4.186518350898265\n",
      "      accuracy\n",
      "        CV score: 0.9451198129748685 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9613400917566967 with variance: 7.372410336901019e-06\n",
      "          test  score: 0.9451198129748685 with variance: 0.0005053900552720199\n",
      "        Refitted train score: 0.9553264604810997,  RMSE: 0.211361158964698, Log-Loss:1.5429693922125054\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9715003119592136 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9796628789505828 with variance: 2.571451730478584e-05\n",
      "          test  score: 0.9715003119592136 with variance: 6.298613035870533e-05\n",
      "        Refitted train score: 0.9719626168224299,  RMSE: 0.2030692330267238, Log-Loss:1.4242794389653899\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9587375803623612 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9699237827438212 with variance: 5.215191415459233e-05\n",
      "          test  score: 0.9587375803623612 with variance: 7.301057789167022e-05\n",
      "        Refitted train score: 0.9621993127147767,  RMSE: 0.19442398845107403, Log-Loss:1.3055894857182742\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9535786053027433 using:8,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9582502574876566 with variance: 6.553523799451773e-05\n",
      "          test  score: 0.9535786053027433 with variance: 0.0006809281959339993\n",
      "        Refitted train score: 0.9504950495049505,  RMSE: 0.26967994498529685, Log-Loss:2.511911010538959\n",
      "        Refitted test  score: 0.9459459459459459,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "      accuracy\n",
      "        CV score: 0.9345454545454546 using:8,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9381818181818182 with variance: 0.00013719008264462842\n",
      "          test  score: 0.9345454545454546 with variance: 0.0008727272727272733\n",
      "        Refitted train score: 0.9272727272727272,  RMSE: 0.26967994498529685, Log-Loss:2.511911010538959\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.8195245872347585\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9429410079006761 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9680306287727148 with variance: 2.1367727216107747e-05\n",
      "          test  score: 0.9429410079006761 with variance: 0.0006403811084191387\n",
      "        Refitted train score: 0.9613526570048311,  RMSE: 0.2412090756622109, Log-Loss:2.0095317160581865\n",
      "        Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      accuracy\n",
      "        CV score: 0.9163636363636364 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9518181818181818 with variance: 4.62809917355373e-05\n",
      "          test  score: 0.9163636363636364 with variance: 0.001137190082644629\n",
      "        Refitted train score: 0.9381818181818182,  RMSE: 0.24863262420322443, Log-Loss:2.135127266585135\n",
      "        Refitted test  score: 0.8775510204081632,  RMSE: 0.3499271061118826, Log-Loss:4.229237925907431\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9763493068113321 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9802195630786146 with variance: 1.020066820635213e-05\n",
      "          test  score: 0.9763493068113321 with variance: 0.0001619453932937805\n",
      "        Refitted train score: 0.9760765550239233,  RMSE: 0.19069251784911845, Log-Loss:1.2559584128964991\n",
      "        Refitted test  score: 0.9722222222222222,  RMSE: 0.20203050891044214, Log-Loss:1.4097622936173795\n",
      "      accuracy\n",
      "        CV score: 0.9636363636363636 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.96 with variance: 0.00027603305785124\n",
      "          test  score: 0.9636363636363636 with variance: 0.00013223140495867777\n",
      "        Refitted train score: 0.9563636363636364,  RMSE: 0.2088931871468374, Log-Loss:1.5071524215774141\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.964529010137866 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9720772686922381 with variance: 1.3549813715242777e-05\n",
      "          test  score: 0.964529010137866 with variance: 0.0004328803389462518\n",
      "        Refitted train score: 0.9640287769784173,  RMSE: 0.23354968324845687, Log-Loss:1.88393325790422\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9454545454545455 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9572727272727273 with variance: 3.801652892561992e-05\n",
      "          test  score: 0.9454545454545455 with variance: 0.0009256198347107443\n",
      "        Refitted train score: 0.9527272727272728,  RMSE: 0.2174229226018436, Log-Loss:1.6327421568503242\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.8462970409819726 using:12,LogisticRegression(),28,None\n",
      "          train score: 0.8428899916647653 with variance: 0.00020322697449186338\n",
      "          test  score: 0.8462970409819726 with variance: 0.0015919991043137223\n",
      "        Refitted train score: 0.8435013262599469,  RMSE: 0.4631905164675271, Log-Loss:7.41016074210608\n",
      "        Refitted test  score: 0.8857142857142858,  RMSE: 0.40406101782088427, Log-Loss:5.638983901209909\n",
      "      accuracy\n",
      "        CV score: 0.7890909090909092 using:10,LogisticRegression(),28,None\n",
      "          train score: 0.7809090909090909 with variance: 0.00016033057851239695\n",
      "          test  score: 0.7890909090909092 with variance: 0.0031206611570247897\n",
      "        Refitted train score: 0.7818181818181819,  RMSE: 0.46709936649691375, Log-Loss:7.535756292633027\n",
      "        Refitted test  score: 0.8367346938775511,  RMSE: 0.40406101782088427, Log-Loss:5.638983901209909\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9803644157666209 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9797339741195508 with variance: 3.304250667408414e-05\n",
      "          test  score: 0.9803644157666209 with variance: 0.0001708543344489125\n",
      "        Refitted train score: 0.9711538461538461,  RMSE: 0.2088931871468374, Log-Loss:1.507146606323376\n",
      "        Refitted test  score: 0.9253731343283582,  RMSE: 0.31943828249996997, Log-Loss:3.524381256571095\n",
      "      accuracy\n",
      "        CV score: 0.9709090909090909 using:10,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9690909090909091 with variance: 7.768595041322314e-05\n",
      "          test  score: 0.9709090909090909 with variance: 0.00034380165289256225\n",
      "        Refitted train score: 0.9563636363636364,  RMSE: 0.2088931871468374, Log-Loss:1.507146606323376\n",
      "        Refitted test  score: 0.9183673469387755,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9669669645256501 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9718963642066709 with variance: 9.371919869585395e-06\n",
      "          test  score: 0.9669669645256501 with variance: 0.0004303274717350994\n",
      "        Refitted train score: 0.9674185463659148,  RMSE: 0.2174229226018436, Log-Loss:1.632742156850324\n",
      "        Refitted test  score: 0.988235294117647,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512393\n",
      "      accuracy\n",
      "        CV score: 0.9527272727272728 using:8,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9636363636363636 with variance: 2.479338842975178e-05\n",
      "          test  score: 0.9527272727272728 with variance: 0.0007404958677685956\n",
      "        Refitted train score: 0.9563636363636364,  RMSE: 0.2088931871468374, Log-Loss:1.507146606323376\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9559775837264048 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9728082720535612 with variance: 4.476698615200006e-05\n",
      "          test  score: 0.9559775837264048 with variance: 9.12840973118496e-05\n",
      "        Refitted train score: 0.9662337662337662,  RMSE: 0.22403805523403872, Log-Loss:1.7336065371962899\n",
      "        Refitted test  score: 0.9484536082474226,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "      accuracy\n",
      "        CV score: 0.9343891402714931 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9594620958751394 with variance: 8.938166446891186e-05\n",
      "          test  score: 0.9343891402714931 with variance: 0.00023341045433140158\n",
      "        Refitted train score: 0.9459459459459459,  RMSE: 0.23249527748763857, Log-Loss:1.866960886211389\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9515833277853154 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9694155486354333 with variance: 3.2901873833439936e-05\n",
      "          test  score: 0.9515833277853154 with variance: 0.0010804329474847548\n",
      "        Refitted train score: 0.9560723514211887,  RMSE: 0.2561973177788277, Log-Loss:2.2670239332566866\n",
      "        Refitted test  score: 0.9333333333333332,  RMSE: 0.3038218101251, Log-Loss:3.188207045644528\n",
      "      accuracy\n",
      "        CV score: 0.9263951734539969 using:12,DecisionTreeClassifier(),32,None\n",
      "          train score: 0.9536603493125233 with variance: 8.086191208676797e-05\n",
      "          test  score: 0.9263951734539969 with variance: 0.002344193971822398\n",
      "        Refitted train score: 0.9382239382239382,  RMSE: 0.24854790640048002, Log-Loss:2.1336695842415874\n",
      "        Refitted test  score: 0.8923076923076924,  RMSE: 0.3281650616569468, Log-Loss:3.719572836335462\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9556385078336298 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9717116825901716 with variance: 6.263352874865412e-06\n",
      "          test  score: 0.9556385078336298 with variance: 0.00012208114266769457\n",
      "        Refitted train score: 0.9692307692307691,  RMSE: 0.21524880100025257, Log-Loss:1.600255275429956\n",
      "        Refitted test  score: 0.9690721649484536,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9344645550527902 using:12,DecisionTreeClassifier(),28,None\n",
      "          train score: 0.9536696395392047 with variance: 5.43017374484593e-06\n",
      "          test  score: 0.9344645550527902 with variance: 0.0009683007673425552\n",
      "        Refitted train score: 0.9536679536679536,  RMSE: 0.21524880100025257, Log-Loss:1.600255275429956\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9555796781286977 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9663362008744365 with variance: 5.343588990003715e-05\n",
      "          test  score: 0.9555796781286977 with variance: 0.0005620671799221065\n",
      "        Refitted train score: 0.9695431472081217,  RMSE: 0.21524880100025257, Log-Loss:1.6002521881811906\n",
      "        Refitted test  score: 0.9545454545454545,  RMSE: 0.2480694691784169, Log-Loss:2.125463162763735\n",
      "      accuracy\n",
      "        CV score: 0.9344645550527904 using:12,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9488294314381271 with variance: 0.00013723159668581618\n",
      "          test  score: 0.9344645550527904 with variance: 0.001116229761425396\n",
      "        Refitted train score: 0.9575289575289575,  RMSE: 0.20608503698969138, Log-Loss:1.4668978391660914\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535942\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9548447678447678 using:12,KNeighborsClassifier(),30,None\n",
      "          train score: 0.9576711927656818 with variance: 4.542429736243549e-05\n",
      "          test  score: 0.9548447678447678 with variance: 0.00043669394198292313\n",
      "        Refitted train score: 0.9521276595744681,  RMSE: 0.26362486509824806, Log-Loss:2.400381369520551\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9344645550527904 using:12,KNeighborsClassifier(),30,None\n",
      "          train score: 0.938233927907841 with variance: 8.628837457420627e-05\n",
      "          test  score: 0.9344645550527904 with variance: 0.0008203717732597168\n",
      "        Refitted train score: 0.9305019305019305,  RMSE: 0.26362486509824806, Log-Loss:2.400381369520551\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9797305881965702 using:8,KNeighborsClassifier(),28,None\n",
      "          train score: 0.9749494817889615 with variance: 2.979567046019183e-05\n",
      "          test  score: 0.9797305881965702 with variance: 0.00010312433897647518\n",
      "        Refitted train score: 0.9776674937965261,  RMSE: 0.18641092980036, Log-Loss:1.2001922283846587\n",
      "        Refitted test  score: 0.9411764705882352,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "      accuracy\n",
      "        CV score: 0.9692307692307693 using:8,KNeighborsClassifier(),28,None\n",
      "          train score: 0.9613991081382386 with variance: 6.445677341416758e-05\n",
      "          test  score: 0.9692307692307693 with variance: 0.00023668639053254408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9652509652509652,  RMSE: 0.18641092980036, Log-Loss:1.2001922283846587\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9584525059405749 using:8,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9683783620332089 with variance: 5.150514524198165e-05\n",
      "          test  score: 0.9584525059405749 with variance: 0.0009321218954365454\n",
      "        Refitted train score: 0.967741935483871,  RMSE: 0.21524880100025257, Log-Loss:1.6002521881811909\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.9423076923076923 using:8,DecisionTreeClassifier(),30,None\n",
      "          train score: 0.9546311780007433 with variance: 9.912069437177304e-05\n",
      "          test  score: 0.9423076923076923 with variance: 0.0016272189349112412\n",
      "        Refitted train score: 0.9536679536679536,  RMSE: 0.21524880100025257, Log-Loss:1.6002521881811909\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#kidronclassifier\n",
    "max_estimators = [8, 10, 12]\n",
    "base_estimators = [LogisticRegression(), KNeighborsClassifier(), DecisionTreeClassifier(), SVC()]\n",
    "min_rows = [28, 30, 32]\n",
    "min_columns = [None] #500, 600, 700]\n",
    "    \n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "    \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "        X_train, X_test = dominant_features(X_train, X_test, y_train, testsize, features)\n",
    "        \n",
    "        #no need for treating imbalance here, the classifier does it on its own\n",
    "        #smote = SMOTE(random_state = randomstate)\n",
    "        #X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = pd.DataFrame(robustscaler.transform(X_train))\n",
    "        X_test  = pd.DataFrame(robustscaler.transform(X_test))\n",
    "\n",
    "        #best_scores = {score : [None] for score in scores}\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid\n",
    "        for max_estimator in max_estimators:\n",
    "            for base_estimator in base_estimators:\n",
    "                for min_row in min_rows:\n",
    "                    for min_column in min_columns:\n",
    "       \n",
    "                        kc = KidronClassifier(max_estimators = max_estimator, base_estimator = base_estimator, min_rows = min_row, min_columns = min_column, random_state = randomstate)                           \n",
    "                        cv_results = cross_validate(kc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    " \n",
    "                        for score in scores:\n",
    "                            avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                            var_score_test = np.var(cv_results['test_' + score])\n",
    "                            avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                            var_score_train = np.var(cv_results['train_' + score])\n",
    "                        \n",
    "                            if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                                best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, max_estimator, base_estimator, min_row, min_column]\n",
    "\n",
    "                    \n",
    "            \n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 3 + str(score))\n",
    "            print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            kc = KidronClassifier(max_estimators = best_avg_scores[score][4], base_estimator = best_avg_scores[score][5], min_rows = best_avg_scores[score][6], min_columns = best_avg_scores[score][7], random_state = randomstate)\n",
    "            \n",
    "            kc.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = kc.predict(X_train), kc.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(kc, X_train, y_train), get_scorer(score)(kc, X_test, y_test)\n",
    "            \n",
    "            print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")\n",
    "\n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"KidronClassifier\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "945d6610",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.934465</td>\n",
       "      <td>0.938234</td>\n",
       "      <td>0.000820372</td>\n",
       "      <td>8.62884e-05</td>\n",
       "      <td>0.248069</td>\n",
       "      <td>0.263625</td>\n",
       "      <td>2.12548</td>\n",
       "      <td>2.40038</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1250</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>12,KNeighborsClassifier(),30,None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.979731</td>\n",
       "      <td>0.974949</td>\n",
       "      <td>0.000103124</td>\n",
       "      <td>2.97957e-05</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>2.65684</td>\n",
       "      <td>1.20019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>8,KNeighborsClassifier(),28,None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.969231</td>\n",
       "      <td>0.961399</td>\n",
       "      <td>0.000236686</td>\n",
       "      <td>6.44568e-05</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.186411</td>\n",
       "      <td>2.65684</td>\n",
       "      <td>1.20019</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>8,KNeighborsClassifier(),28,None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.958453</td>\n",
       "      <td>0.968378</td>\n",
       "      <td>0.000932122</td>\n",
       "      <td>5.15051e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.215249</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.60025</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>8,DecisionTreeClassifier(),30,None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.942308</td>\n",
       "      <td>0.954631</td>\n",
       "      <td>0.00162722</td>\n",
       "      <td>9.91207e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.215249</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.60025</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>KidronClassifier</td>\n",
       "      <td>8,DecisionTreeClassifier(),30,None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "107  accuracy   0.934465    0.938234   0.000820372    8.62884e-05  0.248069   \n",
       "108        f1   0.979731    0.974949   0.000103124    2.97957e-05   0.27735   \n",
       "109  accuracy   0.969231    0.961399   0.000236686    6.44568e-05   0.27735   \n",
       "110        f1   0.958453    0.968378   0.000932122    5.15051e-05  0.124035   \n",
       "111  accuracy   0.942308    0.954631    0.00162722    9.91207e-05  0.124035   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "107   0.263625       2.12548        2.40038       0.2         1250   \n",
       "108   0.186411       2.65684        1.20019       0.2         1850   \n",
       "109   0.186411       2.65684        1.20019       0.2         1850   \n",
       "110   0.215249      0.531366        1.60025       0.2         2050   \n",
       "111   0.215249      0.531366        1.60025       0.2         2050   \n",
       "\n",
       "            estimator                    estimator params  \n",
       "107  KidronClassifier   12,KNeighborsClassifier(),30,None  \n",
       "108  KidronClassifier    8,KNeighborsClassifier(),28,None  \n",
       "109  KidronClassifier    8,KNeighborsClassifier(),28,None  \n",
       "110  KidronClassifier  8,DecisionTreeClassifier(),30,None  \n",
       "111  KidronClassifier  8,DecisionTreeClassifier(),30,None  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "74e2c8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9677928112005191 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9713396591586289 with variance: 2.4543861692548494e-05\n",
      "          test  score: 0.9677928112005191 with variance: 0.0007039792792415955\n",
      "        Refitted train score: 0.9684684684684683,  RMSE: 0.17483616785299216, Log-Loss:1.0557704574863536\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.969326325848065 using:1.0,True,True,30,0.8\n",
      "          train score: 0.9694257083724184 with variance: 3.728535958532021e-05\n",
      "          test  score: 0.969326325848065 with variance: 0.0006489586360377187\n",
      "        Refitted train score: 0.9694323144104804,  RMSE: 0.17483616785299216, Log-Loss:1.0557704574863536\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      f1\n",
      "        CV score: 0.9677928112005191 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9713396591586289 with variance: 2.4543861692548494e-05\n",
      "          test  score: 0.9677928112005191 with variance: 0.0007039792792415955\n",
      "        Refitted train score: 0.9684684684684683,  RMSE: 0.17483616785299216, Log-Loss:1.0557704574863536\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.969326325848065 using:1.0,True,True,30,0.8\n",
      "          train score: 0.9694257083724184 with variance: 3.728535958532021e-05\n",
      "          test  score: 0.969326325848065 with variance: 0.0006489586360377187\n",
      "        Refitted train score: 0.9694323144104804,  RMSE: 0.17483616785299216, Log-Loss:1.0557704574863536\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      f1\n",
      "        CV score: 0.9704065294212081 using:1.5,True,False,2,1.0\n",
      "          train score: 0.973640419136134 with variance: 3.151515554707275e-05\n",
      "          test  score: 0.9704065294212081 with variance: 0.00047835911969014596\n",
      "        Refitted train score: 0.9707865168539326,  RMSE: 0.16847634693327884, Log-Loss:0.9803582819516141\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9715241280458672 using:1.5,True,False,2,1.0\n",
      "          train score: 0.9743407632405712 with variance: 2.8784233200451043e-05\n",
      "          test  score: 0.9715241280458672 with variance: 0.00041772691671941673\n",
      "        Refitted train score: 0.9716157205240175,  RMSE: 0.16847634693327884, Log-Loss:0.9803582819516141\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.930088171962197 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9315782766884709 with variance: 7.557979110076282e-05\n",
      "          test  score: 0.930088171962197 with variance: 0.0011158662459246843\n",
      "        Refitted train score: 0.9321663019693655,  RMSE: 0.25903584134163193, Log-Loss:2.3175594437420433\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      accuracy\n",
      "        CV score: 0.9308087891538103 using:1.0,False,True,10,0.8\n",
      "          train score: 0.93452867501648 with variance: 7.978033180534874e-05\n",
      "          test  score: 0.9308087891538103 with variance: 0.0010390800995165154\n",
      "        Refitted train score: 0.935064935064935,  RMSE: 0.25482359571881275, Log-Loss:2.2427984567456343\n",
      "        Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      f1\n",
      "        CV score: 0.930088171962197 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9315782766884709 with variance: 7.557979110076282e-05\n",
      "          test  score: 0.930088171962197 with variance: 0.0011158662459246843\n",
      "        Refitted train score: 0.9321663019693655,  RMSE: 0.25903584134163193, Log-Loss:2.3175594437420433\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      accuracy\n",
      "        CV score: 0.9308087891538103 using:1.0,False,True,10,0.8\n",
      "          train score: 0.93452867501648 with variance: 7.978033180534874e-05\n",
      "          test  score: 0.9308087891538103 with variance: 0.0010390800995165154\n",
      "        Refitted train score: 0.935064935064935,  RMSE: 0.25482359571881275, Log-Loss:2.2427984567456343\n",
      "        Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      f1\n",
      "        CV score: 0.9343892472310141 using:1.5,True,True,2,1.0\n",
      "          train score: 0.934198048921116 with variance: 8.539758863356425e-05\n",
      "          test  score: 0.9343892472310141 with variance: 0.0013287740972384267\n",
      "        Refitted train score: 0.9342105263157895,  RMSE: 0.25482359571881275, Log-Loss:2.2427984567456343\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      accuracy\n",
      "        CV score: 0.9351566152407667 using:1.5,False,True,10,0.8\n",
      "          train score: 0.9356112209770746 with variance: 6.50820657359019e-05\n",
      "          test  score: 0.9351566152407667 with variance: 0.0011492494187839495\n",
      "        Refitted train score: 0.9372294372294372,  RMSE: 0.2505405411716091, Log-Loss:2.1680392004795936\n",
      "        Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.8959432837693708 using:1.0,False,True,20,1.0\n",
      "          train score: 0.898485192745829 with variance: 7.569200474457654e-06\n",
      "          test  score: 0.8959432837693708 with variance: 0.0009160365987050344\n",
      "        Refitted train score: 0.9017857142857143,  RMSE: 0.3086066999241838, Log-Loss:3.289433236661306\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      accuracy\n",
      "        CV score: 0.9004675081813931 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9020581557166925 with variance: 6.639070431000328e-06\n",
      "          test  score: 0.9004675081813931 with variance: 0.0006686831372050183\n",
      "        Refitted train score: 0.9047619047619048,  RMSE: 0.3086066999241838, Log-Loss:3.289433236661306\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      f1\n",
      "        CV score: 0.8990125422197363 using:0.001,False,True,10,1.0\n",
      "          train score: 0.8995310348033776 with variance: 3.648214327490788e-05\n",
      "          test  score: 0.8990125422197363 with variance: 0.0006212276292505782\n",
      "        Refitted train score: 0.8995633187772926,  RMSE: 0.31554254795050946, Log-Loss:3.438962133575597\n",
      "        Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      accuracy\n",
      "        CV score: 0.9004675081813931 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9020581557166925 with variance: 6.639070431000328e-06\n",
      "          test  score: 0.9004675081813931 with variance: 0.0006686831372050183\n",
      "        Refitted train score: 0.9047619047619048,  RMSE: 0.3086066999241838, Log-Loss:3.289433236661306\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "      f1\n",
      "        CV score: 0.8990125422197363 using:0.001,False,True,10,1.0\n",
      "          train score: 0.8995310348033776 with variance: 3.648214327490788e-05\n",
      "          test  score: 0.8990125422197363 with variance: 0.0006212276292505782\n",
      "        Refitted train score: 0.8995633187772926,  RMSE: 0.31554254795050946, Log-Loss:3.438962133575597\n",
      "        Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      accuracy\n",
      "        CV score: 0.9004675081813931 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9020581557166925 with variance: 6.639070431000328e-06\n",
      "          test  score: 0.9004675081813931 with variance: 0.0006686831372050183\n",
      "        Refitted train score: 0.9047619047619048,  RMSE: 0.3086066999241838, Log-Loss:3.289433236661306\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.937416980239755 using:1.0,True,True,10,1.0\n",
      "          train score: 0.9403079724959961 with variance: 5.111386723652188e-05\n",
      "          test  score: 0.937416980239755 with variance: 0.00040946732709959904\n",
      "        Refitted train score: 0.9452054794520548,  RMSE: 0.2279211529192759, Log-Loss:1.794222150384971\n",
      "        Refitted test  score: 0.9714285714285714,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9414913510986442 using:1.0,True,True,10,1.0\n",
      "          train score: 0.9437149344466418 with variance: 4.016856918872575e-05\n",
      "          test  score: 0.9414913510986442 with variance: 0.00031664226400726945\n",
      "        Refitted train score: 0.948051948051948,  RMSE: 0.2279211529192759, Log-Loss:1.794222150384971\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9388697685656442 using:0.001,False,True,10,0.6\n",
      "          train score: 0.940540257840353 with variance: 9.199869330900565e-05\n",
      "          test  score: 0.9388697685656442 with variance: 0.00026359881167508216\n",
      "        Refitted train score: 0.9388646288209607,  RMSE: 0.24618298195866548, Log-Loss:2.0932799442135535\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9415147265077138 using:0.001,False,True,10,0.6\n",
      "          train score: 0.9426338533655606 with variance: 8.387903314025152e-05\n",
      "          test  score: 0.9415147265077138 with variance: 0.00021929936719194162\n",
      "        Refitted train score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.0932799442135535\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9421217962447347 using:1.5,True,True,20,1.0\n",
      "          train score: 0.9409281275347559 with variance: 4.0155598363415644e-05\n",
      "          test  score: 0.9421217962447347 with variance: 0.0005404581822134469\n",
      "        Refitted train score: 0.9476082004555808,  RMSE: 0.2231222754086866, Log-Loss:1.7194628941189305\n",
      "        Refitted test  score: 0.9714285714285714,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.945815801776531 using:1.5,True,True,20,1.0\n",
      "          train score: 0.944256939866696 with variance: 3.185249979789922e-05\n",
      "          test  score: 0.945815801776531 with variance: 0.00042843223459075434\n",
      "        Refitted train score: 0.9502164502164502,  RMSE: 0.2231222754086866, Log-Loss:1.7194628941189305\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9634967827841676 using:1.0,True,False,10,1.0\n",
      "          train score: 0.9643401633793285 with variance: 2.160809777704603e-05\n",
      "          test  score: 0.9634967827841676 with variance: 0.00035681756858639747\n",
      "        Refitted train score: 0.9659863945578231,  RMSE: 0.18176811485266747, Log-Loss:1.1411507610596714\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9648107448107448 using:1.0,True,False,10,1.0\n",
      "          train score: 0.9653119607665064 with variance: 1.9736897652370528e-05\n",
      "          test  score: 0.9648107448107448 with variance: 0.00030796304495938254\n",
      "        Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411507610596714\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9634967827841676 using:1.0,True,False,10,1.0\n",
      "          train score: 0.9643401633793285 with variance: 2.160809777704603e-05\n",
      "          test  score: 0.9634967827841676 with variance: 0.00035681756858639747\n",
      "        Refitted train score: 0.9659863945578231,  RMSE: 0.18176811485266747, Log-Loss:1.1411507610596714\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9648107448107448 using:1.0,True,False,10,1.0\n",
      "          train score: 0.9653119607665064 with variance: 1.9736897652370528e-05\n",
      "          test  score: 0.9648107448107448 with variance: 0.00030796304495938254\n",
      "        Refitted train score: 0.9669603524229075,  RMSE: 0.18176811485266747, Log-Loss:1.1411507610596714\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9658588674178203 using:1.5,False,True,2,0.8\n",
      "          train score: 0.9706780474471193 with variance: 2.137233164016306e-05\n",
      "          test  score: 0.9658588674178203 with variance: 0.0003807310993607977\n",
      "        Refitted train score: 0.9706546275395034,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820914\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9670329670329669 using:1.5,True,False,20,1.0\n",
      "          train score: 0.9697181606272516 with variance: 1.7865225054729856e-05\n",
      "          test  score: 0.9670329670329669 with variance: 0.00043473010505977575\n",
      "        Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9889975610820912\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9330337078651686 using:1.0,False,True,10,0.6\n",
      "          train score: 0.9330353887248244 with variance: 1.2486803032375356e-05\n",
      "          test  score: 0.9330337078651686 with variance: 0.00024816420173908685\n",
      "        Refitted train score: 0.9306487695749441,  RMSE: 0.2613081290851687, Log-Loss:2.35839573438633\n",
      "        Refitted test  score: 0.9523809523809523,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      accuracy\n",
      "        CV score: 0.933968253968254 using:1.0,False,True,10,0.6\n",
      "          train score: 0.9339221384675931 with variance: 1.1939699112030857e-05\n",
      "          test  score: 0.933968253968254 with variance: 0.0002372612599718829\n",
      "        Refitted train score: 0.9317180616740088,  RMSE: 0.2613081290851687, Log-Loss:2.35839573438633\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      f1\n",
      "        CV score: 0.9330337078651686 using:1.0,False,True,10,0.6\n",
      "          train score: 0.9330353887248244 with variance: 1.2486803032375356e-05\n",
      "          test  score: 0.9330337078651686 with variance: 0.00024816420173908685\n",
      "        Refitted train score: 0.9306487695749441,  RMSE: 0.2613081290851687, Log-Loss:2.35839573438633\n",
      "        Refitted test  score: 0.9523809523809523,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      accuracy\n",
      "        CV score: 0.933968253968254 using:1.0,False,True,10,0.6\n",
      "          train score: 0.9339221384675931 with variance: 1.1939699112030857e-05\n",
      "          test  score: 0.933968253968254 with variance: 0.0002372612599718829\n",
      "        Refitted train score: 0.9317180616740088,  RMSE: 0.2613081290851687, Log-Loss:2.35839573438633\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      f1\n",
      "        CV score: 0.9330337078651686 using:1.0,False,True,10,0.6\n",
      "          train score: 0.9330353887248244 with variance: 1.2486803032375356e-05\n",
      "          test  score: 0.9330337078651686 with variance: 0.00024816420173908685\n",
      "        Refitted train score: 0.9306487695749441,  RMSE: 0.2613081290851687, Log-Loss:2.35839573438633\n",
      "        Refitted test  score: 0.9523809523809523,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      accuracy\n",
      "        CV score: 0.933992673992674 using:1.5,False,True,2,1.0\n",
      "          train score: 0.9350255804801261 with variance: 1.6485249929491747e-05\n",
      "          test  score: 0.933992673992674 with variance: 0.00033331454869916415\n",
      "        Refitted train score: 0.933920704845815,  RMSE: 0.25705893323163276, Log-Loss:2.2823191343975395\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9634111591138892 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9606794929859305 with variance: 1.5828575874153137e-06\n",
      "          test  score: 0.9634111591138892 with variance: 0.00013763621886561894\n",
      "        Refitted train score: 0.9636363636363636,  RMSE: 0.18772930178557284, Log-Loss:1.2172273610484614\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9647863247863248 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9620046620046621 with variance: 1.1926914776131004e-06\n",
      "          test  score: 0.9647863247863248 with variance: 0.00011464948021724496\n",
      "        Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172273610484614\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9660624822120785 using:0.001,False,False,30,0.6\n",
      "          train score: 0.9633840559629763 with variance: 2.846207346538037e-06\n",
      "          test  score: 0.9660624822120785 with variance: 5.738968615787373e-05\n",
      "        Refitted train score: 0.9638009049773755,  RMSE: 0.18772930178557284, Log-Loss:1.2172291222762812\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.966984126984127 using:0.001,False,False,30,0.6\n",
      "          train score: 0.9642085187539733 with variance: 2.9206571424683614e-06\n",
      "          test  score: 0.966984126984127 with variance: 4.723947874130991e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172291222762812\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      f1\n",
      "        CV score: 0.9660624822120785 using:0.001,False,False,30,0.6\n",
      "          train score: 0.9633840559629763 with variance: 2.846207346538037e-06\n",
      "          test  score: 0.9660624822120785 with variance: 5.738968615787373e-05\n",
      "        Refitted train score: 0.9638009049773755,  RMSE: 0.18772930178557284, Log-Loss:1.2172291222762812\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.966984126984127 using:0.001,False,False,30,0.6\n",
      "          train score: 0.9642085187539733 with variance: 2.9206571424683614e-06\n",
      "          test  score: 0.966984126984127 with variance: 4.723947874130991e-05\n",
      "        Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172291222762812\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9570755152737686 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9551545135530309 with variance: 3.4684938718305855e-05\n",
      "          test  score: 0.9570755152737686 with variance: 0.0003742200602398113\n",
      "        Refitted train score: 0.952808988764045,  RMSE: 0.21650635094610965, Log-Loss:1.6190212068526706\n",
      "        Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      accuracy\n",
      "        CV score: 0.9575031210986268 using:1.0,True,True,20,0.6\n",
      "          train score: 0.9559110502482066 with variance: 3.587115063983683e-05\n",
      "          test  score: 0.9575031210986268 with variance: 0.0004749655938815567\n",
      "        Refitted train score: 0.9575892857142857,  RMSE: 0.2059386177619785, Log-Loss:1.4648284559882698\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      f1\n",
      "        CV score: 0.9570755152737686 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9551545135530309 with variance: 3.4684938718305855e-05\n",
      "          test  score: 0.9570755152737686 with variance: 0.0003742200602398113\n",
      "        Refitted train score: 0.952808988764045,  RMSE: 0.21650635094610965, Log-Loss:1.6190212068526706\n",
      "        Refitted test  score: 0.9583333333333334,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      accuracy\n",
      "        CV score: 0.9575031210986268 using:1.0,True,True,20,0.6\n",
      "          train score: 0.9559110502482066 with variance: 3.587115063983683e-05\n",
      "          test  score: 0.9575031210986268 with variance: 0.0004749655938815567\n",
      "        Refitted train score: 0.9575892857142857,  RMSE: 0.2059386177619785, Log-Loss:1.4648284559882698\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      f1\n",
      "        CV score: 0.9589023329573638 using:1.5,True,False,2,0.8\n",
      "          train score: 0.9550781044110886 with variance: 5.3020773433277815e-05\n",
      "          test  score: 0.9589023329573638 with variance: 0.0007615618952667542\n",
      "        Refitted train score: 0.9551569506726457,  RMSE: 0.21128856368212914, Log-Loss:1.5419257238283166\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.30151134457776363, Log-Loss:3.139912993398857\n",
      "      accuracy\n",
      "        CV score: 0.9597003745318352 using:1.5,True,False,2,0.8\n",
      "          train score: 0.9553508348765192 with variance: 5.042570870940786e-05\n",
      "          test  score: 0.9597003745318352 with variance: 0.0006877196263721542\n",
      "        Refitted train score: 0.9553571428571429,  RMSE: 0.21128856368212914, Log-Loss:1.5419257238283166\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.139912993398857\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9518614919045616 using:1.0,True,False,20,1.0\n",
      "          train score: 0.9522290196761398 with variance: 5.307075852592538e-05\n",
      "          test  score: 0.9518614919045616 with variance: 0.0005284367846949905\n",
      "        Refitted train score: 0.9521640091116174,  RMSE: 0.21602468994692867, Log-Loss:1.6118184495117236\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      accuracy\n",
      "        CV score: 0.9533333333333334 using:1.0,True,True,20,1.0\n",
      "          train score: 0.9533333333333334 with variance: 3.2098765432099e-05\n",
      "          test  score: 0.9533333333333334 with variance: 0.0005629629629629631\n",
      "        Refitted train score: 0.9533333333333334,  RMSE: 0.21602468994692867, Log-Loss:1.611820226394902\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      f1\n",
      "        CV score: 0.9518614919045616 using:1.0,True,False,20,1.0\n",
      "          train score: 0.9522290196761398 with variance: 5.307075852592538e-05\n",
      "          test  score: 0.9518614919045616 with variance: 0.0005284367846949905\n",
      "        Refitted train score: 0.9521640091116174,  RMSE: 0.21602468994692867, Log-Loss:1.6118184495117236\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      accuracy\n",
      "        CV score: 0.9533333333333334 using:1.0,True,True,20,1.0\n",
      "          train score: 0.9533333333333334 with variance: 3.2098765432099e-05\n",
      "          test  score: 0.9533333333333334 with variance: 0.0005629629629629631\n",
      "        Refitted train score: 0.9533333333333334,  RMSE: 0.21602468994692867, Log-Loss:1.611820226394902\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      f1\n",
      "        CV score: 0.9539955548320582 using:1.5,True,False,10,0.8\n",
      "          train score: 0.9521900736106661 with variance: 3.261209189066799e-05\n",
      "          test  score: 0.9539955548320582 with variance: 0.00035507993077681164\n",
      "        Refitted train score: 0.9497716894977168,  RMSE: 0.22110831935702666, Log-Loss:1.6885712859448585\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      accuracy\n",
      "        CV score: 0.9555555555555555 using:1.5,True,False,10,0.8\n",
      "          train score: 0.9533333333333334 with variance: 2.9012345679012605e-05\n",
      "          test  score: 0.9555555555555555 with variance: 0.0002962962962962957\n",
      "        Refitted train score: 0.9511111111111111,  RMSE: 0.22110831935702666, Log-Loss:1.6885712859448585\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9062210238791255 using:1.0,False,True,20,0.6\n",
      "          train score: 0.9086717649379257 with variance: 9.369728420455939e-05\n",
      "          test  score: 0.9062210238791255 with variance: 0.0015154171194746418\n",
      "        Refitted train score: 0.9095127610208817,  RMSE: 0.2930922784729078, Log-Loss:2.9670014893853707\n",
      "        Refitted test  score: 0.9333333333333332,  RMSE: 0.30151134457776363, Log-Loss:3.139937223624014\n",
      "      accuracy\n",
      "        CV score: 0.911990231990232 using:1.0,False,True,20,0.6\n",
      "          train score: 0.9130021493657857 with variance: 8.550948321921193e-05\n",
      "          test  score: 0.911990231990232 with variance: 0.0011990345294374625\n",
      "        Refitted train score: 0.9140969162995595,  RMSE: 0.2930922784729078, Log-Loss:2.9670014893853707\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.139937223624014\n",
      "      f1\n",
      "        CV score: 0.9099923698881327 using:0.001,True,False,20,0.8\n",
      "          train score: 0.9011377737141224 with variance: 0.0003983942598877862\n",
      "          test  score: 0.9099923698881327 with variance: 0.0014303880427568947\n",
      "        Refitted train score: 0.883054892601432,  RMSE: 0.32852627812475244, Log-Loss:3.727765728045452\n",
      "        Refitted test  score: 0.9767441860465117,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9141880341880342 using:0.001,True,False,20,0.8\n",
      "          train score: 0.9058502103956648 with variance: 0.0003046726365556297\n",
      "          test  score: 0.9141880341880342 with variance: 0.0011221785404935609\n",
      "        Refitted train score: 0.8920704845814978,  RMSE: 0.32852627812475244, Log-Loss:3.727765728045452\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9099923698881327 using:0.001,True,False,20,0.8\n",
      "          train score: 0.9011377737141224 with variance: 0.0003983942598877862\n",
      "          test  score: 0.9099923698881327 with variance: 0.0014303880427568947\n",
      "        Refitted train score: 0.883054892601432,  RMSE: 0.32852627812475244, Log-Loss:3.727765728045452\n",
      "        Refitted test  score: 0.9767441860465117,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9141880341880342 using:0.001,True,False,20,0.8\n",
      "          train score: 0.9058502103956648 with variance: 0.0003046726365556297\n",
      "          test  score: 0.9141880341880342 with variance: 0.0011221785404935609\n",
      "        Refitted train score: 0.8920704845814978,  RMSE: 0.32852627812475244, Log-Loss:3.727765728045452\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9600921550359752 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9581222363290596 with variance: 1.8811554439674727e-05\n",
      "          test  score: 0.9600921550359752 with variance: 0.0005503868327460588\n",
      "        Refitted train score: 0.9619686800894854,  RMSE: 0.19350693507134273, Log-Loss:1.2933110059485304\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9603663003663003 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9603517694426784 with variance: 2.615479006856229e-05\n",
      "          test  score: 0.9603663003663003 with variance: 0.0003178574782970383\n",
      "        Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9600921550359752 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9581222363290596 with variance: 1.8811554439674727e-05\n",
      "          test  score: 0.9600921550359752 with variance: 0.0005503868327460588\n",
      "        Refitted train score: 0.9619686800894854,  RMSE: 0.19350693507134273, Log-Loss:1.2933110059485304\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9603663003663003 using:1.0,True,True,2,0.6\n",
      "          train score: 0.9603517694426784 with variance: 2.615479006856229e-05\n",
      "          test  score: 0.9603663003663003 with variance: 0.0003178574782970383\n",
      "        Refitted train score: 0.9625550660792952,  RMSE: 0.19350693507134273, Log-Loss:1.2933127671763505\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9621922771360975 using:1.5,True,True,2,1.0\n",
      "          train score: 0.9597724856382346 with variance: 1.4690317671375562e-05\n",
      "          test  score: 0.9621922771360975 with variance: 0.0005048689300770667\n",
      "        Refitted train score: 0.9619686800894854,  RMSE: 0.19350693507134273, Log-Loss:1.2933110059485304\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9625641025641025 using:1.5,True,True,2,0.6\n",
      "          train score: 0.9620046620046621 with variance: 3.1548845049394166e-05\n",
      "          test  score: 0.9625641025641025 with variance: 0.0004147861906103667\n",
      "        Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172344059597404\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.8145848280140171 using:1.0,False,True,2,1.0\n",
      "          train score: 0.8068323765413965 with variance: 0.0002441598297302674\n",
      "          test  score: 0.8145848280140171 with variance: 0.00377089005628893\n",
      "        Refitted train score: 0.8120649651972157,  RMSE: 0.42616235142934056, Log-Loss:6.272796580051485\n",
      "        Refitted test  score: 0.9166666666666666,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      accuracy\n",
      "        CV score: 0.822996254681648 using:1.0,True,True,20,1.0\n",
      "          train score: 0.8251203852327448 with variance: 0.00011846510414518545\n",
      "          test  score: 0.822996254681648 with variance: 0.0028384519350811476\n",
      "        Refitted train score: 0.827354260089686,  RMSE: 0.41550660633774994, Log-Loss:5.963026390876745\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      f1\n",
      "        CV score: 0.8211785760410326 using:0.001,False,False,2,1.0\n",
      "          train score: 0.8230552404436393 with variance: 0.00012828586352107228\n",
      "          test  score: 0.8211785760410326 with variance: 0.0030239749452254045\n",
      "        Refitted train score: 0.8237986270022883,  RMSE: 0.41550660633774994, Log-Loss:5.963033562154146\n",
      "        Refitted test  score: 0.9387755102040816,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      accuracy\n",
      "        CV score: 0.8251935081148563 using:0.001,False,False,2,1.0\n",
      "          train score: 0.826796336512133 with variance: 0.00010077126196431642\n",
      "          test  score: 0.8251935081148563 with variance: 0.002570385021220354\n",
      "        Refitted train score: 0.827354260089686,  RMSE: 0.41550660633774994, Log-Loss:5.963033562154146\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      f1\n",
      "        CV score: 0.8211785760410326 using:0.001,False,False,2,1.0\n",
      "          train score: 0.8230552404436393 with variance: 0.00012828586352107228\n",
      "          test  score: 0.8211785760410326 with variance: 0.0030239749452254045\n",
      "        Refitted train score: 0.8237986270022883,  RMSE: 0.41550660633774994, Log-Loss:5.963033562154146\n",
      "        Refitted test  score: 0.9387755102040816,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      accuracy\n",
      "        CV score: 0.8274656679151061 using:1.5,True,True,10,1.0\n",
      "          train score: 0.8279199320177509 with variance: 0.0001445493797896416\n",
      "          test  score: 0.8274656679151061 with variance: 0.0026056069114605493\n",
      "        Refitted train score: 0.8295964125560538,  RMSE: 0.41279969409381373, Log-Loss:5.885586981016924\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9521132507339404 using:1.0,True,False,2,1.0\n",
      "          train score: 0.952480590055138 with variance: 1.2697675330719076e-05\n",
      "          test  score: 0.9521132507339404 with variance: 0.0006078217133938274\n",
      "        Refitted train score: 0.9541284403669725,  RMSE: 0.21176177494381335, Log-Loss:1.5488330176801908\n",
      "        Refitted test  score: 0.9600000000000001,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      accuracy\n",
      "        CV score: 0.9529338327091136 using:1.0,True,True,20,1.0\n",
      "          train score: 0.9517955496805465 with variance: 2.9335264755379766e-05\n",
      "          test  score: 0.9529338327091136 with variance: 0.00047250549796524506\n",
      "        Refitted train score: 0.952914798206278,  RMSE: 0.21699124819614724, Log-Loss:1.6262760131787126\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      f1\n",
      "        CV score: 0.9521132507339404 using:1.0,True,False,2,1.0\n",
      "          train score: 0.952480590055138 with variance: 1.2697675330719076e-05\n",
      "          test  score: 0.9521132507339404 with variance: 0.0006078217133938274\n",
      "        Refitted train score: 0.9541284403669725,  RMSE: 0.21176177494381335, Log-Loss:1.5488330176801908\n",
      "        Refitted test  score: 0.9600000000000001,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      accuracy\n",
      "        CV score: 0.9529338327091136 using:1.0,True,True,20,1.0\n",
      "          train score: 0.9517955496805465 with variance: 2.9335264755379766e-05\n",
      "          test  score: 0.9529338327091136 with variance: 0.00047250549796524506\n",
      "        Refitted train score: 0.952914798206278,  RMSE: 0.21699124819614724, Log-Loss:1.6262760131787126\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      f1\n",
      "        CV score: 0.9564589549672851 using:1.5,True,True,20,0.8\n",
      "          train score: 0.9513511571442607 with variance: 3.222855235364681e-05\n",
      "          test  score: 0.9564589549672851 with variance: 0.0005840540276640824\n",
      "        Refitted train score: 0.9519450800915331,  RMSE: 0.21699124819614724, Log-Loss:1.6262760131787126\n",
      "        Refitted test  score: 0.9600000000000001,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "      accuracy\n",
      "        CV score: 0.9574282147315856 using:1.5,True,True,20,0.8\n",
      "          train score: 0.9523557737701823 with variance: 3.124658226762362e-05\n",
      "          test  score: 0.9574282147315856 with variance: 0.0005723806540201765\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.952914798206278,  RMSE: 0.21699124819614724, Log-Loss:1.6262760131787126\n",
      "        Refitted test  score: 0.9393939393939394,  RMSE: 0.24618298195866548, Log-Loss:2.093259175449133\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9717511278455868 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9720520082584312 with variance: 9.226861516265116e-06\n",
      "          test  score: 0.9717511278455868 with variance: 0.00027754503403811334\n",
      "        Refitted train score: 0.9720930232558139,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189973\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9727272727272729 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9727272727272729 with variance: 8.393595041322413e-06\n",
      "          test  score: 0.9727272727272729 with variance: 0.00023760330578512356\n",
      "        Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189973\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      f1\n",
      "        CV score: 0.9717511278455868 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9720520082584312 with variance: 9.226861516265116e-06\n",
      "          test  score: 0.9717511278455868 with variance: 0.00027754503403811334\n",
      "        Refitted train score: 0.9720930232558139,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189973\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9727272727272729 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9727272727272729 with variance: 8.393595041322413e-06\n",
      "          test  score: 0.9727272727272729 with variance: 0.00023760330578512356\n",
      "        Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189973\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      f1\n",
      "        CV score: 0.9720782576596531 using:1.5,True,False,2,1.0\n",
      "          train score: 0.9732486111231797 with variance: 5.089551171612273e-06\n",
      "          test  score: 0.9720782576596531 with variance: 9.715620559062391e-05\n",
      "        Refitted train score: 0.974477958236659,  RMSE: 0.15811388300841897, Log-Loss:0.8634712271396546\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9727272727272729 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9727272727272729 with variance: 8.393595041322413e-06\n",
      "          test  score: 0.9727272727272729 with variance: 0.00023760330578512356\n",
      "        Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419684462189973\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9306409770408584 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9294769053848173 with variance: 0.00010968421115037515\n",
      "          test  score: 0.9306409770408584 with variance: 0.0012496399470295337\n",
      "        Refitted train score: 0.9307875894988067,  RMSE: 0.2615267221816813, Log-Loss:2.3623446005225763\n",
      "        Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      accuracy\n",
      "        CV score: 0.9315126050420167 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9304164497657471 with variance: 0.00010392637710593356\n",
      "          test  score: 0.9315126050420167 with variance: 0.0012040110161711743\n",
      "        Refitted train score: 0.9316037735849056,  RMSE: 0.2615267221816813, Log-Loss:2.3623446005225763\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      f1\n",
      "        CV score: 0.9306409770408584 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9294769053848173 with variance: 0.00010968421115037515\n",
      "          test  score: 0.9306409770408584 with variance: 0.0012496399470295337\n",
      "        Refitted train score: 0.9307875894988067,  RMSE: 0.2615267221816813, Log-Loss:2.3623446005225763\n",
      "        Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      accuracy\n",
      "        CV score: 0.9315126050420167 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9304164497657471 with variance: 0.00010392637710593356\n",
      "          test  score: 0.9315126050420167 with variance: 0.0012040110161711743\n",
      "        Refitted train score: 0.9316037735849056,  RMSE: 0.2615267221816813, Log-Loss:2.3623446005225763\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      f1\n",
      "        CV score: 0.9306409770408584 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9294769053848173 with variance: 0.00010968421115037515\n",
      "          test  score: 0.9306409770408584 with variance: 0.0012496399470295337\n",
      "        Refitted train score: 0.9307875894988067,  RMSE: 0.2615267221816813, Log-Loss:2.3623446005225763\n",
      "        Refitted test  score: 0.9599999999999999,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "      accuracy\n",
      "        CV score: 0.9315126050420167 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9304164497657471 with variance: 0.00010392637710593356\n",
      "          test  score: 0.9315126050420167 with variance: 0.0012040110161711743\n",
      "        Refitted train score: 0.9316037735849056,  RMSE: 0.2615267221816813, Log-Loss:2.3623446005225763\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.11465159958352\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9443237181314847 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9377127843238814 with variance: 7.041638273396057e-05\n",
      "          test  score: 0.9443237181314847 with variance: 0.0010964354481800289\n",
      "        Refitted train score: 0.9453681710213777,  RMSE: 0.23181526644509276, Log-Loss:1.8560706865943633\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.40406101782088427, Log-Loss:5.63900021952481\n",
      "      accuracy\n",
      "        CV score: 0.9462380300957592 using:1.0,False,True,2,0.6\n",
      "          train score: 0.9427531413567933 with variance: 2.2938011454755963e-05\n",
      "          test  score: 0.9462380300957592 with variance: 0.000310643927981272\n",
      "        Refitted train score: 0.9415887850467289,  RMSE: 0.2416841222614159, Log-Loss:2.017464969754156\n",
      "        Refitted test  score: 0.8367346938775511,  RMSE: 0.40406101782088427, Log-Loss:5.638983901209907\n",
      "      f1\n",
      "        CV score: 0.9443237181314847 using:1.0,True,False,2,1.0\n",
      "          train score: 0.9377127843238814 with variance: 7.041638273396057e-05\n",
      "          test  score: 0.9443237181314847 with variance: 0.0010964354481800289\n",
      "        Refitted train score: 0.9453681710213777,  RMSE: 0.23181526644509276, Log-Loss:1.8560706865943633\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.40406101782088427, Log-Loss:5.63900021952481\n",
      "      accuracy\n",
      "        CV score: 0.9462380300957592 using:1.0,False,True,2,0.6\n",
      "          train score: 0.9427531413567933 with variance: 2.2938011454755963e-05\n",
      "          test  score: 0.9462380300957592 with variance: 0.000310643927981272\n",
      "        Refitted train score: 0.9415887850467289,  RMSE: 0.2416841222614159, Log-Loss:2.017464969754156\n",
      "        Refitted test  score: 0.8367346938775511,  RMSE: 0.40406101782088427, Log-Loss:5.638983901209907\n",
      "      f1\n",
      "        CV score: 0.94647210915038 using:1.5,True,True,10,1.0\n",
      "          train score: 0.941843880243818 with variance: 3.8265870624894085e-05\n",
      "          test  score: 0.94647210915038 with variance: 0.0005139170924015818\n",
      "        Refitted train score: 0.9448441247002399,  RMSE: 0.23181526644509276, Log-Loss:1.8560669501577738\n",
      "        Refitted test  score: 0.888888888888889,  RMSE: 0.3779644730092272, Log-Loss:4.934110913558669\n",
      "      accuracy\n",
      "        CV score: 0.9485636114911081 using:1.5,True,True,10,1.0\n",
      "          train score: 0.9433345267931734 with variance: 3.3454187583894756e-05\n",
      "          test  score: 0.9485636114911081 with variance: 0.0004200830524682753\n",
      "        Refitted train score: 0.9462616822429907,  RMSE: 0.23181526644509276, Log-Loss:1.8560669501577738\n",
      "        Refitted test  score: 0.8571428571428571,  RMSE: 0.3779644730092272, Log-Loss:4.934110913558669\n",
      "    random state: 850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.951151410466778 using:1.0,False,True,2,1.0\n",
      "          train score: 0.952030421375348 with variance: 1.664833130927765e-05\n",
      "          test  score: 0.951151410466778 with variance: 0.00036735680761559874\n",
      "        Refitted train score: 0.9539951573849877,  RMSE: 0.21118934387685415, Log-Loss:1.540467488956793\n",
      "        Refitted test  score: 0.927536231884058,  RMSE: 0.31943828249996997, Log-Loss:3.524381256571095\n",
      "      accuracy\n",
      "        CV score: 0.95296853625171 using:1.0,False,True,2,1.0\n",
      "          train score: 0.9536346386061757 with variance: 1.5540257464252226e-05\n",
      "          test  score: 0.95296853625171 with variance: 0.00033411420369375744\n",
      "        Refitted train score: 0.9553990610328639,  RMSE: 0.21118934387685415, Log-Loss:1.540467488956793\n",
      "        Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524381256571095\n",
      "      f1\n",
      "        CV score: 0.964300896489096 using:0.001,False,False,20,0.6\n",
      "          train score: 0.9619201904941459 with variance: 2.8832204681600585e-05\n",
      "          test  score: 0.964300896489096 with variance: 0.00017225023001066528\n",
      "        Refitted train score: 0.9620853080568721,  RMSE: 0.1938006332446037, Log-Loss:1.2972423002421423\n",
      "        Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9647332421340629 using:0.001,False,True,2,0.8\n",
      "          train score: 0.960672761773331 with variance: 5.450469300756355e-05\n",
      "          test  score: 0.9647332421340629 with variance: 0.00027810712233864376\n",
      "        Refitted train score: 0.960093896713615,  RMSE: 0.1997651202947726, Log-Loss:1.3783248711041167\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "      f1\n",
      "        CV score: 0.964300896489096 using:0.001,False,False,20,0.6\n",
      "          train score: 0.9619201904941459 with variance: 2.8832204681600585e-05\n",
      "          test  score: 0.964300896489096 with variance: 0.00017225023001066528\n",
      "        Refitted train score: 0.9620853080568721,  RMSE: 0.1938006332446037, Log-Loss:1.2972423002421423\n",
      "        Refitted test  score: 0.9428571428571428,  RMSE: 0.2857142857142857, Log-Loss:2.819508268919857\n",
      "      accuracy\n",
      "        CV score: 0.9647332421340629 using:0.001,False,True,2,0.8\n",
      "          train score: 0.960672761773331 with variance: 5.450469300756355e-05\n",
      "          test  score: 0.9647332421340629 with variance: 0.00027810712233864376\n",
      "        Refitted train score: 0.960093896713615,  RMSE: 0.1997651202947726, Log-Loss:1.3783248711041167\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097786119322817\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9482090010155213 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9430581041421329 with variance: 3.130575471091383e-05\n",
      "          test  score: 0.9482090010155213 with variance: 0.0001294036621064005\n",
      "        Refitted train score: 0.943661971830986,  RMSE: 0.23570226039551584, Log-Loss:1.9188375691081678\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9490777866880513 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9438669682499791 with variance: 3.210936330032747e-05\n",
      "          test  score: 0.9490777866880513 with variance: 0.00013736254902704798\n",
      "        Refitted train score: 0.9444444444444444,  RMSE: 0.23570226039551584, Log-Loss:1.9188375691081678\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      f1\n",
      "        CV score: 0.9482090010155213 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9430581041421329 with variance: 3.130575471091383e-05\n",
      "          test  score: 0.9482090010155213 with variance: 0.0001294036621064005\n",
      "        Refitted train score: 0.943661971830986,  RMSE: 0.23570226039551584, Log-Loss:1.9188375691081678\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9490777866880513 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9438669682499791 with variance: 3.210936330032747e-05\n",
      "          test  score: 0.9490777866880513 with variance: 0.00013736254902704798\n",
      "        Refitted train score: 0.9444444444444444,  RMSE: 0.23570226039551584, Log-Loss:1.9188375691081678\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      f1\n",
      "        CV score: 0.9482090010155213 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9430581041421329 with variance: 3.130575471091383e-05\n",
      "          test  score: 0.9482090010155213 with variance: 0.0001294036621064005\n",
      "        Refitted train score: 0.943661971830986,  RMSE: 0.23570226039551584, Log-Loss:1.9188375691081678\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9490777866880513 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9438669682499791 with variance: 3.210936330032747e-05\n",
      "          test  score: 0.9490777866880513 with variance: 0.00013736254902704798\n",
      "        Refitted train score: 0.9444444444444444,  RMSE: 0.23570226039551584, Log-Loss:1.9188375691081678\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.8320167316866443 using:1.0,True,False,2,1.0\n",
      "          train score: 0.8215874075390854 with variance: 0.00010190264651509519\n",
      "          test  score: 0.8320167316866443 with variance: 0.0015656057538447608\n",
      "        Refitted train score: 0.8341708542713567,  RMSE: 0.3964124835860459, Log-Loss:5.427563888589451\n",
      "        Refitted test  score: 0.9014084507042254,  RMSE: 0.3779644730092272, Log-Loss:4.93411091355867\n",
      "      accuracy\n",
      "        CV score: 0.8428571428571429 using:1.0,True,False,2,1.0\n",
      "          train score: 0.8333333333333334 with variance: 7.08616780045353e-05\n",
      "          test  score: 0.8428571428571429 with variance: 0.0010997732426303857\n",
      "        Refitted train score: 0.8428571428571429,  RMSE: 0.3964124835860459, Log-Loss:5.427563888589451\n",
      "        Refitted test  score: 0.8571428571428571,  RMSE: 0.3779644730092272, Log-Loss:4.93411091355867\n",
      "      f1\n",
      "        CV score: 0.8356441320182112 using:0.001,False,False,2,1.0\n",
      "          train score: 0.8375477380368078 with variance: 4.567121538557781e-05\n",
      "          test  score: 0.8356441320182112 with variance: 0.0005900170640916726\n",
      "        Refitted train score: 0.8361858190709046,  RMSE: 0.3994043183589901, Log-Loss:5.509810493302528\n",
      "        Refitted test  score: 0.9014084507042254,  RMSE: 0.3779644730092272, Log-Loss:4.93411091355867\n",
      "      accuracy\n",
      "        CV score: 0.8428571428571429 using:1.0,True,False,2,1.0\n",
      "          train score: 0.8333333333333334 with variance: 7.08616780045353e-05\n",
      "          test  score: 0.8428571428571429 with variance: 0.0010997732426303857\n",
      "        Refitted train score: 0.8428571428571429,  RMSE: 0.3964124835860459, Log-Loss:5.427563888589451\n",
      "        Refitted test  score: 0.8571428571428571,  RMSE: 0.3779644730092272, Log-Loss:4.93411091355867\n",
      "      f1\n",
      "        CV score: 0.8357306459320963 using:1.5,True,True,20,1.0\n",
      "          train score: 0.8304853837084553 with variance: 6.040767050395216e-05\n",
      "          test  score: 0.8357306459320963 with variance: 0.0011319935936635194\n",
      "        Refitted train score: 0.8282828282828283,  RMSE: 0.40237390808147827, Log-Loss:5.59203425237474\n",
      "        Refitted test  score: 0.9014084507042254,  RMSE: 0.3779644730092272, Log-Loss:4.93411091355867\n",
      "      accuracy\n",
      "        CV score: 0.8452380952380952 using:1.5,True,True,20,1.0\n",
      "          train score: 0.8398809523809524 with variance: 5.102040816326494e-05\n",
      "          test  score: 0.8452380952380952 with variance: 0.0007369614512471656\n",
      "        Refitted train score: 0.8380952380952381,  RMSE: 0.40237390808147827, Log-Loss:5.59203425237474\n",
      "        Refitted test  score: 0.8571428571428571,  RMSE: 0.3779644730092272, Log-Loss:4.93411091355867\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9669995204582253 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9685070197971566 with variance: 1.9822288696846764e-05\n",
      "          test  score: 0.9669995204582253 with variance: 0.0002914653380400275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9689737470167065,  RMSE: 0.17428089905580857, Log-Loss:1.0490787203941578\n",
      "        Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      accuracy\n",
      "        CV score: 0.967359781121751 using:1.0,True,True,10,0.8\n",
      "          train score: 0.9725504236782433 with variance: 8.658252884526905e-06\n",
      "          test  score: 0.967359781121751 with variance: 0.0003980649785444674\n",
      "        Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051144\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      f1\n",
      "        CV score: 0.9669995204582253 using:1.0,True,True,2,0.8\n",
      "          train score: 0.9685070197971566 with variance: 1.9822288696846764e-05\n",
      "          test  score: 0.9669995204582253 with variance: 0.0002914653380400275\n",
      "        Refitted train score: 0.9689737470167065,  RMSE: 0.17428089905580857, Log-Loss:1.0490787203941578\n",
      "        Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      accuracy\n",
      "        CV score: 0.967359781121751 using:1.0,True,True,10,0.8\n",
      "          train score: 0.9725504236782433 with variance: 8.658252884526905e-06\n",
      "          test  score: 0.967359781121751 with variance: 0.0003980649785444674\n",
      "        Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051144\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      f1\n",
      "        CV score: 0.969243022510209 using:1.5,True,True,2,0.8\n",
      "          train score: 0.9714638971315528 with variance: 9.108785175379868e-06\n",
      "          test  score: 0.969243022510209 with variance: 0.00025097396570507486\n",
      "        Refitted train score: 0.9689737470167065,  RMSE: 0.17428089905580857, Log-Loss:1.0490787203941578\n",
      "        Refitted test  score: 0.9393939393939393,  RMSE: 0.2857142857142857, Log-Loss:2.819491950604955\n",
      "      accuracy\n",
      "        CV score: 0.9696853625170998 using:1.5,True,True,10,0.8\n",
      "          train score: 0.9737166044362608 with variance: 1.0161444114155068e-05\n",
      "          test  score: 0.9696853625170998 with variance: 0.000409263400584998\n",
      "        Refitted train score: 0.9719626168224299,  RMSE: 0.16744367165578428, Log-Loss:0.9683806447051144\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9672568894520115 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9675736599930402 with variance: 4.174531167851591e-05\n",
      "          test  score: 0.9672568894520115 with variance: 0.0004971084413627874\n",
      "        Refitted train score: 0.9675810473815462,  RMSE: 0.17763276178186396, Log-Loss:1.0898177008040522\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9684689979429916 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9684480058948143 with variance: 3.886988604290333e-05\n",
      "          test  score: 0.9684689979429916 with variance: 0.0004490135020274337\n",
      "        Refitted train score: 0.9684466019417476,  RMSE: 0.17763276178186396, Log-Loss:1.0898177008040522\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9672568894520115 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9675736599930402 with variance: 4.174531167851591e-05\n",
      "          test  score: 0.9672568894520115 with variance: 0.0004971084413627874\n",
      "        Refitted train score: 0.9675810473815462,  RMSE: 0.17763276178186396, Log-Loss:1.0898177008040522\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9684689979429916 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9684480058948143 with variance: 3.886988604290333e-05\n",
      "          test  score: 0.9684689979429916 with variance: 0.0004490135020274337\n",
      "        Refitted train score: 0.9684466019417476,  RMSE: 0.17763276178186396, Log-Loss:1.0898177008040522\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      f1\n",
      "        CV score: 0.9673149355478674 using:1.5,False,True,2,0.8\n",
      "          train score: 0.9707897264853459 with variance: 1.0067712518412414e-05\n",
      "          test  score: 0.9673149355478674 with variance: 0.00031676835972789844\n",
      "        Refitted train score: 0.9727047146401985,  RMSE: 0.16339837553113432, Log-Loss:0.9221537377219613\n",
      "        Refitted test  score: 0.9885057471264368,  RMSE: 0.14285714285714285, Log-Loss:0.7048893059661413\n",
      "      accuracy\n",
      "        CV score: 0.9684689979429916 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9684480058948143 with variance: 3.886988604290333e-05\n",
      "          test  score: 0.9684689979429916 with variance: 0.0004490135020274337\n",
      "        Refitted train score: 0.9684466019417476,  RMSE: 0.17763276178186396, Log-Loss:1.0898177008040522\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9629907946194866 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9611372891951133 with variance: 6.974356218272871e-05\n",
      "          test  score: 0.9629907946194866 with variance: 0.0006312688748491298\n",
      "        Refitted train score: 0.9637305699481865,  RMSE: 0.18755233775398517, Log-Loss:1.2149338420255782\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9647151898734178 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9623035823426195 with variance: 6.356411366882552e-05\n",
      "          test  score: 0.9647151898734178 with variance: 0.0005408087646210545\n",
      "        Refitted train score: 0.964824120603015,  RMSE: 0.18755233775398517, Log-Loss:1.2149338420255782\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      f1\n",
      "        CV score: 0.9629907946194866 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9611372891951133 with variance: 6.974356218272871e-05\n",
      "          test  score: 0.9629907946194866 with variance: 0.0006312688748491298\n",
      "        Refitted train score: 0.9637305699481865,  RMSE: 0.18755233775398517, Log-Loss:1.2149338420255782\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9647151898734178 using:1.0,False,True,20,1.0\n",
      "          train score: 0.9623035823426195 with variance: 6.356411366882552e-05\n",
      "          test  score: 0.9647151898734178 with variance: 0.0005408087646210545\n",
      "        Refitted train score: 0.964824120603015,  RMSE: 0.18755233775398517, Log-Loss:1.2149338420255782\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      f1\n",
      "        CV score: 0.9655224401891068 using:1.5,False,True,20,1.0\n",
      "          train score: 0.9630626275104548 with variance: 5.49119247958283e-05\n",
      "          test  score: 0.9655224401891068 with variance: 0.0007802018807815489\n",
      "        Refitted train score: 0.9664082687338502,  RMSE: 0.1807299548578336, Log-Loss:1.1281529968122348\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9672151898734178 using:1.5,False,True,20,1.0\n",
      "          train score: 0.9641903747954498 with variance: 4.996648084235925e-05\n",
      "          test  score: 0.9672151898734178 with variance: 0.0006797328152539654\n",
      "        Refitted train score: 0.9673366834170855,  RMSE: 0.1807299548578336, Log-Loss:1.1281529968122348\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9562289562289562 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9560703812316715 with variance: 6.824846707544894e-06\n",
      "          test  score: 0.9562289562289562 with variance: 0.00011253421546831739\n",
      "        Refitted train score: 0.9560723514211887,  RMSE: 0.20513217183267982, Log-Loss:1.4533643532511933\n",
      "        Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.1881947441456027\n",
      "      accuracy\n",
      "        CV score: 0.9579320987654321 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9579214921836181 with variance: 6.071036382041621e-06\n",
      "          test  score: 0.9579320987654321 with variance: 9.666590458771543e-05\n",
      "        Refitted train score: 0.9579207920792079,  RMSE: 0.20513217183267982, Log-Loss:1.4533643532511933\n",
      "        Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1881947441456027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9562289562289562 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9560703812316715 with variance: 6.824846707544894e-06\n",
      "          test  score: 0.9562289562289562 with variance: 0.00011253421546831739\n",
      "        Refitted train score: 0.9560723514211887,  RMSE: 0.20513217183267982, Log-Loss:1.4533643532511933\n",
      "        Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.1881947441456027\n",
      "      accuracy\n",
      "        CV score: 0.9579320987654321 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9579214921836181 with variance: 6.071036382041621e-06\n",
      "          test  score: 0.9579320987654321 with variance: 9.666590458771543e-05\n",
      "        Refitted train score: 0.9579207920792079,  RMSE: 0.20513217183267982, Log-Loss:1.4533643532511933\n",
      "        Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1881947441456027\n",
      "      f1\n",
      "        CV score: 0.9562289562289562 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9560703812316715 with variance: 6.824846707544894e-06\n",
      "          test  score: 0.9562289562289562 with variance: 0.00011253421546831739\n",
      "        Refitted train score: 0.9560723514211887,  RMSE: 0.20513217183267982, Log-Loss:1.4533643532511933\n",
      "        Refitted test  score: 0.9318181818181819,  RMSE: 0.3038218101251, Log-Loss:3.1881947441456027\n",
      "      accuracy\n",
      "        CV score: 0.9579320987654321 using:1.0,True,True,2,1.0\n",
      "          train score: 0.9579214921836181 with variance: 6.071036382041621e-06\n",
      "          test  score: 0.9579320987654321 with variance: 9.666590458771543e-05\n",
      "        Refitted train score: 0.9579207920792079,  RMSE: 0.20513217183267982, Log-Loss:1.4533643532511933\n",
      "        Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1881947441456027\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9478969276337699 using:1.0,False,False,10,0.8\n",
      "          train score: 0.9466804554918085 with variance: 2.8610021579793466e-06\n",
      "          test  score: 0.9478969276337699 with variance: 0.00022245764775008367\n",
      "        Refitted train score: 0.9454545454545455,  RMSE: 0.229128784747792, Log-Loss:1.813291757713538\n",
      "        Refitted test  score: 0.9484536082474228,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "      accuracy\n",
      "        CV score: 0.95 using:1.0,False,False,10,0.8\n",
      "          train score: 0.9487500000000001 with variance: 2.3437499999999e-06\n",
      "          test  score: 0.95 with variance: 0.0001874999999999998\n",
      "        Refitted train score: 0.9475,  RMSE: 0.229128784747792, Log-Loss:1.813291757713538\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "      f1\n",
      "        CV score: 0.9538648388648389 using:0.001,False,True,2,1.0\n",
      "          train score: 0.9560424597123081 with variance: 2.894315387009653e-05\n",
      "          test  score: 0.9538648388648389 with variance: 0.0002774451725389671\n",
      "        Refitted train score: 0.9567430025445293,  RMSE: 0.20615528128088303, Log-Loss:1.4679079917515825\n",
      "        Refitted test  score: 0.9400000000000001,  RMSE: 0.3038218101251, Log-Loss:3.1882439501413065\n",
      "      accuracy\n",
      "        CV score: 0.9550000000000001 using:0.001,False,True,2,1.0\n",
      "          train score: 0.9568749999999999 with variance: 2.500000000000021e-05\n",
      "          test  score: 0.9550000000000001 with variance: 0.00022499999999999994\n",
      "        Refitted train score: 0.9575,  RMSE: 0.20615528128088303, Log-Loss:1.4679079917515825\n",
      "        Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1882439501413065\n",
      "      f1\n",
      "        CV score: 0.9538648388648389 using:0.001,False,True,2,1.0\n",
      "          train score: 0.9560424597123081 with variance: 2.894315387009653e-05\n",
      "          test  score: 0.9538648388648389 with variance: 0.0002774451725389671\n",
      "        Refitted train score: 0.9567430025445293,  RMSE: 0.20615528128088303, Log-Loss:1.4679079917515825\n",
      "        Refitted test  score: 0.9400000000000001,  RMSE: 0.3038218101251, Log-Loss:3.1882439501413065\n",
      "      accuracy\n",
      "        CV score: 0.9550000000000001 using:0.001,False,True,2,1.0\n",
      "          train score: 0.9568749999999999 with variance: 2.500000000000021e-05\n",
      "          test  score: 0.9550000000000001 with variance: 0.00022499999999999994\n",
      "        Refitted train score: 0.9575,  RMSE: 0.20615528128088303, Log-Loss:1.4679079917515825\n",
      "        Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1882439501413065\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9778945411274729 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9777923641357832 with variance: 1.2218425175328666e-05\n",
      "          test  score: 0.9778945411274729 with variance: 0.00020246637687533218\n",
      "        Refitted train score: 0.9777777777777779,  RMSE: 0.14888750009563953, Log-Loss:0.7656457781869883\n",
      "        Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      accuracy\n",
      "        CV score: 0.9778681120144534 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9778347578347578 with variance: 1.2792103960195201e-05\n",
      "          test  score: 0.9778681120144534 with variance: 0.00020464154589687383\n",
      "        Refitted train score: 0.9778325123152709,  RMSE: 0.14888750009563953, Log-Loss:0.7656457781869883\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      f1\n",
      "        CV score: 0.9778945411274729 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9777923641357832 with variance: 1.2218425175328666e-05\n",
      "          test  score: 0.9778945411274729 with variance: 0.00020246637687533218\n",
      "        Refitted train score: 0.9777777777777779,  RMSE: 0.14888750009563953, Log-Loss:0.7656457781869883\n",
      "        Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      accuracy\n",
      "        CV score: 0.9778681120144534 using:1.0,True,False,2,0.8\n",
      "          train score: 0.9778347578347578 with variance: 1.2792103960195201e-05\n",
      "          test  score: 0.9778681120144534 with variance: 0.00020464154589687383\n",
      "        Refitted train score: 0.9778325123152709,  RMSE: 0.14888750009563953, Log-Loss:0.7656457781869883\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      f1\n",
      "        CV score: 0.9803628955578525 using:1.5,True,False,2,1.0\n",
      "          train score: 0.9783918147956975 with variance: 3.327348643760671e-06\n",
      "          test  score: 0.9803628955578525 with variance: 0.00021254796441940536\n",
      "        Refitted train score: 0.9827160493827161,  RMSE: 0.13130643285972254, Log-Loss:0.5955020530952359\n",
      "        Refitted test  score: 0.967032967032967,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      accuracy\n",
      "        CV score: 0.9803372478169227 using:1.5,True,False,2,1.0\n",
      "          train score: 0.9784501424501425 with variance: 3.71737242392514e-06\n",
      "          test  score: 0.9803372478169227 with variance: 0.00021638871412301422\n",
      "        Refitted train score: 0.9827586206896551,  RMSE: 0.13130643285972254, Log-Loss:0.5955020530952359\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9407017876638128 using:1.0,False,False,10,0.6\n",
      "          train score: 0.9386604072209541 with variance: 5.510897069258975e-05\n",
      "          test  score: 0.9407017876638128 with variance: 0.001495560540075646\n",
      "        Refitted train score: 0.9435897435897437,  RMSE: 0.23690177073967142, Log-Loss:1.9384211139345338\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9413826679649466 using:1.0,False,False,10,0.6\n",
      "          train score: 0.9394171872774262 with variance: 5.2515591625341214e-05\n",
      "          test  score: 0.9413826679649466 with variance: 0.001444324666441439\n",
      "        Refitted train score: 0.9438775510204082,  RMSE: 0.23690177073967142, Log-Loss:1.9384211139345338\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      f1\n",
      "        CV score: 0.9407017876638128 using:1.0,False,False,10,0.6\n",
      "          train score: 0.9386604072209541 with variance: 5.510897069258975e-05\n",
      "          test  score: 0.9407017876638128 with variance: 0.001495560540075646\n",
      "        Refitted train score: 0.9435897435897437,  RMSE: 0.23690177073967142, Log-Loss:1.9384211139345338\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9414151249594289 using:0.001,False,True,20,0.6\n",
      "          train score: 0.9317637003723979 with variance: 4.2698212087555034e-05\n",
      "          test  score: 0.9414151249594289 with variance: 0.0013799015882015398\n",
      "        Refitted train score: 0.9413265306122449,  RMSE: 0.24222607082590245, Log-Loss:2.0265302373909386\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      f1\n",
      "        CV score: 0.9407017876638128 using:1.0,False,False,10,0.6\n",
      "          train score: 0.9386604072209541 with variance: 5.510897069258975e-05\n",
      "          test  score: 0.9407017876638128 with variance: 0.001495560540075646\n",
      "        Refitted train score: 0.9435897435897437,  RMSE: 0.23690177073967142, Log-Loss:1.9384211139345338\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9414151249594289 using:0.001,False,True,20,0.6\n",
      "          train score: 0.9317637003723979 with variance: 4.2698212087555034e-05\n",
      "          test  score: 0.9414151249594289 with variance: 0.0013799015882015398\n",
      "        Refitted train score: 0.9413265306122449,  RMSE: 0.24222607082590245, Log-Loss:2.0265302373909386\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525213\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9608424986695091 using:1.0,False,False,2,1.0\n",
      "          train score: 0.9668094093046335 with variance: 2.2762480470644194e-05\n",
      "          test  score: 0.9608424986695091 with variance: 0.00013551148316589043\n",
      "        Refitted train score: 0.9728395061728395,  RMSE: 0.16379642332078845, Log-Loss:0.9266559491129476\n",
      "        Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9609756097560975 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9658536585365853 with variance: 2.751338488994651e-05\n",
      "          test  score: 0.9609756097560975 with variance: 8.328375966686511e-05\n",
      "        Refitted train score: 0.9658536585365853,  RMSE: 0.18478728707195913, Log-Loss:1.17937870322205\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "      f1\n",
      "        CV score: 0.9608424986695091 using:1.0,False,False,2,1.0\n",
      "          train score: 0.9668094093046335 with variance: 2.2762480470644194e-05\n",
      "          test  score: 0.9608424986695091 with variance: 0.00013551148316589043\n",
      "        Refitted train score: 0.9728395061728395,  RMSE: 0.16379642332078845, Log-Loss:0.9266559491129476\n",
      "        Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.5941096735717277\n",
      "      accuracy\n",
      "        CV score: 0.9609756097560975 using:1.0,True,False,2,0.6\n",
      "          train score: 0.9658536585365853 with variance: 2.751338488994651e-05\n",
      "          test  score: 0.9609756097560975 with variance: 8.328375966686511e-05\n",
      "        Refitted train score: 0.9658536585365853,  RMSE: 0.18478728707195913, Log-Loss:1.17937870322205\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "      f1\n",
      "        CV score: 0.9676381308710627 using:1.5,True,False,2,0.8\n",
      "          train score: 0.9663500133884545 with variance: 2.7686546207507716e-05\n",
      "          test  score: 0.9676381308710627 with variance: 0.00016979687206083609\n",
      "        Refitted train score: 0.9653465346534654,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "        Refitted test  score: 0.9534883720930233,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "      accuracy\n",
      "        CV score: 0.9682926829268294 using:1.5,True,False,2,0.8\n",
      "          train score: 0.9670731707317073 with variance: 2.751338488994651e-05\n",
      "          test  score: 0.9682926829268294 with variance: 0.0001546698393813209\n",
      "        Refitted train score: 0.9658536585365853,  RMSE: 0.18478728707195913, Log-Loss:1.1793806534596845\n",
      "        Refitted test  score: 0.9384615384615385,  RMSE: 0.2480694691784169, Log-Loss:2.125475464262662\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9594347115000273 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9570498461935454 with variance: 5.502603149378997e-05\n",
      "          test  score: 0.9594347115000273 with variance: 0.00032806937737789267\n",
      "        Refitted train score: 0.9597855227882036,  RMSE: 0.19764235376052372, Log-Loss:1.3491751174961484\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.9610047846889952 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9570392148568043 with variance: 5.1741571059079566e-05\n",
      "          test  score: 0.9610047846889952 with variance: 0.0004704842949977316\n",
      "        Refitted train score: 0.9609375,  RMSE: 0.19764235376052372, Log-Loss:1.349173035211174\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      f1\n",
      "        CV score: 0.9594347115000273 using:1.0,False,True,2,0.8\n",
      "          train score: 0.9570498461935454 with variance: 5.502603149378997e-05\n",
      "          test  score: 0.9594347115000273 with variance: 0.00032806937737789267\n",
      "        Refitted train score: 0.9597855227882036,  RMSE: 0.19764235376052372, Log-Loss:1.3491751174961484\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.9610047846889952 using:1.0,True,True,20,0.8\n",
      "          train score: 0.9570392148568043 with variance: 5.1741571059079566e-05\n",
      "          test  score: 0.9610047846889952 with variance: 0.0004704842949977316\n",
      "        Refitted train score: 0.9609375,  RMSE: 0.19764235376052372, Log-Loss:1.349173035211174\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      f1\n",
      "        CV score: 0.9619014430806828 using:1.5,True,True,2,0.8\n",
      "          train score: 0.958744398099989 with variance: 3.797164316326477e-05\n",
      "          test  score: 0.9619014430806828 with variance: 0.00036518909025621106\n",
      "        Refitted train score: 0.9565217391304348,  RMSE: 0.2041241452319315, Log-Loss:1.439115683121279\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.9636021872863978 using:1.5,True,True,2,0.8\n",
      "          train score: 0.9602901984009475 with variance: 3.106243361505282e-05\n",
      "          test  score: 0.9636021872863978 with variance: 0.00029525282790023575\n",
      "        Refitted train score: 0.9583333333333334,  RMSE: 0.2041241452319315, Log-Loss:1.439115683121279\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n"
     ]
    }
   ],
   "source": [
    "#logistic parameters\n",
    "C = [1.0, 0.001, 1.5]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "            \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "        X_train, X_test = dominant_features(X_train, X_test, y_train, testsize, features)\n",
    "        \n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for c in C:            \n",
    "            lr = LogisticRegression(C = c, solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "\n",
    "            for b in bootstrap:\n",
    "                for bf in bootstrap_features:\n",
    "                    for n_estimator in n_estimators:\n",
    "                        for max_sample in max_samples:\n",
    "\n",
    "                            bc = BaggingClassifier(base_estimator = lr, bootstrap = b, bootstrap_features = bf, n_estimators = n_estimator, max_samples = max_sample, n_jobs = jobs, random_state = randomstate)\n",
    "                            cv_results = cross_validate(bc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "                                \n",
    "                            for score in scores:\n",
    "                                avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                                var_score_test = np.var(cv_results['test_' + score])\n",
    "                                avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                                var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                                if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                                    best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, c, b, bf, n_estimator, max_sample]\n",
    "\n",
    "            \n",
    "            for score in scores: \n",
    "            \n",
    "                print(tab * 3 + str(score))\n",
    "                print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "                print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "                print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "                random.seed(randomstate)\n",
    "                lr = LogisticRegression(C = best_avg_scores[score][4], solver = 'liblinear', max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "                bc = BaggingClassifier(base_estimator = lr, bootstrap = best_avg_scores[score][5], bootstrap_features = best_avg_scores[score][6], n_estimators = best_avg_scores[score][7], max_samples = best_avg_scores[score][8], n_jobs = jobs, random_state = randomstate)\n",
    "                    \n",
    "                bc.fit(X_train, y_train)            \n",
    "                y_train_pred, y_test_pred = bc.predict(X_train), bc.predict(X_test)                          \n",
    "                rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "                log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "                score_train, score_test = get_scorer(score)(bc, X_train, y_train), get_scorer(score)(bc, X_test, y_test)\n",
    "\n",
    "                print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "                print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\") \n",
    "\n",
    "                n = len(results)\n",
    "                results.at[n, 'score'] = score\n",
    "                results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "                results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "                results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "                results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "                results.at[n, 'test rmse'] = rmse_test\n",
    "                results.at[n, 'train rmse'] = rmse_train\n",
    "                results.at[n, 'test log_loss'] = log_loss_test\n",
    "                results.at[n, 'train log_loss'] = log_loss_train\n",
    "                results.at[n, 'test size'] = testsize\n",
    "                results.at[n, 'random state'] = randomstate\n",
    "                results.at[n, 'estimator'] = \"Smote/Bagging/LogisticRegression\"\n",
    "                results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "262b0552",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.961005</td>\n",
       "      <td>0.957039</td>\n",
       "      <td>0.000470484</td>\n",
       "      <td>5.17416e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.34917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,20,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.959435</td>\n",
       "      <td>0.95705</td>\n",
       "      <td>0.000328069</td>\n",
       "      <td>5.5026e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.34918</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,False,True,2,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.961005</td>\n",
       "      <td>0.957039</td>\n",
       "      <td>0.000470484</td>\n",
       "      <td>5.17416e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.197642</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.34917</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.0,True,True,20,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.961901</td>\n",
       "      <td>0.958744</td>\n",
       "      <td>0.000365189</td>\n",
       "      <td>3.79716e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.43912</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.5,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.963602</td>\n",
       "      <td>0.96029</td>\n",
       "      <td>0.000295253</td>\n",
       "      <td>3.10624e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.43912</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/LogisticRegression</td>\n",
       "      <td>1.5,True,True,2,0.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "275  accuracy   0.961005    0.957039   0.000470484    5.17416e-05  0.124035   \n",
       "276        f1   0.959435     0.95705   0.000328069     5.5026e-05  0.124035   \n",
       "277  accuracy   0.961005    0.957039   0.000470484    5.17416e-05  0.124035   \n",
       "278        f1   0.961901    0.958744   0.000365189    3.79716e-05  0.124035   \n",
       "279  accuracy   0.963602     0.96029   0.000295253    3.10624e-05  0.124035   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "275   0.197642      0.531366        1.34917       0.2         2050   \n",
       "276   0.197642      0.531366        1.34918       0.2         2050   \n",
       "277   0.197642      0.531366        1.34917       0.2         2050   \n",
       "278   0.204124      0.531366        1.43912       0.2         2050   \n",
       "279   0.204124      0.531366        1.43912       0.2         2050   \n",
       "\n",
       "                            estimator      estimator params  \n",
       "275  Smote/Bagging/LogisticRegression  1.0,True,True,20,0.8  \n",
       "276  Smote/Bagging/LogisticRegression  1.0,False,True,2,0.8  \n",
       "277  Smote/Bagging/LogisticRegression  1.0,True,True,20,0.8  \n",
       "278  Smote/Bagging/LogisticRegression   1.5,True,True,2,0.8  \n",
       "279  Smote/Bagging/LogisticRegression   1.5,True,True,2,0.8  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d31163d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test size: 0.08\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9536160491182979 using:True,False,2,1.0,rbf,1\n",
      "          train score: 0.9484053573125888 with variance: 4.3703583605295293e-05\n",
      "          test  score: 0.9536160491182979 with variance: 0.0010782845071462192\n",
      "        Refitted train score: 0.9523809523809524,  RMSE: 0.21412969991171116, Log-Loss:1.583659177921365\n",
      "        Refitted test  score: 0.9743589743589743,  RMSE: 0.19611613513818404, Log-Loss:1.328414476727335\n",
      "      accuracy\n",
      "        CV score: 0.9562111801242235 using:True,False,2,1.0,rbf,1\n",
      "          train score: 0.9503208707434375 with variance: 3.7603290686529364e-05\n",
      "          test  score: 0.9562111801242235 with variance: 0.0009172933051700794\n",
      "        Refitted train score: 0.9606986899563319,  RMSE: 0.19824558013652693, Log-Loss:1.3574226513171463\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656859707201984\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9666357322754567 using:False,False,10,0.8,rbf,1.5\n",
      "          train score: 0.9741493953156514 with variance: 5.7321319529549726e-05\n",
      "          test  score: 0.9666357322754567 with variance: 0.0012208144109233435\n",
      "        Refitted train score: 0.9736842105263157,  RMSE: 0.16116459280507606, Log-Loss:0.8971162673835912\n",
      "        Refitted test  score: 0.8750000000000001,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "      accuracy\n",
      "        CV score: 0.9676250584385226 using:False,False,10,0.8,rbf,1.5\n",
      "          train score: 0.9745726214018898 with variance: 5.431555216057193e-05\n",
      "          test  score: 0.9676250584385226 with variance: 0.0011079605124973745\n",
      "        Refitted train score: 0.974025974025974,  RMSE: 0.16116459280507606, Log-Loss:0.8971162673835912\n",
      "        Refitted test  score: 0.8461538461538461,  RMSE: 0.3922322702763681, Log-Loss:5.313657906909336\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9053735189048021 using:False,False,20,0.6,rbf,1\n",
      "          train score: 0.9134452589641292 with variance: 4.647818160744475e-05\n",
      "          test  score: 0.9053735189048021 with variance: 0.0011926627323550476\n",
      "        Refitted train score: 0.9070294784580498,  RMSE: 0.29790030000755074, Log-Loss:3.0651468142113427\n",
      "        Refitted test  score: 0.9473684210526316,  RMSE: 0.2773500981126146, Log-Loss:2.656890460949299\n",
      "      accuracy\n",
      "        CV score: 0.9113136979897147 using:False,False,20,0.6,rbf,1\n",
      "          train score: 0.9172064747674504 with variance: 4.8774734722073956e-05\n",
      "          test  score: 0.9113136979897147 with variance: 0.0008509916571973862\n",
      "        Refitted train score: 0.9155844155844156,  RMSE: 0.29054360157398823, Log-Loss:2.915623109488156\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.19611613513818404, Log-Loss:1.32844523047465\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9570208435663563 using:True,False,2,1.0,rbf,1.5\n",
      "          train score: 0.9565245814845449 with variance: 3.7585009032327905e-05\n",
      "          test  score: 0.9570208435663563 with variance: 0.0002021190564524504\n",
      "        Refitted train score: 0.957303370786517,  RMSE: 0.20279433208435863, Log-Loss:1.4204275997851372\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9588592800374007 using:True,False,2,1.0,rbf,1.5\n",
      "          train score: 0.9583300373544276 with variance: 3.1298130936377217e-05\n",
      "          test  score: 0.9588592800374007 with variance: 0.00016153511414827452\n",
      "        Refitted train score: 0.961038961038961,  RMSE: 0.19738550848793068, Log-Loss:1.3456666127887285\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9610014618407 using:False,True,30,0.6,rbf,1.5\n",
      "          train score: 0.9624047714739208 with variance: 1.1713821471703658e-05\n",
      "          test  score: 0.9610014618407 with variance: 0.00025965938027104206\n",
      "        Refitted train score: 0.9636363636363636,  RMSE: 0.18772930178557284, Log-Loss:1.2172273610484616\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9626129426129426 using:False,True,30,0.6,rbf,1.5\n",
      "          train score: 0.9636590682045227 with variance: 1.009798493306708e-05\n",
      "          test  score: 0.9626129426129426 with variance: 0.00022090968318074582\n",
      "        Refitted train score: 0.960352422907489,  RMSE: 0.1991169934799916, Log-Loss:1.3693805610260417\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9562965124762878 using:True,False,30,1.0,rbf,1.5\n",
      "          train score: 0.9607052372021094 with variance: 4.516515622289545e-05\n",
      "          test  score: 0.9562965124762878 with variance: 0.00036148148239629563\n",
      "        Refitted train score: 0.9612756264236901,  RMSE: 0.19350693507134273, Log-Loss:1.2933039610372516\n",
      "        Refitted test  score: 0.9523809523809523,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "      accuracy\n",
      "        CV score: 0.9581929181929182 using:True,False,30,1.0,rbf,1.5\n",
      "          train score: 0.9620092029182938 with variance: 4.02262199143003e-05\n",
      "          test  score: 0.9581929181929182 with variance: 0.00030721881564372357\n",
      "        Refitted train score: 0.9647577092511013,  RMSE: 0.18772930178557284, Log-Loss:1.2172255998206416\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656828953454669\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9706643745575892 using:False,False,2,0.6,rbf,1\n",
      "          train score: 0.9701078100665406 with variance: 4.190093685427483e-05\n",
      "          test  score: 0.9706643745575892 with variance: 0.00023638502250089783\n",
      "        Refitted train score: 0.9707865168539326,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "      accuracy\n",
      "        CV score: 0.9714285714285715 using:False,False,2,0.6,rbf,1\n",
      "          train score: 0.9708185753640299 with variance: 3.799010668174563e-05\n",
      "          test  score: 0.9714285714285715 with variance: 0.00022219538703055155\n",
      "        Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.9889957998542716\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626413e-16\n",
      "test size: 0.1\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9723661210869221 using:False,False,2,1.0,rbf,1.5\n",
      "          train score: 0.976890871397352 with variance: 4.02680656653306e-05\n",
      "          test  score: 0.9723661210869221 with variance: 0.0007027055731665451\n",
      "        Refitted train score: 0.9774774774774775,  RMSE: 0.1494035761667992, Log-Loss:0.7709601846906201\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.9731086142322096 using:False,False,2,1.0,rbf,1.5\n",
      "          train score: 0.9771152020665724 with variance: 3.878463885177149e-05\n",
      "          test  score: 0.9731086142322096 with variance: 0.000635295767930537\n",
      "        Refitted train score: 0.9776785714285714,  RMSE: 0.1494035761667992, Log-Loss:0.7709601846906201\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9496329252143207 using:True,False,30,1.0,linear,1\n",
      "          train score: 0.9533954712144801 with variance: 2.8935653537988978e-05\n",
      "          test  score: 0.9496329252143207 with variance: 0.000381527779786633\n",
      "        Refitted train score: 0.9545454545454545,  RMSE: 0.21081851067789195, Log-Loss:1.535065613078589\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "      accuracy\n",
      "        CV score: 0.9511111111111111 using:True,False,30,1.0,linear,1\n",
      "          train score: 0.9544444444444444 with variance: 2.654320987654354e-05\n",
      "          test  score: 0.9511111111111111 with variance: 0.0003259259259259255\n",
      "        Refitted train score: 0.9577777777777777,  RMSE: 0.20548046676563256, Log-Loss:1.4583127766454542\n",
      "        Refitted test  score: 0.8787878787878788,  RMSE: 0.3481553119113957, Log-Loss:4.1865183508982655\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9132980383891514 using:False,True,20,0.8,rbf,1.5\n",
      "          train score: 0.9137913894270303 with variance: 5.457587760042592e-05\n",
      "          test  score: 0.9132980383891514 with variance: 0.002125840192554107\n",
      "        Refitted train score: 0.9154929577464789,  RMSE: 0.28159395267835924, Log-Loss:2.7387646445077216\n",
      "        Refitted test  score: 0.9333333333333332,  RMSE: 0.30151134457776363, Log-Loss:3.139937223624014\n",
      "      accuracy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        CV score: 0.9208058608058607 using:False,True,20,0.8,rbf,1.5\n",
      "          train score: 0.9190582145127599 with variance: 4.941045016671892e-05\n",
      "          test  score: 0.9208058608058607 with variance: 0.0016065907230742402\n",
      "        Refitted train score: 0.920704845814978,  RMSE: 0.28159395267835924, Log-Loss:2.738766405735541\n",
      "        Refitted test  score: 0.9090909090909091,  RMSE: 0.30151134457776363, Log-Loss:3.139937223624014\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9708325382482685 using:False,True,30,0.8,rbf,1.5\n",
      "          train score: 0.9696213023996574 with variance: 1.4340865371218624e-05\n",
      "          test  score: 0.9708325382482685 with variance: 0.00022971856506646444\n",
      "        Refitted train score: 0.9661399548532731,  RMSE: 0.18176811485266747, Log-Loss:1.141152522287491\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "      accuracy\n",
      "        CV score: 0.9713797313797313 using:False,True,30,0.8,rbf,1.5\n",
      "          train score: 0.9702645839009476 with variance: 1.3339469338016302e-05\n",
      "          test  score: 0.9713797313797313 with variance: 0.0002215608838319465\n",
      "        Refitted train score: 0.9713656387665198,  RMSE: 0.16921690587373409, Log-Loss:0.988999322309911\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.833328058877702 using:False,False,2,0.8,rbf,1.5\n",
      "          train score: 0.8313394344673517 with variance: 0.0001469206717189838\n",
      "          test  score: 0.833328058877702 with variance: 0.0027458525311417235\n",
      "        Refitted train score: 0.8337468982630273,  RMSE: 0.38758768717109265, Log-Loss:5.188582093336723\n",
      "        Refitted test  score: 0.8979591836734695,  RMSE: 0.3892494720807615, Log-Loss:5.233172168847989\n",
      "      accuracy\n",
      "        CV score: 0.8499126092384518 using:False,False,2,0.8,rbf,1.5\n",
      "          train score: 0.8458581185283102 with variance: 0.00011121366345092843\n",
      "          test  score: 0.8499126092384518 with variance: 0.001890448425111557\n",
      "        Refitted train score: 0.8408071748878924,  RMSE: 0.39898975564807126, Log-Loss:5.49834690405341\n",
      "        Refitted test  score: 0.8181818181818182,  RMSE: 0.4264014327112209, Log-Loss:6.279801756572555\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9626712330179952 using:True,True,10,1.0,rbf,1\n",
      "          train score: 0.9601199996255412 with variance: 3.273975500705198e-05\n",
      "          test  score: 0.9626712330179952 with variance: 0.00041126715400863965\n",
      "        Refitted train score: 0.9559164733178654,  RMSE: 0.20639984704690686, Log-Loss:1.4713864365429679\n",
      "        Refitted test  score: 0.9387755102040816,  RMSE: 0.30151134457776363, Log-Loss:3.1398887631736994\n",
      "      accuracy\n",
      "        CV score: 0.964194756554307 using:True,True,10,1.0,rbf,1\n",
      "          train score: 0.9613272275202217 with variance: 2.9231661424703783e-05\n",
      "          test  score: 0.964194756554307 with variance: 0.0003643535468305061\n",
      "        Refitted train score: 0.9641255605381166,  RMSE: 0.18940548952415134, Log-Loss:1.239061035686102\n",
      "        Refitted test  score: 0.9696969696969697,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9743868850303116 using:True,True,2,1.0,rbf,1.5\n",
      "          train score: 0.9750955917390142 with variance: 9.022368291206027e-06\n",
      "          test  score: 0.9743868850303116 with variance: 8.013416921939914e-05\n",
      "        Refitted train score: 0.9375,  RMSE: 0.24308621740219885, Log-Loss:2.0409295133297918\n",
      "        Refitted test  score: 0.9824561403508771,  RMSE: 0.17407765595569785, Log-Loss:1.046629587724567\n",
      "      accuracy\n",
      "        CV score: 0.975 using:True,True,2,1.0,rbf,1.5\n",
      "          train score: 0.9755681818181818 with variance: 8.393595041322311e-06\n",
      "          test  score: 0.975 with variance: 7.231404958677674e-05\n",
      "        Refitted train score: 0.9727272727272728,  RMSE: 0.1651445647689541, Log-Loss:0.9419666289521104\n",
      "        Refitted test  score: 1.0,  RMSE: 0.0, Log-Loss:9.992007221626415e-16\n",
      "test size: 0.15\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9250327230057916 using:True,False,30,1.0,rbf,1\n",
      "          train score: 0.9255873563333189 with variance: 0.00011532572051409203\n",
      "          test  score: 0.9250327230057916 with variance: 0.0013957282235952464\n",
      "        Refitted train score: 0.9227053140096618,  RMSE: 0.27472112789737807, Log-Loss:2.606720849549232\n",
      "        Refitted test  score: 0.972972972972973,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9267787114845938 using:True,False,30,1.0,rbf,1\n",
      "          train score: 0.9274718028804442 with variance: 0.00011057999855414433\n",
      "          test  score: 0.9267787114845938 with variance: 0.0013208608933769602\n",
      "        Refitted train score: 0.9245283018867925,  RMSE: 0.27472112789737807, Log-Loss:2.606720849549232\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9353402980693538 using:True,False,20,1.0,rbf,1.5\n",
      "          train score: 0.9498278978965438 with variance: 6.092629580797648e-05\n",
      "          test  score: 0.9353402980693538 with variance: 0.0013462547834817667\n",
      "        Refitted train score: 0.9476190476190477,  RMSE: 0.22671980319080753, Log-Loss:1.7753707426870249\n",
      "        Refitted test  score: 0.923076923076923,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "      accuracy\n",
      "        CV score: 0.9369083447332421 using:True,False,20,1.0,rbf,1.5\n",
      "          train score: 0.9509368659744599 with variance: 5.9022635442201616e-05\n",
      "          test  score: 0.9369083447332421 with variance: 0.001285201577210911\n",
      "        Refitted train score: 0.955607476635514,  RMSE: 0.21069533303916815, Log-Loss:1.5332709109650093\n",
      "        Refitted test  score: 0.8979591836734694,  RMSE: 0.31943828249996997, Log-Loss:3.524364938256193\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9807775146497034 using:True,False,2,0.8,rbf,1.5\n",
      "          train score: 0.977176604489 with variance: 9.975364870704202e-06\n",
      "          test  score: 0.9807775146497034 with variance: 9.515407637945641e-05\n",
      "        Refitted train score: 0.9808612440191388,  RMSE: 0.13703774196550633, Log-Loss:0.6486155191532532\n",
      "        Refitted test  score: 0.9859154929577464,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      accuracy\n",
      "        CV score: 0.9812038303693571 using:True,False,2,0.8,rbf,1.5\n",
      "          train score: 0.9776988097291703 with variance: 8.97698925187462e-06\n",
      "          test  score: 0.9812038303693571 with variance: 8.897056484286853e-05\n",
      "        Refitted train score: 0.9788732394366197,  RMSE: 0.14535047493345277, Log-Loss:0.7296924590474099\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.4097459753024781\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.964575394020858 using:True,False,20,1.0,rbf,1.5\n",
      "          train score: 0.9817967133109665 with variance: 1.9296776749583984e-05\n",
      "          test  score: 0.964575394020858 with variance: 0.00011949021345842648\n",
      "        Refitted train score: 0.9741176470588236,  RMSE: 0.15957118462605635, Log-Loss:0.8794632859696258\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "      accuracy\n",
      "        CV score: 0.9653033948142209 using:True,False,20,1.0,rbf,1.5\n",
      "          train score: 0.982065845689872 with variance: 1.7899714755152223e-05\n",
      "          test  score: 0.9653033948142209 with variance: 0.00010573429335635829\n",
      "        Refitted train score: 0.9814814814814815,  RMSE: 0.13608276348795434, Log-Loss:0.639608821196102\n",
      "        Refitted test  score: 0.9795918367346939,  RMSE: 0.14285714285714285, Log-Loss:0.7048729876512395\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.8458479328636784 using:False,True,20,0.6,rbf,1\n",
      "          train score: 0.8461086901695036 with variance: 8.218188777343763e-05\n",
      "          test  score: 0.8458479328636784 with variance: 0.0005681699880998014\n",
      "        Refitted train score: 0.8434343434343434,  RMSE: 0.3842122429322726, Log-Loss:5.098617449608658\n",
      "        Refitted test  score: 0.8888888888888888,  RMSE: 0.40406101782088427, Log-Loss:5.63900021952481\n",
      "      accuracy\n",
      "        CV score: 0.8547619047619047 using:False,True,20,0.6,rbf,1\n",
      "          train score: 0.8535714285714284 with variance: 8.999433106575998e-05\n",
      "          test  score: 0.8547619047619047 with variance: 0.0004195011337868483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.8523809523809524,  RMSE: 0.3842122429322726, Log-Loss:5.0986136420018475\n",
      "        Refitted test  score: 0.8163265306122449,  RMSE: 0.4285714285714286, Log-Loss:6.343873207176049\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.980952380952381 using:True,False,20,0.8,linear,1.5\n",
      "          train score: 0.9791257995735607 with variance: 1.0820781865876242e-05\n",
      "          test  score: 0.980952380952381 with variance: 9.070294784580434e-05\n",
      "        Refitted train score: 0.9809523809523809,  RMSE: 0.13671718540493263, Log-Loss:0.6455846055123502\n",
      "        Refitted test  score: 0.955223880597015,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "      accuracy\n",
      "        CV score: 0.9813406292749658 using:True,False,20,0.8,linear,1.5\n",
      "          train score: 0.9795594428247488 with variance: 1.008124469191688e-05\n",
      "          test  score: 0.9813406292749658 with variance: 8.705425732791157e-05\n",
      "        Refitted train score: 0.9789719626168224,  RMSE: 0.14501047335684952, Log-Loss:0.7262826812013938\n",
      "        Refitted test  score: 0.9387755102040817,  RMSE: 0.24743582965269675, Log-Loss:2.1146189629537164\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9678446939031836 using:True,False,10,1.0,rbf,1.5\n",
      "          train score: 0.9766674367819561 with variance: 1.82301797635174e-05\n",
      "          test  score: 0.9678446939031836 with variance: 0.0002925819155321552\n",
      "        Refitted train score: 0.9802955665024631,  RMSE: 0.13934660285832354, Log-Loss:0.6706577930988254\n",
      "        Refitted test  score: 0.9767441860465116,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "      accuracy\n",
      "        CV score: 0.9684689979429916 using:True,False,10,1.0,rbf,1.5\n",
      "          train score: 0.9769439071566731 with variance: 1.6825814388324297e-05\n",
      "          test  score: 0.9684689979429916 with variance: 0.0002719731228836567\n",
      "        Refitted train score: 0.9781553398058253,  RMSE: 0.14779939172464399, Log-Loss:0.7544878338694091\n",
      "        Refitted test  score: 0.9591836734693877,  RMSE: 0.20203050891044214, Log-Loss:1.40976229361738\n",
      "test size: 0.2\n",
      "    random state: 250\n",
      "      f1\n",
      "        CV score: 0.9655273735273736 using:True,True,30,0.8,rbf,1\n",
      "          train score: 0.9655302590532558 with variance: 3.0024580702825143e-05\n",
      "          test  score: 0.9655273735273736 with variance: 0.000709451244303636\n",
      "        Refitted train score: 0.9662337662337662,  RMSE: 0.1807299548578336, Log-Loss:1.1281509877734652\n",
      "        Refitted test  score: 0.9494949494949495,  RMSE: 0.2773500981126146, Log-Loss:2.6568535564525204\n",
      "      accuracy\n",
      "        CV score: 0.9672151898734178 using:True,True,30,0.8,rbf,1\n",
      "          train score: 0.9667021549259674 with variance: 2.6440805172970612e-05\n",
      "          test  score: 0.9672151898734178 with variance: 0.0006172328152539649\n",
      "        Refitted train score: 0.9673366834170855,  RMSE: 0.1807299548578336, Log-Loss:1.1281509877734652\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.656853556452521\n",
      "    random state: 650\n",
      "      f1\n",
      "        CV score: 0.9532188417598144 using:False,True,30,1.0,rbf,1.5\n",
      "          train score: 0.9547128543554002 with variance: 1.338191163368389e-05\n",
      "          test  score: 0.9532188417598144 with variance: 0.00047248843977329007\n",
      "        Refitted train score: 0.9533678756476685,  RMSE: 0.21107926341908756, Log-Loss:1.5388563740306747\n",
      "        Refitted test  score: 0.9438202247191011,  RMSE: 0.2773500981126146, Log-Loss:2.6568289534546685\n",
      "      accuracy\n",
      "        CV score: 0.9554320987654321 using:True,True,2,1.0,rbf,1.5\n",
      "          train score: 0.953583304666896 with variance: 3.1100306944209616e-05\n",
      "          test  score: 0.9554320987654321 with variance: 0.00040365797896662015\n",
      "        Refitted train score: 0.9356435643564357,  RMSE: 0.2536857024815635, Log-Loss:2.2227925402665303\n",
      "        Refitted test  score: 0.8769230769230769,  RMSE: 0.35082320772281167, Log-Loss:4.25092632552747\n",
      "    random state: 850\n",
      "      f1\n",
      "        CV score: 0.9718922427783188 using:True,False,10,1.0,rbf,1\n",
      "          train score: 0.978384082205619 with variance: 1.8423356457406835e-05\n",
      "          test  score: 0.9718922427783188 with variance: 2.433905876401516e-05\n",
      "        Refitted train score: 0.9770992366412213,  RMSE: 0.15, Log-Loss:0.7771244678790667\n",
      "        Refitted test  score: 0.9791666666666666,  RMSE: 0.17541160386140583, Log-Loss:1.062731581381868\n",
      "      accuracy\n",
      "        CV score: 0.9724999999999999 using:True,False,10,1.0,rbf,1\n",
      "          train score: 0.97875 with variance: 1.718749999999982e-05\n",
      "          test  score: 0.9724999999999999 with variance: 2.499999999999982e-05\n",
      "        Refitted train score: 0.9775,  RMSE: 0.15, Log-Loss:0.7771244678790667\n",
      "        Refitted test  score: 0.9846153846153847,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909346\n",
      "    random state: 1050\n",
      "      f1\n",
      "        CV score: 0.9721423991260361 using:False,False,2,1.0,rbf,1.5\n",
      "          train score: 0.9774287272620066 with variance: 1.7904580306361e-05\n",
      "          test  score: 0.9721423991260361 with variance: 0.00028880838705275247\n",
      "        Refitted train score: 0.9774436090225564,  RMSE: 0.14888750009563953, Log-Loss:0.7656398698315929\n",
      "        Refitted test  score: 0.9347826086956522,  RMSE: 0.3038218101251, Log-Loss:3.1882316486423807\n",
      "      accuracy\n",
      "        CV score: 0.97289972899729 using:False,False,2,1.0,rbf,1.5\n",
      "          train score: 0.9778328584995253 with variance: 1.6647065454916157e-05\n",
      "          test  score: 0.97289972899729 with variance: 0.000268563694703828\n",
      "        Refitted train score: 0.9778325123152709,  RMSE: 0.14888750009563953, Log-Loss:0.7656398698315929\n",
      "        Refitted test  score: 0.9076923076923077,  RMSE: 0.3038218101251, Log-Loss:3.1882316486423807\n",
      "    random state: 1250\n",
      "      f1\n",
      "        CV score: 0.9524849869206964 using:True,True,20,1.0,rbf,1.5\n",
      "          train score: 0.9531066154853027 with variance: 9.6660192280473e-05\n",
      "          test  score: 0.9524849869206964 with variance: 0.0012330575506728167\n",
      "        Refitted train score: 0.9371727748691099,  RMSE: 0.24743582965269675, Log-Loss:2.1146332414792552\n",
      "        Refitted test  score: 0.9615384615384616,  RMSE: 0.2480694691784169, Log-Loss:2.1254754642626614\n",
      "      accuracy\n",
      "        CV score: 0.9541382667964946 using:True,True,20,1.0,rbf,1.5\n",
      "          train score: 0.9540851834517003 with variance: 9.190263319378453e-05\n",
      "          test  score: 0.9541382667964946 with variance: 0.0011302597897448335\n",
      "        Refitted train score: 0.9489795918367347,  RMSE: 0.22587697572631282, Log-Loss:1.7621947078642735\n",
      "        Refitted test  score: 0.9538461538461539,  RMSE: 0.21483446221182986, Log-Loss:1.5940973720728018\n",
      "    random state: 1850\n",
      "      f1\n",
      "        CV score: 0.9826528154170431 using:False,False,2,1.0,rbf,1.5\n",
      "          train score: 0.9882734454705557 with variance: 5.462388406931107e-06\n",
      "          test  score: 0.9826528154170431 with variance: 9.853514462408843e-05\n",
      "        Refitted train score: 0.9901477832512315,  RMSE: 0.09877295966495896, Log-Loss:0.336963672145471\n",
      "        Refitted test  score: 0.9655172413793104,  RMSE: 0.21483446221182986, Log-Loss:1.594109673571728\n",
      "      accuracy\n",
      "        CV score: 0.9829268292682926 using:False,True,20,0.8,rbf,1.5\n",
      "          train score: 0.9871951219512194 with variance: 1.2641284949434884e-05\n",
      "          test  score: 0.9829268292682926 with variance: 3.569303985722791e-05\n",
      "        Refitted train score: 0.9878048780487805,  RMSE: 0.11043152607484655, Log-Loss:0.4212045901818386\n",
      "        Refitted test  score: 0.9230769230769231,  RMSE: 0.2773500981126146, Log-Loss:2.6568412549535947\n",
      "    random state: 2050\n",
      "      f1\n",
      "        CV score: 0.9563877938932013 using:True,False,10,1.0,rbf,1.5\n",
      "          train score: 0.9609921555208979 with variance: 9.509021754747523e-05\n",
      "          test  score: 0.9563877938932013 with variance: 0.0008869543620829296\n",
      "        Refitted train score: 0.9569892473118279,  RMSE: 0.2041241452319315, Log-Loss:1.4391198476912284\n",
      "        Refitted test  score: 0.9911504424778761,  RMSE: 0.12403473458920845, Log-Loss:0.5313657906909345\n",
      "      accuracy\n",
      "        CV score: 0.9584415584415584 using:True,False,2,0.8,linear,1.5\n",
      "          train score: 0.9531304200685309 with variance: 4.013925704506882e-05\n",
      "          test  score: 0.9584415584415584 with variance: 0.0006341710237814139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Refitted train score: 0.9557291666666666,  RMSE: 0.2104063528825433, Log-Loss:1.5290604133163592\n",
      "        Refitted test  score: 0.9692307692307692,  RMSE: 0.17541160386140583, Log-Loss:1.0627315813818679\n"
     ]
    }
   ],
   "source": [
    "#bagging svc\n",
    "kernels = ['linear', 'rbf']\n",
    "C = [0.001, 1, 1.5]\n",
    "\n",
    "for testsize in testsizes:\n",
    "  print(f\"test size: {testsize}\")\n",
    "    \n",
    "  for randomstate in randomstates:\n",
    "        print(tab * 2 + f\"random state: {randomstate}\")\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = testsize, random_state = randomstate)\n",
    "        X_train, X_test = dominant_features(X_train, X_test, y_train, testsize, features)\n",
    "\n",
    "        smote = SMOTE(random_state = randomstate)\n",
    "        X_train, y_train = smote.fit_resample(X_train, y_train)\n",
    "\n",
    "        robustscaler = RobustScaler(quantile_range = (1, 99))\n",
    "        robustscaler.fit(X_train)\n",
    "                                    \n",
    "        X_train = robustscaler.transform(X_train)\n",
    "        X_test  = robustscaler.transform(X_test)\n",
    "\n",
    "        best_avg_scores = {score : [None] for score in scores}\n",
    "        \n",
    "        # Run Grid search for each classifier\n",
    "        for kernel in kernels:\n",
    "            for c in C:\n",
    "                    \n",
    "                svc = SVC(kernel = kernel, C = c, max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "\n",
    "                for b in bootstrap:\n",
    "                    for bf in bootstrap_features:\n",
    "                        for n_estimator in n_estimators:\n",
    "                            for max_sample in max_samples:\n",
    "\n",
    "                                bc = BaggingClassifier(base_estimator = svc, bootstrap = b, bootstrap_features = bf, n_estimators = n_estimator, max_samples = max_sample, n_jobs = jobs, random_state = randomstate)\n",
    "                                cv_results = cross_validate(bc, X_train, y_train, cv = cv, scoring = scores, return_train_score = True, n_jobs = jobs)\n",
    "\n",
    "                                for score in scores:\n",
    "                                    avg_score_test = np.mean(cv_results['test_' + score])\n",
    "                                    var_score_test = np.var(cv_results['test_' + score])\n",
    "                                    avg_score_train = np.mean(cv_results['train_' + score])\n",
    "                                    var_score_train = np.var(cv_results['train_' + score])\n",
    "\n",
    "                                    if(best_avg_scores[score][0] is None or avg_score_test > best_avg_scores[score][0]):\n",
    "                                        best_avg_scores[score] = [avg_score_test, var_score_test, avg_score_train, var_score_train, b, bf, n_estimator, max_sample, kernel, c]\n",
    "\n",
    "\n",
    "        for score in scores: \n",
    "            \n",
    "            print(tab * 3 + str(score))\n",
    "            print(tab * 4 + f\"CV score: {best_avg_scores[score][0]} using:\" + ','.join([str(p) for p in best_avg_scores[score][4:]]))\n",
    "            print(tab * 5 + f\"train score: {best_avg_scores[score][2]} with variance: {best_avg_scores[score][3]}\")\n",
    "            print(tab * 5 + f\"test  score: {best_avg_scores[score][0]} with variance: {best_avg_scores[score][1]}\")\n",
    "\n",
    "            svc = SVC(kernel = best_avg_scores[score][8], C = best_avg_scores[score][9], max_iter = 200, class_weight = 'balanced', random_state = randomstate)\n",
    "            bc = BaggingClassifier(base_estimator = svc, bootstrap = best_avg_scores[score][4], bootstrap_features = best_avg_scores[score][5], n_estimators = best_avg_scores[score][6], max_samples = best_avg_scores[score][7], n_jobs = jobs)\n",
    "            \n",
    "            bc.fit(X_train, y_train)            \n",
    "            y_train_pred, y_test_pred = bc.predict(X_train), bc.predict(X_test)                          \n",
    "            rmse_train, rmse_test = math.sqrt(mean_squared_error(y_train, y_train_pred)), math.sqrt(mean_squared_error(y_test, y_test_pred))                    \n",
    "            log_loss_train, log_loss_test = log_loss(y_train, y_train_pred), log_loss(y_test, y_test_pred)        \n",
    "\n",
    "            score_train, score_test = get_scorer(score)(bc, X_train, y_train), get_scorer(score)(bc, X_test, y_test)\n",
    "            \n",
    "            print(tab * 4 + f\"Refitted train score: {score_train},  RMSE: {rmse_train}, Log-Loss:{log_loss_train}\")\n",
    "            print(tab * 4 + f\"Refitted test  score: {score_test},  RMSE: {rmse_test}, Log-Loss:{log_loss_test}\")            \n",
    "            \n",
    "            n = len(results)\n",
    "            results.at[n, 'score'] = score\n",
    "            results.at[n, 'test score'] = best_avg_scores[score][0]\n",
    "            results.at[n, 'train score'] = best_avg_scores[score][2]\n",
    "            results.at[n, 'test variance'] = best_avg_scores[score][1]\n",
    "            results.at[n, 'train variance'] = best_avg_scores[score][3]\n",
    "            results.at[n, 'test rmse'] = rmse_test\n",
    "            results.at[n, 'train rmse'] = rmse_train\n",
    "            results.at[n, 'test log_loss'] = log_loss_test\n",
    "            results.at[n, 'train log_loss'] = log_loss_train\n",
    "            results.at[n, 'test size'] = testsize\n",
    "            results.at[n, 'random state'] = randomstate\n",
    "            results.at[n, 'estimator'] = \"Smote/Bagging/SVC\"\n",
    "            results.at[n, 'estimator params'] = ','.join([str(p) for p in best_avg_scores[score][4:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "945c51ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "      <th>test score</th>\n",
       "      <th>train score</th>\n",
       "      <th>test variance</th>\n",
       "      <th>train variance</th>\n",
       "      <th>test rmse</th>\n",
       "      <th>train rmse</th>\n",
       "      <th>test log_loss</th>\n",
       "      <th>train log_loss</th>\n",
       "      <th>test size</th>\n",
       "      <th>random state</th>\n",
       "      <th>estimator</th>\n",
       "      <th>estimator params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.954138</td>\n",
       "      <td>0.954085</td>\n",
       "      <td>0.00113026</td>\n",
       "      <td>9.19026e-05</td>\n",
       "      <td>0.214834</td>\n",
       "      <td>0.225877</td>\n",
       "      <td>1.5941</td>\n",
       "      <td>1.76219</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1250</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>True,True,20,1.0,rbf,1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>332</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.982653</td>\n",
       "      <td>0.988273</td>\n",
       "      <td>9.85351e-05</td>\n",
       "      <td>5.46239e-06</td>\n",
       "      <td>0.214834</td>\n",
       "      <td>0.098773</td>\n",
       "      <td>1.59411</td>\n",
       "      <td>0.336964</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>False,False,2,1.0,rbf,1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.982927</td>\n",
       "      <td>0.987195</td>\n",
       "      <td>3.5693e-05</td>\n",
       "      <td>1.26413e-05</td>\n",
       "      <td>0.27735</td>\n",
       "      <td>0.110432</td>\n",
       "      <td>2.65684</td>\n",
       "      <td>0.421205</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1850</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>False,True,20,0.8,rbf,1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>f1</td>\n",
       "      <td>0.956388</td>\n",
       "      <td>0.960992</td>\n",
       "      <td>0.000886954</td>\n",
       "      <td>9.50902e-05</td>\n",
       "      <td>0.124035</td>\n",
       "      <td>0.204124</td>\n",
       "      <td>0.531366</td>\n",
       "      <td>1.43912</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>True,False,10,1.0,rbf,1.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>accuracy</td>\n",
       "      <td>0.958442</td>\n",
       "      <td>0.95313</td>\n",
       "      <td>0.000634171</td>\n",
       "      <td>4.01393e-05</td>\n",
       "      <td>0.175412</td>\n",
       "      <td>0.210406</td>\n",
       "      <td>1.06273</td>\n",
       "      <td>1.52906</td>\n",
       "      <td>0.2</td>\n",
       "      <td>2050</td>\n",
       "      <td>Smote/Bagging/SVC</td>\n",
       "      <td>True,False,2,0.8,linear,1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        score test score train score test variance train variance test rmse  \\\n",
       "331  accuracy   0.954138    0.954085    0.00113026    9.19026e-05  0.214834   \n",
       "332        f1   0.982653    0.988273   9.85351e-05    5.46239e-06  0.214834   \n",
       "333  accuracy   0.982927    0.987195    3.5693e-05    1.26413e-05   0.27735   \n",
       "334        f1   0.956388    0.960992   0.000886954    9.50902e-05  0.124035   \n",
       "335  accuracy   0.958442     0.95313   0.000634171    4.01393e-05  0.175412   \n",
       "\n",
       "    train rmse test log_loss train log_loss test size random state  \\\n",
       "331   0.225877        1.5941        1.76219       0.2         1250   \n",
       "332   0.098773       1.59411       0.336964       0.2         1850   \n",
       "333   0.110432       2.65684       0.421205       0.2         1850   \n",
       "334   0.204124      0.531366        1.43912       0.2         2050   \n",
       "335   0.210406       1.06273        1.52906       0.2         2050   \n",
       "\n",
       "             estimator             estimator params  \n",
       "331  Smote/Bagging/SVC     True,True,20,1.0,rbf,1.5  \n",
       "332  Smote/Bagging/SVC    False,False,2,1.0,rbf,1.5  \n",
       "333  Smote/Bagging/SVC    False,True,20,0.8,rbf,1.5  \n",
       "334  Smote/Bagging/SVC    True,False,10,1.0,rbf,1.5  \n",
       "335  Smote/Bagging/SVC  True,False,2,0.8,linear,1.5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "53c1a3f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "results.to_csv(path + \"classification-results-3-shrink-50.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "classification-7 (17.6.22).ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
